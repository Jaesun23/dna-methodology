# DNA Methodology 상세 문서

> **목적**: 00_CORE_METHODOLOGY.md의 각 Part를 상세하게 풀어쓴 실행 가이드
> **용도**: 실제 작업 시 참조, Stage별 가이드 작성의 기준
> **작성일**: 2025-12-02

## 목차

### Part 1: AI 협업의 문제와 해결

#### 		1.1 Context Rot (문맥 부패) - 핵심 문제

#### 		1.2 AI의 6가지 문제점

### Part 2: DNA 방법론 핵심 

#### 		2.1 DNA 4대 핵심 원칙

#### 		2.2 핵심 1: "부분으로 전체를 완성"

#### 		2.3 핵심 2: "환경으로 제어"

#### 		2.4 추적성 메커니즘: Stage 간 연결

### Part 3: Stage 1-2 분류와 조사

#### 		3.1 Stage 1: 패밀리 분류

#### 		3.2 Stage 2: 환경 제약 조사

### Part 4: Stage 3 결정 문서화 - ADR 

#### 		4.1 ADR의 역할과 위치

#### 		4.2 5대 ADR 카테고리

### Part 5: Stage 4-6 Bridge - 환경 구축

#### 		5.1 Bridge의 의미

#### 		5.2 Stage 4: DNA 시스템 청사진

#### 		5.3 Stage 5: DNA 시스템 구현

#### 		5.4 Stage 6: Project Standards

### Part 6: Stage 7-9 Blueprint → 구현

#### 		6.1 Stage 7: Project Blueprint

#### 		6.2 Stage 8: Task Breakdown

#### 		6.3 Stage 9: Checklist + 구현

### Part 7: AI 협업 기법

#### 		7.1 인지 글쓰기 이론 기반

#### 		7.2 Skeleton-of-Thought (SoT) - 구조 우선

#### 		7.3 Chain of Density (CoD) - 정보 밀도 증가

#### 		7.4 Tree of Thoughts (ToT) - 대안 탐색

#### 		7.5 RDoLT - 난이도별 분해

#### 		7.6 Stage별 기법 적용 요약

---

## Part 1: AI 협업의 문제와 해결

### 1.1 Context Rot (문맥 부패) - 핵심 문제

#### 정의
대화가 길어질수록 초기에 설정한 원칙, 규칙, 컨텍스트의 영향력이 점진적으로 약화되는 현상.

#### 발생 메커니즘

```
세션 시작
├─ 원칙 A 설정 (영향력 100%)
├─ 작업 1 진행
├─ 작업 2 진행
├─ ... (컨텍스트 누적)
├─ 작업 N 진행
└─ 원칙 A의 영향력 → 30% 이하로 감소

원인:
1. Transformer 모델의 Attention 메커니즘
   - 최근 토큰에 더 높은 가중치
   - 초기 토큰의 영향력 감소

2. 컨텍스트 윈도우 한계
   - 물리적 토큰 제한
   - 오래된 내용 truncation

3. 정보 희석
   - 새로운 정보가 추가될수록
   - 기존 정보의 상대적 비중 감소
```

#### 증상 (실제 경험 기반)

| 증상 | 설명 | 실제 사례 |
|------|------|----------|
| **최신성 편향** | 최근 대화 내용에 과도하게 집중 | "방금 말한 것만 기억하고 처음 합의한 건 무시" |
| **Lost in the Middle** | 중간에 언급된 내용을 놓침 | "10개 규칙 중 3-7번을 자주 빠뜨림" |
| **환각 가속화** | 컨텍스트 혼란 → 없는 사실 생성 | "이전에 합의했다고 착각하고 임의로 진행" |
| **원칙 망각** | 처음 합의한 규칙을 점점 무시 | "타입 안전성 강조했는데 any 남발" |

#### 해결 전략: 정적/동적 컨텍스트 분리

```
┌─────────────────────────────────────────┐
│ 정적 컨텍스트 (불변)                      │
├─────────────────────────────────────────┤
│ - 아키텍처 원칙                          │
│ - DNA 시스템 규칙                        │
│ - 품질 기준 (Lint 0, Type 0)            │
│ - 프로젝트 표준                          │
│                                         │
│ → 매 세션 시작 시 주입                   │
│ → 절대 변경하지 않음                     │
│ → 파일로 관리 (PROJECT_STANDARDS.md)    │
└─────────────────────────────────────────┘
              ↓ 분리
┌─────────────────────────────────────────┐
│ 동적 컨텍스트 (가변)                      │
├─────────────────────────────────────────┤
│ - 현재 작업 상태                         │
│ - 진행 상황                              │
│ - 이전 세션 결과물                       │
│ - 현재 세션 목표                         │
│                                         │
│ → 세션마다 갱신                          │
│ → 필요한 부분만 로드                     │
│ → JSON으로 상태 관리                     │
└─────────────────────────────────────────┘
```

---

### 1.2 AI의 6가지 문제점

#### 문제 1: Context 한계

```
현상:
- 일정 토큰 수를 넘으면 앞선 내용 망각
- 현재 작업이 전체 어디에 위치하는지 파악 불가
- 많은 정보를 제공해도 "읽었다"고 하지만 실제로는 반영 안 됨

실제 사례:
"500줄짜리 Blueprint를 제공했는데, 
 뒷부분 구현할 때 앞부분 규칙을 완전히 무시함"

해결:
├─ 단위작업 분할 (80-90K 토큰 안전 범위로)
├─ 현재 작업에 필요한 정보만 제공
└─ 전체 맥락은 요약으로 제공
```

#### 문제 2: 회피

```
현상:
- 너무 많은 정보를 대하면 모른 척 하거나 적당히 하다가 멈춤
- 긍정표현 규칙이 많으면: 그냥 좋은 말로 여기고 넘김
- 부정표현 규칙이 많으면: 부담스러워서 포기하고 싶다고 함

실제 사례:
"20개 규칙을 DO/DON'T로 정리해서 줬더니
 '네, 이해했습니다' 하고는 절반도 안 지킴"

해결:
├─ 최소 정보 제공 (현재 작업에 필수적인 것만)
├─ 환경으로 강제 (규칙 대신 pre-commit hook)
└─ 체크리스트로 검증 (자가 점검)
```

#### 문제 3: 자기 과신

```
현상:
- Context 한계가 있다는 것을 인지하지 못함
- 학습 데이터가 최신이 아니라는 걸 모름
- "차근차근 정리하면서" 하자고 해도 "모두 할 수 있다"고 자신감

실제 사례:
"TypeScript 타입 사용 주의하라고 했는데
 '할 수 있습니다!' 하고는 결국 프로젝트 폐기"

해결:
├─ 명확한 범위 제한 ("이 파일만", "이 함수만")
├─ 단계별 확인 (중간 점검 강제)
└─ Context7로 최신 정보 확인 강제
```

#### 문제 4: 불필요하게 과한 작업

```
현상:
- 요청하지 않은 "안정성", "호환성" 작업 추가
- 간단한 수정을 복잡한 리팩토링으로 확대
- 미운영 시스템인데 마이그레이션 전략 수립

실제 사례:
"랜덤값 실험이 필요한데 '안정성'을 이유로 고정값 하드코딩
 → 실패도 실험의 중요한 결과인데!!"

해결:
├─ 목표만 명확히 ("실험용", "프로토타입", "프로덕션")
├─ 범위 벗어나면 "STOP" 명시
└─ "요청하지 않은 작업은 하지 마세요" 명시
```

#### 문제 5: 할루시네이션

```
현상:
- 여러 기능 조사 → 구현 완료 → 그때서야 안 되는 걸 알게 됨
- "사실확인 안 된 사항 사용 금지" 경고해도
- 없는 사실 언급하거나 동의 없이 임의 추정

실제 사례:
"라이브러리 X의 Y 기능을 사용하면 된다고 해서 구현했는데,
 실제로 그 기능은 존재하지 않았음"

해결:
├─ Context7로 공식 문서 확인 강제
├─ "확인 안 된 사항은 '확인 필요'로 표시"
└─ 구현 전 기술 검증 단계 필수
```

#### 문제 6: 압박감/강박

```
현상:
- 컨텍스트 한계를 느끼는지 한 번에 다 해버리려고 함
- 애매모호한 질문 → 잘 대답해야 한다는 생각 → 할루시네이션
- 불완전해도 "완료"라고 보고

실제 사례:
"10개 파일 수정 요청했더니
 처음 3개는 꼼꼼히, 나머지 7개는 대충 처리"

해결:
├─ 단계별 진행 ("먼저 3개만")
├─ 중간 점검 필수 ("여기까지 확인하고 진행")
└─ 명시적 우선순위 ("1,2,3 순서로, 나머지는 다음 세션")
```

---

### 1.3 AI가 최고 성과를 낼 때

```
조건 1: 규모가 크지 않아 전체를 한 번에 계획해서 진행 가능
────────────────────────────────────────────────────────
- 80-90K 토큰 범위 내에서 완료 가능한 작업
- 명확한 시작점과 종료점
- 중간에 외부 의존성 없음

조건 2: 여러 선택지에서 논리적 흐름/근거에 따른 판단 가능
────────────────────────────────────────────────────────
- 선택지가 명확하게 제시됨 (A vs B vs C)
- 각 선택의 장단점이 정리됨
- 판단 기준이 주어짐 (성능 우선? 유지보수 우선?)

조건 3: 요청내용과 결과에 대한 명확한 지침 존재
────────────────────────────────────────────────────────
- 입력: "이 파일을 읽어서"
- 처리: "X 패턴으로 리팩토링하고"
- 출력: "새 파일로 저장해라"
- 검증: "Type Check 0 오류여야 함"

조건 4: 매번 새로운 대화지만 기존 작업을 어떤 방식으로든 이해
────────────────────────────────────────────────────────
- 이전 세션 결과물 제공
- 현재 위치 명시 ("Stage 3의 ADR 4-6번 작성 중")
- 전체 맥락 요약 제공
```

### 1.4 해결책의 근거: 인지 글쓰기 이론

```
인지 글쓰기 이론 (Flower & Hayes, 1981):

┌─────────────────────────────────────────┐
│         글쓰기 = 문제 해결               │
├─────────────────────────────────────────┤
│                                         │
│   기획 (Planning)                       │
│      ↓                                  │
│   작성 (Translating)                    │
│      ↓                                  │
│   검토 (Reviewing)                      │
│      ↓                                  │
│   반복...                               │
│                                         │
└─────────────────────────────────────────┘

AI 협업에 적용:

1. 기획 = 청사진/ADR 작성
   - 전체 구조 설계
   - 결정 사항 문서화

2. 작성 = 구현
   - 체크리스트 기반 실행
   - 단위작업 완료

3. 검토 = 검증
   - 정적 분석 (Lint, Type Check)
   - 테스트 실행
   - 품질 Gate 통과

4. 반복 = 점진적 완성
   - 세션 단위로 진행
   - 누적해서 전체 완성
```

---

## Part 2: DNA 방법론 핵심

### 2.1 DNA 4대 핵심 원칙

DNA 방법론의 성공을 결정하는 4가지 핵심 원칙:

```
┌─────────────────────────────────────────────────────────┐
│              DNA 4대 핵심 원칙                           │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  1. 🎯 AI 최적 크기                                     │
│     - 80-90K 토큰 = 100-150줄 체크리스트               │
│     - Stage 8이 변환점 (Human-Driven → AI-Driven)      │
│                                                         │
│  2. 🔄 완전해질 때까지 반복                             │
│     - 3단계 검증 (크기, 의존성, 완전성)                 │
│     - "부족함이 없어질 때까지" 재작업                   │
│                                                         │
│  3. 🧩 기능별 분해 + 연결부 + 조립                      │
│     - 레이어별 분해 ❌ → 기능별 분해 ✅                 │
│     - 인터페이스(연결부) 먼저 정의                      │
│     - Task 완료 = 기능 완료 (E2E)                      │
│                                                         │
│  4. ⏪ 역방향 수정 프로토콜                             │
│     - 하위 Stage에서 상위 Stage 오류 발견 시           │
│     - 6단계 프로토콜로 체계적 수정                     │
│     - Stage 7이 가장 Critical (통합의 정점)            │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

#### 원칙 1: AI 최적 크기

```
왜 80-90K 토큰인가?
────────────────────────────────────────────────────────

AI 컨텍스트 윈도우 (예: 200K 토큰)
├─ 시스템 프롬프트: ~30K 토큰
├─ 대화 히스토리: ~20K 토큰
├─ 참조 문서 (Blueprint, Standards): ~50K 토큰
├─ 체크리스트 + 코드: ~20K 토큰
└─ 응답 생성 여유: ~80K 토큰 ← 실제 작업 공간!

Stage 8이 변환점인 이유:
────────────────────────────────────────────────────────
Stage 1-7: Human-Driven (인간 중심)
├─ 문서 크기 제한 없음
├─ 인간의 이해와 의사결정 중심
└─ 컨텍스트 = 인간의 기억력

Stage 8-9: AI-Driven (AI 중심)
├─ AI 컨텍스트 한계 고려 필수!
├─ 80-90K 토큰 내에서 완료 가능해야
└─ 체크리스트 100-150줄 범위
```

#### 원칙 2: 완전해질 때까지 반복

```
3단계 검증 프로토콜:
────────────────────────────────────────────────────────

검증 1: 크기 (Size Check)
├─ 체크리스트 예상 줄 수: 80-180줄?
├─ 예상 시간: 2-4시간?
├─ 생성 파일 수: 1-4개?
└─ 실패 시 → 분할 또는 합치기

검증 2: 의존성 (Dependency Check)
├─ 선행 Task 명확히 정의?
├─ 순환 의존성 없음?
├─ 병렬 실행 가능 Task 식별?
└─ 실패 시 → 의존성 재설계

검증 3: 완전성 (Completeness Check)
├─ 목표: 한 문장으로 명확?
├─ 입력/출력: 모두 명시?
├─ 완료 조건: 측정 가능? (Type 0, Lint 0)
├─ 테스트: 구체적 케이스 3개 이상?
└─ 실패 시 → Task 상세 보완

모든 검증 통과 → Stage 9로 전달 ✅
```

#### 원칙 3: 기능별 분해 + 연결부 + 조립

```
레이어별 분해 vs 기능별 분해:
────────────────────────────────────────────────────────

❌ 레이어별 분해 (Anti-pattern):
Task 001: 모든 엔티티 (Domain Layer)
Task 002: 모든 리포지토리 (Infrastructure)
Task 003: 모든 서비스 (Application)
Task 004: 모든 API (Presentation)

문제: Task 001 완료해도 "작동하는 기능" 없음!

✅ 기능별 분해 (Best Practice):
Task 001: User 기능 (Entity→Repo→Service→API)
Task 002: Order 생성 기능 (E2E)
Task 003: Order 조회 기능 (E2E)

장점: Task 001 완료 = User 기능 작동!

연결부 (Interface) 먼저 정의:
────────────────────────────────────────────────────────
Task 000: 인터페이스 정의
├─ IUserRepository
├─ IOrderRepository
├─ IUserService
└─ IOrderService

이후 Task는 인터페이스 구현 + E2E 작동!
```

#### 원칙 4: 역방향 수정 프로토콜

```
하위 Stage에서 상위 Stage 오류 발견 시:
────────────────────────────────────────────────────────

6단계 프로토콜:

Step 1: 오류 발견 및 문서화
Step 2: 영향 범위 파악 (가장 중요!)
Step 3: 해당 Stage로 이동 → 수정
Step 4: 중간 Stage 전파
Step 5: 현재 Stage 재진행
Step 6: 재진행 결과 검증

Stage 7이 가장 Critical:
────────────────────────────────────────────────────────
├─ Stage 1-6의 모든 결과물이 여기서 통합
├─ 오류 미발견 시 → Stage 8-9 전체 재작업
├─ 오류 수정 시 → Blueprint만 수정 (2-3시간)
└─ 비용 차이: 10배+

추적성:
────────────────────────────────────────────────────────
수정 이력 파일: docs/revision_log.md
각 수정마다 기록: 발견 Stage, 영향 범위, 수정 내용
```

---

### 2.2 핵심 1: "부분으로 전체를 완성"

#### 레고블럭 전략의 이론적 기반

```
Kent Beck의 Augmented Coding (2024):

"AI는 200K 컨텍스트 내에서 완전한 작업을 수행할 때 최고 성과"

DNA 방법론 적용:
├─ Task = 레고블럭 (독립 테스트 가능)
├─ 각 블럭이 완벽하면 전체가 완벽
└─ 블럭 간 인터페이스만 명확하면 됨
```

#### 단위작업 분할의 4가지 질문

**Q1: 컨텍스트 한계를 고려했는가?**

```
💡 핵심 원칙: 숫자는 참고일 뿐! 작업을 완전하게 설명하는 게 우선

에이전트 컨텍스트 기준 (200K, Compact 없음):
├─ 안전 범위: 80-90K 토큰
├─ 체크리스트: 100-150줄 범위 (120줄 내외 권장)
├─ ADR: 세션당 3개 이하
├─ Task: 세션당 1개 (복잡) ~ 3개 (단순)

컨텍스트 계산 근거 (에이전트 기준):
├─ Base (시스템 + 에이전트 정의): ~41K
├─ 읽기 (체크리스트 + 참조문서): ~7.5K
├─ 쓰기 (생각 정리 + 코드 작성): ~22K
├─ 실행/디버그 (테스트 + 수정): ~15K
└─ 총합: ~85.5K (120줄 체크리스트 기준)

⚠️ 중요 - AI 모델별 차이:
├─ 일부 AI: Compact 기능으로 긴 작업 가능
├─ 일부 AI: Compact 없음 → 컨텍스트가 hard limit
└─ Task 크기는 에이전트 기준으로 계산!

컨텍스트 안전 범위:
├─ 80K: 안정적 ✅ (권장)
├─ 90K: 빡빡함 ⚠️ (가능하지만 여유 부족)
├─ 100K+: 위험 ❌ (급히 종료 가능성)
└─ 180K+: 매우 위험 💥 (급히 종료 후 "완료" 보고)
```

**Q2: 의미있는 산출물을 생산하는가?**

```
"의미있는" 기준:
├─ 독립적으로 테스트/검증 가능
├─ 다른 작업 없이도 가치 있음
├─ 명확한 완료 조건 존재
└─ 롤백 가능 (실패해도 다른 부분 영향 없음)

좋은 예:
✅ "User 엔티티 생성 + 테스트" → 독립 검증 가능
✅ "로그인 API 구현 + 테스트" → 독립 실행 가능

나쁜 예:
❌ "User 엔티티 절반 작성" → 검증 불가
❌ "전체 인증 시스템 구현" → 너무 큼
```

**Q3: 일관성을 유지하는가?**

```
일관성 유지 방법:
├─ 동일한 템플릿 사용 (ADR, 체크리스트)
├─ 동일한 코딩 패턴 (Repository, Service)
├─ 동일한 네이밍 컨벤션
├─ 동일한 품질 기준 (Lint 0, Type 0)
└─ 동일한 검증 절차

구현:
- PROJECT_STANDARDS.md → 매 세션 주입
- pre-commit hooks → 자동 강제
- 템플릿 파일 → 복사해서 사용
```

**Q4: 누락이 없는가?**

```
누락 방지 방법:
├─ 전체 목록 먼저 작성 (Blueprint)
├─ 체크리스트로 관리
├─ 완료/미완료 상태 추적
└─ 다음 세션 가이드 제공

추적 방법:
- task_status.json (상태 관리)
- 각 문서의 "다음 작업" 섹션
- Blueprint의 완료 체크박스
```

---

### 2.3 핵심 2: "환경으로 제어"

#### 왜 문서화된 규칙이 실패하는가

```
실패 패턴:

1. 규칙 문서 제공 (20개 DO/DON'T)
      ↓
2. AI: "네, 이해했습니다"
      ↓
3. 구현 시작
      ↓
4. 규칙 50% 이상 위반
      ↓
5. 수정 요청
      ↓
6. 일부 수정, 새로운 위반 발생
      ↓
7. 무한 반복... 또는 포기

원인:
├─ AI는 규칙을 "참조"하지 "강제"하지 않음
├─ 긍정 표현 → "좋은 조언" 정도로 인식
├─ 부정 표현 → 부담감 → 회피
└─ 많은 규칙 → 우선순위 혼란
```

#### 환경 구축의 원리

```
"조심해라" (X) → "못하게 막는다" (O)

┌─────────────────────────────────────────────────────┐
│ 규칙: "print() 사용 금지"                            │
├─────────────────────────────────────────────────────┤
│ ❌ 문서: "print() 대신 logger를 사용하세요"          │
│    → AI가 읽고도 print() 사용                       │
│                                                     │
│ ✅ 환경:                                            │
│    1. src/core/logging/ 제공 (표준 로거)            │
│    2. pre-commit hook: print() 감지 → 커밋 차단    │
│    3. Lint 규칙: print 금지                         │
│    → 물리적으로 print()가 들어간 코드 커밋 불가     │
└─────────────────────────────────────────────────────┘
```

#### DNA 시스템 = 환경 구축의 구체화

```
DNA 11개 시스템 = 프로젝트 전체에 적용되는 "환경"

각 시스템의 역할:
├─ 표준 도구 제공 (바퀴 재발명 방지)
├─ 사용 패턴 강제 (일관성 확보)
├─ 자동 검증 (품질 보장)
└─ 위반 시 차단 (강제력)

예시 - Logging 시스템:
┌─────────────────────────────────────────┐
│ src/core/logging/                       │
│ ├─ logger.* (표준 로깅 래퍼)            │
│ ├─ config.* (로그 레벨, 포맷)          │
│ └─ handlers.* (파일, 콘솔, JSON)       │
├─────────────────────────────────────────┤
│ 사용 강제:                              │
│ - import logger from core.logging      │
│ - logger.info(), logger.error()        │
│ - print() → Lint 오류                  │
├─────────────────────────────────────────┤
│ 자동 제공:                              │
│ - trace_id (분산 추적)                 │
│ - 구조화된 JSON 로그                   │
│ - 로그 레벨별 필터링                   │
└─────────────────────────────────────────┘
```

---

### 2.4 추적성 메커니즘: Stage 간 연결

#### 왜 추적성이 필요한가

```
문제:
├─ Stage 3에서 결정한 사항이 Stage 7에서 무시됨
├─ Stage 6 표준이 Stage 9 체크리스트에 반영 안 됨
├─ 하위 Stage에서 문제 발견 → 상위 Stage 수정 필요
└─ 어디서 뭘 바꿔야 하는지 추적 불가

해결: 명시적 참조 체계
```

#### Stage 간 참조 형식

```
참조 형식: [문서ID] Ln [라인번호] 또는 Section [섹션명]

예시 흐름:

Stage 6 (PROJECT_STANDARDS.md):
┌─────────────────────────────────────────┐
│ ## 6.3 Database Standards (Ln 45-60)   │
│                                         │
│ - 모든 테이블 PK는 UUIDv7 사용          │
│ - created_at, updated_at 필수          │
│ - soft delete 사용 (deleted_at)        │
└─────────────────────────────────────────┘
         ↓ 참조
Stage 7 (07B-01_blueprint.md):
┌─────────────────────────────────────────┐
│ ## User Entity                          │
│ Ref: PROJECT_STANDARDS.md Ln 45-60     │
│                                         │
│ - id: UUIDv7 (PK)                      │
│ - created_at: datetime                 │
│ - updated_at: datetime                 │
│ - deleted_at: datetime (nullable)      │
└─────────────────────────────────────────┘
         ↓ 참조
Stage 9 (09L-001_user_entity.md):
┌─────────────────────────────────────────┐
│ ## Step 2: 테스트 작성                  │
│ Ref: 07B-01 Section "User Entity"      │
│                                         │
│ 검증 항목:                              │
│ - [ ] id가 UUIDv7 형식인가?            │
│ - [ ] created_at 자동 설정되는가?      │
│ - [ ] soft delete 동작하는가?          │
└─────────────────────────────────────────┘
```

#### 핫픽스 루프 (양방향 피드백)

```
정방향 (Top-Down):
Stage 3 → Stage 6 → Stage 7 → Stage 9 → 구현

역방향 (Bottom-Up) - 문제 발견 시:

구현 중 문제 발견
      ↓
"UUIDv7이 PostgreSQL 14에서 네이티브 지원 안 됨"
      ↓
Stage 9 체크리스트에 메모
      ↓
Stage 7 Blueprint 수정 요청
      ↓
Stage 6 Standards 재검토
      ↓
Stage 3 ADR 수정 (ADR-007: UUID 전략 변경)
      ↓
변경 사항 하향 전파
      ↓
Stage 5-6 업데이트 → Stage 7 업데이트 → Stage 9 업데이트

핫픽스 문서화:
┌─────────────────────────────────────────┐
│ ## Hotfix Log                           │
│                                         │
│ HF-001 (2024-01-15):                   │
│ - 원인: PostgreSQL 14 UUIDv7 미지원    │
│ - 영향: ADR-007, STANDARDS Ln 45-60    │
│ - 해결: UUID v4 + 별도 timestamp 컬럼  │
│ - 적용: Stage 6, 7, 9 문서 수정 완료   │
└─────────────────────────────────────────┘
```

---

## Part 3: Stage 1-2 분류와 조사

### 3.1 Stage 1: 패밀리 분류

#### 목표
시스템의 본질적 특성을 파악하여 7가지 패밀리 중 하나로 분류

#### 10가지 ADQ (Architecture-Driving Questions) 상세

**Part 0: 핵심 기능 파악 (ADQ 전 필수)**

```
Q0: "이 시스템은 무엇을 하기 위한 시스템인가?"
────────────────────────────────────────────────────────
목적: 시스템의 존재 이유, 원자적 핵심 기능 정의

핵심 원칙: "구현 방식"이 아닌 "본질적 기능"으로 정의

❌ 잘못된 예:
├─ 수동 거래 (기능 1)
├─ 자동 거래 (기능 2)
└─ 조건 감시 (기능 3)
→ 이건 "구현 방식"의 나열

✅ 올바른 예:
├─ 핵심 기능: 거래 (Trade)
│   ├─ 구현 방식 A: 수동 (사용자 직접)
│   ├─ 구현 방식 B: 자동 (시스템 자동)
│   └─ 구현 방식 C: 조건부 (조건 충족 시)
└─ 비즈니스 목적: 사용자가 원하는 조건에 주식을 매매

질문 체크리스트:
├─ "이 시스템이 없으면 사용자는 무엇을 못하나?"
├─ "한 문장으로 시스템을 설명한다면?"
└─ "가장 중요한 단 하나의 기능은?"

예시:
- 이커머스: "상품 거래" (검색, 장바구니, 결제는 구현 방식)
- 채팅 앱: "메시지 전달" (그룹채팅, 파일공유는 구현 방식)
- 예약 시스템: "일정 예약" (알림, 결제는 구현 방식)
```

**카테고리 A: 비즈니스 가치**

```
Q1: "이 시스템이 1시간 동안 멈추면 어떤 일이 일어나나요?"
────────────────────────────────────────────────────────
목적: 실패의 치명도 판단 (Layer 1 - 실패 영향)

답변 유형:
├─ 치명적 (A): "거래 손실", "인명 피해", "법적 책임"
├─ 심각 (B): "매출 감소", "고객 불만", "경쟁사 이탈"
└─ 경미 (C): "불편함", "지연", "대체 수단 존재"

예시:
- 주식 거래 플랫폼: "1시간 정지 = 수억 원 손실" → A
- 블로그 서비스: "1시간 정지 = 불편하지만 치명적이진 않음" → C
- 병원 예약 시스템: "1시간 정지 = 환자 대기, 심각한 불편" → B

Q2: "고객이 이 시스템에서 가장 중요하게 생각하는 것은?"
────────────────────────────────────────────────────────
목적: 핵심 품질 속성 식별 (Layer 2 - NFR 우선순위)

답변 유형:
├─ 속도: "빨라야 함", "즉시 응답"
├─ 정확성: "틀리면 안 됨", "100% 정확해야"
├─ 가용성: "항상 접속 가능해야", "24/7"
├─ 보안: "절대 유출되면 안 됨"
└─ 비용: "저렴해야 함", "운영비 최소화"

예시:
- 검색 엔진: "속도" (0.1초 내 결과)
- 은행 이체: "정확성" (1원도 틀리면 안 됨)
- 채팅 앱: "가용성" (항상 메시지 전송 가능)
```

**카테고리 B: 사용자/규모**

```
Q3: "사용자가 이 시스템에서 가장 자주 하는 행동 3가지는?"
────────────────────────────────────────────────────────
목적: 핵심 사용자 여정 파악

답변 형식:
1. [행동 1] - 빈도: 일 N회, 소요시간: N초
2. [행동 2] - 빈도: 일 N회, 소요시간: N초
3. [행동 3] - 빈도: 일 N회, 소요시간: N초

예시 (이커머스):
1. 상품 검색 - 일 100회, 1초 이내
2. 상품 상세 보기 - 일 50회, 3초 이내
3. 주문하기 - 일 5회, 30초 이내

Q4: "동시에 이 시스템을 사용하는 사용자는 얼마나 되나요?"
────────────────────────────────────────────────────────
목적: 확장성 요구사항 파악 (Layer 3 - 환경 제약)

답변 유형:
├─ 소규모: 10-100명 동시 접속
├─ 중규모: 100-10,000명 동시 접속
├─ 대규모: 10,000-100,000명 동시 접속
└─ 초대규모: 100,000명+ 동시 접속

추가 질문:
- 피크 시간대는? (출퇴근, 점심, 이벤트)
- 성장 예상치는? (월 N% 증가)
- 지역 분포는? (국내, 글로벌)
```

**카테고리 C: 데이터/의존성**

```
Q5: "이 시스템에서 다루는 데이터 중 가장 민감한 것은?"
────────────────────────────────────────────────────────
목적: 보안 수준 결정

답변 유형:
├─ 극비: 금융 정보, 의료 기록, 생체 정보
├─ 민감: 개인정보, 위치 정보, 연락처
├─ 내부: 비즈니스 데이터, 운영 정보
└─ 공개: 공개 콘텐츠, 통계 정보

규제 연결:
- 금융: 전자금융거래법, PCI-DSS
- 의료: HIPAA, 개인정보보호법
- 일반: GDPR, 개인정보보호법

Q6: "데이터는 어디서 오나요? (원천)"
────────────────────────────────────────────────────────
목적: 통합 복잡도 파악

답변 유형:
├─ 자체 생성: 사용자 입력, 시스템 생성
├─ 외부 API: 증권사 API, 결제 API, 지도 API
├─ 데이터 피드: 실시간 시세, 뉴스 피드
├─ 배치 수집: 일별 정산, 주기적 크롤링
└─ 사용자 업로드: 파일, 이미지, 문서

Q7: "데이터는 얼마나 오래 보관해야 하나요?"
────────────────────────────────────────────────────────
목적: 저장소 설계, 아카이빙 전략

답변 유형:
├─ 실시간: 현재 상태만 (캐시, 세션)
├─ 단기: 7일-30일 (로그, 임시 데이터)
├─ 중기: 1년-5년 (거래 내역, 활동 기록)
├─ 장기: 5년+ (법적 보관, 감사 추적)
└─ 영구: 삭제 불가 (블록체인, 아카이브)
```

**카테고리 D: 운영/환경**

```
Q8: "이 시스템이 연동해야 하는 외부 시스템은?"
────────────────────────────────────────────────────────
목적: 의존성 파악, 장애 전파 범위

답변 형식:
| 시스템 | 연동 방식 | 의존도 | 대체 가능 |
|--------|----------|--------|----------|
| KIS API | REST | 필수 | X |
| Slack | Webhook | 선택 | O (이메일) |

Q9: "시스템은 어디에 배포되나요?"
────────────────────────────────────────────────────────
목적: 인프라 제약 파악

답변 유형:
├─ 클라우드: AWS, GCP, Azure
├─ 온프레미스: 자체 서버, IDC
├─ 하이브리드: 클라우드 + 온프레미스
├─ 엣지: IoT, CDN, 로컬
└─ 제약: 특정 리전, 규제 요건

Q10: "시스템은 얼마나 자주 변경되나요?"
────────────────────────────────────────────────────────
목적: 유지보수 전략, 배포 파이프라인

답변 유형:
├─ 초고빈도: 일 수회 배포 (CI/CD 필수)
├─ 고빈도: 주 1-2회 배포
├─ 중빈도: 월 1-2회 배포
├─ 저빈도: 분기 1회 배포
└─ 극저빈도: 연 1-2회 (안정성 중시)
```

---

#### 7가지 패밀리와 ADQ 매핑

```
10가지 ADQ 답변 → 3-Layer Decision Tree → 패밀리 코드

Layer 1 (Q1 기반): 실패 영향
├─ A: 치명적 (금전/인명/법적)
├─ B: 심각 (비즈니스 영향)
└─ C: 경미 (불편함 수준)

Layer 2 (Q2, Q5, Q6 기반): 데이터 형태
├─ A: 구조화 (정형 데이터, 스키마 고정)
├─ B: 반구조화 (JSON, 유연한 스키마)
└─ C: 비구조화 (스트림, 로그, 자연어)

Layer 3 (Q3, Q4, Q10 기반): 응답 시점
├─ A: 밀리초 (실시간, <100ms)
├─ B: 초 단위 (대화형, <5s)
└─ C: 배치 (분~시간)
```

**7가지 주요 패밀리**:

| 코드 | 패밀리 | 특성 | 대표 사례 |
|------|--------|------|----------|
| **A-A-B** | CRUD/트랜잭션 | 치명적, 구조화, 초 | 주문, 결제, ERP |
| **B-B-B** | 검색/추천 | 점진적, 반구조화, 초 | Elasticsearch, 추천 엔진 |
| **B-C-A** | 실시간 스트리밍 | 점진적, 비구조화, 밀리초 | Netflix, Uber GPS |
| **B-A-C** | 분석/배치 | 점진적, 구조화, 배치 | Snowflake, BI |
| **B-A-A** | 협업/동기화 | 점진적, 구조화, 밀리초 | Google Docs, Figma |
| **A-A-A** | 초고빈도 거래 | 치명적, 구조화, 마이크로초 | HFT, NASDAQ |
| **A-B-A** | 안전-임계 IoT | 치명적, 반구조화, 밀리초 | SCADA, 의료기기 |

#### NFR 프로파일 도출

```
Q2 답변 기반 NFR 우선순위 결정:

예시: 주식 거래 플랫폼

Q2 답변: "빠르고 정확해야 하며, 항상 접속 가능해야 함"
         → 속도, 정확성, 가용성 모두 중요

NFR 프로파일:
┌─────────────────────────────────────────┐
│ 정확성: A (100% 정확, 1원도 틀리면 안됨) │
│ 속도: A (100ms 이내 응답)               │
│ 가용성: A (99.9% uptime)                │
│ 보안: A (금융 데이터)                   │
│ 비용: B (성능이 우선, 비용은 그 다음)    │
└─────────────────────────────────────────┘

프로파일 코드: A-A-A-A-B

충돌 식별:
├─ 정확성 A + 속도 A = 캐싱 전략 신중해야
├─ 가용성 A + 정확성 A = 분산 트랜잭션 필요
└─ → Stage 2에서 충돌 해결 전략 수립
```

#### Stage 1 산출물

```
01C-01_family_classification.md
────────────────────────────────
# 패밀리 분류 결과

## 프로젝트: [프로젝트명]

## 10가지 ADQ 답변
[Q1-Q10 답변 기록]

## 3-Layer 결정
- Layer 1 (실패 영향): A (치명적)
- Layer 2 (데이터 형태): A (구조화)
- Layer 3 (응답 시점): B (초 단위)

## 패밀리 코드: A-A-B (CRUD/트랜잭션)

## NFR 프로파일: A-A-A-A-B
- 정확성: A
- 속도: A
- 가용성: A
- 보안: A
- 비용: B

## 잠재적 충돌
1. 정확성 + 속도: 캐싱 vs 실시간 검증
2. 가용성 + 정확성: 분산 vs 단일 소스

## 다음 단계
→ Stage 2에서 Layer 3 외부 제약 조사
→ 충돌 해결 전략 수립
```

---

### 3.2 Stage 2: 환경 제약 조사

#### 목표
Layer 3 외부 제약 파악, 충돌 패턴 식별, 기술 스택 결정

#### 외부 제약 조사 체크리스트

```
1. API/연동 제약 (Q8 심화)
────────────────────────────────
[ ] 사용할 외부 API 목록
[ ] 각 API의 호출 제한 (rate limit)
[ ] 인증 방식 (OAuth, API Key, 인증서)
[ ] 응답 시간 SLA
[ ] 장애 시 대응 방안

예시 (KIS API):
├─ 호출 제한: 초당 20회
├─ 인증: OAuth 2.0 + 앱키
├─ 시장 시간: 09:00-15:30 (정규)
└─ 장애 대응: 재시도 3회 + 알림

2. 규제/법적 제약
────────────────────────────────
[ ] 적용되는 법규 목록
[ ] 데이터 보관 요건
[ ] 감사 로그 요건
[ ] 암호화 요건
[ ] 지역 제한 (데이터 거주지)

예시 (금융):
├─ 전자금융거래법
├─ 거래 기록 5년 보관
├─ 이상거래 탐지 의무
└─ 국내 서버 필수

3. 인프라 제약 (Q9 심화)
────────────────────────────────
[ ] 클라우드 제공자 제한
[ ] 가용 리전
[ ] 네트워크 대역폭
[ ] 스토리지 용량/비용
[ ] 기존 인프라 연동

4. 시간 제약
────────────────────────────────
[ ] 서비스 운영 시간
[ ] 배치 처리 시간 윈도우
[ ] 유지보수 시간
[ ] 마감 시간 (정산, 리포트)
```

#### 충돌 패턴 식별

```
Stage 1의 NFR 프로파일에서 충돌 식별:

공통 충돌 패턴:

1. 정확성 vs 속도 (CAP Theorem의 C vs A)
────────────────────────────────
상황: 강한 일관성 vs 낮은 지연시간
해결 전략:
├─ 쓰기: 동기식 (정확성)
├─ 읽기: 캐시 + 비동기 (속도)
└─ 중요 작업만 동기, 나머지 비동기

2. 가용성 vs 정확성 (CAP Theorem의 A vs C)
────────────────────────────────
상황: 항상 응답 vs 항상 정확
해결 전략:
├─ 네트워크 정상: 둘 다 만족
├─ 네트워크 장애: 정확성 우선 (금융)
└─ Saga 패턴, Outbox 패턴 검토

3. 성능 vs 비용
────────────────────────────────
상황: 최고 성능 vs 운영비 절감
해결 전략:
├─ 피크 시간: 오토스케일링
├─ 비피크: 최소 인스턴스
└─ 비용 상한선 설정

4. 보안 vs 사용성
────────────────────────────────
상황: 강한 보안 vs 편리한 사용
해결 전략:
├─ 조회: 간단한 인증
├─ 거래: MFA 필수
└─ 위험 기반 인증 (Risk-based Auth)
```

#### 기술 스택 결정 프로세스

```
1. 패밀리 기반 후보군 도출
────────────────────────────────
패밀리: A-A-B (CRUD/트랜잭션)

후보 DB:
├─ PostgreSQL: ACID, JSON 지원, 성숙
├─ MySQL: ACID, 대중적, Aurora 옵션
└─ Oracle: 엔터프라이즈, 비용 높음

후보 프레임워크 (언어별):
├─ Python: FastAPI, Django
├─ TypeScript: NestJS, Express
├─ Java: Spring Boot
└─ Go: Gin, Echo

2. 제약조건 필터링
────────────────────────────────
팀 역량: [팀 주력 언어] → [선택 프레임워크]
비용 제한: 오픈소스 우선 → PostgreSQL
성능 요건: 비동기 필수 → [비동기 지원 프레임워크]

3. 결정 및 근거 문서화
────────────────────────────────
→ Stage 3에서 ADR로 문서화
```

#### Stage 2 산출물

```
02C-01_external_constraints.md
────────────────────────────────
# 외부 제약 조건

## API 제약
[KIS API, 결제 API 등 상세]

## 규제 제약
[법규, 보관 요건 등]

## 인프라 제약
[클라우드, 리전 등]

## 시간 제약
[운영 시간, 배치 윈도우 등]

---

02C-02_conflict_patterns.md
────────────────────────────────
# 충돌 패턴 분석

## 식별된 충돌
1. 정확성 vs 속도
2. 가용성 vs 정확성

## 해결 전략
[각 충돌별 전략]

---

02D-01_tech_stack.md
────────────────────────────────
# 기술 스택 결정

## 결정 사항
- 언어: [선택 언어]
- 프레임워크: [선택 프레임워크]
- DB: PostgreSQL 15
- 캐시: Redis
- 메시징: Kafka

## 선택 근거
[각 기술별 근거]

## 제외된 대안
[검토했으나 제외된 기술과 이유]
```

---

## Part 4: Stage 3 결정 문서화 - ADR

### 4.1 ADR의 역할과 위치

#### ADR이란?

```
ADR = Architecture Decision Record
     아키텍처 결정 기록

목적:
├─ 왜 이 결정을 했는지 기록
├─ 어떤 대안이 있었는지 기록
├─ 나중에 "왜 이렇게 했지?" 질문에 답변
└─ 결정 변경 시 영향 범위 파악

핵심:
"코드는 '무엇'을 보여주지만, ADR은 '왜'를 설명한다"
```

#### ADR vs Design Doc

```
┌─────────────────────────────────────────────────────────┐
│                    Design Doc                           │
│  (상세 분석 문서)                                        │
├─────────────────────────────────────────────────────────┤
│  - 문제 정의                                            │
│  - 여러 대안 상세 분석                                  │
│  - 장단점 비교표                                        │
│  - 프로토타입 결과                                      │
│  - 성능 벤치마크                                        │
│  - 10-50 페이지                                         │
│                                                         │
│  → 복잡한 결정에 사용                                   │
│  → "어머니" 문서                                        │
└─────────────────────────────────────────────────────────┘
                    ↓ 요약
┌─────────────────────────────────────────────────────────┐
│                      ADR                                │
│  (결정 기록)                                            │
├─────────────────────────────────────────────────────────┤
│  - 결정 사항 (1줄)                                      │
│  - 맥락 (왜 필요했나)                                   │
│  - 선택한 대안과 이유                                   │
│  - 결과 (무엇이 바뀌나)                                 │
│  - 1-2 페이지                                           │
│                                                         │
│  → 모든 결정에 사용                                     │
│  → Design Doc의 "결론" 요약                             │
└─────────────────────────────────────────────────────────┘

판단 기준:
├─ 간단한 결정: ADR만 작성
│   예: "로깅은 구조화 로깅 라이브러리 사용"
│
├─ 복잡한 결정: Design Doc → ADR
│   예: "DB 선택 (PostgreSQL vs MySQL vs MongoDB)"
│
└─ 매우 복잡: RFC/KEP → Design Doc → ADR
    예: "마이크로서비스 vs 모놀리식"
```

---

### 4.2 5대 ADR 카테고리

#### 카테고리 1: 외부 제약 ADR

```
정의: 변경할 수 없는 외부 요인에 의한 결정

특징:
├─ 우리가 선택할 수 없음
├─ 반드시 따라야 함
├─ 위반 시 시스템 작동 불가 또는 법적 문제
└─ "왜?"보다 "무엇?"이 중요

예시:
├─ 법규: "금융 거래 기록 5년 보관 (전자금융거래법)"
├─ API 제한: "KIS API 초당 20회 호출 제한"
├─ 시장 시간: "KRX 정규장 09:00-15:30"
└─ 지역 제한: "개인정보 국내 서버 저장 필수"

템플릿:
┌─────────────────────────────────────────────────────────┐
│ ADR-001: KIS API 호출 제한 준수                         │
├─────────────────────────────────────────────────────────┤
│ 상태: 승인됨                                            │
│ 일자: 2024-01-15                                        │
│ 카테고리: 외부 제약                                     │
├─────────────────────────────────────────────────────────┤
│ 맥락:                                                   │
│ KIS API는 초당 20회 호출 제한이 있음.                   │
│ 이를 초과하면 일시적 차단됨.                            │
├─────────────────────────────────────────────────────────┤
│ 결정:                                                   │
│ Rate Limiter를 구현하여 초당 15회로 제한.               │
│ 여유분 5회는 재시도용.                                  │
├─────────────────────────────────────────────────────────┤
│ 결과:                                                   │
│ - 모든 KIS API 호출은 RateLimiter를 거쳐야 함          │
│ - 벌크 요청 시 큐잉 필요                               │
└─────────────────────────────────────────────────────────┘
```

#### 카테고리 2: 충돌 해결 ADR

```
정의: 상충하는 요구사항 간 Trade-off 결정

특징:
├─ 둘 다 중요하지만 둘 다 만족 불가
├─ 하나를 선택하면 다른 하나 희생
├─ "왜 이걸 선택했나?"가 핵심
└─ 나중에 재검토 가능성 있음

예시:
├─ 정확성 vs 속도: "주문 정확성 > 응답 속도"
├─ 일관성 vs 가용성: "CP 선택 (장애 시 거부)"
├─ 보안 vs 편의성: "거래는 MFA, 조회는 단순 인증"
└─ 비용 vs 성능: "피크 시 성능, 비피크 시 비용"

템플릿:
┌─────────────────────────────────────────────────────────┐
│ ADR-002: 정확성 우선 전략                               │
├─────────────────────────────────────────────────────────┤
│ 상태: 승인됨                                            │
│ 일자: 2024-01-15                                        │
│ 카테고리: 충돌 해결                                     │
├─────────────────────────────────────────────────────────┤
│ 맥락:                                                   │
│ 주문 처리에서 정확성(금액 정확)과 속도(빠른 응답)가     │
│ 충돌함. 캐시 사용 시 속도↑ but 정확성 위험.            │
├─────────────────────────────────────────────────────────┤
│ 검토한 대안:                                            │
│ 1. 캐시 사용 + 비동기 검증: 속도↑, 정확성 위험         │
│ 2. 항상 실시간 조회: 정확성↑, 속도↓ (200ms→500ms)     │
│ 3. 하이브리드: 조회는 캐시, 주문은 실시간              │
├─────────────────────────────────────────────────────────┤
│ 결정:                                                   │
│ 대안 3 선택. 주문 관련 데이터는 항상 실시간 조회.      │
│ 시세 조회는 1초 캐시 허용.                              │
├─────────────────────────────────────────────────────────┤
│ 결과:                                                   │
│ - 주문 API: 캐시 사용 금지                              │
│ - 시세 API: Redis 캐시 1초 TTL                          │
│ - 모니터링: 캐시 히트율 + 주문 정확도 추적             │
├─────────────────────────────────────────────────────────┤
│ 재검토 조건:                                            │
│ - 응답 시간이 1초 초과 시                               │
│ - 정확도 문제 발생 시                                   │
└─────────────────────────────────────────────────────────┘
```

#### 카테고리 3: 기술 스택 ADR

```
정의: 여러 기술 대안 중 하나를 선택하는 결정

특징:
├─ 비교 가능한 대안 존재
├─ 정량적 비교 가능 (성능, 비용, 생태계)
├─ Context7 검증 필수
└─ 팀 역량, 생태계 고려

예시:
├─ DB: "PostgreSQL vs MySQL vs MongoDB"
├─ 프레임워크: "[팀 언어]의 프레임워크 비교"
├─ 메시지 큐: "Kafka vs RabbitMQ vs Redis Pub/Sub"
└─ 캐시: "Redis vs Memcached"

템플릿:
┌─────────────────────────────────────────────────────────┐
│ ADR-003: PostgreSQL 선택                                │
├─────────────────────────────────────────────────────────┤
│ 상태: 승인됨                                            │
│ 일자: 2024-01-15                                        │
│ 카테고리: 기술 스택                                     │
├─────────────────────────────────────────────────────────┤
│ 맥락:                                                   │
│ CRUD/트랜잭션 패밀리로, ACID 준수 DB 필요.              │
├─────────────────────────────────────────────────────────┤
│ 검토한 대안:                                            │
│                                                         │
│ | 기준 | PostgreSQL | MySQL | MongoDB |                 │
│ |------|------------|-------|---------|                 │
│ | ACID | ✅ 완전    | ✅    | ⚠️ 제한 |                │
│ | JSON | ✅ JSONB   | ⚠️    | ✅ 네이티브 |            │
│ | 성능 | 복잡쿼리↑  | 단순↑ | 읽기↑   |                │
│ | 비용 | 무료       | 무료  | Atlas$$ |                 │
│ | 팀경험| ✅ 있음   | ✅    | ⚠️ 적음 |                │
├─────────────────────────────────────────────────────────┤
│ 결정:                                                   │
│ PostgreSQL 15 선택.                                     │
│ - ACID 완전 지원                                        │
│ - JSONB로 유연한 스키마 가능                            │
│ - 팀 경험 있음                                          │
├─────────────────────────────────────────────────────────┤
│ 결과:                                                   │
│ - ORM: SQLAlchemy 2.0 (async 지원)                      │
│ - 마이그레이션: Alembic                                 │
│ - 연결: asyncpg (비동기)                                │
└─────────────────────────────────────────────────────────┘
```

#### 카테고리 4: 도메인 기술 ADR

```
정의: 프로젝트 특화 로직/알고리즘 설계 결정

특징:
├─ 외부 라이브러리로 해결 안 됨
├─ 자체 설계/구현 필요
├─ 비즈니스 로직 깊숙이 관련
└─ 성능/정확도가 핵심

예시:
├─ 주문 매칭 알고리즘
├─ 추천 점수 계산 로직
├─ 가격 책정 엔진
└─ 동시성 제어 전략

템플릿:
┌─────────────────────────────────────────────────────────┐
│ ADR-101: 주문 실행 전략                                 │
├─────────────────────────────────────────────────────────┤
│ 상태: 승인됨                                            │
│ 일자: 2024-01-15                                        │
│ 카테고리: 도메인 기술                                   │
├─────────────────────────────────────────────────────────┤
│ 맥락:                                                   │
│ 사용자 주문을 KIS API로 전송하는 전략 필요.             │
│ 부분 체결, 실패, 재시도 처리 필요.                      │
├─────────────────────────────────────────────────────────┤
│ 설계:                                                   │
│ 1. 주문 상태 머신:                                      │
│    CREATED → SUBMITTED → PARTIAL → FILLED/FAILED       │
│                                                         │
│ 2. 재시도 전략:                                         │
│    - 네트워크 오류: 최대 3회, 지수 백오프              │
│    - 비즈니스 오류: 재시도 없음, 사용자 알림           │
│                                                         │
│ 3. 부분 체결:                                           │
│    - 원주문 유지 + 체결 이력 별도 저장                 │
│    - 잔량 추적                                         │
├─────────────────────────────────────────────────────────┤
│ 결과:                                                   │
│ - OrderStateMachine 구현 필요                           │
│ - OrderExecution 서비스 구현 필요                       │
│ - 상태 변경 이벤트 발행 (Kafka)                        │
└─────────────────────────────────────────────────────────┘
```

#### 카테고리 5: DNA 시스템 ADR

```
정의: 프로젝트 공통 인프라/표준 결정

특징:
├─ 전체 프로젝트에 영향
├─ Stage 4-6 (Bridge)에서 구현
├─ 일관성이 핵심
└─ 변경 시 영향 범위 큼

예시:
├─ 로깅 표준: "구조화 로깅 + JSON 포맷"
├─ 에러 처리: "예외 계층 + 에러 코드"
├─ 설정 관리: "타입 안전 설정 + 환경 변수"
└─ 테스트 전략: "테스트 프레임워크 + 95% 커버리지"

템플릿:
┌─────────────────────────────────────────────────────────┐
│ ADR-010: 로깅 표준화                                    │
├─────────────────────────────────────────────────────────┤
│ 상태: 승인됨                                            │
│ 일자: 2024-01-15                                        │
│ 카테고리: DNA 시스템                                    │
├─────────────────────────────────────────────────────────┤
│ 맥락:                                                   │
│ 일관된 로깅으로 디버깅/모니터링 효율화 필요.            │
│ 분산 추적(trace_id) 필수.                               │
├─────────────────────────────────────────────────────────┤
│ 결정:                                                   │
│ - 라이브러리: [언어별 구조화 로깅 도구]                 │
│ - 포맷: JSON (프로덕션), Console (개발)                │
│ - 레벨: DEBUG, INFO, WARNING, ERROR, CRITICAL          │
│ - 컨텍스트: trace_id, user_id, request_id              │
├─────────────────────────────────────────────────────────┤
│ 결과:                                                   │
│ - src/core/logging/ 모듈 구현                          │
│ - print() 사용 금지 (Lint 규칙)                        │
│ - 모든 로그는 logger.info() 등 사용                    │
├─────────────────────────────────────────────────────────┤
│ 강제:                                                   │
│ - pre-commit: print() 감지 차단                        │
│ - Lint: print 금지 규칙 활성화                         │
└─────────────────────────────────────────────────────────┘
```

---

## Part 5: Stage 4-6 Bridge - 환경 구축

### 5.1 Bridge의 의미

#### "Gap이 아니라 Bridge"

```
기존 오해:
├─ Stage 3 (ADR) 완료
├─ ???
├─ ???
├─ ???
└─ Stage 7 (Blueprint) 시작

→ "Stage 4-6은 뭐하는 거지? 그냥 넘어가도 되나?"

Gemini 연구 결과:
┌─────────────────────────────────────────────────────────┐
│ Stage 4-6 = Bridge (다리)                               │
│                                                         │
│ ADR (결정) ──────────────────────→ Blueprint (설계)     │
│             ↑                   ↑                       │
│             │    Stage 4-6     │                       │
│             │                   │                       │
│             └───────────────────┘                       │
│                                                         │
│ 결정을 "실행 가능한 환경"으로 변환하는 단계             │
└─────────────────────────────────────────────────────────┘

비유:
├─ ADR = "서울에서 부산 가기로 결정" (결정)
├─ Bridge = "KTX 티켓 구매, 역 도착" (준비)
└─ Blueprint = "출발역, 환승, 도착역 계획" (상세 계획)
```

#### 4대 구성요소

```
"강제 가능한 환경"의 4대 구성요소:

┌─────────────────────────────────────────────────────────┐
│ 1. 성문화된 결정 (Stage 3)                              │
│    = ADR 문서                                           │
│    = "왜 이렇게 해야 하는지" 근거                       │
│    → 비유: 법률                                         │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│ 2. 재사용 가능한 컴포넌트 (Stage 5)                     │
│    = src/core/ 공통 모듈                                │
│    = "이걸 쓰면 됨" 도구                                │
│    → 비유: 공구                                         │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│ 3. 의무적 규칙 (Stage 6)                                │
│    = PROJECT_STANDARDS.md                               │
│    = "이렇게 해야 함" 명시                              │
│    → 비유: 교통법규                                     │
└─────────────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────┐
│ 4. 자동화된 거버넌스 (Stage 6)                          │
│    = pre-commit, Lint, Type Check, Test                │
│    = "위반하면 막힘" 강제                               │
│    → 비유: 단속 카메라                                  │
└─────────────────────────────────────────────────────────┘
```

#### 핵심 인사이트

```
DNA 시스템 = "환경/플랫폼"
도메인 = "애플리케이션"

관계:
┌─────────────────────────────────────────────────────────┐
│                    도메인 코드                          │
│  (Stage 7-9에서 구현)                                   │
│                                                         │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐                   │
│  │ 주문    │ │ 계좌    │ │ 시세    │  ← 비즈니스 로직  │
│  │ 서비스  │ │ 서비스  │ │ 서비스  │                   │
│  └────┬────┘ └────┬────┘ └────┬────┘                   │
│       │          │          │                          │
│  ═════╪══════════╪══════════╪═══════════════════════   │
│       │          │          │                          │
│  ┌────┴──────────┴──────────┴────┐                     │
│  │        DNA 시스템 (환경)       │                     │
│  │  (Stage 4-6에서 구축)          │                     │
│  │                                │                     │
│  │  logging / config / types     │                     │
│  │  database / cache / messaging │                     │
│  │  testing / monitoring / auth  │                     │
│  │  error handling / api gateway │                     │
│  └────────────────────────────────┘                     │
└─────────────────────────────────────────────────────────┘

핵심:
├─ DNA가 먼저 구축되어야 도메인이 일관되게 구현됨
├─ 도메인은 DNA를 "사용"만 함 (직접 구현 X)
└─ DNA 변경 = 전체 영향 (신중해야)
```

---

### 5.2 Stage 4: DNA 시스템 청사진

#### 목표
DNA 시스템 11개의 설계 문서 작성

#### DNA 11개 시스템 개요

```
┌──────────────────────────────────────────────────────────┐
│                  DNA 11개 시스템                         │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  핵심 인프라 (4개):                                      │
│  ├─ 1. Logging: 구조화된 로깅                           │
│  ├─ 2. Configuration: 타입 안전 설정                    │
│  ├─ 3. Types: 공통 타입 정의                            │
│  └─ 4. Error Handling: 예외 계층 + 에러 코드            │
│                                                          │
│  데이터/통신 (3개):                                      │
│  ├─ 5. Database: ORM + 마이그레이션                     │
│  ├─ 6. Cache: 캐싱 추상화                               │
│  └─ 7. Messaging: 이벤트 발행/구독                      │
│                                                          │
│  품질/보안 (4개):                                        │
│  ├─ 8. Testing: 테스트 인프라                           │
│  ├─ 9. Monitoring: 메트릭 수집                          │
│  ├─ 10. Security: 인증/인가                             │
│  └─ 11. API Gateway: 라우팅/미들웨어                    │
│                                                          │
│  (언어별 구현: docs/manuals/ 참조)                       │
└──────────────────────────────────────────────────────────┘
```

#### 패밀리별 DNA 시스템 선택

```
모든 패밀리 공통 (필수):
├─ Logging
├─ Configuration
├─ Types
├─ Error Handling
└─ Testing

패밀리별 선택:

A-A-B (CRUD/트랜잭션):
├─ Database: ✅ 필수 (ACID)
├─ Cache: ✅ 권장 (읽기 최적화)
├─ Messaging: ⚠️ 선택 (이벤트 발행)
├─ Monitoring: ✅ 권장
├─ Security: ✅ 필수 (금융)
└─ API Gateway: ✅ 필수

B-C-A (실시간 스트리밍):
├─ Database: ⚠️ 선택 (상태 저장)
├─ Cache: ✅ 필수 (버퍼링)
├─ Messaging: ✅ 필수 (Kafka)
├─ Monitoring: ✅ 필수 (지연 모니터링)
├─ Security: ⚠️ 선택
└─ API Gateway: ✅ 필수 (WebSocket)

B-A-A (협업/동기화):
├─ Database: ✅ 필수 (상태 저장)
├─ Cache: ✅ 필수 (로컬 캐시)
├─ Messaging: ✅ 필수 (실시간 동기화)
├─ Monitoring: ✅ 권장
├─ Security: ✅ 필수 (사용자 인증)
└─ API Gateway: ✅ 필수 (WebSocket)
```

#### Stage 4 산출물

```
04B-01_dna_blueprint.md (또는 여러 파트)
────────────────────────────────────────

# DNA 시스템 청사진

## 1. 선택된 DNA 시스템
- 패밀리: A-A-B (CRUD/트랜잭션)
- 필수: Logging, Config, Types, Error, Testing, DB, Security, API
- 선택: Cache, Monitoring
- 제외: Messaging (MVP 이후)

## 2. 각 시스템 설계

### 2.1 Logging 시스템
- 라이브러리: [언어별 구조화 로깅 도구]
- 포맷: JSON (prod), Console (dev)
- 컨텍스트: trace_id, user_id, request_id
- 디렉토리: src/core/logging/

[각 시스템별 상세 설계...]

## 3. 의존성 관계
Logging ← 모든 시스템
Config ← Database, Cache, Messaging
Types ← 모든 시스템
Error ← 모든 시스템

## 4. 구현 순서
1. Types (의존성 없음)
2. Config (Types 의존)
3. Logging (Config 의존)
4. Error (Types, Logging 의존)
5. ...
```

---

### 5.3 Stage 5: DNA 시스템 구현

#### 목표
청사진 기반 src/core/ 공통 모듈 구현

#### 디렉토리 구조

```
(예시: Python 디렉토리 구조 - 언어별 상세: docs/manuals/ 참조)

src/
├── core/                           # DNA 시스템
│   │
│   ├── logging/                    # 1. Logging
│   │   ├── logger.*                # 로깅 래퍼
│   │   ├── config.*                # 로그 레벨, 포맷
│   │   └── handlers.*              # 파일, 콘솔, JSON
│   │
│   ├── config/                     # 2. Configuration
│   │   ├── settings.*              # 타입 안전 설정
│   │   └── validators.*            # 커스텀 검증
│   │
│   ├── types/                      # 3. Types
│   │   ├── base.*                  # 기본 타입 확장
│   │   ├── ids.*                   # ID 타입 (UUID)
│   │   └── common.*                # 공통 타입
│   │
│   ├── errors/                     # 4. Error Handling
│   │   ├── exceptions.*            # 예외 계층
│   │   ├── codes.*                 # 에러 코드
│   │   └── handlers.*              # 전역 핸들러
│   │
│   ├── database/                   # 5. Database
│   │   ├── __init__.py
│   │   ├── session.py              # SQLAlchemy 세션
│   │   ├── base.py                 # Base 모델
│   │   └── mixins.py               # 공통 믹스인
│   │
│   ├── cache/                      # 6. Cache
│   │   ├── __init__.py
│   │   ├── client.py               # Redis 클라이언트
│   │   └── decorators.py           # @cached 데코레이터
│   │
│   └── ...                         # 나머지 시스템
│
├── domain/                         # 도메인 코드 (Stage 7-9)
│   └── ...
│
└── api/                            # API 레이어 (Stage 7-9)
    └── ...
```

#### 구현 원칙

```
1. 표준 라이브러리 우선
────────────────────────────────
❌ 직접 구현:
class MyLogger:
    def log(self, msg):
        print(f"[LOG] {msg}")  # 1679줄...

✅ 표준 라이브러리:
// 언어별 구조화 로깅 도구 사용
// Python: structlog, TypeScript: winston, Java: logback
logger = get_logger()  // 의사코드

2. 인터페이스 추상화
────────────────────────────────
# core/cache/interface.py
class CacheInterface(Protocol):
    async def get(self, key: str) -> Any: ...
    async def set(self, key: str, value: Any, ttl: int) -> None: ...

# core/cache/redis.py
class RedisCache(CacheInterface):
    async def get(self, key: str) -> Any:
        return await self.client.get(key)

# 나중에 Memcached로 교체 가능

3. 설정 주입
────────────────────────────────
# core/config/settings.py
class Settings(BaseSettings):
    redis_url: str = "redis://localhost:6379"
    log_level: str = "INFO"
    
    model_config = SettingsConfigDict(env_file=".env")

# 사용
settings = Settings()
logger.info("Connecting to", redis_url=settings.redis_url)
```

---

### 5.4 Stage 6: Project Standards

#### 목표
DNA 시스템 사용 강제 규칙 + 자동화 설정

#### PROJECT_STANDARDS.md 구조 예시

```
# Project Standards

## 1. 코드 스타일

### 1.1 포맷팅
- 표준 Formatter 사용
- 줄 길이: 80-120자 (언어별 관례)
- 들여쓰기: 언어별 표준

### 1.2 네이밍
- 클래스: PascalCase
- 함수/변수: snake_case 또는 camelCase (언어별)
- 상수: UPPER_SNAKE_CASE
- 비공개: _prefix 또는 private

## 2. DNA 시스템 사용 규칙

### 2.1 Logging (DO/DON'T)
DO:
- from core.logging import logger
- logger.info("message", key=value)

DON'T:
- print() 사용 금지
- logging.getLogger() 직접 사용 금지

### 2.2 Configuration (DO/DON'T)
DO:
- from core.config import settings
- settings.database_url

DON'T:
- os.environ.get() 직접 사용 금지
- 하드코딩된 설정값 금지

### 2.3 Types (DO/DON'T)
DO:
- from core.types import UserId, OrderId
- 모든 함수에 타입 힌트

DON'T:
- Any 타입 사용 금지 (불가피한 경우 주석 필수)
- Dict[str, Any] 대신 TypedDict 사용

### 2.4 Error Handling (DO/DON'T)
DO:
- from core.errors import NotFoundError, ValidationError
- raise NotFoundError(entity="User", id=user_id)

DON'T:
- 일반 Exception raise 금지
- except: pass 금지

## 3. 테스트 규칙

### 3.1 커버리지
- 전체: 95% 이상
- 신규 코드: 100%
- 핵심 로직: 100%

### 3.2 테스트 구조
- tests/unit/: 단위 테스트
- tests/integration/: 통합 테스트
- tests/e2e/: E2E 테스트

## 4. 품질 기준

### 4.1 Zero Tolerance
- Lint: 0 violations
- Type Check: 0 errors
- Test: 0 failures
- Coverage: 95%+

### 4.2 커밋 전 필수
- pre-commit hooks 통과
- 테스트 통과
- 타입 체크 통과
```

#### 자동화 설정

```yaml
# 언어별 설정 파일 (Python: pyproject.toml, TS: eslint.config.js 등)

[Lint 설정]
line-length = 80-120
rules = [코드 스타일, import 정렬, print 금지]

[Type Check 설정]
strict = true
warn_return_any = true

[Test 설정]
coverage = "--cov=src --cov-fail-under=95"

---

# .pre-commit-config.yaml (언어별 도구로 대체)
repos:
  - repo: [Lint 도구 레포지토리]
    rev: [버전]
    hooks:
      - id: lint
        args: [--fix]
      - id: format

  - repo: [Type Check 도구 레포지토리]
    rev: [버전]
    hooks:
      - id: type-check
        additional_dependencies: [필요한 플러그인]

  - repo: local
    hooks:
      - id: test
        name: unit-test
        entry: [테스트 프레임워크] tests/unit -q
        language: system
        pass_filenames: false
        always_run: true

# 언어별 예시:
# Python: ruff, mypy, pytest
# TypeScript: eslint, tsc, jest
# Java: checkstyle, javac, junit
# Go: golint, go vet, go test
```

#### 자동화 성숙도

```
Day 1: 정적 분석
────────────────────────────────
├─ pre-commit 설치
├─ Ruff (린팅 + 포맷팅)
├─ MyPy (타입 체크)
└─ 기본 테스트 실행

Week 2: 아키텍처 검증
────────────────────────────────
├─ import-linter 설정
│   - core → domain 금지
│   - domain → api 금지
├─ 아키텍처 테스트 추가
└─ 의존성 방향 검증

Month 1+: 고급 거버넌스
────────────────────────────────
├─ Fitness Functions
│   - 응답 시간 < 200ms
│   - 커버리지 > 95%
├─ Policy-as-Code
│   - 보안 정책 자동 검증
└─ 메트릭 기반 알림
```

---

## Part 6: Stage 7-9 Blueprint → 구현

### 6.1 Stage 7: Project Blueprint

#### 목표
도메인 ADR 기반 완전히 상세한 청사진 작성

#### Blueprint vs ADR

```
ADR (Stage 3):
├─ "무엇을" 결정했는지
├─ "왜" 그렇게 결정했는지
└─ 개별 결정 단위

Blueprint (Stage 7):
├─ "어떻게" 구현할 것인지
├─ 모든 ADR을 통합한 전체 그림
├─ 구체적인 구현 명세
└─ 코드 작성 직전 단계

관계:
ADR-001 ─┐
ADR-002 ─┼──→ Blueprint
ADR-003 ─┘
```

#### Blueprint 필수 섹션

```
07B-01_project_blueprint.md
────────────────────────────

# Project Blueprint

## 1. 시스템 개요
- 목적
- 범위
- 핵심 기능
- 참조: 01C-01 패밀리 분류

## 2. 아키텍처 구조
- 레이어 다이어그램
- 컴포넌트 다이어그램
- 데이터 흐름
- 참조: ADR-004 하이브리드 아키텍처

## 3. 도메인 모델
### 3.1 엔티티
- User: id, email, created_at, ...
- Order: id, user_id, status, ...
- 참조: PROJECT_STANDARDS.md Ln 45-60 (DB 규칙)

### 3.2 값 객체
- Money: amount, currency
- OrderStatus: enum

### 3.3 집계 (Aggregate)
- Order (루트): Order + OrderItems

## 4. API 설계
### 4.1 엔드포인트
- POST /orders: 주문 생성
- GET /orders/{id}: 주문 조회
- 참조: ADR-101 API 버저닝

### 4.2 요청/응답 스키마
- CreateOrderRequest: {...}
- OrderResponse: {...}

## 5. 데이터베이스 설계
### 5.1 테이블
- users: id(PK), email, ...
- orders: id(PK), user_id(FK), ...
- 참조: ADR-003 PostgreSQL

### 5.2 인덱스
- orders_user_id_idx
- orders_created_at_idx

## 6. 외부 연동
### 6.1 KIS API
- 인증 흐름
- 주문 API 호출
- 참조: ADR-001 KIS API 제한

## 7. 에러 처리
- 에러 코드 체계
- 재시도 전략
- 참조: ADR-010 에러 표준

## 8. 보안
- 인증: JWT
- 인가: RBAC
- 참조: ADR-011 보안

## 9. 다음 단계
→ Stage 8 Task Breakdown
```

#### SoT (Skeleton-of-Thought) 적용

```
Blueprint 작성에 SoT 적용:

Step 1: 목차 (뼈대) 생성
────────────────────────────────
1. 시스템 개요
2. 아키텍처 구조
3. 도메인 모델
4. API 설계
5. 데이터베이스 설계
6. 외부 연동
7. 에러 처리
8. 보안
9. 다음 단계

Step 2: 각 섹션 병렬 확장
────────────────────────────────
세션 1: 1-3 섹션 작성
세션 2: 4-6 섹션 작성
세션 3: 7-9 섹션 작성

Step 3: 전체 일관성 검토
────────────────────────────────
- ADR 참조 확인
- PROJECT_STANDARDS 참조 확인
- 섹션 간 모순 확인
```

---

### 6.2 Stage 8: Task Breakdown

#### 목표
AI가 한 세션에 완료할 수 있는 크기로 작업 분해

#### 분해 기준

```
좋은 Task의 조건:

1. 크기 (참고 기준, 핵심은 컨텍스트!)
────────────────────────────────
├─ 체크리스트: 100-150줄 범위 (120줄 내외)
├─ 예상 시간: 2-4시간
├─ 컨텍스트: 80-90K 토큰 이내 ← 실제 제한
└─ 💡 숫자는 참고! 작업을 완전하게 설명하는 게 우선

2. 독립성
────────────────────────────────
├─ 다른 Task 없이 테스트 가능
├─ 명확한 입력/출력
├─ 자체 완결적
└─ 롤백 가능

3. 검증 가능
────────────────────────────────
├─ 테스트 작성 가능
├─ 성공/실패 판단 명확
├─ 품질 기준 적용 가능
└─ MyPy 0, Ruff 0 달성

4. 가치 있음
────────────────────────────────
├─ 완료 시 실제 기능 동작
├─ 데모 가능
└─ 진행 상황 확인 가능
```

#### 분해 패턴

```
Blueprint 섹션 → Tasks 분해:

예시: "3. 도메인 모델" 섹션

┌─────────────────────────────────────────────────────────┐
│ 3. 도메인 모델                                          │
│                                                         │
│ 3.1 User 엔티티                                         │
│ 3.2 Order 엔티티                                        │
│ 3.3 OrderItem 엔티티                                    │
│ 3.4 Money 값 객체                                       │
│ 3.5 OrderStatus 열거형                                  │
└─────────────────────────────────────────────────────────┘
            ↓ 분해
┌─────────────────────────────────────────────────────────┐
│ Task 001: User 엔티티 + 테스트                          │
│   - User 모델 구현 (20줄)                               │
│   - 단위 테스트 (30줄)                                  │
│   - 예상: 2시간                                         │
├─────────────────────────────────────────────────────────┤
│ Task 002: Order 엔티티 + OrderItem + 테스트             │
│   - Order, OrderItem 모델 (40줄)                        │
│   - 집계 로직 (20줄)                                    │
│   - 단위 테스트 (40줄)                                  │
│   - 예상: 3시간                                         │
├─────────────────────────────────────────────────────────┤
│ Task 003: 값 객체 + 열거형 + 테스트                     │
│   - Money, OrderStatus (20줄)                           │
│   - 단위 테스트 (20줄)                                  │
│   - 예상: 1.5시간                                       │
└─────────────────────────────────────────────────────────┘
```

#### RDoLT 적용 (난이도별 분해)

```
RDoLT: Recursive Decomposition of Logical Thoughts

Level 1 - Easy (기본 기능):
────────────────────────────────
├─ 단순 CRUD
├─ 기본 모델 정의
├─ 단순 API 엔드포인트
└─ 명확한 로직

예: Task 001 (User 엔티티)

Level 2 - Intermediate (상호작용):
────────────────────────────────
├─ 엔티티 간 관계
├─ 트랜잭션 로직
├─ 서비스 계층 통합
└─ 검증 로직

예: Task 005 (주문 생성 서비스)

Level 3 - Final (엣지 케이스):
────────────────────────────────
├─ 에러 처리
├─ 동시성 제어
├─ 성능 최적화
├─ 보안 검증
└─ 예외 상황

예: Task 015 (주문 동시성 처리)

작업 순서:
Easy → Intermediate → Final
(기반 먼저, 복잡한 것 나중)
```

#### Stage 8 산출물

```
08T-01_task_breakdown.md
────────────────────────────

# Task Breakdown

## 개요
- 총 Tasks: 20개
- 예상 시간: 60시간
- 세션 수: 20-25 세션

## Task 목록

### Phase 1: Domain Models (Easy)
| ID | Task | 예상 | 의존성 |
|----|------|------|--------|
| 001 | User 엔티티 | 2h | - |
| 002 | Order + OrderItem | 3h | 001 |
| 003 | 값 객체 | 1.5h | - |

### Phase 2: Services (Intermediate)
| ID | Task | 예상 | 의존성 |
|----|------|------|--------|
| 005 | 주문 생성 서비스 | 4h | 002 |
| 006 | 주문 조회 서비스 | 2h | 002 |

### Phase 3: Integration (Final)
| ID | Task | 예상 | 의존성 |
|----|------|------|--------|
| 015 | 동시성 처리 | 4h | 005 |
| 016 | KIS API 연동 | 4h | 005 |

## 의존성 다이어그램
[Mermaid 또는 ASCII]

## 우선순위
1. 핵심 경로: 001 → 002 → 005 → 016
2. 병렬 가능: 003, 006
```

---

### 6.3 Stage 9: Checklist + 구현

#### 목표
TDD 기반 9-Step 체크리스트 작성 및 실행

#### 9-Step Checklist 구조

````
09L-001_user_entity.md
────────────────────────────

# Task 001: User 엔티티 체크리스트

## 메타 정보
- Task ID: 001
- Blueprint 참조: 07B-01 Section 3.1
- 의존성: 없음
- 예상 시간: 2시간

## Step 1: 목표 이해 ✅
────────────────────────────────
[ ] Blueprint Section 3.1 읽기
[ ] PROJECT_STANDARDS DB 규칙 확인
[ ] 관련 ADR 확인 (ADR-003)

예상 산출물:
- src/domain/entities/user.py
- tests/unit/domain/test_user.py

## Step 2: 테스트 작성 🧪
────────────────────────────────
[ ] 테스트 파일 생성
[ ] User 생성 테스트
[ ] User 필드 검증 테스트
[ ] User ID 형식 테스트 (UUIDv7)

```python
# tests/unit/domain/test_user.py
def test_user_creation():
    user = User(email="test@example.com")
    assert user.id is not None
    assert user.email == "test@example.com"
    assert user.created_at is not None

def test_user_id_is_uuidv7():
    user = User(email="test@example.com")
    # UUIDv7 검증 로직
    assert is_valid_uuidv7(user.id)
```

## Step 3: 구현 🔨
────────────────────────────────
[ ] User 모델 작성
[ ] ID 생성 로직
[ ] 타임스탬프 자동 설정
[ ] soft delete 필드

```python
# src/domain/entities/user.py
from core.types import UserId
from core.database import Base

class User(Base):
    __tablename__ = "users"
    
    id: UserId = Field(default_factory=generate_uuidv7)
    email: str
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)
    deleted_at: datetime | None = None
```

## Step 4: 정적 검증 🔍
────────────────────────────────
[ ] Lint 실행: `[lint-tool] check src/domain/entities/user.*`
[ ] Type Check 실행: `[type-check-tool] src/domain/entities/user.*`
[ ] 0 violations 확인

## Step 5: 단위 테스트 실행 ✅
────────────────────────────────
[ ] 테스트 실행: `[test-framework] tests/unit/domain/test_user.* -v`
[ ] 모든 테스트 통과 확인
[ ] 커버리지 확인: `[test-framework] --cov=src/domain/entities/user`

## Step 6: 리팩토링 🔄
────────────────────────────────
[ ] 중복 코드 제거
[ ] 네이밍 개선
[ ] 타입 힌트 완성
[ ] 문서화 (주석/docstring)

## Step 7: 종합 테스트 🧪
────────────────────────────────
[ ] 전체 테스트 실행: `[test-framework] tests/ -v`
[ ] 기존 테스트 깨지지 않음 확인
[ ] 커버리지 95%+ 확인

## Step 8: 문서화 📝
────────────────────────────────
[ ] 모듈 docstring 작성
[ ] 주요 함수 docstring
[ ] 사용 예시 추가 (필요시)

## Step 9: 커밋 ✅
────────────────────────────────
[ ] pre-commit 통과 확인
[ ] 커밋 메시지 작성
    ```
    feat(domain): add User entity
    
    - Add User model with UUIDv7 ID
    - Add soft delete support
    - Add unit tests (100% coverage)
    
    Refs: Task-001, ADR-003
    ```

[ ] 커밋

## 완료 조건
────────────────────────────────

- [ ] Ruff 0 violations
- [ ] MyPy 0 errors
- [ ] 테스트 100% 통과
- [ ] 커버리지 95%+
- [ ] pre-commit 통과
- [ ] 커밋 완료
````

#### 체크리스트 작성 원칙

```markdown
1. 복사-붙여넣기 가능
   ────────────────────────────────
   모든 명령어는 그대로 실행 가능해야 함

❌ "테스트를 실행하세요"
✅ "[test-framework] tests/unit/domain/test_user.* -v"

2. 구체적인 코드 예시
   ────────────────────────────────
   예상되는 코드 구조를 미리 제시

❌ "User 모델을 구현하세요"
✅ 실제 코드 스니펫 제공

3. 검증 가능한 완료 조건
   ────────────────────────────────
   ❌ "잘 작동해야 함"
   ✅ "Ruff 0, MyPy 0, 테스트 100% 통과"

4. 참조 명확
   ────────────────────────────────
   ❌ "표준을 따르세요"
   ✅ "PROJECT_STANDARDS.md Ln 45-60 참조"
```

---

## Part 7: AI 협업 기법

### 7.1 인지 글쓰기 이론 기반

```markdown
Flower & Hayes (1981) - 인지 글쓰기 프로세스:

┌─────────────────────────────────────────────────────────┐
│                   글쓰기 = 문제 해결                    │
├─────────────────────────────────────────────────────────┤
│                                                         │
│   ┌─────────┐                                          │
│   │ 기획    │ ← 아이디어 생성, 구조화, 목표 설정       │
│   │Planning │                                          │
│   └────┬────┘                                          │
│        ↓                                               │
│   ┌─────────┐                                          │
│   │ 작성    │ ← 아이디어를 텍스트로 변환               │
│   │Translating│                                        │
│   └────┬────┘                                          │
│        ↓                                               │
│   ┌─────────┐                                          │
│   │ 검토    │ ← 평가, 수정, 개선                       │
│   │Reviewing│                                          │
│   └────┬────┘                                          │
│        │                                               │
│        └────→ 반복...                                  │
│                                                         │
└─────────────────────────────────────────────────────────┘

DNA 방법론 적용:
├─ 기획 = Stage 1-3 (ADR까지)
├─ 작성 = Stage 7-9 (Blueprint → 구현)
├─ 검토 = 각 Stage의 검증 단계
└─ 반복 = 세션 단위 점진적 완성
```
### 7.2 Skeleton-of-Thought (SoT) - 구조 우선

#### 원리

```markdown
전통적 방식:
────────────────────────────────
시작 → 서론 작성 → 본론 1 → 본론 2 → ... → 결론
(순차적, 한 줄로)

문제:
├─ 앞부분에서 시간 소모
├─ 전체 구조 놓침
├─ 논리적 표류 발생
└─ 뒷부분 품질 저하

SoT 방식:
────────────────────────────────
Step 1: 뼈대 (Skeleton) 생성
┌───────────────────────────────┐
│ 1. 서론                       │
│ 2. 본론 A                     │
│ 3. 본론 B                     │
│ 4. 본론 C                     │
│ 5. 결론                       │
└───────────────────────────────┘

Step 2: 각 부분 병렬 확장
┌───────────────────────────────┐
│ 1. 서론 ────→ [상세 내용]    │
│ 2. 본론 A ──→ [상세 내용]    │  병렬 처리
│ 3. 본론 B ──→ [상세 내용]    │  가능
│ 4. 본론 C ──→ [상세 내용]    │
│ 5. 결론 ────→ [상세 내용]    │
└───────────────────────────────┘

장점:
├─ 전체 구조 먼저 확정
├─ 논리적 표류 방지
├─ 병렬 작업 가능 (여러 세션)
└─ 일관성 유지
```

#### DNA 적용: Blueprint 작성

```markdown
Stage 7 Blueprint에 SoT 적용:

세션 1: 뼈대 생성
────────────────────────────────
1. 시스템 개요
2. 아키텍처 구조
3. 도메인 모델
4. API 설계
5. 데이터베이스 설계
6. 외부 연동
7. 에러 처리
8. 보안
9. 다음 단계

→ 목차만 작성 (10분)
→ 각 섹션 2-3줄 요약

세션 2: 섹션 1-3 확장
────────────────────────────────
각 섹션 상세 내용 작성
ADR 참조 추가
다이어그램 포함

세션 3: 섹션 4-6 확장
────────────────────────────────
API 스펙 상세화
테이블 스키마 정의
외부 API 연동 명세

세션 4: 섹션 7-9 확장 + 검토
────────────────────────────────
에러 코드 정의
보안 정책 명세
전체 일관성 검토
```
#### 프롬프트 템플릿

```markdown
SoT 뼈대 생성 프롬프트:

"[주제]에 대한 문서를 작성하려 합니다.
먼저 전체 구조(목차)만 작성해주세요.
각 섹션은 제목과 2-3줄 요약만 포함합니다.
상세 내용은 이후 별도로 작성합니다."

SoT 확장 프롬프트:

"아래 목차의 섹션 [N-M]을 상세하게 작성해주세요.
[목차 제공]
[관련 ADR/참조 문서 제공]
다른 섹션은 작성하지 마세요."
```
---

### 7.3 Chain of Density (CoD) - 정보 밀도 증가

#### 원리

```markdown
전통적 요약:
────────────────────────────────
원문 1000자 → 요약 200자
(한 번에 압축, 정보 손실 큼)

CoD 방식:
────────────────────────────────
Round 1: 초기 요약 (200자)
├─ 핵심 주제 파악
└─ 기본 구조 유지

Round 2: 밀도 증가 (200자 유지)
├─ 불필요한 수식어 제거
├─ 새로운 핵심 정보 추가
└─ 더 많은 내용을 같은 길이에

Round 3: 밀도 증가 (200자 유지)
├─ 추가 압축
├─ 더 많은 엔티티 포함
└─ 문장 구조 최적화

Round 4-5: 최종 밀도
├─ 최대 정보 밀도 달성
├─ 핵심만 남김
└─ 읽기 어려우면 롤백

핵심:
├─ 길이 고정 (200자)
├─ 정보량 증가 (매 라운드)
└─ 4-5회 반복
```
#### DNA 적용: 요구사항 정제

```markdown
Stage 1-2에서 CoD 적용:

원본 (사용자 요청):
────────────────────────────────
"주식 거래할 수 있는 앱을 만들고 싶어요.
한국투자증권 API를 사용하고요.
실시간으로 시세도 보고 싶고
주문도 넣을 수 있으면 좋겠어요.
자동매매도 나중에 추가하고 싶어요."

Round 1 (요약):
────────────────────────────────
"한국투자증권 API 기반 주식 거래 앱.
실시간 시세 조회, 주문 기능 필요.
자동매매는 추후 확장."

Round 2 (밀도 증가):
────────────────────────────────
"KIS API 기반 주식 거래 플랫폼.
핵심: 실시간 시세(WebSocket), 주문 CRUD.
패밀리: A-A-B (거래 정확성 최우선).
확장: 자동매매 (Phase 2)."

Round 3 (밀도 증가):
────────────────────────────────
"KIS API 주식 거래 플랫폼.
실시간 시세(WS) + 주문(REST/ACID).
A-A-B 패밀리, NFR: 정확성>속도>가용성.
제약: KIS 20req/s, KRX 09:00-15:30.
확장: 자동매매 (조건부 주문)."

Round 4 (최종):
────────────────────────────────
"KIS API 주식 거래 (A-A-B)
├─ 시세: WebSocket 실시간
├─ 주문: REST + PostgreSQL ACID
├─ NFR: 정확성 A, 속도 A, 가용성 A
├─ 제약: 20req/s, 09:00-15:30
└─ Phase 2: 조건부 자동매매"
```

#### 프롬프트 템플릿

```markdown
CoD 적용 프롬프트:

"아래 요구사항을 5줄로 요약해주세요.
[요구사항 제공]

이제 같은 5줄을 유지하면서,
더 많은 핵심 정보를 포함하도록 다시 작성해주세요.
불필요한 수식어를 제거하고, 새로운 엔티티를 추가하세요.

이 과정을 3번 더 반복합니다."
```
---

### 7.4 Tree of Thoughts (ToT) - 대안 탐색

#### 원리

```markdown
전통적 방식 (단일 경로):
────────────────────────────────
문제 → 해결책 1 → 구현
(첫 번째 아이디어에 고착)

ToT 방식 (다중 경로):
────────────────────────────────
          문제
            │
     ┌──────┼──────┐
     ↓      ↓      ↓
   해결책1 해결책2 해결책3
     │      │      │
   평가    평가    평가
   (60점) (85점) (70점)
            │
            ↓
        해결책2 선택
            │
     ┌──────┼──────┐
     ↓      ↓      ↓
   구현A   구현B   구현C
     │      │      │
   평가    평가    평가
            │
            ↓
        최적 경로 완성

핵심:
├─ 여러 대안 생성
├─ 각 대안 평가 (점수화)
├─ 최적 선택
├─ 역추적 가능 (막히면)
└─ BFS/DFS 탐색
```
#### DNA 적용: ADR 대안 비교

```markdown
Stage 3 ADR에서 ToT 적용:

문제: "데이터베이스 선택"

Step 1: 대안 생성
────────────────────────────────
대안 1: PostgreSQL
대안 2: MySQL
대안 3: MongoDB

Step 2: 평가 기준 정의
────────────────────────────────
├─ ACID 지원 (필수)
├─ JSON 지원 (중요)
├─ 팀 경험 (중요)
├─ 성능 (보통)
└─ 비용 (보통)

Step 3: 각 대안 평가
────────────────────────────────

| 기준   | PostgreSQL | MySQL | MongoDB |
| ------ | ---------- | ----- | ------- |
| ACID   | 10/10      | 9/10  | 6/10    |
| JSON   | 9/10       | 6/10  | 10/10   |
| 팀경험 | 8/10       | 8/10  | 4/10    |
| 성능   | 8/10       | 9/10  | 8/10    |
| 비용   | 10/10      | 10/10 | 6/10    |
| 총점   | 45         | 42    | 34      |

Step 4: 최적 선택
────────────────────────────────
PostgreSQL 선택 (45점)

근거:
├─ ACID 완전 지원 (필수 요건)
├─ JSONB로 유연성 확보
├─ 팀 경험 있음
└─ 오픈소스 (비용 절감)

역추적 조건:
├─ 성능 문제 심각 시 → MySQL 재검토
├─ 스키마리스 필요 시 → MongoDB 재검토
```
#### 프롬프트 템플릿

```markdown
ToT 적용 프롬프트:

"[문제]에 대해 3가지 대안을 제시해주세요.

각 대안에 대해:

1. 장점 3가지
2. 단점 3가지
3. 적합한 상황
4. 점수 (10점 만점)

평가 기준:

- [기준 1] (가중치: 높음)
- [기준 2] (가중치: 중간)
- [기준 3] (가중치: 낮음)

최종적으로 하나를 선택하고 근거를 설명해주세요.
역추적 조건(언제 재검토해야 하는지)도 명시해주세요."
```
---

### 7.5 RDoLT - 난이도별 분해

#### 원리

```
전통적 분해:
────────────────────────────────
전체 기능 → 균등 분할
(복잡도 고려 없음)

RDoLT 방식:
────────────────────────────────
Level 1 - Easy:
├─ 기본 CRUD
├─ 단순 모델
├─ 명확한 로직
└─ 의존성 없음

Level 2 - Intermediate:
├─ 엔티티 간 관계
├─ 서비스 통합
├─ 트랜잭션
└─ 외부 연동 (단순)

Level 3 - Final:
├─ 에러 처리
├─ 동시성
├─ 성능 최적화
├─ 보안
└─ 예외 상황

작업 순서:
Easy → Intermediate → Final
(기반부터, 복잡한 것은 나중에)
```
#### DNA 적용: Task Breakdown

```
Stage 8 Task Breakdown에 RDoLT 적용:

전체 기능: "주문 시스템"

Level 1 - Easy (먼저):
────────────────────────────────
Task 001: Order 엔티티 기본 필드
Task 002: OrderItem 엔티티
Task 003: OrderStatus 열거형
Task 004: 기본 Repository

Level 2 - Intermediate (다음):
────────────────────────────────
Task 005: 주문 생성 서비스 (트랜잭션)
Task 006: Order-OrderItem 관계 처리
Task 007: 주문 조회 서비스 (조인)
Task 008: KIS API 연동 (기본)

Level 3 - Final (마지막):
────────────────────────────────
Task 009: 동시 주문 처리 (락)
Task 010: 부분 체결 처리
Task 011: 주문 실패 복구
Task 012: 주문 취소/정정
Task 013: 성능 최적화 (인덱스, 캐시)
Task 014: 보안 검증 (권한, 한도)
```
#### 프롬프트 템플릿

```
RDoLT 적용 프롬프트:

"[기능]을 구현하기 위한 Task를 분해해주세요.

3단계로 분류합니다:

Level 1 - Easy (기본):

- 단순 모델, CRUD, 명확한 로직
- 의존성 없음

Level 2 - Intermediate (상호작용):

- 엔티티 관계, 서비스 통합, 트랜잭션
- Level 1에 의존

Level 3 - Final (고급):

- 에러 처리, 동시성, 성능, 보안
- Level 1, 2에 의존

각 Task는:

- 2-4시간 분량
- 독립 테스트 가능
- 명확한 완료 조건"
```
---

### 7.6 Stage별 기법 적용 요약

```
┌─────────────────────────────────────────────────────────┐
│ Stage │ 기법 │ 적용 목적                                │
├───────┼──────┼─────────────────────────────────────────┤
│ 1     │ CoD  │ 아이디어 → 정제된 요구사항               │
│       │ RDoLT│ 핵심 기능 파악 (Easy부터)               │
├───────┼──────┼─────────────────────────────────────────┤
│ 2     │ CoD  │ 제약조건 정리                           │
│       │ ToT  │ 충돌 패턴 분석                          │
├───────┼──────┼─────────────────────────────────────────┤
│ 3     │ ToT  │ ADR 대안 비교, 결정 근거                │
├───────┼──────┼─────────────────────────────────────────┤
│ 4-6   │ SoT  │ DNA 청사진 구조화                       │
├───────┼──────┼─────────────────────────────────────────┤
│ 7     │ SoT  │ Blueprint 목차 먼저, 확장               │
├───────┼──────┼─────────────────────────────────────────┤
│ 8     │ RDoLT│ Task 난이도별 분해                      │
│       │ SoT  │ Task 구조화                             │
├───────┼──────┼─────────────────────────────────────────┤
│ 9     │ SoT  │ Checklist 구조                          │
└─────────────────────────────────────────────────────────┘
```
---

## 마무리

### 이 문서의 위치

```
┌─────────────────────────────────────────────────────────┐
│ Tier 1: Overview (빠른 파악)                            │
│ 00_CORE_METHODOLOGY.md                                │
│ → 전체 맥락, 현재 위치                                 │
└───────────────────────┬─────────────────────────────────┘
                        │
                        ↓
┌─────────────────────────────────────────────────────────┐
│ Tier 2: Detailed (상세 참조) ← 현재 문서               │
│ 01_DNA_METHODOLOGY_DETAILED.md                            │
│ → 실제 작업 시 참조                                    │
└───────────────────────┬─────────────────────────────────┘
                        │
                        ↓
┌─────────────────────────────────────────────────────────┐
│ Tier 3: Stage별 가이드                                │
│ STAGE_1_GUIDE.md, STAGE_2_GUIDE.md, ...               │
│ → 각 Stage 실행 시 로드                                │
└─────────────────────────────────────────────────────────┘
```
---

**문서 작성 완료**: 2025-12-02
**총 라인 수**: ~1900줄
**참조**: 00_CORE_METHODOLOGY.md, GEMINI_RESEARCH_SYNTHESIS.md


------
# DNA Stage 1-9 가이드 - 각 Stage별 상세 실행 가이드
# 생성일: 2025-12-10
# 포함된 파일 수: 9

================================================================================

📄 FILE: 01G-00_core_definition_guide.md
--------------------------------------------------------------------------------

# Stage 1: 핵심 정의 가이드 (Core Definition Guide)

> **목적**: 시스템의 본질적 특성을 파악하여 7가지 패밀리 중 하나로 분류
>
> **버전**: v4.1 (2025-12-03)
>
> - v4.0 (2025-12-03): Gemini 연구 기반 10가지 ADQ 체계 도입, 01_DNA_METHODOLOGY_DETAILED.md 기준 전면 재작성
> 
> - v3.0: 3-Layer Decision Tree 도입

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage1 실행 가이드) ← 지금 여기!
```

**참조 문서**:
- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` **Part 3**
- **패밀리별 기술**: `./family-tech-matrix/` (8개 파일)
  - `00_overview.md`
  - `01_ultra_high_frequency_trading_tech_options.md`
  - `02_transaction_crud_tech_options.md`
  - `03_collaboration_sync_tech_options.md`
  - `04_search_recommendation_tech_options.md`
  - `05_real_time_streaming_tech_options.md`
  - `06_analytics_batch_tech_options.md`
  - `07_safety_critical_iot_tech_options.md`

- **실전 사례**: `./manual-cases/02E-01_stock_trading_case.md`

---

## 📥 입력 문서

**없음** - Stage 1은 프로젝트의 시작점입니다.

**필요한 것**:
- 프로젝트 아이디어 (간단한 설명)
- 해결하고자 하는 문제
- 기본적인 요구사항 (선택적)

---

## 📤 출력 문서

### 필수 산출물 (3개)

| 파일명 | 내용 | 다음 Stage 전달 |
|--------|------|----------------|
| `01C-01_family_classification.md` | 패밀리 코드 + 10가지 ADQ 답변 | ✅ 패밀리 코드 (예: B-C-A) |
| `01C-02_nfr_profile.md` | NFR 우선순위 프로파일 | ✅ NFR 프로파일 (예: A-B-B-A) |
| `01D-01_tech_candidates.md` | 기술 후보군 (family-tech-matrix 기반) | ✅ 기술 방향 |

---

## Part 0: 핵심 기능 파악 ⭐

프로젝트의 시작은 아이디어나 문제 인식에서 출발합니다. 
먼저 **가장 근원적인 기능**과 **비즈니스 목적**을 파악해야 합니다.

### Q0: 이 시스템은 무엇을 하기 위한 시스템인가?

**작성 원칙**:
- 가장 **원자적인 기능(핵심기능)**만 파악
- **구현 방식**을 별개의 기능으로 보지 않음
- **비즈니스 목적**으로 구분

**예시**:
```
❌ 잘못된 구분:
   - 수동 거래 (기능 1)
   - 자동 거래 (기능 2)

✅ 올바른 구분:
   - 거래 (핵심기능)
     ├─ 구현 방식 A: 수동
     └─ 구현 방식 B: 자동
   - 비즈니스 목적: 계약 체결로 법적 소유권 이전 

✅ 다른 예시:
   - AI 챗봇 + 외부메모리 (X) → AI 외부메모리 (CRUD) (O)
   - 일반 검색 + AI 검색 (X) → 검색 (O)
```

---

## Part 1: 10가지 ADQ (Architecture-Driving Questions)

> **핵심 원칙**: "질문이 결론을 이끈다"
>
> 10가지 질문에 답하면 패밀리와 NFR이 자연스럽게 도출됩니다.


### 카테고리 A: 비즈니스 가치

#### Q1: "이 시스템이 1시간 동안 멈추면 어떤 일이 일어나나요?"

**목적**: 실패의 치명도 판단 → Layer 1 결정

| 답변 | 의미 | 예시 |
|------|------|------|
| **A (치명적)** | 금전/인명/법적 피해 | 주식 거래: "1시간 정지 = 수억 원 손실" |
| **B (심각)** | 비즈니스 영향, 고객 불만 | 병원 예약: "환자 대기, 심각한 불편" |
| **C (경미)** | 불편함, 대체 수단 존재 | 블로그: "불편하지만 치명적이진 않음" |

---

#### Q2: "고객이 이 시스템에서 가장 중요하게 생각하는 것은?"

**목적**: 핵심 품질 속성 식별 → NFR 우선순위

| 답변 | 의미 | 전형적 시스템 |
|------|------|-------------|
| **속도** | "빨라야 함", "즉시 응답" | 검색 엔진 (0.1초 내 결과) |
| **정확성** | "틀리면 안 됨", "100% 정확" | 은행 이체 (1원도 틀리면 안 됨) |
| **가용성** | "항상 접속 가능", "24/7" | 채팅 앱 |
| **보안** | "절대 유출 안 됨" | 의료 시스템 |
| **비용** | "저렴해야 함" | 내부 도구 |

---

### 카테고리 B: 사용자/규모

#### Q3: "사용자가 이 시스템에서 가장 자주 하는 행동 3가지는?"

**목적**: 핵심 사용자 여정 파악 → Layer 3 참고

**답변 형식**:
```
1. [행동 1] - 빈도: 일 N회, 소요시간: N초
2. [행동 2] - 빈도: 일 N회, 소요시간: N초
3. [행동 3] - 빈도: 일 N회, 소요시간: N초
```

**예시 (이커머스)**:
```
1. 상품 검색 - 일 100회, 1초 이내
2. 상품 상세 보기 - 일 50회, 3초 이내
3. 주문하기 - 일 5회, 30초 이내
```

---

#### Q4: "동시에 이 시스템을 사용하는 사용자는 얼마나 되나요?"

**목적**: 확장성 요구사항 파악

| 답변 | 규모 | 아키텍처 영향 |
|------|------|-------------|
| **A (소규모)** | 10-100명 | 단일 서버 가능 |
| **B (중규모)** | 100-10,000명 | 수평 확장 고려 |
| **C (대규모)** | 10,000-100,000명 | 분산 아키텍처 필수 |
| **D (초대규모)** | 100,000명+ | 글로벌 분산 |

**추가 질문**:
- 피크 시간대는? (출퇴근, 점심, 이벤트)
- 성장 예상치는? (월 N% 증가)

---

### 카테고리 C: 데이터/의존성

#### Q5: "이 시스템에서 다루는 데이터 중 가장 민감한 것은?"

**목적**: 보안 수준 결정 → Layer 2, NFR

| 답변 | 데이터 유형 | 규제 연결 |
|------|-----------|----------|
| **A (극비)** | 금융, 의료, 생체 | PCI-DSS, HIPAA |
| **B (민감)** | 개인정보, 위치 | GDPR, 개인정보보호법 |
| **C (내부)** | 비즈니스 데이터 | 내부 정책 |
| **D (공개)** | 공개 콘텐츠 | 없음 |

---

#### Q6: "데이터는 어디서 오나요? (원천)"

**목적**: 통합 복잡도 파악 → Layer 2

| 답변 | 원천 | 예시 |
|------|------|------|
| **자체 생성** | 사용자 입력, 시스템 생성 | 게시글, 주문 |
| **외부 API** | 증권사, 결제, 지도 | KIS API, Stripe |
| **데이터 피드** | 실시간 시세, 뉴스 | WebSocket 피드 |
| **배치 수집** | 일별 정산, 크롤링 | ETL 파이프라인 |
| **사용자 업로드** | 파일, 이미지 | S3 업로드 |

---

#### Q7: "데이터는 얼마나 오래 보관해야 하나요?"

**목적**: 저장소 설계, 아카이빙 전략

| 답변 | 기간 | 저장소 전략 |
|------|------|-----------|
| **실시간** | 현재 상태만 | 캐시, 세션 |
| **단기** | 7-30일 | 로그, 임시 |
| **중기** | 1-5년 | 거래 내역, 활동 |
| **장기** | 5년+ | 법적 보관, 감사 |
| **영구** | 삭제 불가 | 블록체인, 아카이브 |

---

### 카테고리 D: 운영/환경

#### Q8: "이 시스템이 연동해야 하는 외부 시스템은?"

**목적**: 의존성 파악, 장애 전파 범위

**답변 형식**:
| 시스템 | 연동 방식 | 의존도 | 대체 가능 |
|--------|----------|--------|----------|
| KIS API | REST | 필수 | X |
| Slack | Webhook | 선택 | O (이메일) |

---

#### Q9: "시스템은 어디에 배포되나요?"

**목적**: 인프라 제약 파악

| 답변 | 환경 | 고려사항 |
|------|------|---------|
| **클라우드** | AWS, GCP, Azure | 관리형 서비스 활용 |
| **온프레미스** | 자체 서버, IDC | 직접 운영 |
| **하이브리드** | 클라우드 + 온프레미스 | 연결 복잡도 |
| **엣지** | IoT, CDN, 로컬 | 지연시간 최적화 |

---

#### Q10: "시스템은 얼마나 자주 변경되나요?"

**목적**: 유지보수 전략, 배포 파이프라인

| 답변 | 빈도 | CI/CD 요구 |
|------|------|-----------|
| **초고빈도** | 일 수회 | 완전 자동화 필수 |
| **고빈도** | 주 1-2회 | 자동화 권장 |
| **중빈도** | 월 1-2회 | 반자동화 |
| **저빈도** | 분기 1회 | 수동 가능 |

---


## Part 2: 3-Layer Decision Tree → 패밀리 코드 도출

10가지 ADQ 답변을 3개 Layer로 매핑하여 패밀리 코드를 도출합니다.

### ADQ → Layer 매핑

```
Layer 1 (실패 영향): Q1 기반
├─ A: 치명적 (금전/인명/법적)
└─ B: 점진적 (불편함, 재시도 가능)

Layer 2 (데이터 형태): Q5, Q6 기반
├─ A: 구조화 (고정 스키마, RDBMS)
├─ B: 반구조화 (JSON, 유연한 스키마)
└─ C: 비구조화 (스트림, 로그, 자연어)

Layer 3 (응답 시점): Q3 기반
├─ A: 밀리초 (<100ms, 실시간)
├─ B: 초 단위 (1-10초, 대화형)
└─ C: 배치 (분~시간)
```

### 7가지 패밀리

| 코드 | 패밀리명 | 특성 | 대표 사례 | 기술 매트릭스 |
|------|---------|------|----------|-------------|
| **A-A-A** | 초고속 거래 | 치명적, 구조화, 마이크로초 | NASDAQ (14μs), HFT | `01_ultra_high_frequency_trading_tech_options.md` |
| **A-A-B** | 트랜잭션/CRUD | 치명적, 구조화, 초 | Amazon 주문, Stripe | `02_transaction_crud_tech_options.md` |
| **B-A-A** | 협업/동기화 | 점진적, 구조화, 밀리초 | Google Docs, Figma | `03_collaboration_sync_tech_options.md` |
| **B-B-B** | 검색/추천 | 점진적, 반구조화, 초 | Elasticsearch, AI 외부메모리 | `04_search_recommendation_tech_options.md` |
| **B-C-A** | 실시간 스트리밍 | 점진적, 비구조화, 밀리초 | Netflix, Uber GPS | `05_real_time_streaming_tech_options.md` |
| **B-A-C** | 분석/배치 | 점진적, 구조화, 배치 | Snowflake, BigQuery | `06_analytics_batch_tech_options.md` |
| **A-B-A** | 안전-임계 IoT | 치명적, 반구조화, 밀리초 | SCADA, 의료기기 | `07_safety_critical_iot_tech_options.md` |

### 패밀리 선택 플로우차트

```
시작: 프로젝트 아이디어
  ↓
[Q1] 1시간 멈추면?
  ├─ 금전/인명/법적 손실 → A (치명적)
  └─ 불편함, 재시도 가능 → B (점진적)
       ↓
[Q5, Q6] 데이터 형태는?
  ├─ 고정 스키마, 관계형 → A (구조화)
  ├─ JSON, 유연한 스키마 → B (반구조화)
  └─ 이벤트, 로그, 스트림 → C (비구조화)
       ↓
[Q3] 응답 속도는?
  ├─ 즉시 (<100ms) → A (밀리초)
  ├─ 기다림 (1-10초) → B (초)
  └─ 나중에 (분~시간) → C (배치)
       ↓
패밀리 코드 확정! (예: B-C-A)
  ↓
해당 패밀리 기술 매트릭스 참고
→ ./family-tech-matrix/05_real_time_streaming_tech_options.md
```

---

## Part 3: NFR 프로파일 도출

### NFR 5가지 품질 속성 (SEI Quality Attributes 기반)

Q1, Q2, Q3, Q4, Q5 답변을 기반으로 NFR 프로파일을 도출합니다.

```
NFR 프로파일: [정확성]-[속도]-[가용성]-[보안]-[비용]

예: A-B-A-A-B
├─ 정확성: A (100% 정확해야 함)
├─ 속도: B (1초 이내면 충분)
├─ 가용성: A (99.9%+ 가동률)
├─ 보안: A (극비 수준)
└─ 비용: B (중간 예산)
```

### 각 속성 등급 기준

| 속성 | A 등급 | B 등급 | C 등급 | 근거 ADQ |
|------|--------|--------|--------|----------|
| **정확성** | 100% 정확 필수 | 99%+ 허용 | 95%+ 허용 | Q2 |
| **속도** | <100ms 실시간 | <1초 준실시간 | 배치 허용 | Q3 |
| **가용성** | 99.9%+ (연 8.7시간 이하 장애) | 99%+ | 95%+ | Q1 |
| **보안** | 극비 (금융, 의료) | 민감 (개인정보) | 공개 가능 | Q5 |
| **비용** | 무제한 | 중간 (예산 내) | 최소화 | 예산 제약 |

### 컨텍스트 정보 (별도 기록)

NFR 프로파일과 별도로, 환경 조건을 기록합니다:

| 항목 | 값 예시 | 근거 ADQ |
|------|---------|----------|
| **규모** | 중규모 (10만 사용자) | Q4 |
| **최신성** | 실시간 (<100ms) | Q3 |
| **데이터량** | 일 100만 건 | Q7 |
| **보관 기간** | 5년 | Q7 |

### NFR 충돌 패턴 감지 ⚠️

**5차원 프로파일에서 충돌 패턴 식별**:

| 충돌 패턴 | 조건 | 이론적 근거 | 해결 방향 |
|----------|------|------------|----------|
| **정확성 vs 속도** | 둘 다 A | CAP Theorem (C vs Latency) | 쓰기=동기, 읽기=캐시 |
| **가용성 vs 정확성** | 둘 다 A | CAP Theorem (A vs C) | 정상=둘 다, 장애=정확성 우선 |
| **속도 vs 보안** | 둘 다 A | 암호화 오버헤드 | 인증 후 고속 처리 |
| **가용성 vs 비용** | A + C | 고가용성=고비용 | 중요 컴포넌트만 HA |

⚠️ **충돌 발견 시**: Stage 2 Part 2에서 트레이드오프 결정 필수!

---


## 📋 템플릿

### 01C-01_family_classification.md 템플릿

```markdown
# 패밀리 분류 문서

**프로젝트**: [프로젝트명]
**작성일**: [YYYY-MM-DD]
**작성자**: [이름]

---

## Part 0: 핵심 기능

### Q0: 존재 이유
- **핵심 기능**: [기능명]
- **비즈니스 목적**: [목적]
- **구현 방식들**: [A, B, C...]

---

## Part 1: 10가지 ADQ 답변

### 카테고리 A: 비즈니스 가치

**Q1: 1시간 멈추면?**
- 답변: [A/B/C]
- 이유: [구체적 설명]

**Q2: 고객이 가장 중요하게 생각하는 것?**
- 답변: [속도/정확성/가용성/보안/비용]
- 이유: [구체적 설명]

### 카테고리 B: 사용자/규모

**Q3: 가장 자주 하는 행동 3가지?**
1. [행동 1] - 빈도: 일 N회, 소요시간: N초
2. [행동 2] - 빈도: 일 N회, 소요시간: N초
3. [행동 3] - 빈도: 일 N회, 소요시간: N초

**Q4: 동시 사용자 규모?**
- 답변: [A/B/C/D]
- 피크 시간대: [시간]
- 성장 예상: [월 N%]

### 카테고리 C: 데이터/의존성

**Q5: 가장 민감한 데이터?**
- 답변: [A/B/C/D]
- 데이터 유형: [구체적 데이터]
- 관련 규제: [규제명]

**Q6: 데이터 원천?**
- [ ] 자체 생성
- [ ] 외부 API: [API명]
- [ ] 데이터 피드: [피드 유형]
- [ ] 배치 수집
- [ ] 사용자 업로드

**Q7: 데이터 보관 기간?**
- 답변: [실시간/단기/중기/장기/영구]
- 이유: [법적 요건 등]

### 카테고리 D: 운영/환경

**Q8: 연동 외부 시스템?**
| 시스템 | 연동 방식 | 의존도 | 대체 가능 |
|--------|----------|--------|----------|
| [시스템1] | [방식] | [필수/선택] | [O/X] |

**Q9: 배포 환경?**
- 답변: [클라우드/온프레미스/하이브리드/엣지]
- 상세: [AWS/GCP 등]

**Q10: 변경 빈도?**
- 답변: [초고빈도/고빈도/중빈도/저빈도]
- CI/CD 요구: [수준]

---

## Part 2: 패밀리 코드 도출

### Layer 매핑
- Layer 1 (Q1 → 실패 영향): [A/B]
- Layer 2 (Q5,Q6 → 데이터 형태): [A/B/C]
- Layer 3 (Q3 → 응답 시점): [A/B/C]

### 📌 패밀리 코드: [X-X-X]
### 📌 패밀리명: [패밀리 이름]

---

## Part 3: 기술 방향

**참조**: `./family-tech-matrix/[해당 파일].md`

### 필수 기술 방향
- ✅ [방향 1]
- ✅ [방향 2]
- ✅ [방향 3]

### 기술 후보군
- [기술 1], [기술 2], [기술 3]
```

---

### 01C-02_nfr_profile.md 템플릿

```markdown
# NFR 프로파일 문서

**프로젝트**: [프로젝트명]
**작성일**: [YYYY-MM-DD]

---

## NFR 5가지 품질 속성 (SEI Quality Attributes 기반)

| 속성 | 등급 | 의미 | 근거 (ADQ) |
|------|------|------|-----------|
| **정확성** | [A/B/C] | [100% 정확 / 99%+ / 95%+] | Q2: [이유] |
| **속도** | [A/B/C] | [<100ms / <1초 / 배치] | Q3: [이유] |
| **가용성** | [A/B/C] | [99.9%+ / 99%+ / 95%+] | Q1: [이유] |
| **보안** | [A/B/C] | [극비 / 민감 / 공개] | Q5: [이유] |
| **비용** | [A/B/C] | [무제한 / 중간 / 최소화] | 예산: [금액] |

### 📌 NFR 프로파일: [X-X-X-X-X]

---

## 컨텍스트 정보

| 항목 | 값 | 근거 (ADQ) |
|------|-----|-----------|
| 규모 | [소/중/대/초대규모] | Q4: [동시 사용자 수] |
| 최신성 | [실시간/준실시간/배치] | Q3: [사용자 기대] |
| 데이터량 | [일 N건] | Q7: [추정 근거] |
| 보관 기간 | [N년] | Q7: [법적/비즈니스 요건] |

---

## 충돌 패턴 분석

### 잠재적 충돌 체크
- [ ] 정확성 A + 속도 A → CAP Theorem 충돌 가능
- [ ] 가용성 A + 정확성 A → CAP Theorem 충돌 가능
- [ ] 속도 A + 보안 A → 암호화 오버헤드
- [ ] 가용성 A + 비용 C → 고가용성=고비용

### 발견된 충돌
| 충돌 | 설명 | Stage 2 분석 필요? |
|------|------|-------------------|
| [충돌 1] | [설명] | ✅/❌ |
| [충돌 2] | [설명] | ✅/❌ |

### Stage 2 전달 사항
- [Stage 2에서 상세 분석 필요한 충돌 목록]
```

---

### 01D-01_tech_candidates.md 템플릿

```markdown
# 기술 후보군 문서

**프로젝트**: [프로젝트명]
**작성일**: [YYYY-MM-DD]
**패밀리 코드**: [X-X-X]

---

## 패밀리 기반 기술 방향

**참조**: `./family-tech-matrix/[해당 파일].md`

### 이 패밀리의 필수 특성
- ✅ [특성 1] (예: ACID 트랜잭션 필수)
- ✅ [특성 2] (예: 실시간 처리)
- ✅ [특성 3] (예: 강한 일관성)

---

## 기술 후보군

### 데이터베이스
| 후보 | 장점 | 단점 | 적합도 |
|------|------|------|--------|
| [DB 1] | [장점] | [단점] | ⭐⭐⭐ |
| [DB 2] | [장점] | [단점] | ⭐⭐ |
| [DB 3] | [장점] | [단점] | ⭐ |

### 프레임워크
| 후보 | 장점 | 단점 | 적합도 |
|------|------|------|--------|
| [FW 1] | [장점] | [단점] | ⭐⭐⭐ |
| [FW 2] | [장점] | [단점] | ⭐⭐ |

### 메시징/캐시
| 후보 | 장점 | 단점 | 적합도 |
|------|------|------|--------|
| [기술 1] | [장점] | [단점] | ⭐⭐⭐ |
| [기술 2] | [장점] | [단점] | ⭐⭐ |

---

## Stage 2 검토 필요 사항

- [ ] [후보 1] vs [후보 2] 성능 비교
- [ ] [기술 X] 팀 역량 확인
- [ ] [기술 Y] 비용 분석
```

---

## ✅ Stage 1 완료 체크리스트

```
□ Part 0: 핵심 기능 파악 완료
□ Part 1: 10가지 ADQ 모두 답변
□ Part 2: 패밀리 코드 도출 (X-X-X)
□ Part 3: NFR 프로파일 도출 (X-X-X-X-X)
□ 산출물 생성:
  □ 01C-01_family_classification.md
  □ 01C-02_nfr_profile.md
  □ 01D-01_tech_candidates.md (family-tech-matrix 참조)
□ 충돌 패턴 기록 (있는 경우)
```

---

## 🔜 다음 단계

### Stage 1 → Stage 2 전달 사항

| 항목 | 예시 | Stage 2에서 사용 |
|------|------|----------------|
| 패밀리 코드 | B-C-A | 기술 스택 결정 기준 |
| 핵심 기능 | 거래 | 도메인 설계 기준 |
| NFR 프로파일 | A-B-B-A | 트레이드오프 결정 |
| 기술 후보군 | Kafka, Redis, PostgreSQL | 비교 평가 대상 |
| 충돌 패턴 | 속도 vs 정확성 | Stage 2에서 해결 |

### Stage 2에서 할 일
- 🔄 외부 제약 상세 조사 (API 비교, 법규 등)
- 🔄 충돌 패턴 해결 방안 도출
- 🔄 기술 스택 최종 확정
- 🔄 결정 요소 목록 작성 (ADR 준비)

**다음 문서**: `02G-00_environment_constraints_guide.md`

---

## 📚 참고 문서

| 문서 | 용도 |
|------|------|
| `01_DNA_METHODOLOGY_DETAILED.md` Part 3 | 10가지 ADQ 상세 원리 |
| `./family-tech-matrix/*.md` | 7가지 패밀리별 기술 선택 |
| `./02E-01_stock_trading_case.md` | 실전 사례 (주식 거래 플랫폼) |
| `./standards/01_STAGE_STRUCTURE.md` | Stage 간 연결 구조 |

---

**버전 이력**:
- v4.0 (2025-12-03): Gemini 연구 기반 10가지 ADQ 체계 도입, 01_DNA_METHODOLOGY_DETAILED.md 기준 전면 재작성
- v3.0 (2025-11-12): 3-Layer Decision Tree 도입
- v2.0 (2025-11-11): 초기 버전


================================================================================

📄 FILE: 02G-00_environment_constraints_guide.md
--------------------------------------------------------------------------------

# Stage 2: 환경 제약 가이드 (Environment Constraints Guide)

> **목적**: Stage 1의 패밀리/NFR이 현실 환경에서 구현 가능한지 확인하고, 충돌 발견 시 트레이드오프 결정
>
> **버전**: v4.1 (2025-12-03)
>
> - v4.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
> - v3.0 (2025-11-14): Stage 2 구조 확립

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage 2 실행 가이드) ← 지금 여기!
```

**참조 문서**:
- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` Part 3.2
- **실전 사례**: `./02E-01_stock_trading_case.md`

---

## 📥 입력 문서

### Stage 1에서 전달받는 것

| 파일 | 핵심 내용 | 이 Stage에서 사용 |
|------|----------|-----------------|
| `01C-01_family_classification.md` | 패밀리 코드, 10가지 ADQ 답변 | Layer 3 목표 확인 |
| `01C-02_nfr_profile.md` | NFR 프로파일 | 충돌 패턴 분석 기준 |
| `01D-01_tech_candidates.md` | 기술 후보군 | 기술 스택 결정 입력 |

---

## 📤 출력 문서

### 필수 산출물 (3개)

| 파일명 | 내용 | 다음 Stage 전달 |
|--------|------|----------------|
| `02C-01_external_constraints.md` | 외부 제약 조사 결과 | ✅ API, 규제, 인프라 제약 |
| `02C-02_conflict_patterns.md` | 충돌 패턴 분석 | ✅ 트레이드오프 결정 |
| `02D-01_tech_stack.md` | 기술 스택 최종 결정 | ✅ ADR 작성 기반 |

---

## 🎯 Stage 2가 필요한 이유

> **"이상과 현실 사이의 간극 파악"**

Stage 1에서 결정한 패밀리와 NFR은 **이상적 목표**입니다.
Stage 2에서는 **현실의 제약**을 조사하여 충돌을 발견하고 해결합니다.

```
예시: 주식 거래 플랫폼

Stage 1 결정:
├─ 패밀리: A-A-B (트랜잭션/CRUD)
├─ NFR 프로파일: A-B-B-A (정확성, 중규모, 민감, 실시간)
└─ 목표: "100개 조건을 실시간 감시"

Stage 2 조사:
├─ 한국투자증권 API: 초당 20건 제한 ❌
├─ WebSocket: 최대 41개 종목 ❌
└─ 현실: "100개 동시 감시 불가능!"

충돌 발견! → 트레이드오프 필요
├─ 옵션 A: 감시 종목 41개로 축소
├─ 옵션 B: Polling + WebSocket 하이브리드
└─ 옵션 C: 목표 조정 (초단위 → 분단위)
```

---


## Part 1: 외부 제약 조사

Stage 1의 Q8-Q10 답변을 심화 조사합니다.

### 외부 제약 조사 체크리스트

#### 1. API/연동 제약 (Q8 심화)

```
조사 항목:
[ ] 사용할 외부 API 목록
[ ] 각 API의 호출 제한 (rate limit)
[ ] 인증 방식 (OAuth, API Key, 인증서)
[ ] 응답 시간 SLA
[ ] 장애 시 대응 방안
[ ] 문서화 수준 및 지원 품질
```

**작성 예시**:
```markdown
## API 제약 조사: 증권 거래 API

| 항목 | 한국투자증권 | 키움증권 |
|------|------------|---------|
| 호출 제한 | 실전 20건/초, 모의 2건/초 | 5건/초 |
| 인증 방식 | OAuth 2.0 + 앱키 | HTS ID/PW |
| 평균 응답 | 200-400ms | 300-600ms |
| WebSocket | ✅ (41개 종목) | ❌ |
| SLA | 99.9% | 99.5% |
```

---

#### 2. 규제/법적 제약

```
조사 항목:
[ ] 적용되는 법규 목록
[ ] 데이터 보관 요건 (기간, 형식)
[ ] 감사 로그 요건
[ ] 암호화 요건
[ ] 지역 제한 (데이터 거주지)
[ ] 인증/면허 요건
```

**산업별 주요 규제**:

| 산업 | 주요 규제 | 핵심 요건 |
|------|----------|----------|
| **금융** | 전자금융거래법, PCI-DSS | 거래 기록 5년, 이상거래 탐지 |
| **의료** | HIPAA, 개인정보보호법 | PHI 암호화, 접근 로그 |
| **교육** | FERPA | 학생 정보 보호 |
| **일반** | GDPR, 개인정보보호법 | 동의, 삭제권, 국외 이전 제한 |

---

#### 3. 인프라 제약 (Q9 심화)

```
조사 항목:
[ ] 클라우드 제공자 제한 (AWS/GCP/Azure/온프레미스)
[ ] 가용 리전 (데이터 거주지 요건)
[ ] 네트워크 대역폭
[ ] 스토리지 용량/비용
[ ] 기존 인프라 연동 요건
[ ] 예산 한도
```

**작성 예시**:
```markdown
## 인프라 제약

- 클라우드: AWS 허용 (금융권 승인됨)
- 리전: 서울 필수 (데이터 국외 반출 금지)
- 예산: 월 50만원 이하
- 기존 인프라: 없음 (신규 프로젝트)
```

---

#### 4. 시간 제약

```
조사 항목:
[ ] 서비스 운영 시간
[ ] 배치 처리 시간 윈도우
[ ] 유지보수 허용 시간
[ ] 마감 시간 (정산, 리포트)
[ ] 시장 시간 (거래소, 외부 시스템)
```

**작성 예시**:
```markdown
## 시간 제약

- 시장 시간: 09:00-15:30 (정규), 15:40-18:00 (시간외)
- 배치 윈도우: 18:00-09:00 (야간)
- 유지보수: 주말 00:00-06:00
- 정산 마감: 매일 18:00
```

---


## Part 2: 충돌 패턴 식별

Part 1의 **현실적 제약**과 Stage 1의 **이상적 목표(NFR)** 사이의 충돌을 분석합니다.

### 4가지 공통 충돌 패턴

#### 충돌 1: 정확성 vs 속도 (CAP Theorem의 C vs A)

```
상황: 강한 일관성을 원하지만 낮은 지연시간도 필요

예시:
├─ 목표: "잔고 조회는 항상 정확해야 함" (정확성)
├─ 목표: "조회 응답은 100ms 이하" (속도)
└─ 충돌: 동기화 대기 vs 캐시 사용

해결 전략:
├─ 쓰기: 동기식 (정확성 보장)
├─ 읽기: 캐시 + 비동기 (속도 확보)
├─ 중요 작업만 동기, 나머지 비동기
└─ Read-after-Write 일관성 적용
```

---

#### 충돌 2: 가용성 vs 정확성 (CAP Theorem의 A vs C)

```
상황: 항상 응답해야 하지만 항상 정확해야 함

예시:
├─ 목표: "시스템은 24/7 응답 가능" (가용성)
├─ 목표: "거래 금액은 절대 틀리면 안 됨" (정확성)
└─ 충돌: 네트워크 장애 시 어떻게 할 것인가?

해결 전략:
├─ 네트워크 정상: 둘 다 만족
├─ 네트워크 장애: 정확성 우선 (금융)
├─ Saga 패턴: 분산 트랜잭션 관리
└─ Outbox 패턴: 이벤트 유실 방지
```

---

#### 충돌 3: 성능 vs 비용

```
상황: 최고 성능을 원하지만 운영비 제한

예시:
├─ 목표: "피크 시간에도 1초 이내 응답"
├─ 제약: "월 예산 50만원 이하"
└─ 충돌: 상시 고성능 인스턴스 vs 비용

해결 전략:
├─ 오토스케일링: 피크 시간만 확장
├─ 예약 인스턴스: 기본 용량 확보
├─ 스팟 인스턴스: 비용 절감 (배치용)
└─ 비용 상한선 알림 설정
```

---

#### 충돌 4: 보안 vs 사용성

```
상황: 강한 보안이 필요하지만 편리한 사용도 원함

예시:
├─ 목표: "모든 거래는 2단계 인증" (보안)
├─ 목표: "빠른 조회/주문 경험" (사용성)
└─ 충돌: 매번 MFA vs 원클릭 주문

해결 전략:
├─ 조회: 간단한 인증 (세션 기반)
├─ 거래: MFA 필수
├─ 위험 기반 인증: 이상 징후 시만 추가 인증
└─ 세션 유효 기간 차등 적용
```

---

### 충돌 분석 템플릿

각 충돌마다 다음 형식으로 분석:

```markdown
### 충돌 #N: [목표 vs 제약]

**NFR 목표** (Stage 1):
- [NFR 프로파일에서 정한 목표]

**현실 제약** (Part 1 조사 결과):
- [외부 제약 조사에서 발견한 제약]

**충돌 상황**:
- [왜 불가능한가? 구체적 수치로]

**영향 분석**:
- 이 충돌을 무시하면: [결과]
- 이 충돌을 해결하면: [기대 효과]

**트레이드오프 옵션**:
| 옵션 | 설명 | 장점 | 단점 |
|------|------|------|------|
| A | [방법 1] | [장점] | [단점] |
| B | [방법 2] | [장점] | [단점] |
| C | [방법 3] | [장점] | [단점] |

**선택**: [옵션 X]
**근거**: [선택 이유]
```

---


## Part 3: 기술 스택 결정

Stage 1의 기술 후보군 + Part 1의 제약 + Part 2의 충돌 해결을 종합하여 최종 기술 스택을 결정합니다.

### 기술 스택 결정 3단계

#### 단계 1: 패밀리 기반 후보군 확인

```
Stage 1에서 결정된 패밀리 기반 기술 후보군 확인

예시: A-A-B (트랜잭션/CRUD) 패밀리

참조: ./family-tech-matrix/02_transaction_crud_tech_options.md

후보 DB:
├─ PostgreSQL: ACID, JSON 지원, 성숙
├─ MySQL: ACID, 대중적, Aurora 옵션
└─ CockroachDB: 분산 ACID, 글로벌

후보 프레임워크 (언어별):
├─ Python: FastAPI, Django
├─ TypeScript: NestJS, Express
├─ Java: Spring Boot
├─ Go: Gin, Echo
└─ Rust: Axum, Actix
```

---

#### 단계 2: 제약조건 필터링

```
Part 1 조사 결과로 후보군 필터링

필터링 기준:
├─ 팀 역량: [팀 주력 언어] 중심 → 다른 언어 제외
├─ 비용 제한: 오픈소스 우선 → 상용 라이선스 제외
├─ 규제 요건: 국내 서버 → 글로벌 분산 DB 제한
├─ 기존 인프라: 없음 → 제약 없음
└─ 성능 요건: 비동기 필수 → 동기 전용 프레임워크 제외

필터링 결과:
├─ DB: [선택된 DB] ✅
├─ Framework: [선택된 프레임워크] ✅
└─ Cache: [선택된 캐시] ✅
```

---

#### 단계 3: 충돌 해결 반영

```
Part 2의 트레이드오프 결정을 기술 스택에 반영

예시:
├─ 충돌 1 (정확성 vs 속도) 해결:
│   → Redis 캐시 도입 (읽기 속도)
│   → PostgreSQL 트랜잭션 유지 (쓰기 정확성)
│
├─ 충돌 3 (성능 vs 비용) 해결:
│   → AWS t3.medium 시작
│   → 오토스케일링 설정
│
└─ 충돌 4 (보안 vs 사용성) 해결:
    → JWT + Refresh Token
    → 거래 시 추가 인증
```

---

### 기술 스택 문서화 형식

```markdown
## 최종 기술 스택

### 핵심 선택

| 영역 | 선택 | 대안 | 선택 근거 |
|------|------|------|----------|
| 언어 | [프로젝트 선택 언어] | - | 팀 역량, 에코시스템 |
| 프레임워크 | [선택 프레임워크] | [대안들] | 비동기, 타입 안전 |
| DB | PostgreSQL 15 | MySQL | ACID, JSON, 성숙도 |
| 캐시 | Redis | Memcached | 데이터 구조, 지속성 |
| 메시징 | Redis Streams | Kafka | 규모 적합, 단순성 |

### DNA 시스템 기술

| DNA 시스템 | 역할 | 언어별 도구 예시 |
|-----------|------|-----------------|
| Testing | 테스트 프레임워크 | pytest(Py), Jest(TS), JUnit(Java) |
| Code Quality | 린터/타입 체커 | Ruff+MyPy(Py), ESLint+TSC(TS) |
| Observability | 구조화 로깅 | structlog(Py), winston(TS), logback(Java) |
| Configuration | 설정 관리 | pydantic-settings(Py), zod(TS) |
| Resilience | 재시도/회복 | tenacity(Py), cockatiel(TS) |

**참조**: 언어별 상세 도구는 `docs/manuals/` 참조

### 인프라

| 영역 | 선택 | 비고 |
|------|------|------|
| 클라우드 | AWS Seoul | 규제 요건 |
| 컴퓨팅 | ECS Fargate | 서버리스 컨테이너 |
| DB | RDS PostgreSQL | 관리형 |
| 캐시 | ElastiCache Redis | 관리형 |
```

---


## 📋 템플릿

### 02C-01_external_constraints.md 템플릿

```markdown
# 외부 제약 조건

**프로젝트**: [프로젝트명]
**작성일**: [YYYY-MM-DD]
**작성자**: [이름]

---

## 1. API/연동 제약

### 1.1 외부 API 목록

| API | 용도 | 호출 제한 | 인증 | 응답 시간 |
|-----|------|----------|------|----------|
| [API 1] | [용도] | [제한] | [방식] | [시간] |
| [API 2] | [용도] | [제한] | [방식] | [시간] |

### 1.2 연동 시 제약사항
- [제약 1]
- [제약 2]

---

## 2. 규제/법적 제약

### 2.1 적용 법규
- [법규 1]: [핵심 요건]
- [법규 2]: [핵심 요건]

### 2.2 데이터 보관 요건
| 데이터 유형 | 보관 기간 | 형식 | 근거 법규 |
|------------|----------|------|----------|
| [유형 1] | [기간] | [형식] | [법규] |

### 2.3 암호화 요건
- [요건 1]
- [요건 2]

---

## 3. 인프라 제약

### 3.1 클라우드/서버
- 허용 클라우드: [AWS/GCP/Azure/온프레미스]
- 필수 리전: [리전명]
- 이유: [데이터 거주지 등]

### 3.2 예산
- 초기 예산: [금액]
- 월 운영비: [금액]

### 3.3 기존 인프라
- [연동 필요한 기존 시스템]

---

## 4. 시간 제약

### 4.1 서비스 운영 시간
- 정규: [시간]
- 시간외: [시간]

### 4.2 배치 처리 윈도우
- [시간대]

### 4.3 외부 시스템 시간
- [시장 시간, 정산 마감 등]
```

---

### 02C-02_conflict_patterns.md 템플릿

```markdown
# 충돌 패턴 분석

**프로젝트**: [프로젝트명]
**작성일**: [YYYY-MM-DD]

---

## NFR 달성 가능성 분석

### Stage 1 NFR 프로파일: [X-X-X-X]

| NFR | 목표 | 외부 제약 | 달성 가능? |
|-----|------|----------|-----------|
| [NFR 1] | [목표] | [제약] | ✅/⚠️/❌ |
| [NFR 2] | [목표] | [제약] | ✅/⚠️/❌ |

---

## 발견된 충돌 패턴

### 충돌 #1: [목표 vs 제약]

**NFR 목표**:
- [목표 설명]

**현실 제약**:
- [제약 설명]

**충돌 상황**:
- [구체적 수치로 설명]

**트레이드오프 옵션**:
| 옵션 | 설명 | 장점 | 단점 |
|------|------|------|------|
| A | [방법] | [장점] | [단점] |
| B | [방법] | [장점] | [단점] |

**선택**: [옵션]
**근거**: [이유]

---

### 충돌 #2: [목표 vs 제약]
[같은 형식으로 작성]

---

## 충돌 해결 요약

| 충돌 | 선택한 옵션 | Stage 3 ADR 필요? |
|------|-----------|------------------|
| #1 | [옵션] | ✅/❌ |
| #2 | [옵션] | ✅/❌ |
```

---

### 02D-01_tech_stack.md 템플릿

```markdown
# 기술 스택 결정

**프로젝트**: [프로젝트명]
**작성일**: [YYYY-MM-DD]

---

## 결정 과정

### 1. 패밀리 기반 후보군
- 패밀리: [코드] ([패밀리명])
- 참조: `./family-tech-matrix/[파일].md`

### 2. 제약조건 필터링
| 제약 | 영향 | 필터링 결과 |
|------|------|-----------|
| [제약 1] | [영향] | [제외된 기술] |

### 3. 충돌 해결 반영
| 충돌 | 해결 옵션 | 기술 영향 |
|------|----------|----------|
| [충돌 1] | [옵션] | [기술 추가/변경] |

---

## 최종 기술 스택

### 핵심 선택

| 영역 | 선택 | 대안 | 선택 근거 |
|------|------|------|----------|
| 언어 | [언어] | [대안] | [근거] |
| 프레임워크 | [프레임워크] | [대안] | [근거] |
| DB | [DB] | [대안] | [근거] |
| 캐시 | [캐시] | [대안] | [근거] |

### DNA 시스템 기술

| DNA 시스템 | 기술 | 설정 |
|-----------|------|------|
| Testing | [기술] | [설정] |
| Code Quality | [기술] | [설정] |
| Observability | [기술] | [설정] |
| Configuration | [기술] | [설정] |
| Resilience | [기술] | [설정] |

### 인프라

| 영역 | 선택 | 비고 |
|------|------|------|
| 클라우드 | [선택] | [비고] |
| 컴퓨팅 | [선택] | [비고] |
| DB | [선택] | [비고] |

---

## Stage 3 ADR 목록 (예정)

이 문서의 결정들은 Stage 3에서 ADR로 공식화됩니다:

- [ ] ADR-001: [DB 선택]
- [ ] ADR-002: [프레임워크 선택]
- [ ] ADR-003: [충돌 해결 전략]
```

---


## ✅ Stage 2 완료 체크리스트

```
□ Part 1: 외부 제약 조사 완료
  □ API/연동 제약 조사
  □ 규제/법적 제약 조사
  □ 인프라 제약 조사
  □ 시간 제약 조사

□ Part 2: 충돌 패턴 식별 완료
  □ NFR 달성 가능성 분석
  □ 충돌 패턴 식별 (최소 1개 이상)
  □ 각 충돌별 트레이드오프 옵션 도출
  □ 각 충돌별 선택 및 근거 문서화

□ Part 3: 기술 스택 결정 완료
  □ 패밀리 기반 후보군 확인
  □ 제약조건 필터링
  □ 충돌 해결 반영
  □ 최종 기술 스택 문서화

□ 산출물 생성:
  □ 02C-01_external_constraints.md
  □ 02C-02_conflict_patterns.md
  □ 02D-01_tech_stack.md

□ Stage 3 ADR 목록 작성
```

---

## 🔜 다음 단계

### Stage 2 → Stage 3 전달 사항

| 항목 | 예시 | Stage 3에서 사용 |
|------|------|-----------------|
| 외부 제약 | API 호출 제한, 규제 | ADR 카테고리 1 (외부 제약) |
| 충돌 해결 | 정확성 vs 속도 해결 | ADR 카테고리 2 (충돌 해결) |
| 기술 스택 | PostgreSQL, [선택 프레임워크] | ADR 카테고리 3 (기술 스택) |
| ADR 목록 | 예정된 ADR 3개 | Stage 3 작업 범위 |

### Stage 3에서 할 일
- 🔄 ADR 카테고리별 작성
- 🔄 Bootstrap ADR (DNA 시스템)
- 🔄 Domain ADR (도메인 특화)
- 🔄 Design Doc → ADR 변환 (복잡한 결정)

**다음 문서**: `03G-00_adr_guide.md`

---

## ⏪ 이전 Stage 검증 및 수정 프로토콜

### 검증 시점
- Stage 2 시작 전 필수 체크
- Part 1 (기술 환경 조사) 완료 후 재검증

### 검증 대상

| Stage | 산출물 | 검증 항목 |
|-------|--------|----------|
| Stage 1 | 01C-01_*.md (패밀리) | 선택한 패밀리가 기술 제약과 호환? |
| Stage 1 | 01C-01_*.md (NFR) | NFR 우선순위가 현실적? |

### 오류 발견 시 프로토콜

```
Stage 2에서 Stage 1 오류 발견 시:

Step 1: 오류 발견 및 문서화
├─ 발견 위치: Stage 2 Part [N]
├─ 오류 내용: [구체적 설명]
└─ 기록: 02C-01에 "발견된 이슈" 섹션 추가

Step 2: 영향 범위 파악
├─ 직접 영향: Stage 1 (패밀리/NFR)
├─ 재작업 예상: [X]시간
└─ 기록 완료

Step 3: Stage 1로 이동 → 수정
├─ 01C-01_*.md 수정
├─ 버전 업데이트 (v1.0 → v1.1)
└─ 수정 완료 검증

Step 4: Stage 2 재진행
├─ 수정된 입력으로 Part 1부터 재검토
└─ 충돌 분석 재수행

Step 5: 검증
├─ 오류 해결 확인
├─ 새로운 문제 없음 확인
└─ Stage 3 전달 가능 ✅
```

### 흔한 오류 패턴

| 오류 유형 | 예시 | 해결 |
|----------|------|------|
| 패밀리 불일치 | 실시간 요구사항인데 CRUD 패밀리 선택 | Stage 1 패밀리 재분류 |
| NFR 비현실적 | 10ms 응답 요구 but 팀에 경험 없음 | Stage 1 NFR 현실화 |
| 제약 누락 | 예산 제약 미고려 | Stage 1 제약조건 추가 |

### 추적성

```
수정 이력 파일: docs/revision_log.md

기록 형식:
## [날짜] Stage 2 → Stage 1 수정
- **발견**: [오류 내용]
- **원인**: [근본 원인]
- **수정**: [수정 내용]
- **영향**: [영향 범위]
- **검증**: [검증 결과]
```

---

## 📚 참고 문서

| 문서 | 용도 |
|------|------|
| `01_DNA_METHODOLOGY_DETAILED.md` Part 3.2 | Stage 2 상세 원리 |
| `./family-tech-matrix/*.md` | 패밀리별 기술 선택 |
| `./02E-01_stock_trading_case.md` | 실전 사례 (주식 거래) |
| `./standards/01_STAGE_STRUCTURE.md` | Stage 간 연결 구조 |

---

## 💡 핵심 원칙 요약

```
Stage 2의 본질:

1. "이상과 현실의 간극 파악"
   - Stage 1의 NFR은 이상
   - Part 1 조사 결과는 현실
   - 간극 = 충돌

2. "충돌은 정상이다"
   - 모든 프로젝트에 충돌 존재
   - 중요한 것은 의식적 트레이드오프
   - 결정과 근거를 문서화

3. "기술 스택은 제약의 산물"
   - 이상적 기술 ≠ 최종 선택
   - 제약조건 필터링 후 남는 것이 정답
   - 선택 근거가 핵심
```

---

**버전 이력**:
- v5.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
- v4.0 (2025-11-14): Stage 2 구조 확립
- v3.0 (2025-11-12): 초기 버전


================================================================================

📄 FILE: 03G-00_adr_guide.md
--------------------------------------------------------------------------------

# Stage 3: ADR 작성 가이드 (Architecture Decision Records Guide)

> **목적**: Stage 2에서 결정된 기술 스택과 충돌 해결을 공식 ADR로 문서화
>
> **버전**: v4.1 (2025-12-03)
>
> - v4.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
> - v3.0 (2025-11-13): Stage 3 분리

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리) - Part 4
           ↓
Tier 3: 이 문서 (Stage 3 실행 가이드) ← 지금 여기!
```

**참조 문서**:
- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` Part 4
- **실전 사례**: `IMPLEMENTATION_CASES.md`

---

## 🧬 DNA 방법론 4대 핵심 원칙 (Stage 3 적용)

> **"AI가 한 세션에서 최고 성과를 낼 수 있는 크기로 작업하고, 완전해질 때까지 반복하며, 오류 발견 시 되돌아가서 수정한다"**

Stage 3 (ADR 작성)에서 DNA 4대 핵심 원칙이 적용되는 방식:

---

### DNA 핵심 원칙 1: AI 최적 크기

**"컨텍스트 범위 내에서 작업한다"**

#### Stage 3의 작업 크기 전략

```
❌ 잘못된 접근: 모든 ADR 한 번에
"20개 ADR을 한 세션에서 모두 작성하세요"
→ 컨텍스트 초과 (200K 토큰 한계)
→ 후반부 ADR 품질 저하
→ 일관성 없는 형식

✅ 올바른 접근: 카테고리별 순차 작성
Session 1: 외부 제약 ADR (03A-001 ~ 03A-00N)
Session 2: 충돌 해결 ADR (03A-101 ~ 03A-1NN)
Session 3: 기술 스택 ADR (03A-201 ~ 03A-2NN)
Session 4: 도메인 기술 ADR (03A-301 ~ 03A-3NN)
Session 5: DNA 시스템 ADR (03A-401 ~ 03A-4NN)

각 세션: 3-5개 ADR, 80-90K 토큰 범위
```

#### 컨텍스트 구성 (각 세션)

```
AI 컨텍스트 윈도우 (예: 200K 토큰):
├─ 시스템 프롬프트: ~30K 토큰
├─ 대화 히스토리: ~20K 토큰
├─ Stage 2 참조 문서: ~30-40K 토큰
│   ├─ 02C-01_external_constraints.md
│   ├─ 02C-02_conflict_patterns.md
│   └─ 02D-01_tech_stack.md
├─ ADR 템플릿: ~10K 토큰
├─ 작업 중 ADR 작성: ~20K 토큰 (3-5개 × 4-6K)
└─ 응답 생성 여유: ~80K 토큰
```

#### 세션당 작업량 기준

| 카테고리 | 평균 ADR 수 | 세션 수 | 세션당 ADR 수 |
|---------|------------|--------|--------------|
| 외부 제약 | 3-5개 | 1 session | 3-5개 |
| 충돌 해결 | 5-10개 | 2 sessions | 3-5개 |
| 기술 스택 | 10-15개 | 3 sessions | 3-5개 |
| 도메인 기술 | 5-10개 | 2 sessions | 3-5개 |
| DNA 시스템 | 11개 | 3 sessions | 3-4개 |

**핵심**: 한 세션에 3-5개 ADR이 최적 (각 4-6K 토큰)

---

### DNA 핵심 원칙 2: 완전해질 때까지 반복

**"부족하면 반복해서 부족함이 없어질 때까지"**

#### ADR 완전성 기준

각 ADR은 다음 5가지 섹션을 모두 포함해야 함:

```
✅ 완전한 ADR 체크리스트:
□ 1. Status & Context (상태 및 맥락)
   - 상태: Proposed/Accepted/Deprecated/Superseded
   - 날짜: 작성일, 승인일, 폐기일
   - 맥락: 왜 이 결정이 필요한가?

□ 2. Decision (결정 사항)
   - 무엇을 선택했는가?
   - 구체적 기술/방법 명시

□ 3. Rationale (근거)
   - 왜 이것을 선택했는가?
   - 어떤 대안이 있었는가?
   - 각 대안의 장단점은?

□ 4. Consequences (결과)
   - 긍정적 결과 (이점)
   - 부정적 결과 (트레이드오프)
   - 영향받는 시스템/모듈

□ 5. Compliance (준수 사항)
   - 검증 방법 (어떻게 확인?)
   - 위반 시 조치 (어떻게 강제?)
   - 재검토 조건 (언제 다시 평가?)
```

#### 3단계 검증 프로토콜

```
ADR 세션 완전성 검증 (의사코드):

FUNCTION validate_adr_session(adrs):
    
    # 검증 1: 각 ADR 구조 검증
    FOR EACH adr IN adrs:
        IF adr가 5개 섹션 중 하나라도 누락:
            - 상태/맥락, 결정, 근거, 결과, 준수
            RETURN 실패: "ADR {id}: 5개 섹션 중 누락 발견"
            ACTION: "해당 ADR 재작성"

    # 검증 2: 카테고리 일관성 검증
    IF adrs의 카테고리가 서로 다름:
        RETURN 실패: "한 세션에 여러 카테고리 혼재"
        ACTION: "카테고리별로 세션 분리"

    # 검증 3: Stage 2 추적성 검증
    FOR EACH adr IN adrs:
        IF adr에 Stage 2 참조가 없음:
            RETURN 실패: "ADR {id}: Stage 2 참조 누락"
            ACTION: "Stage 2 문서 참조 추가"

    RETURN 성공
```

#### 불완전 → 재작성 사례

```markdown
## 사례: ADR-201 데이터베이스 선택

### ❌ 불완전한 버전 (1차 작성)
**결정**: PostgreSQL 사용
**이유**: 관계형 데이터베이스가 필요해서

❌ 문제점:
- 대안 검토 없음 (MySQL, MongoDB는?)
- 구체적 근거 없음 ("필요해서"는 설명 아님)
- 결과/영향 명시 없음
- 준수 사항 없음

### ✅ 완전한 버전 (2차 재작성)
**맥락**: 주문 데이터는 ACID 보장 필요, 복잡한 조인 쿼리 빈번

**결정**: PostgreSQL 13+ 사용

**근거**:
- 검토한 대안:
  1. PostgreSQL: ACID 완벽, JSON 지원, 성능 우수
  2. MySQL: ACID 지원하나 JSON 기능 제한적
  3. MongoDB: 유연하나 트랜잭션 복잡
- 선택 이유: 주문 데이터의 ACID 필수, JSON 컬럼 필요

**결과**:
- 긍정: 데이터 일관성 보장, 복잡한 쿼리 가능
- 부정: NoSQL 대비 스키마 변경 부담
- 영향: DNA Database 시스템, Order 도메인

**준수**:
- 검증: SQLAlchemy ORM으로만 접근
- 위반 시: pre-commit hook으로 raw SQL 차단
- 재검토: 쓰기 속도 < 100 TPS 시
```

---

### DNA 핵심 원칙 3: 기능별 분해 + 연결부 + 조립

**"모듈이 크면 기능별로 나누고, 연결부 설계 후 조립"**

#### Stage 3에서의 적용

Stage 3는 "문서 작성" 단계이므로 원칙 3은 직접 적용되지 않습니다.

다만, ADR 자체가 "연결부" 역할을 합니다:

```
Stage 2 (결정) ←─┐
                  ├─ ADR (연결부) ─→ Stage 4 (DNA 계획)
Stage 8 (작업)  ←─┘                     ↓
   ↓                                 Stage 5 (DNA 구현)
Stage 9 (체크리스트)

ADR의 연결 역할:
├─ Stage 2 결정을 공식 기록
├─ Stage 4-5에서 참조
└─ Stage 8-9 작업 시 검증 기준
```

#### ADR 간 연결 관리

```markdown
## ADR 간 의존성 예시

ADR-001: Python 3.11+ 사용
   ↓ supersedes
ADR-005: Python 3.9+ 사용 (폐기됨)

ADR-201: PostgreSQL 사용
   ↓ related to
ADR-401: DNA Database 시스템 (SQLAlchemy 2.0)

ADR-102: 캐시는 조회만 사용
   ↓ enforced by
ADR-402: DNA Cache 시스템 (Redis 구조)
```

---

### DNA 핵심 원칙 4: 역방향 수정 프로토콜

**"앞선 결정의 오류 발견 시 → 되돌아가서 수정 → 다시 현재까지 진행"**

#### Stage 3에서 역방향 수정이 발생하는 경우

```
시나리오 1: Stage 2 결정 오류 발견
├─ Stage 3 ADR 작성 중
├─ Stage 2 충돌 해결이 잘못됨을 발견
├─ → Stage 2로 돌아가 수정
├─ → Stage 3 ADR 재작성
└─ → 추적성 업데이트

시나리오 2: Stage 4-5에서 ADR 오류 발견
├─ Stage 5 DNA 구현 중
├─ ADR-201 (PostgreSQL) 제약 불가능 발견
├─ → Stage 3로 돌아가 ADR-201 수정
├─ → Stage 4 청사진 업데이트
├─ → Stage 5 구현 재진행
└─ → 추적성 업데이트
```

#### 6단계 수정 프로토콜

```markdown
## 실제 사례: ADR-102 캐시 전략 수정

### Step 1: 오류 발견 및 문서화
**발견 시점**: Stage 5 (DNA Cache 시스템 구현 중)
**파일**: `docs/adr/category-2-conflict/03A-102_cache_strategy.md`
**문제**: "조회만 캐시 사용"인데, 통계 데이터도 캐시 필요함을 발견

### Step 2: 영향 범위 파악
**영향받는 문서**:
- Stage 2: `02D-01_tech_stack.md` (Line 234-256)
- Stage 3: `03A-102_cache_strategy.md` (전체)
- Stage 4: `04D-02_dna_cache_blueprint.md` (Line 45-67)

**영향받는 구현**: 없음 (아직 구현 전)

### Step 3: 해당 Stage로 이동 및 수정
```bash
# Stage 2 재검토
$ edit 02D-01_tech_stack.md
  Line 234-256: "조회 + 통계 데이터에 캐시 사용" 으로 수정

# Stage 3 ADR 수정
$ edit 03A-102_cache_strategy.md
  - Status: Accepted → Superseded
  - Superseded by: 03A-102-v2

$ create 03A-102-v2_cache_strategy_updated.md
  - 새로운 결정: 조회 + 통계 → 캐시
  - 주문/결제 → 캐시 없음
```

### Step 4: 중간 Stage 전파
```bash
# Stage 4 청사진 업데이트
$ edit 04D-02_dna_cache_blueprint.md
  Line 45-67: 통계 데이터 캐시 구조 추가
  Ref: 03A-102-v2 (Line 23-45)
```

### Step 5: 현재 Stage 재진행
```bash
# Stage 5 재구현
$ implement src/core/cache/
  - stats_cache.py 추가
  - Ref: 03A-102-v2
```

### Step 6: 재진행 결과 검증
**검증 항목**:
- [ ] Stage 2 충돌 재분석 완료
- [ ] ADR-102-v2 5개 섹션 완전
- [ ] Stage 4 청사진 ADR 참조 업데이트
- [ ] Stage 5 구현 ADR 준수
- [ ] 모든 파일에 추적성 명시
```

#### 추적성 (Traceability) 유지

**모든 수정은 명시적으로 참조**:

```markdown
## Stage 2 문서 (02D-01_tech_stack.md)
Line 234-256: 캐시 전략
> **History**:
> - v1.0 (2024-11-10): "조회만 캐시"
> - v2.0 (2024-11-15): "조회 + 통계 캐시" (Reason: ADR-102-v2)

## Stage 3 ADR (03A-102-v2_cache_strategy_updated.md)
**Supersedes**: ADR-102 (2024-11-10)
**Reason**: 통계 데이터 캐시 필요성 발견
**Impact**: Stage 4 (04D-02, Line 45-67), Stage 5 (src/core/cache/)

## Stage 4 청사진 (04D-02_dna_cache_blueprint.md)
Line 45-67: 통계 데이터 캐시 구조
> **Ref**: ADR-102-v2 (Line 23-45)
> **Updated**: 2024-11-15 (Reason: ADR 수정)

## Stage 5 구현 (src/core/cache/stats_cache.py)
Line 1: # Ref: ADR-102-v2 (docs/adr/category-2-conflict/03A-102-v2)
Line 5: # Updated: 2024-11-15 (통계 데이터 캐시 추가)
```

---

## 🎯 DNA 원칙 적용 요약 (Stage 3)

| 원칙 | Stage 3 적용 방법 | 체크포인트 |
|------|------------------|-----------|
| **1. AI 최적 크기** | 카테고리별 세션 분리 (3-5 ADR/세션) | 세션당 80-90K 토큰 |
| **2. 완전해질 때까지** | 5개 섹션 완전성, 3단계 검증 | 모든 ADR 5 sections |
| **3. 기능별 분해** | (문서 단계라 직접 적용 안 됨) | ADR 자체가 연결부 |
| **4. 역방향 수정** | 6단계 프로토콜, 추적성 유지 | Superseded/History |

---

## 🤔 왜 ADR이 필요한가?

### 문제 상황: "왜 이렇게 했지?"

```
6개월 후...

새로운 팀원: "왜 PostgreSQL인가요? MongoDB가 더 좋을 것 같은데..."
기존 팀원: "음... 그때 뭔가 이유가 있었는데..."

결과:
├─ 같은 논의 반복 (시간 낭비)
├─ 근거 없이 기술 변경 시도
├─ 변경 후 예상치 못한 문제 발생
└─ "그냥 원래대로 하자" (발전 없음)
```

### 실제 사례: 주식 거래 플랫폼

```
상황:
- Stage 2에서 "정확성 > 속도" 결정
- 주문 처리에 캐시 사용 안 함
- 조회에만 캐시 사용

6개월 후:
- 새 개발자: "주문도 캐시 쓰면 빨라질 텐데?"
- ADR 없다면 → 캐시 적용 → 금액 불일치 사고
- ADR 있다면 → ADR-101 확인 → "아, 이래서 안 쓰는구나"

ADR-101 정확성 우선 전략:
├─ 맥락: 주문 금액 정확성 필수
├─ 검토한 대안: 캐시 사용, 실시간 조회, 하이브리드
├─ 결정: 주문은 실시간, 조회만 캐시
├─ 결과: 500ms 느려지지만 정확도 100%
└─ 재검토 조건: 정확도 문제 발생 시
```

### ADR의 핵심 가치

| 가치 | 설명 | 없을 때 문제 |
|------|------|-------------|
| **기억** | 결정 근거 보존 | 왜 이렇게 했는지 모름 |
| **방지** | 같은 실수 반복 방지 | 이미 검토한 대안 재논의 |
| **속도** | 신규 인원 온보딩 | 모든 결정을 다시 설명 |
| **변경** | 영향 범위 파악 | 변경 시 뭐가 깨지는지 모름 |

---

## 📥 입력 문서

### Stage 2에서 전달받는 것

| 파일 | 핵심 내용 | 이 Stage에서 사용 |
|------|----------|-----------------|
| `02C-01_external_constraints.md` | 외부 제약 조사 | ADR 카테고리 1 |
| `02C-02_conflict_patterns.md` | 충돌 패턴 분석 | ADR 카테고리 2 |
| `02D-01_tech_stack.md` | 기술 스택 결정 | ADR 카테고리 3, 5 |

---

## 📤 출력 문서

### 필수 산출물

```
docs/adr/
├── 03A-000_adr_index.md           # ADR 목록 및 상태
├── category-1-external/           # 외부 제약 ADR
│   └── 03A-001_*.md ~ 03A-00N.md
├── category-2-conflict/           # 충돌 해결 ADR
│   └── 03A-101_*.md ~ 03A-1NN.md
├── category-3-tech-stack/         # 기술 스택 ADR
│   └── 03A-201_*.md ~ 03A-2NN.md
├── category-4-domain/             # 도메인 기술 ADR
│   └── 03A-301_*.md ~ 03A-3NN.md
└── category-5-dna-system/         # DNA 시스템 ADR
    └── 03A-401_*.md ~ 03A-4NN.md
```

---

## 🎯 ADR이란?

> **ADR = Architecture Decision Record**
> 
> "코드는 '무엇'을 보여주지만, ADR은 '왜'를 설명한다"

### ADR의 역할

```
왜 필요한가?
├─ 왜 이 결정을 했는지 기록
├─ 어떤 대안이 있었는지 기록
├─ 나중에 "왜 이렇게 했지?" 질문에 답변
└─ 결정 변경 시 영향 범위 파악
```

### ADR vs Design Doc

| 구분 | Design Doc | ADR |
|------|------------|-----|
| **목적** | 상세 분석 | 결정 기록 |
| **분량** | 10-50 페이지 | 1-2 페이지 |
| **내용** | 문제 정의, 대안 분석, 벤치마크 | 맥락, 결정, 결과 |
| **사용 시점** | 복잡한 결정 전 | 모든 결정 후 |
| **관계** | "어머니" 문서 | Design Doc의 "결론" |

**판단 기준**:
```
├─ 간단한 결정: ADR만 작성
│   예: "로깅 라이브러리 선택"
│
├─ 복잡한 결정: Design Doc → ADR
│   예: "DB 선택 (PostgreSQL vs MySQL vs MongoDB)"
│
└─ 매우 복잡: RFC/KEP → Design Doc → ADR
    예: "마이크로서비스 vs 모놀리식"
```

---


## 5대 ADR 카테고리

### 카테고리 1: 외부 제약 ADR (001-099)

> **정의**: 변경할 수 없는 외부 요인에 의한 결정

```
특징:
├─ 우리가 선택할 수 없음
├─ 반드시 따라야 함
├─ 위반 시 시스템 작동 불가 또는 법적 문제
└─ "왜?"보다 "무엇?"이 중요
```

**예시**:
| 유형 | 예시 | ADR 제목 |
|------|------|---------|
| 법규 | 거래 기록 5년 보관 | ADR-001: 전자금융거래법 준수 |
| API 제한 | KIS API 초당 20회 | ADR-002: KIS API Rate Limit 대응 |
| 시장 시간 | KRX 정규장 09:00-15:30 | ADR-003: 시장 시간 기반 스케줄링 |
| 지역 제한 | 개인정보 국내 서버 필수 | ADR-004: 데이터 거주지 요건 |

---

### 카테고리 2: 충돌 해결 ADR (101-199)

> **정의**: 상충하는 요구사항 간 Trade-off 결정

```
특징:
├─ 둘 다 중요하지만 둘 다 만족 불가
├─ 하나를 선택하면 다른 하나 희생
├─ "왜 이걸 선택했나?"가 핵심
└─ 나중에 재검토 가능성 있음
```

**예시**:
| 충돌 | 결정 | ADR 제목 |
|------|------|---------|
| 정확성 vs 속도 | 주문=정확성, 조회=속도 | ADR-101: 정확성 우선 전략 |
| 일관성 vs 가용성 | CP 선택 (장애 시 거부) | ADR-102: CAP 선택 - CP |
| 보안 vs 편의성 | 거래=MFA, 조회=단순 | ADR-103: 인증 레벨 차등화 |
| 비용 vs 성능 | 피크=성능, 비피크=비용 | ADR-104: 오토스케일링 전략 |

---

### 카테고리 3: 기술 스택 ADR (201-299)

> **정의**: 여러 기술 대안 중 하나를 선택하는 결정

```
특징:
├─ 비교 가능한 대안 존재
├─ 정량적 비교 가능 (성능, 비용, 생태계)
├─ Context7 검증 필수
└─ 팀 역량, 생태계 고려
```

**예시**:
| 영역 | 선택 | 대안 | ADR 제목 |
|------|------|------|---------|
| DB | PostgreSQL | MySQL, MongoDB | ADR-201: PostgreSQL 선택 |
| 프레임워크 | [선택 프레임워크] | [대안들] | ADR-202: 프레임워크 선택 |
| 메시지 큐 | Redis Streams | Kafka, RabbitMQ | ADR-203: Redis Streams 선택 |
| 캐시 | Redis | Memcached | ADR-204: Redis 캐시 선택 |

---

### 카테고리 4: 도메인 기술 ADR (301-399)

> **정의**: 프로젝트 특화 로직/알고리즘 설계 결정

```
특징:
├─ 외부 라이브러리로 해결 안 됨
├─ 자체 설계/구현 필요
├─ 비즈니스 로직 깊숙이 관련
└─ 성능/정확도가 핵심
```

**예시**:
| 영역 | 설계 내용 | ADR 제목 |
|------|----------|---------|
| 주문 처리 | 상태 머신, 재시도 전략 | ADR-301: 주문 실행 전략 |
| 데이터 모델 | 주문 스키마, 관계 | ADR-302: 주문 데이터 모델 |
| API 설계 | 엔드포인트, 응답 형식 | ADR-303: REST API 설계 |
| 동시성 | 낙관적 락, 충돌 해결 | ADR-304: 동시성 제어 전략 |

---

### 카테고리 5: DNA 시스템 ADR (401-499)

> **정의**: 프로젝트 공통 인프라/표준 결정

```
특징:
├─ 전체 프로젝트에 영향
├─ Stage 4-6 (Bridge)에서 구현
├─ 일관성이 핵심
└─ 변경 시 영향 범위 큼
```

**예시**:
| 시스템 | 결정 내용 | ADR 제목 |
|--------|----------|---------|
| 로깅 | 구조화 로깅 + JSON | ADR-401: 로깅 표준화 |
| 에러 처리 | 예외 계층 + 에러 코드 | ADR-402: 에러 처리 표준 |
| 설정 관리 | 타입 안전 설정 | ADR-403: 설정 관리 표준 |
| 테스트 | 테스트 프레임워크 + 95% 커버리지 | ADR-404: 테스트 전략 |
| 인증 | JWT + RS256 | ADR-405: 인증 표준 |

---


## ADR 작성 우선순위

### 권장 순서

```
Phase 1: 외부 제약 ADR (카테고리 1)
────────────────────────────────────
- 가장 먼저 작성 (변경 불가능)
- Stage 2 02C-01_external_constraints.md 기반
- 다른 ADR의 제약 조건이 됨

Phase 2: 충돌 해결 ADR (카테고리 2)
────────────────────────────────────
- 외부 제약 기반 해결책
- Stage 2 02C-02_conflict_patterns.md 기반
- 기술 스택 선택에 영향

Phase 3: 기술 스택 ADR (카테고리 3)
────────────────────────────────────
- Stage 2 02D-01_tech_stack.md 기반
- 핵심 기술 선택 근거

Phase 4: DNA 시스템 ADR (카테고리 5)
────────────────────────────────────
- 공통 인프라 결정
- Stage 4-6에서 구현할 내용

Phase 5: 도메인 기술 ADR (카테고리 4)
────────────────────────────────────
- 비즈니스 로직 설계
- Stage 7-9에서 구현할 내용
```

---

## 📋 ADR 템플릿

### 표준 ADR 템플릿

```markdown
# ADR-XXX: {Decision Title}

**상태**: Proposed | Accepted | Deprecated | Superseded
**작성일**: YYYY-MM-DD
**카테고리**: 외부제약 | 충돌해결 | 기술스택 | 도메인기술 | DNA시스템

---

## 맥락 (Context)

왜 이 결정이 필요한가?
- 문제 상황
- 제약 조건
- 요구사항

## 검토한 대안 (Alternatives)

### 대안 1: [이름]
- 설명: ...
- 장점: ...
- 단점: ...

### 대안 2: [이름]
- 설명: ...
- 장점: ...
- 단점: ...

### 대안 3: [이름]
- 설명: ...
- 장점: ...
- 단점: ...

## 결정 (Decision)

**선택**: [대안 N]

**핵심 근거**:
1. [이유 1]
2. [이유 2]
3. [이유 3]

## 결과 (Consequences)

### 긍정적 영향
- ✅ [영향 1]
- ✅ [영향 2]

### 트레이드오프
- ⚠️ [트레이드오프 1]
- ⚠️ [트레이드오프 2]

### 부정적 영향
- ❌ [영향 1] (해결 방안: ...)

## 후속 조치 (Follow-up)

- [ ] [조치 1]
- [ ] [조치 2]

## 참조 (References)

- Stage 2 문서: `02C-01_external_constraints.md`
- 관련 ADR: ADR-XXX
- 외부 링크: [URL]
```

---

### 카테고리별 템플릿 변형

#### 외부 제약 ADR (간소화)

```markdown
# ADR-00X: [외부 제약 제목]

**상태**: Accepted
**카테고리**: 외부제약
**작성일**: YYYY-MM-DD

---

## 제약 조건

| 항목 | 내용 |
|------|------|
| 출처 | [법규/API/규제 등] |
| 제약 내용 | [구체적 제약] |
| 위반 시 영향 | [결과] |

## 대응 방안

[제약을 준수하기 위한 구현 방안]

## 결과

- 모든 [관련 기능]은 [제약]을 준수해야 함
- [구현 위치/방법]
```

---

#### 기술 스택 ADR (비교표 포함)

```markdown
# ADR-2XX: [기술 선택 제목]

**상태**: Accepted
**카테고리**: 기술스택
**작성일**: YYYY-MM-DD

---

## 맥락

[왜 이 기술이 필요한가]

## 대안 비교

| 기준 | [기술 A] | [기술 B] | [기술 C] |
|------|---------|---------|---------|
| 성능 | ⭐⭐⭐ | ⭐⭐ | ⭐ |
| 비용 | 무료 | 무료 | $$$ |
| 팀 경험 | ✅ 있음 | ⚠️ 적음 | ❌ 없음 |
| 생태계 | ✅ 풍부 | ⚠️ 보통 | ⚠️ 보통 |
| [기타 기준] | ... | ... | ... |

## 결정

**선택**: [기술 A]

**핵심 근거**:
1. [이유 1]
2. [이유 2]

## 결과

- [구현에 미치는 영향]
- [함께 사용할 라이브러리]
```

---


### ADR Index 템플릿 (03A-000_adr_index.md)

```markdown
# ADR Index

**프로젝트**: [프로젝트명]
**최종 업데이트**: YYYY-MM-DD
**총 ADR 수**: [N]개

---

## 상태별 요약

| 상태 | 개수 |
|------|------|
| Proposed | N |
| Accepted | N |
| Deprecated | N |
| Superseded | N |

---

## 카테고리 1: 외부 제약 (001-099)

| 번호 | 제목 | 상태 | 작성일 |
|------|------|------|--------|
| ADR-001 | [제목] | Accepted | YYYY-MM-DD |
| ADR-002 | [제목] | Accepted | YYYY-MM-DD |

---

## 카테고리 2: 충돌 해결 (101-199)

| 번호 | 제목 | 충돌 유형 | 상태 | 작성일 |
|------|------|----------|------|--------|
| ADR-101 | [제목] | 정확성 vs 속도 | Accepted | YYYY-MM-DD |

---

## 카테고리 3: 기술 스택 (201-299)

| 번호 | 제목 | 영역 | 선택 | 상태 |
|------|------|------|------|------|
| ADR-201 | [제목] | DB | PostgreSQL | Accepted |
| ADR-202 | [제목] | Framework | [선택 프레임워크] | Accepted |

---

## 카테고리 4: 도메인 기술 (301-399)

| 번호 | 제목 | 도메인 | 상태 |
|------|------|--------|------|
| ADR-301 | [제목] | 주문 | Accepted |

---

## 카테고리 5: DNA 시스템 (401-499)

| 번호 | 제목 | 시스템 | 상태 |
|------|------|--------|------|
| ADR-401 | [제목] | 로깅 | Accepted |
| ADR-402 | [제목] | 에러처리 | Accepted |

---

## 의존성 그래프

```
ADR-001 (외부제약)
    ↓
ADR-101 (충돌해결) ← ADR-002 (외부제약)
    ↓
ADR-201 (기술스택)
    ↓
ADR-401 (DNA시스템)
```
```

---

## 📝 ADR 작성 예시 (주식 거래 플랫폼)

### 예시 1: 외부 제약 ADR

```markdown
# ADR-002: KIS API 호출 제한 대응

**상태**: Accepted
**카테고리**: 외부제약
**작성일**: 2024-01-15

---

## 제약 조건

| 항목 | 내용 |
|------|------|
| 출처 | 한국투자증권 KIS API 문서 |
| 제약 내용 | 초당 20회 호출 제한, 초과 시 일시 차단 |
| 위반 시 영향 | API 차단으로 서비스 중단 |

## 대응 방안

1. Rate Limiter 구현
   - 초당 15회로 제한 (5회 여유분)
   - Token Bucket 알고리즘 사용
   
2. 요청 큐잉
   - 초과 요청은 큐에 대기
   - 최대 대기 시간: 5초

3. 벌크 요청 최적화
   - 여러 종목 조회 → 배치 API 활용

## 결과

- core/external/kis_client.py에 RateLimiter 구현
- 모든 KIS API 호출은 rate_limiter를 거쳐야 함
- 모니터링: 초당 호출 수, 큐 대기 시간
```

---

### 예시 2: 충돌 해결 ADR

```markdown
# ADR-101: 정확성 우선 전략

**상태**: Accepted
**카테고리**: 충돌해결
**작성일**: 2024-01-15

---

## 맥락

주문 처리에서 정확성(금액 정확)과 속도(빠른 응답)가 충돌.
캐시 사용 시 속도↑ but 정확성 위험.

## 검토한 대안

### 대안 1: 캐시 전면 사용
- 장점: 응답 속도 200ms → 50ms
- 단점: 가격 불일치 가능, 금융 사고 위험
- 거부 이유: 금융 거래에서 정확성 타협 불가

### 대안 2: 실시간 조회 전면 사용
- 장점: 100% 정확
- 단점: 모든 요청 500ms, 시세 조회도 느림
- 거부 이유: 시세 조회까지 느릴 필요 없음

### 대안 3: 하이브리드 (선택)
- 주문 관련: 항상 실시간
- 시세 조회: 1초 캐시 허용
- 장점: 정확성 + 사용성 균형

## 결정

**선택**: 대안 3 (하이브리드)

**핵심 근거**:
1. 주문 정확성은 금융 서비스의 핵심 가치
2. 시세 조회는 1초 지연 허용 가능
3. 사용자 경험과 안전성 균형

## 결과

### 긍정적 영향
- ✅ 주문 금액 100% 정확
- ✅ 시세 조회 응답 속도 개선

### 트레이드오프
- ⚠️ 주문 응답 500ms (캐시 사용 시 50ms)

### 부정적 영향
- ❌ 구현 복잡도 증가 (해결: 명확한 분리 설계)

## 재검토 조건

- 주문 응답 시간이 1초 초과 시
- 정확도 관련 이슈 발생 시
```

---

### 예시 3: 기술 스택 ADR

```markdown
# ADR-201: PostgreSQL 선택

**상태**: Accepted
**카테고리**: 기술스택
**작성일**: 2024-01-15

---

## 맥락

CRUD/트랜잭션 패밀리(A-A-B)로, ACID 준수 DB 필요.
주문, 계좌, 포트폴리오 데이터 저장.

## 대안 비교

| 기준 | PostgreSQL | MySQL | MongoDB |
|------|------------|-------|---------|
| ACID | ✅ 완전 지원 | ✅ 지원 | ⚠️ 제한적 |
| JSON 지원 | ✅ JSONB | ⚠️ JSON | ✅ 네이티브 |
| 복잡 쿼리 | ✅ 우수 | ⚠️ 보통 | ❌ 제한적 |
| 비용 | 무료 | 무료 | Atlas$$$ |
| 팀 경험 | ✅ 있음 | ✅ 있음 | ⚠️ 적음 |
| 비동기 | asyncpg | aiomysql | motor |

## 결정

**선택**: PostgreSQL 15

**핵심 근거**:
1. ACID 완전 지원 (금융 거래 필수)
2. JSONB로 유연한 스키마 가능 (설정, 메타데이터)
3. 팀 경험 있음, 생태계 풍부

## 결과

- ORM: SQLAlchemy 2.0 (async 지원)
- 마이그레이션: Alembic
- 연결: asyncpg (비동기)
- 풀링: connection pool size 20
```

---

## ✅ Stage 3 완료 체크리스트

```
□ ADR 구조 설정
  □ docs/adr/ 디렉토리 생성
  □ 카테고리별 하위 디렉토리 생성
  □ 03A-000_adr_index.md 생성

□ 카테고리 1: 외부 제약 ADR
  □ Stage 2 02C-01 기반 작성
  □ 법규, API 제한, 시간 제약 등
  □ 최소 1개 이상

□ 카테고리 2: 충돌 해결 ADR
  □ Stage 2 02C-02 기반 작성
  □ 각 충돌 패턴별 해결 전략
  □ 최소 1개 이상

□ 카테고리 3: 기술 스택 ADR
  □ Stage 2 02D-01 기반 작성
  □ DB, 프레임워크, 캐시 등
  □ 주요 기술별 1개씩

□ 카테고리 4: 도메인 기술 ADR
  □ 핵심 비즈니스 로직 설계
  □ 데이터 모델, API 설계

□ 카테고리 5: DNA 시스템 ADR
  □ 로깅, 에러 처리, 설정 관리
  □ 테스트, 인증 전략

□ ADR Index 업데이트
  □ 모든 ADR 등록
  □ 상태별 요약
  □ 의존성 그래프
```

---

## 🔜 다음 단계

### Stage 3 → Stage 4 전달 사항

| 항목 | 예시 | Stage 4에서 사용 |
|------|------|-----------------|
| DNA 시스템 ADR | ADR-401~499 | DNA 시스템 청사진 |
| 기술 스택 ADR | ADR-201~299 | 개발 환경 설정 |
| 도메인 기술 ADR | ADR-301~399 | 도메인 청사진 |

### Stage 4에서 할 일
- 🔄 DNA 시스템 ADR 기반 청사진 작성
- 🔄 src/core/ 모듈 구조 설계
- 🔄 공통 컴포넌트 인터페이스 정의

**다음 문서**: `04G-00_dna_system_blueprint_guide.md`

---

## ⏪ 이전 Stage 검증 및 수정 프로토콜

### 검증 시점
- Stage 3 시작 전 필수 체크
- 각 ADR 카테고리 작성 완료 후 재검증

### 검증 대상

| Stage | 산출물 | 검증 항목 |
|-------|--------|----------|
| Stage 1 | 01C-01_*.md (패밀리) | ADR이 패밀리 특성과 일치? |
| Stage 1 | 01C-01_*.md (NFR) | ADR이 NFR 우선순위 반영? |
| Stage 2 | 02C-01_*.md (제약) | 기술 제약이 ADR에 반영? |
| Stage 2 | 02C-01_*.md (충돌) | 충돌 해결이 ADR로 문서화? |

### 오류 발견 시 프로토콜

```
Stage 3에서 Stage 1-2 오류 발견 시:

Step 1: 오류 발견 및 문서화
├─ 발견 위치: ADR-[NNN] 작성 중
├─ 오류 내용: [구체적 설명]
├─ 영향 Stage: Stage [1 또는 2]
└─ 기록: 해당 ADR에 "발견된 이슈" 추가

Step 2: 영향 범위 파악
├─ Stage 1 영향: 패밀리/NFR 수정 필요?
├─ Stage 2 영향: 제약/충돌 분석 수정 필요?
├─ 재작업 예상: [X]시간
└─ 기록 완료

Step 3: 해당 Stage로 이동 → 수정
├─ 01C-01 또는 02C-01 수정
├─ 버전 업데이트
└─ 수정 검증

Step 4: Stage 3 재진행
├─ 수정된 입력으로 ADR 재검토
├─ 관련 ADR 업데이트
└─ 일관성 확인

Step 5: 검증
├─ 오류 해결 확인
└─ Stage 4 전달 가능 ✅
```

### 흔한 오류 패턴

| 오류 유형 | 예시 | 해결 |
|----------|------|------|
| NFR 충돌 누락 | 성능 vs 보안 충돌 미식별 | Stage 2 충돌 분석 추가 |
| 제약 미반영 | 예산으로 SaaS 불가인데 ADR에 SaaS 선택 | Stage 2 제약 재검토 |
| 패밀리 불일치 | 실시간 패밀리인데 배치 DB 선택 | Stage 1 재검토 또는 ADR 수정 |

### 추적성

```
수정 이력 파일: docs/revision_log.md

기록 형식:
## [날짜] Stage 3 → Stage [N] 수정
- **발견 ADR**: ADR-[NNN]
- **오류**: [오류 내용]
- **수정 Stage**: Stage [N]
- **수정 내용**: [구체적 수정]
- **영향 ADR**: [재검토 필요한 ADR 목록]
- **검증**: [검증 결과]
```

---

## 📚 참고 문서

| 문서 | 용도 |
|------|------|
| `01_DNA_METHODOLOGY_DETAILED.md` Part 4 | Stage 3 상세 원리 |
| `IMPLEMENTATION_CASES.md` | ADR 실전 사례 |
| `./standards/01_STAGE_STRUCTURE.md` | Stage 간 연결 구조 |

---

## 💡 핵심 원칙 요약

```
ADR 작성의 3가지 원칙:

1. "왜"를 기록
   - 코드는 "무엇"을 보여줌
   - ADR은 "왜"를 설명
   - 나중에 질문에 답할 수 있어야 함

2. 대안을 기록
   - 선택한 것만 기록 ❌
   - 검토한 대안과 거부 이유도 기록 ✅
   - 재검토 시 불필요한 반복 방지

3. 결과를 예측
   - 긍정적 영향
   - 트레이드오프
   - 부정적 영향과 완화 방안
```

```
카테고리 분류 원칙:

1. 외부 제약: "변경 불가, 따라야 함"
2. 충돌 해결: "둘 다 원하지만 선택해야 함"
3. 기술 스택: "여러 대안 중 하나 선택"
4. 도메인 기술: "직접 설계해야 함"
5. DNA 시스템: "전체에 영향, 일관성 핵심"
```

---

**버전 이력**:
- v5.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
- v3.0 (2025-11-13): Stage 3 분리
- v2.0 (2025-11-12): ADR 유형 구분
- v1.0 (2025-11-10): 초기 버전


================================================================================

📄 FILE: 04G-00_dna_planning_guide.md
--------------------------------------------------------------------------------

# Stage 4: DNA 시스템 청사진 가이드 (DNA Blueprint Guide)

> **목적**: Stage 3 ADR 기반으로 DNA 시스템 11개의 설계 청사진 작성
>
> **버전**: v4.1 (2025-12-03)
>
> - v4.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
> - v1.0 (2025-11-13): 초기 버전

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage 4 실행 가이드) ← 지금 여기!
```

**참조 문서**:
- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` Part 5
- **DNA 상세**: `standards/03_DNA_SYSTEMS_GUIDE.md`

---

## 🧬 DNA 방법론 4대 핵심 원칙 (Stage 4 적용)

> **"AI가 한 세션에서 최고 성과를 낼 수 있는 크기로 작업하고, 완전해질 때까지 반복하며, 오류 발견 시 되돌아가서 수정한다"**

Stage 4 (DNA 시스템 청사진)에서 DNA 4대 핵심 원칙이 적용되는 방식:

---

### DNA 핵심 원칙 1: AI 최적 크기

**"컨텍스트 범위 내에서 작업한다"**

#### Stage 4의 작업 크기 전략

```
❌ 잘못된 접근: 11개 DNA 시스템 청사진 한 번에
"11개 DNA 시스템 청사진을 한 세션에서 모두 작성하세요"
→ 컨텍스트 초과 (200K 토큰 한계)
→ 후반부 청사진 품질 저하 (상세도 감소)
→ 시스템 간 일관성 부족

✅ 올바른 접근: 시스템 유형별 순차 작성
Session 1: 기초 시스템 (Logging + Types)
Session 2: 데이터 시스템 (Database + Cache)
Session 3: 통신 시스템 (Messaging + API Gateway)
Session 4: 보안/운영 시스템 (Security + Monitoring)
Session 5: 설정/테스트/에러 (Config + Testing + Error)

각 세션: 2-3개 시스템, 80-90K 토큰 범위
```

#### 컨텍스트 구성 (각 세션)

```
AI 컨텍스트 윈도우 (예: 200K 토큰):
├─ 시스템 프롬프트: ~30K 토큰
├─ 대화 히스토리: ~20K 토큰
├─ Stage 3 참조 문서: ~30-40K 토큰
│   ├─ 03A-401_dna_logging.md (ADR)
│   ├─ 03A-402_dna_types.md (ADR)
│   └─ 03A-000_adr_index.md (인덱스)
├─ DNA 시스템 가이드: ~20K 토큰
│   └─ standards/03_DNA_SYSTEMS_GUIDE.md (해당 섹션)
├─ 작업 중 청사진 작성: ~20K 토큰 (2-3개 × 8-10K)
└─ 응답 생성 여유: ~80K 토큰
```

#### 세션당 작업량 기준

| 세션 | DNA 시스템 | 청사진 크기 | 총 토큰 |
|-----|-----------|-----------|---------|
| Session 1 | Logging, Types | 각 8-10K | ~20K |
| Session 2 | Database, Cache | 각 10-12K | ~24K |
| Session 3 | Messaging, API Gateway | 각 8-10K | ~20K |
| Session 4 | Security, Monitoring | 각 8-10K | ~20K |
| Session 5 | Config, Testing, Error | 각 6-8K | ~21K |

**핵심**: 한 세션에 2-3개 DNA 시스템 청사진이 최적

#### 그룹화 원칙: 의존성 기반

```
그룹 1: 기초 (Foundation)
├─ Logging: 로그 출력
└─ Types: 타입 정의
  → 다른 모든 시스템이 의존

그룹 2: 데이터 (Data)
├─ Database: 영구 저장
└─ Cache: 임시 저장
  → 비즈니스 로직이 의존

그룹 3: 통신 (Communication)
├─ Messaging: 비동기 통신
└─ API Gateway: HTTP 통신
  → 외부 연동이 의존

그룹 4: 보안/운영 (Security/Ops)
├─ Security: 인증/인가
└─ Monitoring: 관찰성
  → 프로덕션 배포 필수

그룹 5: 지원 (Support)
├─ Config: 설정 관리
├─ Testing: 테스트 도구
└─ Error: 에러 처리
  → 개발/배포 지원
```

---

### DNA 핵심 원칙 2: 완전해질 때까지 반복

**"부족하면 반복해서 부족함이 없어질 때까지"**

#### DNA 시스템 청사진 완전성 기준

각 DNA 시스템 청사진은 다음을 모두 포함해야 함:

```
✅ 완전한 DNA 청사진 체크리스트:
□ 1. 목적 및 범위 (Purpose & Scope)
   - 이 시스템이 해결하는 문제
   - 담당 범위와 책임
   - 다른 시스템과의 경계

□ 2. 공개 API (Public API)
   - 함수/클래스 시그니처
   - 입력/출력 타입
   - 사용 예시 (코드)

□ 3. 디렉토리 구조 (Directory Structure)
   - 파일 목록과 역할
   - 모듈 간 의존성
   - 명명 규칙

□ 4. 핵심 설계 결정 (Design Decisions)
   - ADR 참조 (명시적)
   - 아키텍처 패턴
   - 성능/보안 고려사항

□ 5. 의존성 (Dependencies)
   - 외부 라이브러리 (버전 명시)
   - 다른 DNA 시스템 의존
   - 순환 의존성 없음 보장

□ 6. 테스트 전략 (Testing Strategy)
   - 단위 테스트 범위
   - 통합 테스트 시나리오
   - 목표 커버리지 (95%+)

□ 7. 구현 우선순위 (Implementation Priority)
   - 어떤 파일부터 구현?
   - 의존성 순서
   - Stage 5 작업 단위
```

#### 3단계 검증 프로토콜

**검증 프로토콜 (의사코드)**:

```python
def validate_dna_blueprint_session(blueprints: list[Blueprint]) -> ValidationResult:
    """DNA 청사진 세션 완전성 검증."""

    # 검증 1: 각 청사진 구조 검증
    for bp in blueprints:
        if not all([
            bp.has_purpose_and_scope(),
            bp.has_public_api(),
            bp.has_directory_structure(),
            bp.has_design_decisions(),
            bp.has_dependencies(),
            bp.has_testing_strategy(),
            bp.has_implementation_priority()
        ]):
            return ValidationResult(
                passed=False,
                message=f"Blueprint {bp.name}: 7개 섹션 중 누락 발견",
                action="해당 청사진 재작성"
            )

    # 검증 2: 의존성 일관성 검증
    for bp in blueprints:
        for dep in bp.dependencies:
            if dep not in [b.name for b in blueprints] and not dep.startswith("external:"):
                return ValidationResult(
                    passed=False,
                    message=f"Blueprint {bp.name}: 정의되지 않은 의존성 {dep}",
                    action="의존성 추가 또는 제거"
                )

    # 검증 3: ADR 추적성 검증
    for bp in blueprints:
        if not bp.has_adr_references():
            return ValidationResult(
                passed=False,
                message=f"Blueprint {bp.name}: ADR 참조 누락",
                action="Stage 3 ADR 참조 추가"
            )

    # 검증 4: 순환 의존성 검증
    if has_circular_dependency(blueprints):
        return ValidationResult(
            passed=False,
            message="순환 의존성 발견",
            action="의존성 방향 재설계"
        )

    return ValidationResult(passed=True)
```

#### 불완전 → 재작성 사례

```markdown
## 사례: DNA Observability System (Logging) 청사진

### ❌ 불완전한 버전 (1차 작성)
**목적**: 로그를 기록한다
**API**: `log(message)`
**구조**: 로깅 모듈 하나

❌ 문제점:
- 범위 불명확 (콘솔? 파일? 외부 전송?)
- API 너무 단순 (레벨은? 컨텍스트는?)
- 구조 불충분 (설정은? 포맷터는?)
- ADR 참조 없음
- 의존성 명시 없음
- 테스트 전략 없음
- 구현 순서 없음

### ✅ 완전한 버전 (2차 재작성)

#### 1. 목적 및 범위
**문제**: 분산 시스템에서 추적 가능한 구조화된 로그 필요
**범위**:
- 구조화된 로그 (JSON/structured format)
- 컨텍스트 자동 추가 (request_id, user_id 등)
- 다중 출력 (콘솔 + 파일 + 클라우드)
**제외**: 로그 수집/분석 (외부 시스템)

#### 2. 공개 API (개념)
```
기본 사용:
├─ get_logger(module_name) → logger
├─ logger.info(message, context_data)
├─ logger.warning(message, context_data)
└─ logger.error(message, context_data)

컨텍스트 바인딩:
└─ logger.bind(key=value) → 이후 로그에 자동 포함

예외 로깅:
└─ logger.exception(message) → 자동 스택트레이스 포함
```

#### 3. 디렉토리 구조 (개념)
```
core/logging/
├─ [entry point]         # 공개 API 제공
├─ [logger impl]         # Logger 구현
├─ [config]              # 설정 (레벨, 포맷)
├─ [formatters]          # JSON/Console 포맷터
├─ [handlers]            # File/Cloud 핸들러
└─ [context]             # Context 관리
```

#### 4. 핵심 설계 결정
- **Ref**: ADR-401 (로깅 도구 선택)
- **패턴**: Singleton Logger Factory
- **성능**: 비동기 파일 쓰기

#### 5. 의존성
- External: [로깅 라이브러리] (ADR-401 참조)
- External: [비동기 I/O 라이브러리] (필요 시)
- DNA: Type System (LogLevel 타입)

#### 6. 테스트 전략
- 단위: 각 포맷터/핸들러 격리 테스트
- 통합: 전체 로그 파이프라인 E2E 테스트
- 커버리지: 95%+

#### 7. 구현 우선순위
1. LogLevel 타입 정의 - 기초
2. 설정 모듈 - 설정
3. 포맷터 - 핵심
4. Logger 구현 - 핵심
5. Context 관리 - 고급
6. 핸들러 - 확장

**참조**: 구체적 파일명/코드는 언어별 매뉴얼 참조
```

---

### DNA 핵심 원칙 3: 기능별 분해 + 연결부 + 조립

**"모듈이 크면 기능별로 나누고, 연결부 설계 후 조립"**

#### Stage 4에서의 적용

Stage 4는 "청사진 설계" 단계이므로 원칙 3은 **계획 차원**에서 적용됩니다.

```
DNA 시스템 크기 판단:
├─ 작은 시스템 (< 5 파일): 한 번에 청사진 작성
│   예: Types, Config, Error
│
├─ 중간 시스템 (5-10 파일): 청사진에서 모듈 명시
│   예: Logging, Cache, Testing
│   청사진: 모듈별 섹션 분리
│
└─ 큰 시스템 (10+ 파일): 청사진을 모듈별로 분할
    예: Database (Connection + Session + Query + Migration)
    청사진: 각 모듈별 별도 섹션 + 연결부 명시
```

#### 큰 DNA 시스템 청사진 분해 전략

```markdown
## 사례: DNA Database 시스템 (큰 시스템)

### 청사진 구조 (모듈별 분해)

#### Module 1: Connection Pool
**책임**: 데이터베이스 연결 관리
**파일**: `connection.py`
**공개 API**:
- `get_connection_pool() -> Pool`
- `close_pool()`

#### Module 2: Session Manager
**책임**: 트랜잭션 세션 관리
**파일**: `session.py`
**공개 API**:
- `get_session() -> AsyncSession`
- `begin_transaction()`

#### Module 3: Query Builder
**책임**: 타입 안전한 쿼리 빌더
**파일**: `query.py`
**공개 API**:
- `select(model: Type[T]) -> Query[T]`
- `insert(model: T) -> None`

#### Module 4: Migration
**책임**: 스키마 버전 관리
**파일**: `migration.py`
**공개 API**:
- `migrate_up()`
- `migrate_down()`

### 연결부 설계 (Interface/Protocol)

```
연결부: 인터페이스 기반 설계
─────────────────────────────────

ConnectionProvider (인터페이스):
├─ get_connection() → Connection
└─ 목적: 연결 제공 추상화

SessionProvider (인터페이스):
├─ get_session() → Session
└─ 목적: 세션 제공 추상화

모듈 간 의존성:
├─ Module 1 구현 → ConnectionProvider
├─ Module 2 구현 → SessionProvider
├─ Module 3은 SessionProvider 의존
└─ Module 4는 ConnectionProvider 의존

**참조**: 언어별 인터페이스 구현 방법은 매뉴얼 참조
  - Python: Protocol, ABC
  - TypeScript: interface
  - Rust: trait
  - Go: interface
```

### Stage 5 구현 계획 (조립 전략)

```
Task 001: Connection Pool 구현
├─ connection.py 작성
├─ ConnectionProvider 구현
└─ 테스트 (Mock 없음, 실제 Pool)

Task 002: Session Manager 구현
├─ session.py 작성
├─ SessionProvider 구현
├─ ConnectionProvider Mock 사용
└─ 테스트

Task 003: Query Builder 구현
├─ query.py 작성
├─ SessionProvider Mock 사용
└─ 테스트

Task 004: Migration 구현
├─ migration.py 작성
├─ ConnectionProvider Mock 사용
└─ 테스트

Task 999: Database 통합 (조립)
├─ 실제 구현체로 Mock 교체
├─ 통합 테스트 (E2E)
└─ 성능 테스트
```
```

#### 작은 DNA 시스템 청사진 전략

```markdown
## 사례: DNA Types 시스템 (작은 시스템)

### 단일 청사진 (분해 불필요)

#### 목적
타입 안전성 보장을 위한 공통 타입 정의

#### 디렉토리 구조
```
src/core/types/
├─ __init__.py
├─ ids.py        # UserId, OrderId 등
├─ enums.py      # Status, Level 등
└─ models.py     # BaseModel, DTO 등
```

#### 구현 계획 (한 번에)
Task 001: DNA Types 전체 구현
├─ ids.py, enums.py, models.py 모두 작성
├─ 테스트 전체
└─ 완료 (분해 불필요)
```

---

### DNA 핵심 원칙 4: 역방향 수정 프로토콜

**"앞선 결정의 오류 발견 시 → 되돌아가서 수정 → 다시 현재까지 진행"**

#### Stage 4에서 역방향 수정이 발생하는 경우

```
시나리오 1: Stage 3 ADR 오류 발견
├─ Stage 4 청사진 작성 중
├─ ADR-401 (로깅 도구 선택) 제약 발견
│   예: 선택된 도구가 특정 플랫폼에서 문제 발견
├─ → Stage 3로 돌아가 ADR-401 수정
├─ → Stage 4 청사진 재작성
└─ → 추적성 업데이트

시나리오 2: Stage 5에서 청사진 불완전 발견
├─ Stage 5 Observability 구현 중
├─ 청사진에 비동기 로그 쓰기 누락 발견
├─ → Stage 4로 돌아가 청사진 보완
├─ → Stage 5 구현 재진행
└─ → 추적성 업데이트
```

#### 6단계 수정 프로토콜

```markdown
## 실제 사례: DNA Database 청사진 수정

### Step 1: 오류 발견 및 문서화
**발견 시점**: Stage 4 (Data System 청사진 작성 중)
**파일**: `04B-01_dna_blueprint.md`
**문제**: ADR-201에서 "[DB-A]"인데, 청사진에 "[DB-B]" 언급

### Step 2: 영향 범위 파악
**영향받는 문서**:
- Stage 3: `03A-402_database_selection.md` (확인 필요)
- Stage 4: `04D-02_dna_database_blueprint.md` (현재)

**영향받는 구현**: 없음 (아직 구현 전)

### Step 3: 해당 Stage로 이동 및 수정
```bash
# Stage 3 ADR 재확인
$ cat 03A-402_database_selection.md
  → "PostgreSQL 13+" 맞음

# Stage 4 청사진 수정
$ edit 04D-02_dna_database_blueprint.md
  Line 45: MySQL → PostgreSQL로 수정
  Line 67: MySQL 전용 기능 제거
  Line 89: PostgreSQL 전용 기능 추가 (JSONB, Full-text search)
```

### Step 4: 중간 Stage 전파
Stage 5 아직 시작 안 함 → 전파 불필요

### Step 5: 현재 Stage 재진행
```bash
# Stage 4 청사진 재검토
$ review 04D-02_dna_database_blueprint.md
  - PostgreSQL 전용 기능 반영 확인
  - ADR-402 참조 업데이트
  - 의존성에 psycopg3 추가
```

### Step 6: 재진행 결과 검증
**검증 항목**:
- [ ] ADR-402 "PostgreSQL 13+" 확인
- [ ] 청사진 7개 섹션 완전
- [ ] MySQL 언급 모두 제거
- [ ] PostgreSQL 전용 기능 추가
- [ ] 추적성 명시 (Ref: ADR-402)
```

#### 추적성 (Traceability) 유지

**모든 수정은 명시적으로 참조**:

```markdown
## Stage 3 ADR (03A-402_database_selection.md)
**결정**: PostgreSQL 13+ 사용
**날짜**: 2024-11-10

## Stage 4 청사진 (04D-02_dna_database_blueprint.md)
Line 1: # DNA Database 시스템 청사진
Line 2: # Ref: ADR-402 (PostgreSQL 13+)
Line 3:
Line 4: > **History**:
Line 5: > - v1.0 (2024-11-10): 초기 작성
Line 6: > - v1.1 (2024-11-11): MySQL → PostgreSQL 수정 (ADR 불일치 발견)

Line 45: ## 데이터베이스 엔진
Line 46: **선택**: PostgreSQL 13+
Line 47: **Ref**: ADR-402 (Line 23-45)
Line 48: **전용 기능**:
Line 49: - JSONB 타입
Line 50: - Full-text search
Line 51: - Row-level security

## Stage 5 구현 (src/core/database/)
Line 1: # Ref: 04D-02_dna_database_blueprint.md
Line 2: # Updated: 2024-11-11 (PostgreSQL 전용 기능 반영)
```

---

## 🎯 DNA 원칙 적용 요약 (Stage 4)

| 원칙 | Stage 4 적용 방법 | 체크포인트 |
|------|------------------|-----------|
| **1. AI 최적 크기** | 시스템 유형별 세션 분리 (2-3개/세션) | 세션당 80-90K 토큰 |
| **2. 완전해질 때까지** | 7개 섹션 완전성, 4단계 검증 | 모든 청사진 7 sections |
| **3. 기능별 분해** | 큰 시스템은 모듈별 분해 + Protocol | Protocol + Mock + 조립 |
| **4. 역방향 수정** | 6단계 프로토콜, 추적성 유지 | History/Ref 명시 |

---

## 🤔 왜 DNA 시스템 청사진이 필요한가?

### Bridge의 의미: "Gap이 아니라 다리"

```
기존 오해:
├─ Stage 3 (ADR) 완료
├─ ???
├─ ???
├─ ???
└─ Stage 7 (Blueprint) 시작

→ "Stage 4-6은 뭐하는 거지? 그냥 넘어가도 되나?"

실제:
┌─────────────────────────────────────────────────────────┐
│ Stage 4-6 = Bridge (다리)                               │
│                                                         │
│ ADR (결정) ──────────────────────→ Blueprint (설계)     │
│             ↑                   ↑                       │
│             │    Stage 4-6     │                       │
│             │                   │                       │
│             └───────────────────┘                       │
│                                                         │
│ 결정을 "실행 가능한 환경"으로 변환하는 단계             │
└─────────────────────────────────────────────────────────┘
```

### 비유: 집 짓기

```
ADR = "서울에서 부산 가기로 결정" (결정)
Bridge = "KTX 티켓 구매, 역 도착" (준비)
Blueprint = "출발역, 환승, 도착역 계획" (상세 계획)

ADR = "콘크리트 기초로 결정" (결정)
Bridge = "콘크리트 배합, 거푸집 준비" (환경 구축)
Blueprint = "각 방의 기초 위치와 크기" (상세 설계)
```

### DNA 시스템 = 환경/플랫폼

```
┌─────────────────────────────────────────────────────────┐
│                    도메인 코드                          │
│  (Stage 7-9에서 구현)                                   │
│                                                         │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐                   │
│  │ 주문    │ │ 계좌    │ │ 시세    │  ← 비즈니스 로직  │
│  │ 서비스  │ │ 서비스  │ │ 서비스  │                   │
│  └────┬────┘ └────┬────┘ └────┬────┘                   │
│       │          │          │                          │
│  ═════╪══════════╪══════════╪═══════════════════════   │
│       │          │          │                          │
│  ┌────┴──────────┴──────────┴────┐                     │
│  │        DNA 시스템 (환경)       │                     │
│  │  (Stage 4-6에서 구축)          │                     │
│  │                                │                     │
│  │  logging / config / types     │                     │
│  │  database / cache / messaging │                     │
│  │  testing / monitoring / auth  │                     │
│  └────────────────────────────────┘                     │
└─────────────────────────────────────────────────────────┘

핵심:
├─ DNA가 먼저 구축되어야 도메인이 일관되게 구현됨
├─ 도메인은 DNA를 "사용"만 함 (직접 구현 X)
└─ DNA 변경 = 전체 영향 (신중해야)
```

---

## 📥 입력 문서

### Stage 3에서 전달받는 것

| 파일 | 핵심 내용 | 이 Stage에서 사용 |
|------|----------|-----------------|
| `03A-401~499_*.md` | DNA 시스템 ADR | 각 시스템 설계 근거 |
| `03A-201~299_*.md` | 기술 스택 ADR | 구현 기술 선택 |
| `03A-000_adr_index.md` | ADR 목록 | 전체 결정 참조 |

---

## 📤 출력 문서

### 필수 산출물

```
docs/
├── 04B-01_dna_blueprint.md        # DNA 시스템 청사진 (통합)
└── 04B-02_dna_directory.md        # 디렉토리 구조 상세

또는 시스템별 분리:
docs/dna-blueprint/
├── 04B-00_overview.md             # 전체 개요
├── 04B-01_logging.md              # 로깅 시스템
├── 04B-02_config.md               # 설정 시스템
├── 04B-03_types.md                # 타입 시스템
├── 04B-04_errors.md               # 에러 처리
├── 04B-05_database.md             # 데이터베이스
├── 04B-06_cache.md                # 캐시
├── 04B-07_messaging.md            # 메시징
├── 04B-08_testing.md              # 테스팅
├── 04B-09_monitoring.md           # 모니터링
├── 04B-10_security.md             # 보안
└── 04B-11_api_gateway.md          # API 게이트웨이
```

---


## 🧬 DNA 11개 시스템

> **참조**: `standards/03_DNA_SYSTEMS_GUIDE.md` - 언어 무관 개념 및 상세 설명

### 시스템 개요

```
┌──────────────────────────────────────────────────────────┐
│                  DNA 11개 시스템                         │
│              (언어 무관 - Language Agnostic)              │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  핵심 인프라 (4개):                                      │
│  ├─ 1. Type System: 타입 안전성 보장                    │
│  ├─ 2. Observability System: 로깅/메트릭/추적           │
│  ├─ 3. Testing System: 품질 보증                        │
│  └─ 4. Code Quality System: 일관된 스타일               │
│                                                          │
│  아키텍처/설정 (3개):                                    │
│  ├─ 5. Architecture Enforcement: 경계 유지              │
│  ├─ 6. Configuration System: 설정 관리                  │
│  └─ 7. Error Handling System: 에러 처리                 │
│                                                          │
│  성능/통신/데이터/보안 (4개):                            │
│  ├─ 8. Performance System: 성능 측정                    │
│  ├─ 9. API System: 인터페이스/통신                      │
│  ├─ 10. Data System: 저장/조회                          │
│  └─ 11. Security System: 인증/인가                      │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

### 시스템별 상세

| # | 시스템 | 목적 | ADR 참조 | 디렉토리 예시 |
|---|--------|------|---------|-------------|
| 1 | Type System | 타입 안전성, 런타임 에러 방지 | ADR-301 | `core/types/` |
| 2 | Observability System | 시스템 상태 관찰, 디버깅 | ADR-401, ADR-901 | `core/logging/`, `core/monitoring/` |
| 3 | Testing System | 품질 보증, 95%+ 커버리지 | ADR-801 | `tests/` |
| 4 | Code Quality System | 일관된 스타일, 자동 검증 | ADR-302 | `.pre-commit-config.yaml` |
| 5 | Architecture Enforcement | Layer 경계, 의존성 제어 | ADR-102 | `.importlinter` |
| 6 | Configuration System | 환경 변수, 의존성 관리 | ADR-601 | `core/config/` |
| 7 | Error Handling System | 에러 타입, 일관된 처리 | ADR-701 | `core/errors/` |
| 8 | Performance System | 벤치마크, 프로파일링 | ADR-902 | `benchmarks/` |
| 9 | API System | 인터페이스 정의, 통신 | ADR-501 | `api/` |
| 10 | Data System | 데이터 접근, 캐싱, 메시징 | ADR-201, ADR-202 | `core/database/`, `core/cache/` |
| 11 | Security System | 인증, 인가, 입력 검증 | ADR-1001 | `core/security/` |

---

## 🎯 패밀리별 DNA 시스템 선택

### 모든 패밀리 공통 (필수 5개)

```
항상 필요 (언어/프로젝트 무관):
├─ 1. Type System (타입 안전성 필수)
├─ 2. Observability System (디버깅 불가능 방지)
├─ 3. Testing System (품질 보증 필수)
├─ 4. Code Quality System (일관성 유지)
└─ 7. Error Handling System (에러 처리 표준화)
```

### 패밀리별 선택 가이드

| DNA 시스템 | A-A-B (CRUD) | B-C-A (스트리밍) | B-A-A (협업) | B-B-B (검색) |
|-----------|-------------|----------------|-------------|-------------|
| 5. Architecture Enforcement | ✅ 권장 | ✅ 권장 | ✅ 권장 | ✅ 권장 |
| 6. Configuration System | ✅ 필수 | ✅ 필수 | ✅ 필수 | ✅ 필수 |
| 8. Performance System | ✅ 권장 | ✅ 필수 | ✅ 권장 | ✅ 권장 |
| 9. API System | ✅ 필수 | ✅ 필수 | ✅ 필수 | ✅ 필수 |
| 10. Data System | ✅ 필수 | ⚠️ 선택 | ✅ 필수 | ⚠️ 선택 |
| 11. Security System | ✅ 필수 | ⚠️ 선택 | ✅ 필수 | ⚠️ 선택 |

**범례**: ✅ 필수 / ⚠️ 프로젝트에 따라 선택

### 패밀리별 특화 설정

**A-A-B (CRUD/트랜잭션)** - 예: 주식 거래 플랫폼
```
필수: 전체 11개 (금융 서비스 특성)
├─ Data System: ACID 트랜잭션 필수
├─ Security System: 필수 (금융 규제)
├─ Observability System: 감사 추적 필수
└─ Performance System: 응답 시간 모니터링
```

**B-C-A (실시간 스트리밍)** - 예: IoT 센서 데이터
```
필수: 9개 (Data System, Security System 선택)
├─ Data System: 스트림 처리 (메시징)
├─ Performance System: 지연 모니터링 필수
├─ Observability System: 분산 추적
└─ API System: 실시간 통신 (WebSocket)
```

**B-A-A (협업/동기화)** - 예: 실시간 문서 편집
```
필수: 10개 이상
├─ Data System: 상태 저장 + 캐싱
├─ API System: 실시간 동기화
├─ Security System: 사용자 인증 필수
└─ Performance System: 동시성 모니터링
```

---


## 📋 청사진 작성 방법

### Part 1: 시스템 선택 결정

```
Step 1: 패밀리 확인
─────────────────────────────────
01C-01_family.md에서 패밀리 확인
→ A-A-B (CRUD/트랜잭션)

Step 2: 필수/선택 시스템 결정
─────────────────────────────────
필수 (공통 5개):
- Logging, Config, Types, Error, Testing

필수 (패밀리별):
- Database (A-A-B이므로)
- Security (금융이므로)
- API Gateway (웹 서비스이므로)

선택:
- Cache (읽기 최적화 원함 → 포함)
- Monitoring (운영 필수 → 포함)
- Messaging (MVP 이후 → 제외)

Step 3: ADR 확인
─────────────────────────────────
ADR-301: 타입 도구 선택
ADR-401: 로깅 도구 선택
ADR-701: 에러 처리 전략
ADR-201: 데이터 저장소 선택
ADR-202: 캐싱 전략 선택

Step 4: 청사진 포맷 결정
─────────────────────────────────
**통합 청사진 (04B-01_dna_blueprint.md)** vs **분리 청사진 (04B-00~11_*.md)**

통합 청사진 사용 조건:
├─ DNA 시스템 < 5개
├─ 프로젝트 규모 작음 (MVP)
└─ 한 세션에서 전체 청사진 작성 가능

분리 청사진 사용 조건:
├─ DNA 시스템 5-7개
├─ 프로젝트 규모 중간 이상
├─ 세션별로 나눠 작성 필요
└─ 시스템별 독립 유지보수 필요

대규모 프로젝트 (8+ 시스템):
└─ 분리 청사진 필수
    ├─ 04B-00_overview.md (전체 개요)
    ├─ 04B-01~11_*.md (시스템별)
    └─ 각 세션 2-3개 시스템씩

권장:
├─ 첫 프로젝트: 통합 청사진 (간단함)
└─ 운영 프로젝트: 분리 청사진 (유지보수성)
```

---

### Part 2: 디렉토리 구조 설계

**참조**: 언어/프레임워크별 구조는 해당 언어 매뉴얼 참조

```
Step 1: 기본 구조 결정
─────────────────────────────────
프로젝트 루트/
├── src/ (또는 lib/, pkg/)      # 소스 코드
│   ├── core/                   # DNA 시스템
│   ├── domain/                 # 도메인 로직 (Stage 7-9)
│   └── api/                    # API 레이어 (Stage 7-9)
│
├── tests/                      # 테스트 코드
│   ├── unit/                   # 단위 테스트
│   └── integration/            # 통합 테스트
│
└── docs/                       # 문서

Step 2: core/ 상세 구조
─────────────────────────────────
src/core/
├── types/              # Type System (ADR-301)
├── logging/            # Observability System (ADR-401)
├── monitoring/         # Observability System (ADR-901)
├── config/             # Configuration System (ADR-601)
├── errors/             # Error Handling System (ADR-701)
├── database/           # Data System (ADR-201)
├── cache/              # Data System (ADR-202)
├── security/           # Security System (ADR-1001)
└── performance/        # Performance System (ADR-902)
```

---

### Part 3: 인터페이스 설계

각 DNA 시스템의 **공개 API 원칙**을 정의합니다.

```
1. Type System
─────────────────────────────────
목적: 타입 안전한 도메인 모델 제공
공개 API:
├─ 공통 타입 (ID, Value Object)
├─ 도메인 모델 베이스
└─ 타입 검증 함수

2. Observability System
─────────────────────────────────
목적: 로깅, 메트릭, 추적 통합
공개 API:
├─ get_logger(name) → 로거 반환
├─ log(level, message, context) → 구조화된 로그
└─ trace_context() → trace_id 전파

3. Configuration System
─────────────────────────────────
목적: 환경별 설정 관리
공개 API:
├─ get_config(key) → 설정 값
├─ validate_config() → 설정 검증
└─ reload_config() → 동적 리로드

4. Error Handling System
─────────────────────────────────
목적: 일관된 에러 처리
공개 API:
├─ 에러 타입 (NotFound, Validation, etc.)
├─ error_to_response() → 에러 변환
└─ log_error() → 에러 로깅

5. Data System
─────────────────────────────────
목적: 데이터 접근 추상화
공개 API:
├─ get_connection() → DB 연결
├─ transaction() → 트랜잭션 관리
└─ cache(key, value) → 캐싱

6. Security System
─────────────────────────────────
목적: 인증/인가
공개 API:
├─ authenticate() → 인증
├─ authorize(role) → 인가
└─ validate_input() → 입력 검증

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조
```

---

### Part 4: 구현 순서 결정

의존성 기반으로 구현 순서를 결정합니다.

```
의존성 그래프:
─────────────────────────────────

Types (의존성 없음)
   ↓
Config (Types 의존)
   ↓
Logging (Config, Types 의존)
   ↓
Error (Types, Logging 의존)
   ↓
Database (Config, Types, Error 의존)
   ↓
Cache (Config, Types, Error 의존)
   ↓
Security (Config, Types, Error, Database 의존)
   ↓
Testing (전체 의존)
   ↓
Monitoring (Logging, Config 의존)
   ↓
API Gateway (전체 의존)

권장 구현 순서:
─────────────────────────────────
1. Types      → 의존성 없음, 먼저 구현
2. Config     → Types만 의존
3. Logging    → Config, Types 의존
4. Error      → Types, Logging 의존
5. Testing    → 위 4개 테스트 가능해야
6. Database   → 위 4개 + Testing
7. Cache      → 위 4개 + Testing
8. Security   → 위 전체
9. Monitoring → Logging, Config
10. API GW    → 전체 통합
```

---


## 📋 청사진 템플릿

### 04B-01_dna_blueprint.md 템플릿

```markdown
# DNA 시스템 청사진

**프로젝트**: [프로젝트명]
**패밀리**: [패밀리 코드] ([패밀리명])
**작성일**: YYYY-MM-DD

**참조**: standards/03_DNA_SYSTEMS_GUIDE.md (시스템별 상세 설명)

---

## 1. 선택된 DNA 시스템

### 1.1 필수 시스템 (공통)

| # | 시스템 | 목적 | ADR 참조 |
|---|--------|------|---------|
| 1 | Type System | 타입 안전성, 런타임 에러 방지 | ADR-301 |
| 2 | Observability System | 로깅, 메트릭, 분산 추적 | ADR-401, ADR-901 |
| 3 | Testing System | 품질 보증, 95%+ 커버리지 | ADR-801 |
| 4 | Code Quality System | 일관된 스타일, 품질 유지 | ADR-302, ADR-303 |

### 1.2 필수 시스템 (패밀리)

| # | 시스템 | 목적 | ADR 참조 | 선택 근거 |
|---|--------|------|---------|----------|
| 5 | Architecture Enforcement | 레이어 경계, 의존성 제어 | ADR-501 | 복잡도 관리 |
| 10 | Data System | DB, 캐시, 메시징 | ADR-201, ADR-204 | 데이터 관리 |
| 11 | API System | 인터페이스 정의, 프로토콜 | ADR-202 | 통신 표준화 |

### 1.3 선택 시스템

| # | 시스템 | 목적 | ADR 참조 | 선택 근거 |
|---|--------|------|---------|----------|
| 6 | Configuration System | 환경별 설정 관리 | ADR-601 | 환경 분리 |
| 8 | Performance System | 벤치마킹, 프로파일링 | ADR-701 | 성능 기준 |

### 1.4 제외 시스템

| # | 시스템 | 제외 근거 | 추가 시점 |
|---|--------|----------|----------|
| 7 | Error Handling System | 기본 예외 처리로 충분 | Phase 2 |
| 9 | Security System | MVP 범위 외 | Phase 3 |

---

## 2. 디렉토리 구조

```
src/
├── core/                    # DNA 시스템 모듈
│   ├── types/              # Type System
│   ├── logging/            # Observability System (Logging)
│   ├── monitoring/         # Observability System (Metrics)
│   ├── config/             # Configuration System
│   ├── errors/             # Error Handling System
│   ├── database/           # Data System (DB)
│   ├── cache/              # Data System (Cache)
│   └── security/           # Security System
├── domain/                 # 도메인 로직
└── api/                    # API 레이어

tests/
├── unit/                   # 단위 테스트
├── integration/            # 통합 테스트
└── conftest.py            # 테스트 공통 설정

**참조**: 구체적 파일명/확장자는 언어별 매뉴얼 참조
```

---

## 3. 각 시스템 상세

### 3.1 Type System

**ADR 참조**: ADR-301 (타입 도구 선택)

**디렉토리**: `core/types/`

**목적**:
- 타입 안전한 도메인 모델 제공
- 런타임 에러 방지
- IDE 자동완성 지원

**공개 API (개념)**:
```
├─ 공통 타입 (ID, Value Object)
├─ 도메인 모델 베이스
└─ 타입 검증 함수
```

**설정**:
- 개발: Strict mode, 모든 타입 체크
- 운영: 런타임 검증 추가

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조

---

### 3.2 Observability System

**ADR 참조**: ADR-401 (로깅 도구), ADR-901 (모니터링 도구)

**디렉토리**: `core/logging/`, `core/monitoring/`

**목적**:
- 구조화된 로깅 (JSON/structured)
- 분산 추적 (trace_id)
- 성능 메트릭 수집

**공개 API (개념)**:
```
로깅:
├─ get_logger(name) → logger instance
├─ logger.info/warning/error(message, **context)
└─ context binding (trace_id, user_id)

메트릭:
├─ counter(name, labels)
├─ histogram(name, value)
└─ gauge(name, value)
```

**설정**:
- 개발: Console, 컬러 출력, DEBUG
- 운영: JSON, 파일/클라우드, INFO

**금지 사항**:
- ❌ print() / console.log() 직접 사용
- ❌ 민감 정보 로깅 (비밀번호, 토큰)

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조

---

### 3.3 Data System

**ADR 참조**: ADR-201 (DB 선택), ADR-204 (캐시 선택)

**디렉토리**: `core/database/`, `core/cache/`

**목적**:
- 데이터 영속성 (Database)
- 성능 최적화 (Cache)
- 트랜잭션 관리

**공개 API (개념)**:
```
Database:
├─ Session management
├─ Transaction control
└─ Migration tools

Cache:
├─ get(key) → value | null
├─ set(key, value, ttl)
└─ delete(key)
```

**설정**:
- DB 연결 문자열 (환경변수)
- 캐시 TTL, 메모리 제한
- 트랜잭션 격리 수준

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조

---

[... 다른 시스템도 동일 패턴 ...]

---

## 4. 구현 순서

| 순서 | 시스템 | 의존성 | 예상 시간 |
|------|--------|-------|----------|
| 1 | Type System | 없음 | 2시간 |
| 2 | Configuration System | Type System | 2시간 |
| 3 | Observability System | Config, Types | 3시간 |
| 4 | Error Handling System | Types, Observability | 3시간 |
| 5 | Testing System | 위 4개 | 4시간 |
| 6 | Data System | 위 5개 | 4시간 |
| 7 | Architecture Enforcement | 위 5개 | 3시간 |
| 8 | Security System | 위 전체 | 4시간 |
| 9 | Performance System | Observability, Config | 3시간 |
| 10 | API System | 전체 | 4시간 |

**총 예상 시간**: 32시간 (약 4일)

---

## 5. 의존성 그래프

```
Type System
   ↓
Configuration System ← Observability System
   ↓                      ↓
Error Handling System ←──┘
   ↓
Data System ← Architecture Enforcement
   ↓
Security System
   ↓
Testing System → Performance System → API System
```

---

## 6. Stage 5 전달 사항

- [ ] 각 시스템별 상세 설계 완료
- [ ] 공개 API 정의 완료
- [ ] 구현 순서 결정 완료
- [ ] 예상 시간 산정 완료
```

---


## 📝 청사진 작성 예시 (주식 거래 플랫폼)

### 예시: Observability System 청사진 (Logging 부분)

```markdown
### 3.1 Observability System (Logging)

**ADR 참조**: ADR-401 (로깅 도구 선택)

**디렉토리**: `core/logging/`

**목적**:
- 구조화된 로깅으로 디버깅 효율 향상
- 분산 추적 ID로 요청 추적
- 환경별 로그 레벨/포맷 제어

**파일 구성 (개념)**:
```
core/logging/
├── [entry point]        # get_logger, configure_logging 제공
├── [logger impl]        # 로깅 도구 래퍼
├── [config]             # 로그 설정 (레벨, 포맷)
└── [processors]         # 컨텍스트 추가 (trace_id 주입)
```

**공개 API (개념)**:
```
기본 사용:
├─ get_logger(module_name) → logger
├─ logger.info(message, context_data)
├─ logger.warning(message, context_data)
└─ logger.error(message, context_data)

컨텍스트 바인딩:
└─ logger.bind(key=value) → 이후 모든 로그에 자동 포함

예외 로깅:
└─ logger.exception(message) → 자동 스택트레이스 포함
```

**설정**:
| 환경 | 포맷 | 레벨 | 출력 |
|------|------|------|------|
| 개발 | Console (컬러/읽기 쉬움) | DEBUG | 터미널 |
| 스테이징 | JSON (구조화) | INFO | 터미널 + 파일 |
| 운영 | JSON (구조화) | INFO | 터미널 + 클라우드 |

**필수 컨텍스트**:
- `trace_id`: 분산 추적 ID (미들웨어 자동 주입)
- `user_id`: 인증된 사용자 ID (인증 후 바인딩)
- `request_id`: 요청 고유 ID (미들웨어 자동 주입)

**금지 사항**:
- ❌ print() / console.log() 직접 사용 (ADR-401)
- ❌ 표준 라이브러리 로거 직접 사용
- ❌ 민감 정보 로깅 (비밀번호, 토큰, 카드번호)

**Stage 5 구현 항목**:
- [ ] Logger 모듈 구현
- [ ] Config 모듈 구현
- [ ] Processors 구현 (trace_id, user_id 주입)
- [ ] 단위 테스트 작성

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조
```

---

### 예시: Error Handling System 청사진

```markdown
### 3.4 Error Handling System

**ADR 참조**: ADR-404 (에러 처리 표준)

**디렉토리**: `core/errors/`

**목적**:
- 일관된 에러 응답 형식
- 에러 코드 체계로 문제 추적
- API 레이어 자동 변환

**파일 구성 (개념)**:
```
core/errors/
├── [entry point]        # 예외 클래스 제공
├── [exceptions]         # 예외 계층 정의
├── [codes]              # 에러 코드 상수/Enum
└── [handlers]           # API 예외 핸들러
```

**예외 계층 (개념)**:
```
AppError (기본 예외)
├─ code: 에러 코드
├─ message: 사용자 메시지
└─ status_code: HTTP 상태 코드

DomainError (도메인 로직 에러)
├─ NotFoundError (404)
├─ ValidationError (400)
└─ ConflictError (409)

ExternalError (외부 시스템 에러)
├─ APIError (502)
└─ TimeoutError (504)
```

**에러 코드 체계**:
```
1xxx: 도메인 에러
├─ 1001: 리소스 없음 (NotFound)
├─ 1002: 중복 생성 (Conflict)
└─ 1003: 검증 실패 (Validation)

2xxx: 외부 API 에러
├─ 2001: API Rate Limit
└─ 2002: API Timeout

9xxx: 시스템 에러
├─ 9001: 데이터베이스 에러
└─ 9002: 캐시 에러
```

**사용 패턴 (개념)**:
```
예외 발생:
└─ throw NotFoundError(code="1001", message="...", context_data)

API 응답 형식:
{
  "error": {
    "code": "1001",
    "message": "리소스를 찾을 수 없습니다",
    "details": { ... }
  }
}
```

**금지 사항**:
- ❌ 일반 예외 throw (반드시 AppError 계층 사용)
- ❌ 예외 무시 (catch 후 아무것도 안 함)
- ❌ 에러 코드 없는 예외 발생

**Stage 5 구현 항목**:
- [ ] 예외 계층 구현
- [ ] 에러 코드 정의
- [ ] API 핸들러 구현
- [ ] 단위 테스트 작성

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조
```

---

## ✅ Stage 4 완료 체크리스트

```
□ 시스템 선택
  □ 패밀리 확인 (01C-01)
  □ 필수 시스템 5개 확인
  □ 패밀리별 필수 시스템 결정
  □ 선택 시스템 결정 + 근거
  □ 제외 시스템 명시 + 추가 시점

□ 디렉토리 구조
  □ src/core/ 구조 설계
  □ tests/ 구조 설계
  □ 각 시스템별 파일 목록

□ 각 시스템 상세
  □ 공개 API 정의
  □ 설정 항목 정의
  □ 금지 사항 명시
  □ Stage 5 구현 항목 목록

□ 구현 계획
  □ 의존성 그래프 작성
  □ 구현 순서 결정
  □ 예상 시간 산정

□ 산출물 생성
  □ 04B-01_dna_blueprint.md 작성
  □ (선택) 시스템별 분리 문서
```

---

## 🔜 다음 단계

### Stage 4 → Stage 5 전달 사항

| 항목 | 예시 | Stage 5에서 사용 |
|------|------|-----------------|
| DNA 청사진 | 04B-01_dna_blueprint.md | 구현 가이드 |
| 시스템별 상세 | 각 시스템 설계 | 코드 구현 |
| 구현 순서 | 의존성 기반 순서 | 작업 스케줄 |

### Stage 5에서 할 일
- 🔄 청사진 기반 src/core/ 모듈 구현
- 🔄 각 시스템별 테스트 작성
- 🔄 통합 테스트로 시스템 간 연동 검증

**다음 문서**: `05G-00_dna_implementation_guide.md`

---

## ⏪ 이전 Stage 검증 및 수정 프로토콜

### 검증 시점
- Stage 4 시작 전 필수 체크
- DNA 시스템 선택 후 ADR과 교차 검증

### 검증 대상

| Stage | 산출물 | 검증 항목 |
|-------|--------|----------|
| Stage 1 | 01C-01_*.md | DNA 수준이 패밀리 특성에 적합? |
| Stage 2 | 02C-01_*.md | 기술 제약이 DNA 선택에 반영? |
| Stage 3 | 03A-*_*.md | ADR 결정이 DNA 설계에 반영? |

### 오류 발견 시 프로토콜

```
Stage 4에서 Stage 1-3 오류 발견 시:

Step 1: 오류 발견 및 문서화
├─ 발견 위치: DNA 시스템 [N] 설계 중
├─ 오류 내용: [구체적 설명]
├─ 영향 Stage: Stage [1, 2, 또는 3]
└─ 기록: 04B-01에 "발견된 이슈" 추가

Step 2: 영향 범위 파악
├─ Stage 1: 패밀리/NFR 수정 필요?
├─ Stage 2: 제약/충돌 수정 필요?
├─ Stage 3: ADR 수정/추가 필요?
└─ 재작업 예상: [X]시간

Step 3: 해당 Stage로 이동 → 수정
├─ 해당 산출물 수정
├─ 버전 업데이트
└─ 수정 검증

Step 4: 중간 Stage 전파 (해당 시)
├─ Stage 2, 3 영향 확인
└─ 필요 시 수정

Step 5: Stage 4 재진행
├─ 수정된 입력으로 DNA 청사진 재검토
└─ 일관성 확인

Step 6: 검증 → Stage 5 전달 ✅
```

### 흔한 오류 패턴

| 오류 유형 | 예시 | 해결 |
|----------|------|------|
| ADR 누락 | 로깅 레벨 결정 없이 DNA 설계 | Stage 3 ADR 추가 |
| 패밀리 불일치 | 실시간인데 L2 로깅 선택 | Stage 1 재검토 또는 DNA 수준 상향 |
| 제약 미반영 | 팀 경험 없는 기술 DNA에 포함 | Stage 2 제약 반영 |

### 추적성

```
수정 이력: docs/revision_log.md
```

---

## 📚 참고 문서

| 문서 | 용도 |
|------|------|
| `01_DNA_METHODOLOGY_DETAILED.md` Part 5 | Stage 4-6 상세 원리 |
| `standards/03_DNA_SYSTEMS_GUIDE.md` | DNA 시스템 상세 설명 |
| `./standards/01_STAGE_STRUCTURE.md` | Stage 간 연결 구조 |

---

## 💡 핵심 원칙 요약

```
DNA 청사진 작성의 3가지 원칙:

1. 패밀리 기반 선택
   - 모든 패밀리 공통 5개 필수
   - 패밀리별 추가 시스템 선택
   - 제외 시스템도 근거와 추가 시점 명시

2. 의존성 기반 순서
   - Types → Config → Logging → Error
   - 의존성 없는 것부터 구현
   - 테스트는 중간에 (기반 4개 후)

3. 인터페이스 우선
   - 공개 API 먼저 정의
   - 사용법 예시 제공
   - 금지 사항 명확히
```

```
Bridge(Stage 4-6)의 4대 구성요소:

1. 성문화된 결정 (Stage 3)
   = ADR 문서
   → 비유: 법률

2. 청사진 (Stage 4)
   = DNA 시스템 설계
   → 비유: 건축 도면

3. 구현된 코드 (Stage 5)
   = src/core/ 모듈
   → 비유: 공구

4. 강제 규칙 (Stage 6)
   = PROJECT_STANDARDS.md
   → 비유: 교통법규
```

---

**버전 이력**:
- v5.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
- v1.0 (2025-11-13): 초기 버전


================================================================================

📄 FILE: 05G-00_dna_implementation_guide.md
--------------------------------------------------------------------------------

# Stage 5: DNA 시스템 구현 가이드 (DNA Implementation Guide)

> **목적**: Stage 4 청사진 기반으로 src/core/ DNA 시스템 실제 구현
>
> **버전**: v4.1 (2025-12-03)
>
> - v5.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
> - v1.0 (2025-11-13): 초기 버전

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage 5 실행 가이드) ← 지금 여기!
```

**참조 문서**:

- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` **Part 5**
- **DNA 상세**: `./standards/03_DNA_SYSTEMS_GUIDE.md`

---

## 🧬 DNA 방법론 4대 핵심 원칙 (Stage 5 적용)

> **"AI가 한 세션에서 최고 성과를 낼 수 있는 크기로 작업하고, 완전해질 때까지 반복하며, 기능별로 분해하여 조립한다"**

Stage 5 (DNA 시스템 구현)에서 DNA 4대 핵심 원칙이 적용되는 방식:

---

### DNA 핵심 원칙 1: AI 최적 크기

**"컨텍스트 범위 내에서 작업한다"**

#### Stage 5의 작업 크기 전략

```
❌ 잘못된 접근: 11개 DNA 시스템 한 번에 구현
"11개 DNA 시스템을 한 세션에서 모두 구현하세요"
→ 컨텍스트 초과 (200K 토큰 한계)
→ 후반부 구현 품질 저하
→ 테스트 누락, 타입 오류, print() 사용 등
→ 품질 게이트 실패

✅ 올바른 접근: 시스템별 순차 구현
Session 1: Logging 시스템 구현 (완전)
Session 2: Types 시스템 구현 (완전)
Session 3: Database 시스템 구현 (완전)
Session 4: Cache 시스템 구현 (완전)
...
Session 11: Error 시스템 구현 (완전)

각 세션: 1개 시스템 완전 구현 + 테스트, 80-90K 토큰
```

#### 컨텍스트 구성 (각 세션)

```
AI 컨텍스트 윈도우 (예: 200K 토큰):
├─ 시스템 프롬프트: ~30K 토큰
├─ 대화 히스토리: ~20K 토큰
├─ Stage 4 청사진: ~10-15K 토큰
│   └─ 04D-0X_dna_XXX_blueprint.md (해당 시스템)
├─ Stage 6 프로젝트 표준: ~10-15K 토큰
│   └─ 06D-01_project_standards.md (관련 섹션)
├─ Stage 3 ADR 참조: ~5-10K 토큰
│   └─ 03A-40X_dna_XXX.md
├─ 구현 코드 작성: ~20-25K 토큰
│   ├─ core/XXX/* (구현 파일들)
│   └─ tests/core/XXX/* (테스트 파일들)
└─ 응답 생성 여유: ~80-90K 토큰

**참조**: 파일 확장자는 언어별로 다름 (.py, .ts, .rs, .go 등)
```

#### 세션당 작업량 기준

| DNA 시스템               | 파일 수 (근사치) | 테스트 파일 | 총 토큰 | 세션 수        |
| ------------------------ | ---------------- | ----------- | ------- | -------------- |
| Type System              | 3-4개            | 3-4개       | ~15K    | 1 session      |
| Configuration System     | 2-3개            | 2-3개       | ~12K    | 1 session      |
| Error Handling System    | 3-4개            | 3-4개       | ~15K    | 1 session      |
| Observability System     | 5-6개            | 5-6개       | ~20K    | 1 session      |
| Data System (Cache)      | 4-5개            | 4-5개       | ~18K    | 1 session      |
| Testing System           | 4-5개            | 4-5개       | ~18K    | 1 session      |
| Security System          | 6-7개            | 6-7개       | ~22K    | 1 session      |
| Performance System       | 5-6개            | 5-6개       | ~20K    | 1 session      |
| API System               | 6-7개            | 6-7개       | ~22K    | 1 session      |
| Data System (DB)         | 8-10개           | 8-10개      | ~28K    | **2 sessions** |
| Architecture Enforcement | 4-5개            | 4-5개       | ~18K    | 1 session      |

**핵심**: 대부분 시스템은 1 세션, Data System (DB)만 2 세션

**참조**: 파일 수는 언어/프로젝트에 따라 다를 수 있음. 핵심은 "AI 최적 크기 (80-90K 토큰)"

#### Data System (DB) 분해 전략 (유일한 예외)

```
Data System (DB)는 유일하게 2 세션 필요:

Session 1: DB 기초 (Connection + Session)
├─ connection.*: Connection Pool 구현
├─ session.*: Session Manager 구현
├─ protocols.*: ConnectionProvider, SessionProvider 정의
└─ 테스트 (각 모듈 격리)
  → ~25K 토큰

Session 2: DB 고급 (Query + Migration)
├─ query.*: Query Builder 구현
├─ migration.*: Schema Migration 구현
├─ integration.*: 모듈 통합
└─ 테스트 (통합 테스트 포함)
  → ~25K 토큰

**참조**: 파일 확장자는 언어별로 다름 (.py, .ts, .rs, .go 등)
```

---

### DNA 핵심 원칙 2: 완전해질 때까지 반복

**"부족하면 반복해서 부족함이 없어질 때까지"**

#### DNA 시스템 구현 완전성 기준

각 DNA 시스템 구현은 다음을 모두 포함해야 함:

```
✅ 완전한 DNA 구현 체크리스트:
□ 1. 공개 API 구현
   - 청사진의 모든 함수/클래스 구현
   - 타입 안전성 완전 (타입 체커 0 오류, ADR-301 참조)
   - 문서 주석 (프로젝트 표준 참조)

□ 2. 내부 헬퍼 구현
   - Private 함수/클래스
   - 유틸리티 모듈
   - 상수/설정

□ 3. 에러 처리
   - 예외 처리 적절히 배치
   - 커스텀 예외 정의
   - 에러 로깅 (직접 출력 금지, ADR-401 참조)

□ 4. 로깅 통합
   - Observability System 통합
   - 모든 중요 시점에 로그
   - 표준 로거 사용 (ADR-401)

□ 5. 테스트 작성 (TDD)
   - 단위 테스트: 각 함수/클래스
   - 통합 테스트: 모듈 간 상호작용
   - 커버리지: 95%+
   - 테스트 프레임워크 (ADR-801 참조)

□ 6. 품질 검증 (Zero-Tolerance)
   - Linter: 0 오류 (ADR-302 참조)
   - Type Checker: 0 오류 (ADR-301 참조)
   - Import 규칙: 0 위반 (ADR-501 참조)
   - 테스트: 100% pass

□ 7. 문서화
   - Entry point: 공개 API 노출
   - README: 사용 예시
   - 주석: 복잡한 로직 설명
```

#### 3단계 검증 프로토콜

```
검증 함수: validate_dna_implementation(system_name)
─────────────────────────────────────────────────

검증 1: 청사진 대비 완성도
├─ 청사진 읽기: 04B-01_dna_blueprint.md
├─ 구현 파일 탐색: core/{system_name}/*
└─ 각 공개 API 구현 확인:
    ├─ 미구현 발견 시:
    │   ├─ passed: false
    │   ├─ message: "{system_name}: 공개 API {api} 미구현"
    │   └─ action: "해당 API 구현"
    └─ 모두 구현됨 → 검증 2로

검증 2: 품질 게이트 (Zero-Tolerance)
├─ Linter 실행 (ADR-302):
│   └─ 오류 > 0 → 실패, "Linter 오류 수정"
├─ Type Checker 실행 (ADR-301):
│   └─ 오류 > 0 → 실패, "타입 오류 수정"
├─ Import 규칙 검증 (ADR-501):
│   └─ 위반 > 0 → 실패, "Import 규칙 수정"
└─ 모두 통과 → 검증 3으로

검증 3: 테스트 커버리지
├─ 테스트 실행 (ADR-801):
│   └─ tests/core/{system_name}/
├─ 커버리지 측정:
│   └─ < 95% → 실패, "테스트 추가"
└─ >= 95% → passed: true

**참조**: 구체적 도구/명령어는 언어별 매뉴얼 참조
```

#### 불완전 → 재구현 사례

```markdown
## 사례: DNA Observability System (Logging) 구현

### ❌ 불완전한 버전 (1차 구현)

**파일**: core/logging/logger.*

함수: get_logger(name)
  ❌ 타입 정보 없음 (반환 타입 미지정)
  └─ 표준 라이브러리 로거 반환

클래스: Logger
  └─ 메서드: info(msg)
      ❌ 타입 정보 없음
      ❌ 직접 출력 사용! (print/console.log)

**품질 검증 실패**:

Type Checker (ADR-301):
  logger.*:3: error: Missing return type
  logger.*:6: error: Missing type for 'msg'
  → Type Checker: 2 errors

Linter (ADR-302):
  logger.*:8: 직접 출력 금지 (print/console.log)
  → Linter: 1 error

테스트 (ADR-801):
  → Coverage: 45% (목표: 95%)

❌ 문제점:
- 타입 정보 누락 → Type Checker 오류
- 직접 출력 사용 → Linter 위반
- 테스트 부족 → 커버리지 45%
- 청사진의 context() 미구현

### ✅ 완전한 버전 (2차 재구현)

**파일**: core/logging/logger.*

함수: get_logger(name: string) → Logger
  ✅ 타입 정보 완전
  ✅ 문서 주석 포함
  └─ 구조화된 로거 반환 (ADR-401 도구 사용)

클래스: Logger
  ├─ 생성자(logger: LoggerImpl) → Logger
  │   ✅ 타입 정보 완전
  │
  ├─ info(msg: string, context: map) → void
  │   ✅ 타입 정보 완전
  │   ✅ 구조화된 로깅 사용 (ADR-401)
  │   └─ 직접 출력 없음!
  │
  └─ context(context: map) → LogContext
      ✅ 청사진 API 완전 구현

**테스트 파일**: tests/core/logging/test_logger.*


테스트 1: get_logger가 Logger 인스턴스 반환
  └─ get_logger("test") → Logger 타입 확인

테스트 2: info()가 메시지 로깅
  └─ logger.info("테스트", key="value")
      → 로그에 메시지/컨텍스트 포함 확인

테스트 3: context()가 컨텍스트 추가
  └─ logger.context(request_id="123")로
      → 이후 로그에 request_id 자동 포함 확인

**품질 검증 성공**:

Type Checker (ADR-301):
  → Success: no issues found

Linter (ADR-302):
  → All checks passed!

테스트 (ADR-801):
  → Coverage: 97% ✅

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조
```

---

### DNA 핵심 원칙 3: 기능별 분해 + 연결부 + 조립

**"모듈이 크면 기능별로 나누고, 연결부 설계 후 조립"**

#### Stage 5에서의 적용 (가장 중요!)

Stage 5는 **실제 코드 구현** 단계이므로 원칙 3이 **직접 적용**됩니다!

```markdown
DNA 시스템 크기별 전략:

작은 시스템 (< 5 파일):
├─ 한 세션에 전체 구현
└─ 분해 불필요
    예: Type System, Configuration System, Error Handling System

중간 시스템 (5-7 파일):
├─ 한 세션에 구현 가능
├─ 모듈 간 의존성 관리
└─ Interface/Protocol 정의
    예: Observability System, Data System (Cache), Testing System

큰 시스템 (8+ 파일):
├─ 기능별 분해 필수!
├─ Interface/Protocol 정의 (연결부)
├─ 각 기능 독립 구현
└─ 마지막에 조립
    예: Data System (DB) - 유일한 케이스!
```

#### Data System (DB) 분해 실전 (개념)

**참조**: 구체적 코드는 언어별 매뉴얼 참조

```markdown
Task 000: Interface/Protocol 정의 (연결부)
─────────────────────────────────────────

목적: 모듈 간 연결 인터페이스 정의

정의할 Interface:
├─ ConnectionProvider: DB 연결 제공
│   └─ get_connection() → Connection
├─ SessionProvider: DB 세션 제공
│   └─ get_session() → Session
└─ 테스트: Interface 정의만, 구현 없음

---

Task 001: Connection Pool 구현
─────────────────────────────────────────

목적: DB 연결 풀 관리

구현 체크리스트:
□ ConnectionPool 클래스
  ├─ ConnectionProvider 구현
  ├─ 연결 생성/관리/해제
  └─ 설정 주입 (DB URL, pool size 등)

□ 테스트 (Mock 없음, 실제 DB 사용)
  ├─ 연결 생성 테스트
  ├─ 연결 풀 관리 테스트
  └─ 동시성 테스트

□ 품질 검증
  ├─ Type Checker: 0 오류
  ├─ Linter: 0 오류
  └─ Coverage: 95%+

---

Task 002: Session Manager 구현
─────────────────────────────────────────

목적: 트랜잭션 관리, 세션 라이프사이클

구현 체크리스트:
□ SessionManager 클래스
  ├─ SessionProvider 구현
  ├─ ConnectionProvider Mock 사용 (의존성)
  ├─ 트랜잭션 관리 (begin/commit/rollback)
  └─ 설정 주입

□ 테스트 (ConnectionProvider Mock)
  ├─ 세션 생성 테스트
  ├─ 트랜잭션 테스트 (commit/rollback)
  └─ 에러 처리 테스트

□ 품질 검증: Type/Lint/Coverage

---

Task 999: Database 통합 (조립)
─────────────────────────────────────────

목적: 모든 모듈 통합, 공개 API 제공

통합 체크리스트:
□ 공개 API 모듈 (entry point)
  ├─ ConnectionPool, SessionManager import
  ├─ 실제 구현체 생성
  └─ get_session() 함수 제공

□ 통합 테스트 (E2E)
  ├─ Mock 없음, 실제 DB 사용
  ├─ 전체 플로우 테스트
  └─ 성능 테스트 (선택)

□ 최종 검증
  ├─ 모든 공개 API 동작 확인
  ├─ Type/Lint/Coverage 통과
  └─ 문서화 완료 (README, 사용 예시)
```

---

#### 작은/중간 시스템 구현 전략

**개념**: 작은 시스템 (< 5 파일)은 한 세션에 전체 구현

**예시: Type System (분해 불필요)**

```markdown
한 세션 구현 체크리스트:
□ 도메인 타입 정의 (ID types: UserId, OrderId 등)
□ Enum 타입 (LogLevel, Status 등)
□ Value Objects (Email, Money 등)
□ Base 클래스 (BaseEntity, BaseValueObject)
□ 테스트 (모든 타입 생성/검증)
□ 품질 검증 (Type/Lint/Coverage)
```

**참조**: 구체적 코드는 언어별 매뉴얼 참조

**결과**: 1 세션에 전체 완성 (분해 불필요)

---

### DNA 핵심 원칙 4: 역방향 수정 프로토콜

**"앞선 결정의 오류 발견 시 → 되돌아가서 수정 → 다시 현재까지 진행"**

#### Stage 5에서 역방향 수정이 발생하는 경우

```markdown
시나리오 1: Stage 4 청사진 오류 발견
├─ Stage 5 Logging 구현 중
├─ 청사진에 비동기 로그 쓰기 누락 발견
├─ → Stage 4로 돌아가 청사진 보완
├─ → Stage 5 재구현
└─ → 추적성 업데이트

시나리오 2: Stage 3 ADR 오류 발견
├─ Stage 5 Database 구현 중
├─ ADR-402 "PostgreSQL 13+"가 실제로는 14+ 필요
├─ → Stage 3로 돌아가 ADR-402 수정
├─ → Stage 4 청사진 업데이트
├─ → Stage 5 재구현
└─ → 추적성 업데이트

시나리오 3: 구현 중 설계 결함 발견
├─ Stage 5 Cache 구현 중
├─ Redis 연결 풀 전략이 청사진과 다르게 필요
├─ → Stage 4 청사진 수정
├─ → Stage 5 재구현
└─ → 추적성 업데이트
```

#### 6단계 수정 프로토콜

````markdown
## 실제 사례: Logging 시스템 비동기 쓰기 추가

### Step 1: 오류 발견 및 문서화
**발견 시점**: Stage 5 (Observability System 구현 중)
**파일**: `core/logging/handlers.*`
**문제**: 파일 핸들러가 동기 쓰기라 성능 저하
          청사진에 비동기 쓰기 언급 없음

### Step 2: 영향 범위 파악
**영향받는 문서**:
- Stage 4: `04B-01_dna_blueprint.md` (청사진 수정 필요)
- Stage 3: `03A-401_*.md` (ADR 확인 - 수정 불필요)

**영향받는 구현**:
- `core/logging/handlers.*` (재구현 필요)
- `tests/core/logging/test_handlers.*` (재작성 필요)

### Step 3: 해당 Stage로 이동 및 수정
```bash
# Stage 4 청사진 수정
$ edit 04D-01_dna_logging_blueprint.md
  Line 67: 동기 파일 쓰기 → 비동기 파일 쓰기
  Line 78: aiofiles 의존성 추가
  Line 89: FileHandler → AsyncFileHandler

# 수정 이유 명시
> **History**:
> - v1.0 (2024-11-10): 초기 청사진
> - v1.1 (2024-11-12): 비동기 쓰기 추가 (성능 개선)

### Step 4: 중간 Stage 전파

Stage 5 진행 중이므로 즉시 반영

### Step 5: 현재 Stage 재진행

```
Stage 5 재구현 절차:

1. 기존 구현 제거
   ├─ core/logging/handlers.* 삭제
   └─ tests/core/logging/test_handlers.* 삭제

2. 수정된 청사진 기반 재구현
   ├─ AsyncFileHandler 클래스
   │   └─ 비동기 파일 쓰기 구현
   ├─ 비동기 I/O 라이브러리 사용 (ADR-401 참조)
   └─ 설정 주입 (파일 경로 등)

3. 테스트 재작성
   ├─ 비동기 테스트 작성
   ├─ 파일 쓰기/읽기 검증
   └─ 에러 처리 테스트

**참조**: 구체적 코드는 언어별 매뉴얼 참조
```

### Step 6: 재진행 결과 검증

```
품질 검증:
├─ Type Checker (ADR-301): 0 오류 ✅
├─ Linter (ADR-302): 0 오류 ✅
└─ 테스트 (ADR-801): Coverage 97% ✅

검증 체크리스트:
□ 청사진 v1.1 반영 확인
□ 비동기 쓰기 구현 완료
□ 비동기 I/O 의존성 추가
□ 품질 게이트 통과 (Type/Lint: 0 오류)
□ 테스트 커버리지 95%+
□ 추적성 명시 (Ref: 04B-01 v1.1)
```
````

#### 추적성 (Traceability) 유지

**모든 수정은 명시적으로 참조**

````
추적성 예시: 파일 헤더 주석

```
파일: core/logging/handlers.*
목적: 비동기 파일 핸들러

참조: 04B-01_dna_blueprint.md v1.1 (Section 3.2)
수정일: 2024-11-12 (비동기 쓰기로 변경)
사유: 동기 쓰기 성능 저하 → 비동기 쓰기 필요
```

청사진 버전 이력 예시:

```
파일: 04B-01_dna_blueprint.md

History:
- v1.0 (2024-11-10): 초기 청사진
- v1.1 (2024-11-12): 비동기 쓰기 추가 (Stage 5 성능 이슈 발견)

Section 3.2: 파일 핸들러
  전략: 비동기 쓰기
  라이브러리: [ADR-401 참조]
  참조: Stage 5 구현 중 성능 이슈 발견
```

**참조**: 구체적 코드는 언어별 매뉴얼 참조
````

---

## 🎯 DNA 원칙 적용 요약 (Stage 5)

| 원칙                   | Stage 5 적용 방법                               | 체크포인트                              |
| ---------------------- | ----------------------------------------------- | --------------------------------------- |
| **1. AI 최적 크기**    | 시스템별 순차 구현 (1개/세션)                   | Database만 2 sessions                   |
| **2. 완전해질 때까지** | 7개 항목 완전성, Zero-Tolerance                 | Linter 0, Type Checker 0, Coverage 95%+ |
| **3. 기능별 분해**     | Database 시스템만 분해 (Protocol + Mock + 조립) | Protocol 정의 필수                      |
| **4. 역방향 수정**     | 6단계 프로토콜, 추적성 유지                     | Ref + Updated 명시                      |

---

## 🤔 왜 DNA 구현이 필요한가?

### 청사진 vs 구현

```markdown
Stage 4 청사진:
├─ "무엇을" 만들 것인지 설계
├─ 디렉토리 구조, 파일 목록
├─ 공개 API 정의
└─ 문서 (Markdown)

Stage 5 구현:
├─ "실제로" 코드 작성
├─ core/ 모듈 구현
├─ 테스트 작성
└─ 언어별 구현 (ADR-101 참조)

비유:
├─ 청사진 = 건축 도면
└─ 구현 = 실제 건설
```

### DNA 없이 도메인 구현하면?

```
❌ DNA 없이 도메인부터 구현:

domain/orders/service.*:
────────────────────────────────
표준 라이브러리 직접 사용
├─ 직접 출력 사용 (print/console.log)
├─ 표준 로거 직접 사용
├─ 에러 처리 없음
├─ 타입 정보 없음
└─ DB 직접 쿼리

결과 (문제점):
├─ 로깅 형식 불일치 (JSON vs Console)
├─ 직접 출력과 로거 혼재
├─ 에러 처리 누락
├─ 타입 안전성 없음
└─ 테스트 불가능한 코드
```

```
✅ DNA 먼저 구현 후 도메인:

domain/orders/service.*:
────────────────────────────────
DNA Systems 통합 사용
├─ from core.logging import get_logger
├─ from core.errors import ValidationError, NotFoundError
├─ from core.types import OrderId, UserId
└─ from core.database import get_session

OrderService 클래스:
├─ create_order(data: CreateOrderRequest) → OrderId
│   ├─ 타입 안전성 (모든 파라미터/리턴 타입 명시)
│   ├─ 구조화된 로깅 (컨텍스트 포함)
│   ├─ 데이터 검증 (ValidationError 활용)
│   ├─ 세션 관리 (get_session 사용)
│   ├─ 트랜잭션 처리 (commit/rollback)
│   └─ 타입 안전한 반환 (OrderId)

구현 흐름:
1. 입력 데이터 검증 → ValidationError
2. DB 세션 획득 → get_session()
3. 엔티티 생성 및 저장
4. 트랜잭션 커밋
5. 타입 안전한 ID 반환

결과 (장점):
├─ 일관된 로깅 (JSON, trace_id 포함)
├─ 표준화된 에러 처리
├─ 타입 안전성
├─ 테스트 가능한 코드
└─ DNA가 "환경"으로 보호
```

---

## 📥 입력 문서

### Stage 4에서 전달받는 것

| 파일                      | 핵심 내용         | 이 Stage에서 사용 |
| ------------------------- | ----------------- | ----------------- |
| `04B-01_dna_blueprint.md` | DNA 시스템 청사진 | 구현 명세         |
| `03A-401~499_*.md`        | DNA 시스템 ADR    | 기술 선택 근거    |

---

## 📤 출력 문서

### 필수 산출물

```markdown
core/                              # 구현된 DNA 모듈
├── [entry_point]                  # 진입점 (언어별 형식)
├── logging/                       # Observability System
├── config/                        # Configuration System
├── types/                         # Type System
├── errors/                        # Error Handling System
├── database/                      # Data System (DB)
├── cache/                         # Data System (Cache)
└── security/                      # Security System

tests/                             # DNA 테스트
├── unit/core/
│   ├── test_logging.*             # 단위 테스트
│   ├── test_config.*
│   └── ...
└── integration/core/
    └── test_database.*            # 통합 테스트

docs/
└── 05D-01_dna_implementation.md   # 구현 완료 문서

**참조**: 디렉토리 구조는 언어별로 다를 수 있음 (ADR-101 참조)
```

---

## 🔧 DNA 구현 3대 원칙

### 원칙 1: 표준 라이브러리 우선

```markdown
❌ 직접 구현 (실패 사례):
────────────────────────────────
과거 V5 프로젝트:
├─ 89개 커스텀 타입 클래스 직접 작성
├─ 1,679줄의 검증 로직 구현
├─ 버그 발생 시 직접 수정
└─ 유지보수 부담 증가

문제점:
├─ 휠을 재발명 (Reinventing the wheel)
├─ 검증되지 않은 코드
├─ 표준 라이브러리보다 성능 저하
└─ 유지보수 비용 증가

✅ 표준 라이브러리 활용:
────────────────────────────────
타입 시스템 라이브러리 활용 (ADR-301 참조):
├─ 검증된 타입 검증 기능
├─ 자동 변환/직렬화
├─ 명확한 에러 메시지
└─ 3-5줄로 구현 완료

장점:
├─ 커뮤니티 검증된 코드
├─ 성능 최적화 완료
├─ 문서화 및 예제 풍부
└─ 유지보수 부담 최소화
```

**참조**: 구체적 라이브러리는 언어별 매뉴얼 참조

**DNA별 표준 라이브러리 선택 원칙**:

| DNA 시스템           | 라이브러리 선택 기준 (ADR 참조)  | 직접 구현 금지 사항          |
| -------------------- | -------------------------------- | ---------------------------- |
| Observability System | 구조화 로깅 라이브러리 (ADR-401) | print/console 직접 사용      |
| Configuration System | 타입 안전 설정 관리 (ADR-402)    | 환경변수 직접 접근           |
| Type System          | 타입 검증 라이브러리 (ADR-301)   | 커스텀 타입 클래스 직접 작성 |
| Error Handling       | 타입 안전 에러 클래스 (ADR-303)  | 일반 Exception만 사용        |
| Data System (DB)     | ORM/쿼리 빌더 (ADR-501)          | 직접 SQL 문자열 작성         |
| Data System (Cache)  | 캐시 클라이언트 (ADR-502)        | 직접 소켓 통신               |
| Testing System       | 테스트 프레임워크 (ADR-801)      | 커스텀 테스트 러너           |

**원칙**: 언어별 커뮤니티 검증된 표준 라이브러리 사용 (ADR에서 결정)

### 원칙 2: 인터페이스 추상화

**핵심 개념**: 구현체가 아닌 인터페이스에 의존

```
파일 구조:
────────────────────────────────
core/cache/
├── interface.*              # 캐시 인터페이스 정의
│   └─ CacheInterface
│       ├─ get(key) → value
│       ├─ set(key, value, ttl)
│       └─ delete(key)
│
├── redis.*                  # Redis 구현체
│   └─ RedisCache implements CacheInterface
│
└── memcached.*              # 대체 구현체 (교체 가능)
    └─ MemcachedCache implements CacheInterface

인터페이스 정의 (개념):
────────────────────────────────
CacheInterface:
  목적: 캐시 작업 표준 인터페이스
  메서드:
    - get(key: string) → value | null
    - set(key: string, value: any, ttl: number) → void
    - delete(key: string) → void

구현체 1 (Redis):
  RedisCache implements CacheInterface
  ├─ Redis 클라이언트 활용
  └─ 모든 인터페이스 메서드 구현

구현체 2 (Memcached):
  MemcachedCache implements CacheInterface
  ├─ Memcached 클라이언트 활용
  └─ 동일한 인터페이스 구현

교체 시나리오:
  Redis → Memcached 전환
  ├─ 도메인 코드 변경 없음 (인터페이스 동일)
  ├─ 설정만 변경 (ADR-502 업데이트)
  └─ 테스트 통과 확인
```

**가치**:

- **테스트 용이성**: Mock/Stub 주입 간편
- **기술 독립성**: 구현체 교체 시 도메인 코드 무수정
- **설계 원칙**: 의존성 역전 원칙 (DIP) 준수
- **유연성**: 런타임 구현체 선택 가능

**참조**: 구체적 인터페이스 정의는 언어별 매뉴얼 참조

### 원칙 3: 설정 주입 (환경별 분리)

**핵심 개념**: 환경변수 기반 설정 관리, 타입 안전성 보장

```
파일 구조:
────────────────────────────────
core/config/
├── settings.*               # 설정 클래스 정의
└── [환경별 설정 파일]       # .env.* 또는 언어별 형식

설정 클래스 정의 (개념):
────────────────────────────────
Settings 클래스:
  목적: 환경별 설정 중앙 관리

  필드 정의:
    - database_url: string (기본값: 개발 DB URL)
    - cache_url: string (기본값: 로컬 캐시)
    - log_level: string (기본값: "INFO")
    - log_format: string (기본값: "json")
    - environment: string (기본값: "development")

  로딩 전략:
    ├─ 환경변수 파일 읽기 (.env.*)
    ├─ 타입 검증 (문자열 → 타입 변환)
    ├─ 필수 값 검증 (누락 시 에러)
    └─ 기본값 적용 (선택 필드)

사용 패턴:
────────────────────────────────
1. 설정 인스턴스 생성
   settings = Settings()

2. 타입 안전한 접근
   db_url = settings.database_url  # 타입: string
   log_level = settings.log_level  # 타입: string

3. DNA 시스템에서 활용
   logger.configure(level=settings.log_level)
   db.connect(url=settings.database_url)
```

**환경별 설정 파일 예시**:

```bash
# 개발 환경 (.env.development)
DATABASE_URL=postgresql://localhost/dev
CACHE_URL=redis://localhost:6379
LOG_LEVEL=DEBUG
LOG_FORMAT=console
ENVIRONMENT=development

# 프로덕션 환경 (.env.production)
DATABASE_URL=postgresql://prod-db:5432/prod
CACHE_URL=redis://prod-cache:6379
LOG_LEVEL=INFO
LOG_FORMAT=json
ENVIRONMENT=production
```

**장점**:

- **타입 안전성**: 설정 값 타입 검증
- **중앙 관리**: 모든 설정 한 곳에서 관리
- **환경 분리**: 개발/스테이징/프로덕션 독립
- **검증 자동화**: 필수 값 누락 시 즉시 에러

**참조**: 구체적 설정 라이브러리는 언어별 매뉴얼 참조 (ADR-402)

---

## 📋 구현 단계 (Part 1-4)

### Part 1: 프로젝트 구조 생성 (30분)

#### Step 1: 디렉토리 구조 생성

**목적**: Stage 4 청사진 기반 DNA 모듈 디렉토리 구조 생성

```
생성할 디렉토리 구조:
────────────────────────────────
[project_root]/
├── core/                        # DNA 시스템 모듈
│   ├── logging/                 # Observability System
│   ├── config/                  # Configuration System
│   ├── types/                   # Type System
│   ├── errors/                  # Error Handling System
│   ├── database/                # Data System (DB)
│   ├── cache/                   # Data System (Cache)
│   └── security/                # Security System
│
└── tests/                       # 테스트
    ├── unit/core/               # 단위 테스트
    └── integration/core/        # 통합 테스트

필수 작업:
□ 각 DNA 시스템별 디렉토리 생성
□ 테스트 디렉토리 분리 (unit/integration)
□ 언어별 진입점 파일 생성 (필요시)
```

**참조**: 언어별 구체적 명령어는 매뉴얼 참조

#### Step 2: 의존성 설치

**목적**: DNA 시스템 구현에 필요한 라이브러리 설치

```
필수 의존성 (ADR 참조):
────────────────────────────────
□ Type System 라이브러리 (ADR-301)
  └─ 타입 검증, 직렬화/역직렬화

□ Configuration 라이브러리 (ADR-402)
  └─ 환경변수 관리, 타입 안전 설정

□ Observability 라이브러리 (ADR-401)
  └─ 구조화 로깅, 메트릭, 추적

□ Data 라이브러리 (ADR-501, ADR-502)
  └─ ORM/쿼리빌더, 캐시 클라이언트

□ Testing 라이브러리 (ADR-801)
  └─ 테스트 프레임워크, 커버리지 도구

개발 도구:
□ 코드 품질 (ADR-302)
  ├─ Linter (코드 스타일)
  ├─ Formatter (자동 정렬)
  └─ Type Checker (타입 검증)

□ 자동화 도구
  └─ Pre-commit hooks (품질 게이트)
```

**참조**: 언어별 패키지명은 매뉴얼 참조

#### Step 3: 기본 설정 파일

**목적**: 코드 품질 자동 검증 설정

```
설정할 항목:
────────────────────────────────
□ Linter 설정 (ADR-302)
  ├─ 코드 스타일 규칙
  ├─ 금지 패턴 (print/console 사용 등)
  └─ 최대 줄 길이

□ Type Checker 설정 (ADR-301)
  ├─ Strict 모드 활성화
  ├─ 타입 추론 경고
  └─ Any 타입 경고

□ Test 설정 (ADR-801)
  ├─ 최소 커버리지 요구 (95%)
  ├─ 비동기 테스트 지원
  └─ 테스트 경로 설정
```

**참조**: 언어별 설정 파일 형식은 매뉴얼 참조

### Part 2: 핵심 DNA 구현 순서 (의존성 기반)

```
구현 순서 (의존성 그래프):

Phase 1: 기반 (의존성 없음)
────────────────────────────────
1. Types      [30분]  ← 다른 모든 DNA가 의존
2. Config     [30분]  ← Types만 의존
3. Logging    [45분]  ← Config, Types 의존
4. Errors     [45분]  ← Types, Logging 의존

Phase 2: 데이터/통신
────────────────────────────────
5. Database   [1시간] ← Config, Types, Errors, Logging
6. Cache      [45분]  ← Config, Types, Errors, Logging

Phase 3: 품질/보안
────────────────────────────────
7. Testing    [30분]  ← 모든 Phase 1-2 완료 후
8. Security   [1시간] ← Database, Config, Types
```

### Part 3: 각 DNA 시스템 구현 (개념)

**참조**: 구체적 코드 예시는 언어별 매뉴얼 참조

- Python 매뉴얼: `docs/manuals/05M-01_python_implementation.md`
- TypeScript 매뉴얼: `docs/manuals/05M-02_typescript_implementation.md`
- Rust 매뉴얼: `docs/manuals/05M-03_rust_implementation.md`

---

각 DNA 시스템별 핵심 구현 체크리스트:

---

#### 3.1 Type System

**목적**: 타입 안전성 보장, 런타임 에러 방지

**핵심 체크리스트**:

```
□ 도메인 타입 정의
  ├─ Entity Base (ID, timestamps, 동등성)
  ├─ Value Object Base (불변성, 자체 검증)
  └─ Domain-specific 타입 (UserId, Money, Email 등)

□ 타입 검증
  ├─ 생성 시점 검증 (불완전한 객체 생성 금지)
  ├─ 불변성 보장
  └─ 타입 체커 0 오류 (ADR-301)

□ 공개 API
  ├─ BaseEntity, BaseValueObject export
  ├─ 도메인 타입들 export
  └─ 타입 검증 함수 (선택)
```

**파일 구조** (언어 무관):

```
core/types/
├── [entry_point]    # 공개 API export
├── base.*           # Entity/ValueObject 기반 클래스
├── ids.*            # ID 타입들 (UserId, OrderId)
└── common.*         # 공통 타입 (Email, Money)
```

**구현 요소**:

```
1. 공개 API (Entry Point)
   └─ BaseEntity, BaseValueObject, 도메인 타입들 export

2. 기반 클래스 (base.*)
   ├─ BaseEntity: ID, timestamps, 동등성 비교
   └─ BaseValueObject: 불변성, 자체 검증

3. ID 타입들 (ids.*)
   ├─ UserId, OrderId, ProductId 등
   ├─ 타입 안전성 (타입 구분)
   └─ ID 생성 함수

4. 공통 값 객체 (common.*)
   ├─ Email: 이메일 검증
   ├─ Money: 정밀 계산, 통화 관리
   └─ PhoneNumber: 전화번호 형식 검증
```

**구현 체크리스트**:

```
□ Base 클래스 구현
  ├─ Entity: 식별자 기반 동등성
  ├─ ValueObject: 값 기반 동등성
  └─ 불변성 보장 (방어적 복사)

□ ID 타입 구현
  ├─ 타입 안전 ID (UserId ≠ OrderId)
  ├─ ID 생성 함수 (UUID/ULID 등)
  └─ 타입 체커 검증 통과

□ 값 객체 구현
  ├─ Email: 형식 검증
  ├─ Money: 정밀 계산 (부동소수점 금지)
  └─ 도메인 규칙 검증

□ 테스트 작성
  ├─ ID 고유성 검증
  ├─ 값 객체 검증 로직 테스트
  ├─ Money 연산 테스트 (덧셈, 통화 체크)
  └─ 불완전한 객체 생성 방지 확인
```

**참조**: 구체적 코드는 언어별 매뉴얼 참조



#### 3.2 Configuration System

**목적**: 환경별 설정 관리, 타입 안전성 보장

**파일 구조** (언어 무관):

```
core/config/
├── [entry_point]    # 공개 API export
├── settings.*       # 환경 설정 클래스
└── validators.*     # 커스텀 검증 (선택)
```

**구현 요소**:

```
1. Settings 클래스
   ├─ 환경 변수 자동 로딩 (.env.*)
   ├─ 타입 안전 필드 정의
   ├─ 기본값 제공
   └─ 필수 값 검증

2. 설정 카테고리
   ├─ 환경: environment, debug
   ├─ Database: URL, pool_size
   ├─ Cache: URL, TTL
   ├─ Logging: level, format
   └─ External API: keys, rate_limit

3. 접근 패턴
   ├─ 싱글톤 인스턴스
   ├─ get_settings() 함수
   └─ 타입 안전한 접근
```

**구현 체크리스트**:

```
□ Settings 클래스 정의
  ├─ 필드별 타입 지정
  ├─ 기본값 설정
  ├─ 범위 검증 (min/max)
  └─ 환경변수 파일 경로

□ 검증 로직
  ├─ log_level 값 제한 (DEBUG, INFO, etc.)
  ├─ log_format 값 제한 (json, console)
  ├─ URL 형식 검증
  └─ 범위 검증 (pool_size: 1-20)

□ 싱글톤 패턴
  ├─ get_settings() 구현
  ├─ 전역 인스턴스 관리
  └─ 스레드 안전성 (필요시)

□ 환경별 설정 파일
  ├─ .env.development
  ├─ .env.staging
  ├─ .env.production
  └─ 자동 로딩 구현
```

**참조**: 구체적 코드는 언어별 매뉴얼 참조

#### 3.3 Observability System (Logging)

**목적**: 구조화 로깅, 컨텍스트 전파, 환경별 포맷

**파일 구조** (언어 무관):

```
core/logging/
├── [entry_point]    # 공개 API export
├── logger.*         # 로거 설정 및 생성
├── config.*         # 로깅 설정
└── processors.*     # 커스텀 프로세서 (선택)
```

**구현 요소**:

```
1. 로깅 설정 (configure_logging)
   ├─ 환경별 포맷 (JSON/Console)
   ├─ 로그 레벨 필터링
   ├─ 공통 프로세서 체인
   │   ├─ 컨텍스트 병합
   │   ├─ 타임스탬프 추가
   │   ├─ 로그 레벨 추가
   │   └─ 스택 정보 (에러 시)
   └─ 출력 포맷
       ├─ JSON (운영)
       └─ Console (개발)

2. 로거 인스턴스 (get_logger)
   ├─ 모듈별 로거 생성
   ├─ 캐싱 (성능)
   └─ 타입 안전 반환

3. 컨텍스트 관리
   ├─ bind_context(): trace_id, user_id 등
   ├─ clear_context(): 초기화
   └─ 요청 범위 전파
```

**구현 체크리스트**:

```
□ configure_logging() 함수
  ├─ Settings에서 log_level, log_format 로드
  ├─ 프로세서 체인 구성
  ├─ JSON vs Console 렌더러 선택
  └─ 앱 시작 시 1회 호출

□ get_logger() 함수
  ├─ 모듈명 기반 로거 반환
  ├─ 구조화 로깅 지원
  └─ 컨텍스트 자동 포함

□ 컨텍스트 헬퍼
  ├─ bind_context(trace_id, user_id, ...)
  ├─ 스레드/비동기 안전 저장
  └─ 모든 로그에 자동 포함

□ 출력 포맷
  ├─ JSON: {"event": "...", "trace_id": "...", "timestamp": "..."}
  ├─ Console: 컬러 출력 (개발 편의)
  └─ 타임스탬프 ISO 8601 형식
```

**사용 패턴**:

```
1. 앱 시작 시 초기화
   configure_logging()

2. 모듈별 로거 생성
   logger = get_logger(module_name)

3. 요청 컨텍스트 바인딩
   bind_context(trace_id="abc-123", user_id="user-456")

4. 구조화 로깅
   logger.info("주문 생성", order_id="order-789", amount=50000)

5. 출력 (JSON 예시)
   {"event": "주문 생성", "trace_id": "abc-123", "user_id": "user-456",
    "order_id": "order-789", "amount": 50000, "level": "info",
    "timestamp": "2025-12-03T10:30:00Z"}
```

**참조**: 구체적 코드는 언어별 매뉴얼 참조

#### 3.4 Error Handling System

**목적**: 표준화된 예외 처리, 에러 코드 체계, 전역 핸들링

**파일 구조** (언어 무관):

```
core/errors/
├── [entry_point]    # 공개 API export
├── exceptions.*     # 예외 계층 정의
├── codes.*          # 에러 코드 체계
└── handlers.*       # 전역 핸들러
```

**구현 요소**:

```
1. 에러 코드 체계 (ErrorCode)
   ├─ 1xxx: 도메인 에러 (비즈니스 로직)
   │   ├─ 1001: ValidationError
   │   ├─ 1002: NotFoundError
   │   ├─ 1003: ConflictError
   │   └─ 1004+: 도메인 특화
   ├─ 2xxx: 외부 API 에러
   │   ├─ 2001: External API Error
   │   ├─ 2002: Rate Limit
   │   └─ 2003: Auth Failed
   └─ 9xxx: 시스템 에러
       ├─ 9001: Internal Error
       ├─ 9002: Database Error
       └─ 9003: Cache Error

2. 예외 계층
   ├─ AppError (최상위)
   │   ├─ message, code, details
   │   └─ to_dict() (API 응답)
   ├─ DomainError extends AppError
   │   ├─ ValidationError
   │   ├─ NotFoundError
   │   └─ ConflictError
   └─ ExternalError extends AppError
       └─ 외부 API별 에러

3. 전역 핸들러
   ├─ 예상된 에러 (AppError)
   │   ├─ 로깅 (warning level)
   │   ├─ HTTP 상태 코드 매핑
   │   └─ 구조화된 응답
   └─ 예상치 못한 에러
       ├─ 로깅 (error level + stack)
       ├─ 500 Internal Error
       └─ 상세 숨김 (보안)
```

**구현 체크리스트**:

```
□ 에러 코드 정의
  ├─ 1xxx, 2xxx, 9xxx 범위 할당
  ├─ 프로젝트별 도메인 코드 추가
  └─ Enum/Constant로 관리

□ AppError 기반 클래스
  ├─ 생성자: message, code, details
  ├─ to_dict(): API 응답 포맷
  └─ 로깅 친화적 구조

□ 도메인 예외 클래스
  ├─ ValidationError(message, field)
  ├─ NotFoundError(resource, identifier)
  ├─ ConflictError(message)
  └─ 도메인 특화 에러

□ 전역 핸들러 등록
  ├─ AppError → 적절한 HTTP 상태
  ├─ 로깅 (경고 vs 에러)
  ├─ 구조화 응답: {error: {code, message, details}}
  └─ 예상치 못한 에러 처리

□ HTTP 상태 매핑
  ├─ 1001 → 400 Bad Request
  ├─ 1002 → 404 Not Found
  ├─ 1003 → 409 Conflict
  ├─ 2xxx → 502 Bad Gateway
  └─ 9xxx → 500 Internal Error
```

**사용 패턴**:

```
1. 도메인 에러 발생
   if not order.items:
       raise ValidationError("주문 항목이 비어있습니다", field="items")

2. 리소스 없음
   order = find_order(order_id)
   if not order:
       raise NotFoundError("주문", order_id)

3. 전역 핸들러 등록
   app.add_exception_handler(Exception, global_exception_handler)

4. API 응답 (자동)
   {
     "error": {
       "code": "1001",
       "message": "주문 항목이 비어있습니다",
       "details": {"field": "items"}
     }
   }
```

**참조**: 구체적 코드는 언어별 매뉴얼 참조



### Part 4: 통합 검증

#### 4.1 DNA 통합 테스트

**목적**: DNA 시스템 간 연동 검증

**테스트 시나리오**:

```
1. Logging ↔ Config 연동
   ├─ 설정(Settings)에서 log_level, log_format 로드
   ├─ 로거 초기화 시 설정 반영 확인
   └─ 다양한 로그 레벨 동작 검증

2. Errors ↔ Logging 연동
   ├─ 에러 발생 시 자동 로깅
   ├─ 에러 코드, 메시지, details 포함
   └─ 로그 레벨 적절성 (warning vs error)

3. Types ↔ Errors 연동
   ├─ 타입 검증 실패 시 적절한 에러
   ├─ Money 음수 검증 → ValidationError
   └─ Email 형식 검증 → ValidationError

4. Config ↔ All Systems
   ├─ Database URL 주입
   ├─ Cache URL 주입
   ├─ External API 키 주입
   └─ 환경별 설정 격리
```

**테스트 체크리스트**:

```
□ Setup
  ├─ 테스트 환경 초기화
  ├─ DNA 시스템 설정 로드
  └─ 로깅 초기화

□ 통합 테스트
  ├─ Logging이 Config 사용 확인
  ├─ Errors가 Logging 연동 확인
  ├─ Types 검증 실패 → 에러 확인
  └─ 전체 플로우 E2E 테스트

□ 품질 기준
  ├─ 모든 테스트 통과
  ├─ 통합 커버리지 85%+
  └─ 실제 DB/Cache 사용 (Mock 최소화)
```

**참조**: 구체적 테스트 코드는 언어별 매뉴얼 참조

#### 4.2 품질 검증

**목적**: DNA 시스템 품질 게이트 통과

**검증 항목** (ADR 참조):

```
1. Type Checker (ADR-301)
   ├─ Strict 모드 실행
   ├─ 0 errors 필수
   └─ 예상 결과: "Success: no issues found"

2. Linter (ADR-302)
   ├─ 코드 스타일 검증
   ├─ 0 violations 필수
   └─ 예상 결과: "All checks passed!"

3. Formatter (ADR-302)
   ├─ 자동 코드 정렬
   └─ 일관된 스타일 적용

4. Test + Coverage (ADR-801)
   ├─ 단위 + 통합 테스트 실행
   ├─ 최소 커버리지: 95%
   └─ 예상 결과: "PASSED, Coverage 95%+"

5. 전체 검증
   ├─ CI 파이프라인 통과
   ├─ Pre-commit hooks 통과
   └─ 품질 게이트 100% 통과
```

**실행 순서**:

```
Step 1: Type Checker → 0 errors
Step 2: Linter → 0 violations
Step 3: Formatter → 자동 적용
Step 4: Tests → 95%+ coverage
Step 5: Integration → 전체 검증
```

**참조**: 언어별 명령어는 매뉴얼 참조

#### 4.3 DNA 완성도 평가 (Kent Beck 기준)

```
DNA 성숙도 레벨:

Level 0 (미완성): 0-3개 DNA 동작
Level 1 (최소):   4-6개 DNA 동작
Level 2 (양호):   7-9개 DNA 동작
Level 3 (완성):   10-11개 DNA 동작 ← 목표!

Kent Beck 수준 = Level 3 (10/11개 이상)
```

---

## 📄 구현 완료 문서 템플릿

### 05D-01_dna_implementation.md

```markdown
# DNA 시스템 구현 완료 문서

## 1. 구현 현황

### 1.1 완료된 DNA 시스템

| DNA 시스템 | 상태 | 파일 수 | 테스트 커버리지 | 담당자 |
|-----------|------|--------|---------------|-------|
| Types | ✅ 완료 | 4 | 98% | - |
| Config | ✅ 완료 | 3 | 95% | - |
| Logging | ✅ 완료 | 4 | 96% | - |
| Errors | ✅ 완료 | 4 | 97% | - |
| Database | ✅ 완료 | 5 | 94% | - |
| Cache | ✅ 완료 | 3 | 95% | - |
| Security | ⏳ 진행 중 | 2 | 80% | - |
| ... | ... | ... | ... | ... |

### 1.2 품질 메트릭

```

Type Checker: 0 errors ✅
Linter:       0 violations ✅
Tests:        45 passed, 0 failed ✅
Coverage:     96% (목표: 95%) ✅

```
## 2. 디렉토리 구조

```

core/
├── [entry_point]       # DNA 공개 API
├── logging/
│   ├── [entry_point]
│   ├── logger.*        # 285 lines
│   ├── config.*        # 45 lines
│   └── processors.*    # 62 lines
├── config/
│   ├── [entry_point]
│   ├── settings.*      # 120 lines
│   └── validators.*    # 35 lines
├── types/
│   ├── [entry_point]
│   ├── base.*          # 50 lines
│   ├── ids.*           # 40 lines
│   └── common.*        # 85 lines
├── errors/
│   ├── [entry_point]
│   ├── exceptions.*    # 95 lines
│   ├── codes.*         # 45 lines
│   └── handlers.*      # 60 lines
└── database/
    ├── [entry_point]
    ├── session.*       # 75 lines
    ├── base.*          # 55 lines
    └── mixins.*        # 40 lines

```
## 3. 공개 API

### 3.1 사용 예시 (개념)

```

# DNA 임포트

import 필요한 시스템 from core

필수 임포트:

  - Logging: get_logger, configure_logging
  - Config: get_settings
  - Types: UserId, OrderId, Money
  - Errors: NotFoundError, ValidationError
  - Database: get_session

# 초기화

configure_logging()
settings = get_settings()
logger = get_logger(module_name)

# 사용

logger.info("서비스 시작", environment=settings.environment)

database_session 사용:

  - 세션 획득
  - 트랜잭션 수행
  - 자동 커밋/롤백

```
**참조**: 구체적 코드는 언어별 매뉴얼 참조

## 4. Stage 6 전달 사항

### 4.1 Project Standards에 포함할 규칙

- [ ] 직접 출력 금지 (print/console) → get_logger() 사용
- [ ] 환경변수 직접 접근 금지 → get_settings() 사용
- [ ] 일반 Exception 금지 → AppError 계층 사용
- [ ] 직접 쿼리 문자열 금지 → ORM/쿼리빌더 사용 (ADR-501)

### 4.2 자동화 설정

- [ ] Pre-commit hooks 설정 (품질 게이트)
- [ ] CI 파이프라인에 DNA 테스트 포함
- [ ] Import 규칙 강제 (layer 경계)

```

---

## ✏️ DNA 연동 패턴 (개념)

**목적**: DNA 시스템 간 연동 방식 이해

### 패턴 1: Logging ↔ Config

**연동 개념**:

```
configure_logging() 함수:
  1. get_settings()로 설정 로드
  2. 환경별 로거 설정
     - 개발: 컬러 콘솔, DEBUG
     - 운영: JSON, WARNING
  3. 도메인 특화 컨텍스트 추가
     - trace_id, user_id, account_id 등
```

**핵심 포인트**:

- Config에서 log_level, log_format 동적 로드
- 환경 변경 시 코드 수정 불필요
- 도메인 컨텍스트 자동 포함

### 패턴 2: Errors ↔ Logging

**연동 개념**:

```
global_exception_handler():
  1. 에러 타입별 로그 레벨 결정
     - AppError → warning
     - 중요 경로 에러 → critical
     - 예상치 못한 에러 → error + stack
  2. 요청 컨텍스트 포함
     - trace_id, user_id, path
  3. 구조화 로깅
     - error_code, message, details
```

**핵심 포인트**:

- 에러 발생 = 자동 로깅
- 에러 코드로 로그 레벨 결정
- 컨텍스트 전파 (trace_id)

### 패턴 3: 전체 DNA 연동

**도메인 서비스에서 DNA 활용**:

```
OrderService.create_order():
  1. Types DNA
     - 타입 안전 파라미터 (UserId, Money)
     - ID 생성 (generate_order_id)

  2. Logging DNA
     - 컨텍스트 바인딩 (bind_context)
     - 단계별 로깅 (info/error)

  3. Errors DNA
     - 검증 실패 → ValidationError
     - 외부 API 실패 → ExternalError

  4. Database DNA
     - 세션 관리 (get_session)
     - 트랜잭션 (commit/rollback)

  5. Cache DNA
     - 시세 캐싱 (@cached decorator)

  6. Config DNA
     - 외부 API 설정 (rate_limit 등)
```

**핵심 포인트**:

- 도메인 로직에만 집중
- DNA가 횡단 관심사 처리
- 일관성 자동 보장

**참조**: 구체적 코드는 언어별 매뉴얼 참조

---

## ✅ Stage 5 완료 체크리스트

### 구조 검증

- [ ] core/ 디렉토리 생성됨
- [ ] 각 DNA 시스템 하위 디렉토리 존재
- [ ] tests/unit/core/ 테스트 디렉토리 존재
- [ ] tests/integration/core/ 통합 테스트 존재

### 필수 DNA 구현 (5개)

- [ ] **Type System**: ID 타입, 공통 값 객체 구현
- [ ] **Configuration System**: Settings 클래스, 환경별 분리
- [ ] **Observability System**: 로깅 라이브러리 (ADR-401), get_logger() 동작
- [ ] **Error Handling System**: 예외 계층, 에러 코드 정의
- [ ] **Testing System**: 테스트 프레임워크 (ADR-801), 커버리지 95%+

### 패밀리별 추가 DNA

- [ ] **Data System (DB)** (A-A-B 필수): ORM/쿼리빌더 (ADR-501) 세션 관리
- [ ] **Data System (Cache)** (A-A-B 권장): 캐시 클라이언트 (ADR-502)
- [ ] **Security System** (A-A-B 필수): 인증/인가 미들웨어

### 품질 검증

- [ ] Type Checker 0 errors (ADR-301)
- [ ] Linter 0 violations (ADR-302)
- [ ] 테스트 통과 (단위 + 통합)
- [ ] 커버리지 95%+ (ADR-801)

### 통합 검증

- [ ] DNA 간 의존성 정상 (Types → Config → Logging → Errors)
- [ ] 전체 통합 테스트 통과
- [ ] Kent Beck 수준 달성 (10/11개 이상)

### 산출물 생성

- [ ] `05D-01_dna_implementation.md` 작성
- [ ] Stage 6 전달 사항 정리

---

## 🔗 Stage 5 → Stage 6 연결

### Stage 6에 전달하는 것

| 전달 항목       | 내용                        | 용도                      |
| --------------- | --------------------------- | ------------------------- |
| 구현된 DNA 모듈 | core/                       | 프로젝트 표준의 기반      |
| 금지 규칙       | 직접 출력, 환경변수 접근 등 | PROJECT_STANDARDS.md 작성 |
| 자동화 설정     | 설정 파일, pre-commit hooks | 강제 규칙 설정            |

### Stage 6 미리보기

```
Stage 6: Project Standards
├─ PROJECT_STANDARDS.md 작성
│   - 코드 스타일 규칙
│   - DNA 사용 규칙 (금지/필수)
│   - 아키텍처 규칙
├─ 자동화 설정
│   - pre-commit hooks
│   - import-linter
│   - CI 파이프라인
└─ 강제 규칙 검증
```

---

## ⏪ 이전 Stage 검증 및 수정 프로토콜

### 검증 시점

- Stage 5 시작 전 필수 체크
- 각 DNA 시스템 구현 완료 후 청사진과 교차 검증

### 검증 대상

| Stage   | 산출물      | 검증 항목              |
| ------- | ----------- | ---------------------- |
| Stage 1 | 01C-01_*.md | 구현 수준이 NFR 만족?  |
| Stage 2 | 02C-01_*.md | 기술 제약 내에서 구현? |
| Stage 3 | 03A-*_*.md  | ADR 결정대로 구현?     |
| Stage 4 | 04B-01_*.md | DNA 청사진대로 구현?   |

### 오류 발견 시 프로토콜

```
Stage 5에서 Stage 1-4 오류 발견 시:

Step 1: 오류 발견 및 문서화
├─ 발견 위치: DNA 시스템 [N] 구현 중
├─ 오류 내용: [구체적 설명]
├─ 영향 Stage: Stage [1, 2, 3, 또는 4]
└─ 기록: 05D-01에 "발견된 이슈" 추가

Step 2: 영향 범위 파악
├─ 청사진(Stage 4) 수정 필요?
├─ ADR(Stage 3) 수정 필요?
├─ 제약(Stage 2) 재검토 필요?
└─ 재작업 예상: [X]시간

Step 3: 해당 Stage로 이동 → 수정
├─ 해당 산출물 수정
├─ 버전 업데이트
└─ 수정 검증

Step 4: 중간 Stage 전파
├─ Stage 4, 5 영향 확인
└─ 필요 시 청사진 업데이트

Step 5: Stage 5 재진행
├─ 수정된 청사진으로 구현 재검토
└─ 코드 일관성 확인

Step 6: 검증 → Stage 6 전달 ✅
```

### 흔한 오류 패턴

| 오류 유형     | 예시                        | 해결                    |
| ------------- | --------------------------- | ----------------------- |
| 청사진 불완전 | 인터페이스 정의 누락        | Stage 4 청사진 보완     |
| ADR 미반영    | 로깅 포맷 ADR과 구현 불일치 | 구현 수정 또는 ADR 갱신 |
| 의존성 오류   | 순환 의존성 발생            | Stage 4 설계 재검토     |

### 추적성

```
수정 이력: docs/revision_log.md
코드 주석: # Stage 5 구현 - ADR-XXX 참조
```

---

## 💡 핵심 원칙 요약

### DNA 구현의 3대 원칙

```
1. 표준 라이브러리 우선
────────────────────────────────
❌ 직접 구현 (89개 클래스, 1,679줄)
✅ 검증된 라이브러리 사용 (ADR 참조, 3줄)

2. 인터페이스 추상화
────────────────────────────────
Protocol 정의 → 구현체 교체 가능
테스트 시 Mock 주입 용이

3. 설정 주입
────────────────────────────────
설정 라이브러리로 환경별 분리 (ADR-402)
.env.development / .env.production
```

### 구현 순서 (의존성 기반)

```
Phase 1: 기반 (의존성 없음)
Types → Config → Logging → Errors

Phase 2: 데이터/통신
Database → Cache → Messaging

Phase 3: 품질/보안
Testing → Security → Monitoring
```

### 품질 기준 (Zero Tolerance)

```
Type Checker: 0 errors    (타입 안전성, ADR-301)
Linter:       0 violations (코드 품질, ADR-302)
Tests:        0 failures   (기능 정확성, ADR-801)
Coverage:     95%+         (테스트 충분성)
```

---

**Remember**: 

- DNA 없이 도메인 구현 = 기반 없는 건물
- 표준 라이브러리 우선 = 바퀴 재발명 금지
- 의존성 순서 준수 = Types → Config → Logging → Errors
- Kent Beck 수준 = 10/11개 DNA 동작

*DNA가 "환경"으로 구축되어야 도메인 코드가 그 위에서 안전하게 실행됩니다.*


================================================================================

📄 FILE: 06G-00_project_standards_guide.md
--------------------------------------------------------------------------------

# Stage 6: 프로젝트 표준 가이드 (Project Standards Guide)

> **목적**: DNA 시스템 사용 강제 규칙 + 자동화 설정으로 일관성 보장
>
> **버전**: v4.1 (2025-12-03)
>
> - v4.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
> - v2.0 (2025-11-12): 입력/출력 문서 추가
> - v1.0 (2025-11-10): 초기 버전

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage 6 실행 가이드) ← 지금 여기!
```

**참조 문서**:
- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` **Part 5.4**

---

## 📖 이 가이드의 구성

이 가이드는 **언어 무관 개념 + Python 생태계 예시**로 구성됩니다:

```
개념 (언어 무관):
├─ DNA 사용 규칙 (DO/DON'T)
├─ 품질 기준 (Zero Tolerance)
├─ 자동화 전략 (3단계 성숙도)
└─ 강제 메커니즘 (pre-commit, CI/CD)

Python 생태계 예시:
├─ 도구: Ruff, MyPy, pytest, pre-commit
├─ 설정: pyproject.toml, .pre-commit-config.yaml
└─ CI/CD: GitHub Actions

다른 언어:
└─ 해당 언어 매뉴얼 참조
    ├─ TypeScript: ESLint, TypeScript, Jest, Husky
    ├─ Rust: Clippy, rustc, Cargo test
    └─ Go: golangci-lint, go test
```

**참조**: 구체적 도구/설정은 언어별 매뉴얼 참조

---

## 🤔 왜 Project Standards가 필요한가?

### Bridge의 마지막 조각

```
Bridge(Stage 4-6)의 4대 구성요소:

┌─────────────────────────────────────────────────────┐
│  Stage 3: ADR (결정)                                │
│  "PostgreSQL을 쓰기로 했다"                          │
└─────────────────────────────────────────────────────┘
           ↓
┌─────────────────────────────────────────────────────┐
│  Stage 4: DNA 청사진 (설계)                          │
│  "src/core/database/ 구조와 API 설계"                │
└─────────────────────────────────────────────────────┘
           ↓
┌─────────────────────────────────────────────────────┐
│  Stage 5: DNA 구현 (코드)                            │
│  "get_session(), Base 클래스 구현"                   │
└─────────────────────────────────────────────────────┘
           ↓
┌─────────────────────────────────────────────────────┐
│  Stage 6: Project Standards (강제) ← 지금 여기!     │
│  "직접 SQL 금지, get_session() 필수 사용"            │
│  "위반 시 pre-commit에서 자동 차단"                  │
└─────────────────────────────────────────────────────┘
```

### 규칙만 있고 강제가 없으면?

```
❌ 강제 없는 규칙:

PROJECT_STANDARDS.md:
"print() 대신 logger를 사용하세요"

현실:
domain/orders/service.py:
    print(f"Creating order: {data}")  # 급하니까 일단...
    print("DEBUG: ", response)        # 디버깅용...

결과:
├─ 규칙 문서는 존재하지만 아무도 안 읽음
├─ 코드 리뷰에서 발견? "이번만 넘어가죠"
├─ 운영에서 print 로그가 stdout에 뒤섞임
└─ 3개월 후 "누가 print 쓴 거야?!" 😱
```

```
✅ 강제 있는 규칙:

PROJECT_STANDARDS.md:
"print() 대신 logger를 사용하세요"

자동화 (Python 예시):
pyproject.toml:
    select = ["T201"]  # T201 = print 금지

.pre-commit-config.yaml:
    - id: ruff
      args: [--fix]

결과:
$ git commit -m "Add order feature"
Ruff.....Failed
- T201: print found (domain/orders/service.py:15)

├─ 커밋 자체가 차단됨
├─ 개발자가 즉시 수정
├─ 코드 리뷰 불필요 (자동 강제)
└─ 운영 환경 100% 안전

**참조**: 다른 언어의 린터 설정은 해당 언어 매뉴얼 참조
```

### 비유: 교통 법규 vs 과속 카메라

```
교통 법규 (규칙):
"제한 속도 60km/h를 지키세요"

과속 카메라 (강제):
위반 시 자동 촬영 → 벌금 → 면허 정지

Project Standards:
├─ 규칙 = PROJECT_STANDARDS.md (교통 법규)
├─ 강제 = pre-commit hooks (과속 카메라)
├─ 처벌 = 커밋 차단 (벌금)
└─ 결과 = 100% 준수 (안전한 도로)
```

---

## 📥 입력 문서

### Stage 5에서 전달받는 것

| 파일 | 핵심 내용 | 이 Stage에서 사용 |
|------|----------|-----------------|
| `src/core/` | 구현된 DNA 모듈 | 사용 규칙 작성 |
| `05D-01_dna_implementation.md` | 구현 완료 문서 | 금지/필수 규칙 도출 |
| `03A-401~499_*.md` | DNA 시스템 ADR | 기술 선택 근거 |

---

## 📤 출력 문서

### 필수 산출물

```
docs/
├── 06D-01_project_standards.md    # THE 산출물 (규칙 문서)
└── 06D-02_automation_config.md    # 자동화 설정 문서

프로젝트 루트/
├── pyproject.toml                 # Ruff, MyPy, pytest 설정
├── .pre-commit-config.yaml        # pre-commit hooks
└── .importlinter                  # 아키텍처 의존성 규칙
```

---

## 🔧 Project Standards 3대 영역

### 영역 1: DNA 사용 규칙 (DO/DON'T)

```
각 DNA 시스템마다:

DO (필수):
├─ 어떤 API를 사용해야 하는지
├─ 어떤 패턴을 따라야 하는지
└─ 코드 예시 (언어별)

DON'T (금지):
├─ 어떤 것을 사용하면 안 되는지
├─ 왜 금지인지
└─ 린터/타입 체커 규칙 코드

**참조**: 구체적 규칙 코드는 언어별 매뉴얼 참조
  - Python: Ruff, MyPy 규칙
  - TypeScript: ESLint, TSConfig 규칙
  - Rust: Clippy lints
  - Go: golangci-lint 규칙
```

### 영역 2: 품질 기준 (Zero Tolerance)

```
절대 타협 없는 기준 (언어 무관):

린터:       0 violations
타입 체커:   0 errors
테스트:     0 failures
커버리지:   95%+

위반 시:
├─ 커밋 차단 (pre-commit hook)
├─ PR 머지 차단 (CI)
└─ 배포 차단 (CD)

**Python 예시**:
├─ 린터: Ruff
├─ 타입 체커: MyPy
├─ 테스트: pytest
└─ 커버리지: pytest-cov

**참조**: 다른 언어의 도구는 해당 언어 매뉴얼 참조
```

### 영역 3: 자동화 설정 (강제 메커니즘)

```
3단계 강제 (언어 무관 전략):

Day 1: 로컬 강제 (commit hook)
├─ 린터 (포맷팅 + 스타일)
├─ 타입 체커
└─ 빠른 테스트 (unit)

Week 2: 아키텍처 강제 (dependency checker)
├─ core → domain 금지
├─ domain → api 금지
└─ 레이어 의존성 방향 강제

Month 1+: CI/CD 파이프라인
├─ 전체 테스트 + 커버리지 게이트
├─ 보안 스캔
└─ 자동 배포

**Python 예시**:
├─ Day 1: pre-commit (Ruff, MyPy, pytest)
├─ Week 2: import-linter
└─ Month 1+: GitHub Actions

**참조**: 다른 언어의 도구/파이프라인은 해당 언어 매뉴얼 참조
```

---

## 📋 작성 단계 (Part 1-4)

### Part 1: DNA 사용 규칙 작성 (1시간)

#### Step 1: Logging 규칙

```markdown
## Logging (DNA 1)

### DO ✅

**사용 패턴 (Python 예시)**:

```python
# 올바른 사용
from core.logging import get_logger

logger = get_logger(__name__)

# 기본 로깅
logger.info("주문 생성", order_id=order_id, user_id=user_id)

# 에러 로깅
logger.error("주문 실패", error=str(e), order_id=order_id)

# 컨텍스트 바인딩
from core.logging import bind_context
bind_context(trace_id=trace_id, user_id=user_id)
```

### DON'T ❌

**금지 패턴 (Python 예시)**:

```python
# 금지 1: print() 사용
print(f"Creating order: {data}")  # ❌ Ruff T201 위반!

# 금지 2: logging 직접 사용
import logging
logger = logging.getLogger(__name__)  # ❌ 구조화 로깅 불가

# 금지 3: f-string 메시지
logger.info(f"Order {order_id} created")  # ❌ 구조화 파괴
# 올바른: logger.info("Order created", order_id=order_id)
```

### 린터 규칙 (Python - Ruff)
- `T201`: print 금지
- `G004`: f-string in logging 금지

**참조**: 다른 언어의 로깅 규칙은 해당 언어 매뉴얼 참조
```

#### Step 2: Config 규칙

```markdown
## Configuration (DNA 2)

### DO ✅

**사용 패턴 (Python 예시)**:

```python
# 올바른 사용
from core.config import get_settings

settings = get_settings()

# 설정값 접근
db_url = settings.database_url
redis_url = settings.redis_url

# 환경 확인
if settings.is_production:
    # 운영 전용 로직
```

### DON'T ❌

**금지 패턴 (Python 예시)**:

```python
# 금지 1: os.environ 직접 접근
import os
db_url = os.environ.get("DATABASE_URL")  # ❌ 타입 안전성 없음

# 금지 2: 하드코딩
db_url = "postgresql://localhost/dev"  # ❌ 환경별 분리 불가

# 금지 3: 설정 파일 직접 읽기
import json
config = json.load(open("config.json"))  # ❌ 검증 없음
```

### 의존성 규칙 (Python - import-linter)
- 커스텀 규칙으로 `os.environ` 직접 사용 감지

**참조**: 다른 언어의 설정 관리 규칙은 해당 언어 매뉴얼 참조
```

#### Step 3: Types 규칙

```markdown
## Types (DNA 3)

### DO ✅

**사용 패턴 (Python 예시)**:

```python
# 올바른 사용
from core.types import UserId, OrderId, Money

def create_order(
    user_id: UserId,
    amount: Money,
) -> OrderId:
    ...

# 값 객체 사용
price = Money(amount=Decimal("50000"), currency="KRW")
```

### DON'T ❌

**금지 패턴 (Python 예시)**:

```python
# 금지 1: Any 타입
def process(data: Any) -> Any:  # ❌ 타입 안전성 없음
    ...

# 금지 2: Dict[str, Any]
def create_order(data: Dict[str, Any]):  # ❌ TypedDict 사용
    ...

# 금지 3: 타입 힌트 누락
def create_order(user_id, amount):  # ❌ MyPy strict 위반
    ...
```

### 타입 체커 규칙 (Python - MyPy)
- `strict = true`: 모든 함수에 타입 힌트 필수
- `warn_return_any = true`: Any 반환 경고
- `disallow_any_explicit = true`: 명시적 Any 금지

**참조**: 다른 언어의 타입 규칙은 해당 언어 매뉴얼 참조
```

#### Step 4: Errors 규칙

```markdown
## Error Handling (DNA 4)

### DO ✅

**사용 패턴 (Python 예시)**:

```python
# 올바른 사용
from core.errors import ValidationError, NotFoundError, KISAPIError

# 도메인 에러
if not items:
    raise ValidationError("주문 항목이 비어있습니다", field="items")

# 리소스 없음
if not order:
    raise NotFoundError("Order", order_id)

# 외부 API 에러
if response.status_code != 200:
    raise KISAPIError("KIS API 호출 실패", status_code=response.status_code)
```

### DON'T ❌

**금지 패턴 (Python 예시)**:

```python
# 금지 1: 일반 Exception
raise Exception("Something went wrong")  # ❌ 에러 코드 없음

# 금지 2: except: pass
try:
    ...
except:  # ❌ 모든 에러 삼킴
    pass

# 금지 3: bare except
try:
    ...
except Exception:  # ❌ 너무 광범위
    logger.error("Error")

# 올바른: 구체적 예외 처리
try:
    ...
except ValidationError as e:
    logger.warning("검증 실패", error=e.message)
    raise
except KISAPIError as e:
    logger.error("외부 API 실패", error=e.message)
    raise
```

### 린터 규칙 (Python - Ruff)
- `E722`: bare except 금지
- `B001`: assert 대신 raise 사용

**참조**: 다른 언어의 에러 처리 규칙은 해당 언어 매뉴얼 참조
```

#### Step 5: Database 규칙

```markdown
## Database (DNA 5)

### DO ✅

**사용 패턴 (Python 예시)**:

```python
# 올바른 사용
from core.database import get_session

# 세션 사용 (컨텍스트 매니저)
async with get_session() as session:
    order = Order(user_id=user_id, amount=amount)
    session.add(order)
    await session.commit()

# 쿼리
async with get_session() as session:
    result = await session.execute(
        select(Order).where(Order.user_id == user_id)
    )
    orders = result.scalars().all()
```

### DON'T ❌

**금지 패턴 (Python 예시)**:

```python
# 금지 1: 직접 SQL 문자열
cursor.execute(f"SELECT * FROM orders WHERE id = {order_id}")  # ❌ SQL Injection!

# 금지 2: 세션 수동 관리
session = Session()
try:
    ...
finally:
    session.close()  # ❌ 컨텍스트 매니저 사용

# 금지 3: 트랜잭션 없이 여러 쓰기
session.add(order)
session.commit()
session.add(payment)
session.commit()  # ❌ 원자성 위반
```

### 보안 규칙 (Python - Ruff)
- `S608`: SQL Injection 가능 코드 감지

**참조**: 다른 언어의 데이터베이스 규칙은 해당 언어 매뉴얼 참조
```



### Part 2: 품질 기준 설정 (30분)

#### Zero Tolerance 기준

```markdown
## 품질 기준 (Zero Tolerance)

### 정적 분석 (언어 무관 기준)

| 도구 유형 | 기준 | 위반 시 |
|----------|-----|--------|
| 린터 | 0 violations | 커밋 차단 |
| 타입 체커 | 0 errors | 커밋 차단 |
| 테스트 | 0 failures | 머지 차단 |
| 커버리지 | 95%+ | 머지 차단 |

**Python 예시**: Ruff (린터), MyPy (타입 체커), pytest (테스트)

### 린터 규칙 (Python - Ruff)

```toml
[tool.ruff]
line-length = 88
target-version = "py312"

select = [
    "E",      # pycodestyle errors
    "F",      # pyflakes
    "I",      # isort
    "T201",   # print 금지
    "G004",   # f-string in logging 금지
    "B",      # bugbear
    "S",      # security
    "E722",   # bare except 금지
]

ignore = [
    "E501",   # line too long (formatter가 처리)
]
```

### 타입 체커 규칙 (Python - MyPy)

```toml
[tool.mypy]
python_version = "3.12"
strict = true
warn_return_any = true
warn_unused_ignores = true
disallow_untyped_defs = true
disallow_any_explicit = true

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false
```

### 테스트 규칙 (Python - pytest)

```toml
[tool.pytest.ini_options]
asyncio_mode = "auto"
addopts = """
    --cov=src
    --cov-fail-under=95
    --cov-report=term-missing
    -q
"""
testpaths = ["tests"]
```

**참조**: 다른 언어의 품질 기준 설정은 해당 언어 매뉴얼 참조
  - TypeScript: ESLint, TSConfig, Jest
  - Rust: Clippy, rustc, Cargo test
  - Go: golangci-lint, go test
```

### Part 3: 자동화 설정 (1시간)

#### Step 1: Commit Hook 설정

**개념 (언어 무관)**:
- 커밋 전에 자동으로 실행되는 검증 스크립트
- 린터, 타입 체커, 빠른 테스트 실행
- 위반 시 커밋 차단

**Python 예시 (.pre-commit-config.yaml)**:

```yaml
# .pre-commit-config.yaml

repos:
  # Ruff (린팅 + 포맷팅)
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.8.0
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  # MyPy (타입 체크)
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.13.0
    hooks:
      - id: mypy
        additional_dependencies:
          - pydantic>=2.0
          - pydantic-settings>=2.0
        args: [--strict]

  # pytest (로컬 테스트)
  - repo: local
    hooks:
      - id: pytest-unit
        name: pytest unit tests
        entry: pytest tests/unit -q --no-cov
        language: system
        pass_filenames: false
        always_run: true

  # import-linter (아키텍처 검증)
  - repo: local
    hooks:
      - id: import-linter
        name: import-linter
        entry: lint-imports
        language: system
        pass_filenames: false
        always_run: true
```

**참조**: 다른 언어의 commit hook 설정은 해당 언어 매뉴얼 참조
  - TypeScript: Husky + lint-staged
  - Rust: cargo-husky
  - Go: pre-commit with golangci-lint
```

#### Step 2: 아키텍처 의존성 검증 설정

**개념 (언어 무관)**:
- 레이어 간 의존성 방향 강제
- 역방향 의존성 차단
- Clean Architecture 레이어 순서 보장

**Python 예시 (.importlinter)**:

```ini
# .importlinter

[importlinter]
root_package = src

[importlinter:contract:core-independence]
name = Core는 Domain/API에 의존하지 않음
type = forbidden
source_modules =
    src.core
forbidden_modules =
    src.domain
    src.api

[importlinter:contract:domain-independence]
name = Domain은 API에 의존하지 않음
type = forbidden
source_modules =
    src.domain
forbidden_modules =
    src.api

[importlinter:contract:layers]
name = Clean Architecture 레이어
type = layers
layers =
    src.api
    src.domain
    src.core
```

**의존성 방향 (언어 무관 규칙)**:
```
허용:
api → domain → core

금지:
core → domain (역방향!)
domain → api (역방향!)
core → api (건너뛰기!)
```

**참조**: 다른 언어의 의존성 검증 도구는 해당 언어 매뉴얼 참조
  - TypeScript: dependency-cruiser, eslint-plugin-import
  - Rust: cargo-modules, cargo-deny
  - Go: go-mod-outdated, go list
```

#### Step 3: CI 파이프라인 설정

**개념 (언어 무관)**:
- PR 머지 전 자동 검증
- 전체 테스트 + 커버리지 체크
- 보안 스캔 (선택)
- 배포 게이트

**Python 예시 (GitHub Actions)**:

```yaml
# .github/workflows/ci.yml

name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  quality:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        run: pip install uv

      - name: Install dependencies
        run: uv sync

      - name: Ruff (lint)
        run: uv run ruff check src tests

      - name: Ruff (format)
        run: uv run ruff format --check src tests

      - name: MyPy
        run: uv run mypy src --strict

      - name: import-linter
        run: uv run lint-imports

      - name: pytest
        run: uv run pytest --cov=src --cov-fail-under=95

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          fail_ci_if_error: true
```

**참조**: 다른 언어/플랫폼의 CI 설정은 해당 언어 매뉴얼 참조
  - TypeScript: GitHub Actions with Node.js
  - Rust: GitHub Actions with Cargo
  - Go: GitHub Actions with Go
  - GitLab CI, CircleCI, Jenkins 등
```

### Part 4: 자동화 성숙도 로드맵 (30분)

#### Day 1: 로컬 강제 (Commit Hook)

**개념**: 개발자 로컬에서 즉시 검증

**Python 예시**:
```bash
# pre-commit 설치
uv add --dev pre-commit
pre-commit install

# 첫 검증
pre-commit run --all-files
```

**이 시점의 강제 (언어 무관)**:
- ✅ 린터 (포맷팅 + 스타일)
- ✅ 타입 체커
- ✅ 빠른 테스트 (unit)

#### Week 2: 아키텍처 강제 (Dependency Check)

**개념**: 레이어 간 의존성 방향 검증

**Python 예시**:
```bash
# import-linter 설치
uv add --dev import-linter

# 검증
lint-imports
```

**이 시점의 강제 (언어 무관)**:
- ✅ Day 1 모든 것
- ✅ 레이어 의존성 (core ← domain ← api)
- ✅ 역방향 의존성 차단

#### Month 1+: CI/CD 파이프라인

**개념**: PR 머지 전 전체 검증 + 배포 자동화

**Python 예시**:
```bash
# GitHub Actions 설정
mkdir -p .github/workflows
cp templates/ci.yml .github/workflows/
```

**이 시점의 강제 (언어 무관)**:
- ✅ Week 2 모든 것
- ✅ PR 머지 게이트
- ✅ 커버리지 리포트
- ✅ 배포 파이프라인

**참조**: 다른 언어의 자동화 로드맵은 해당 언어 매뉴얼 참조

---

## 📄 PROJECT_STANDARDS.md 템플릿

> **참고**: 이 템플릿은 Python 예시입니다. 다른 언어는 해당 언어 매뉴얼의 템플릿을 참조하세요.

### 06D-01_project_standards.md (Python)

```markdown
# Project Standards

> **프로젝트**: [프로젝트명]
> **버전**: v1.0
> **작성일**: YYYY-MM-DD
> **기반 ADR**: 03A-401 ~ 03A-411 (DNA 시스템)
> **언어**: Python 3.12+

---

## 1. 코드 스타일

### 1.1 포맷팅
- **도구**: Ruff formatter
- **줄 길이**: 88자
- **들여쓰기**: 4 spaces
- **인용부호**: 큰따옴표 (")

### 1.2 네이밍
| 대상 | 규칙 | 예시 |
|------|-----|------|
| 클래스 | PascalCase | `OrderService` |
| 함수/변수 | snake_case | `create_order` |
| 상수 | UPPER_SNAKE_CASE | `MAX_RETRY_COUNT` |
| 비공개 | _prefix | `_internal_method` |

### 1.3 Import 순서
```python
# 1. 표준 라이브러리
import os
from datetime import datetime

# 2. 서드파티
from fastapi import FastAPI
from pydantic import BaseModel

# 3. 로컬 (core → domain → api 순)
from core.logging import get_logger
from domain.orders import OrderService
```

---

## 2. DNA 시스템 사용 규칙

### 2.1 Logging

**DO ✅**
```python
from core.logging import get_logger
logger = get_logger(__name__)
logger.info("주문 생성", order_id=order_id)
```

**DON'T ❌**
```python
print("debug")                    # T201 위반
import logging                    # 직접 사용 금지
logger.info(f"Order {id}")        # G004 위반
```

### 2.2 Configuration

**DO ✅**
```python
from core.config import get_settings
settings = get_settings()
db_url = settings.database_url
```

**DON'T ❌**
```python
import os
os.environ.get("DB_URL")          # 타입 안전성 없음
db_url = "postgresql://..."       # 하드코딩 금지
```

### 2.3 Types

**DO ✅**
```python
from core.types import UserId, OrderId, Money

def create_order(user_id: UserId, amount: Money) -> OrderId:
    ...
```

**DON'T ❌**
```python
def create_order(user_id, amount):  # 타입 힌트 누락
    ...

def process(data: Any) -> Any:      # Any 금지
    ...
```

### 2.4 Error Handling

**DO ✅**
```python
from core.errors import ValidationError, NotFoundError

if not items:
    raise ValidationError("항목 필요", field="items")
```

**DON'T ❌**
```python
raise Exception("error")           # 일반 Exception 금지
except:                            # bare except 금지
    pass
```

### 2.5 Database

**DO ✅**
```python
from core.database import get_session

async with get_session() as session:
    session.add(order)
    await session.commit()
```

**DON'T ❌**
```python
cursor.execute(f"SELECT * WHERE id = {id}")  # SQL Injection!
session = Session()                           # 수동 관리 금지
```

---

## 3. 품질 기준

### 3.1 Zero Tolerance

| 항목 | 기준 | 검증 명령어 |
|------|-----|-----------|
| Ruff | 0 violations | `ruff check src tests` |
| MyPy | 0 errors | `mypy src --strict` |
| pytest | 0 failures | `pytest tests` |
| Coverage | 95%+ | `pytest --cov-fail-under=95` |

### 3.2 커밋 전 필수

```bash
# 모든 검증 통과 필수
pre-commit run --all-files
```

위반 시 커밋 차단됨.

---

## 4. 아키텍처 규칙

### 4.1 레이어 구조

```
src/
├── core/      # DNA 시스템 (공통 인프라)
├── domain/    # 비즈니스 로직
└── api/       # HTTP 인터페이스
```

### 4.2 의존성 방향

```
허용: api → domain → core
금지: core → domain, domain → api
```

### 4.3 import-linter로 강제

```bash
# 검증
lint-imports

# 위반 시
FAILED: Core는 Domain/API에 의존하지 않음
  src.core.database imports src.domain.orders
```

---

## 5. Git 규칙

### 5.1 커밋 메시지

```
<type>(<scope>): <subject>

feat(orders): 주문 생성 API 추가
fix(auth): 토큰 만료 처리 수정
refactor(core): 로깅 설정 개선
test(orders): 주문 서비스 테스트 추가
docs(readme): 설치 가이드 업데이트
```

### 5.2 브랜치 전략

```
main         ← 운영 (보호됨)
develop      ← 개발 통합
feature/*    ← 기능 개발
fix/*        ← 버그 수정
```

### 5.3 PR 규칙

- [ ] 모든 CI 통과
- [ ] 리뷰어 1명 이상 승인
- [ ] 커버리지 유지 또는 증가

---

## 6. 참조

- ADR: `docs/adr/03A-401~411_*.md`
- DNA 구현: `src/core/`
- 자동화 설정: `pyproject.toml`, `.pre-commit-config.yaml`
```



---

## ✏️ 작성 예시: 주식 거래 플랫폼

> **참고**: 이 예시들은 Python 생태계 기반입니다. 다른 언어는 해당 언어 매뉴얼의 예시를 참조하세요.

### 예시 1: DNA 사용 규칙 (Logging 상세) - Python

```markdown
## 2.1 Logging

> **ADR 참조**: ADR-401 (structlog 선택)

### 목적
모든 로그는 JSON 구조화 형식으로, trace_id를 포함하여 추적 가능해야 함.

### DO ✅ (필수 사용법)

```python
# 1. 로거 초기화
from core.logging import get_logger, bind_context

logger = get_logger(__name__)

# 2. 요청 시작 시 컨텍스트 바인딩
@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    bind_context(
        trace_id=request.headers.get("X-Trace-ID", str(uuid4())[:8]),
        user_id=getattr(request.state, "user_id", "anonymous"),
    )
    return await call_next(request)

# 3. 비즈니스 로직에서 로깅
async def create_order(self, data: CreateOrderRequest) -> OrderId:
    logger.info("주문 생성 시작", symbol=data.symbol, quantity=data.quantity)
    
    try:
        order = await self._process_order(data)
        logger.info("주문 생성 완료", order_id=str(order.id))
        return order.id
    except KISAPIError as e:
        logger.error("KIS API 실패", error=str(e), symbol=data.symbol)
        raise
```

### DON'T ❌ (금지 사항)

```python
# 금지 1: print() 사용
# Ruff T201 위반 → 커밋 차단
print(f"Order created: {order_id}")

# 금지 2: logging 직접 사용
# 구조화 로깅 불가, trace_id 누락
import logging
logging.info("Order created")

# 금지 3: f-string 메시지
# Ruff G004 위반 → 검색/필터링 어려움
logger.info(f"Order {order_id} created by {user_id}")
# 올바른: logger.info("Order created", order_id=order_id, user_id=user_id)

# 금지 4: 예외 정보 누락
try:
    ...
except Exception:
    logger.error("실패")  # ❌ 예외 정보 없음
# 올바른: logger.exception("실패", exc_info=True)
```

### 검증 방법

```bash
# Ruff로 print 검사
ruff check src --select=T201,G004

# 결과 (위반 시)
src/domain/orders/service.py:45:5: T201 `print` found
src/domain/orders/service.py:52:9: G004 Logging statement uses f-string
```

### 로그 출력 예시

```json
{
  "event": "주문 생성 완료",
  "trace_id": "abc12345",
  "user_id": "user-789",
  "order_id": "order-456",
  "timestamp": "2025-12-03T10:30:00Z",
  "level": "info",
  "logger": "domain.orders.service"
}
```
```

### 예시 2: 자동화 설정 (전체) - Python

```markdown
## 자동화 설정 (Python)

### pyproject.toml (완전판)

```toml
[project]
name = "stock-trading-platform"
version = "0.1.0"
requires-python = ">=3.12"

dependencies = [
    "fastapi>=0.115.0",
    "pydantic>=2.11.0",
    "pydantic-settings>=2.6.0",
    "structlog>=24.1.0",
    "sqlalchemy>=2.0.0",
    "redis>=5.0.0",
    "httpx>=0.27.0",
    "uvloop>=0.21.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.3.0",
    "pytest-cov>=6.0.0",
    "pytest-asyncio>=0.24.0",
    "ruff>=0.8.0",
    "mypy>=1.13.0",
    "pre-commit>=4.0.0",
    "import-linter>=2.0.0",
]

[tool.ruff]
line-length = 88
target-version = "py312"

select = [
    "E",      # pycodestyle errors
    "F",      # pyflakes
    "I",      # isort
    "T201",   # print 금지
    "G004",   # f-string in logging 금지
    "B",      # bugbear
    "S",      # security (SQL injection 등)
    "E722",   # bare except 금지
    "UP",     # pyupgrade
]

[tool.ruff.format]
quote-style = "double"

[tool.mypy]
python_version = "3.12"
strict = true
warn_return_any = true
warn_unused_ignores = true
disallow_untyped_defs = true

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false

[tool.pytest.ini_options]
asyncio_mode = "auto"
addopts = "--cov=src --cov-fail-under=95 --cov-report=term-missing -q"
testpaths = ["tests"]

[tool.coverage.run]
source = ["src"]
omit = ["tests/*", "*/__init__.py"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "if TYPE_CHECKING:",
    "raise NotImplementedError",
]
```

### .pre-commit-config.yaml (완전판)

```yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.8.0
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.13.0
    hooks:
      - id: mypy
        additional_dependencies:
          - pydantic>=2.0
          - pydantic-settings>=2.0
          - sqlalchemy>=2.0
        args: [--strict]
        pass_filenames: false
        entry: mypy src

  - repo: local
    hooks:
      - id: pytest-unit
        name: pytest unit tests
        entry: pytest tests/unit -q --no-cov
        language: system
        pass_filenames: false
        always_run: true
        stages: [pre-commit]

      - id: import-linter
        name: import-linter
        entry: lint-imports
        language: system
        pass_filenames: false
        always_run: true
```

### .importlinter (완전판)

```ini
[importlinter]
root_package = src

[importlinter:contract:core-independence]
name = Core는 Domain/API에 의존하지 않음
type = forbidden
source_modules =
    src.core
forbidden_modules =
    src.domain
    src.api

[importlinter:contract:domain-independence]
name = Domain은 API에 의존하지 않음
type = forbidden
source_modules =
    src.domain
forbidden_modules =
    src.api

[importlinter:contract:clean-layers]
name = Clean Architecture 레이어 순서
type = layers
layers =
    src.api
    src.domain
    src.core
```
```

### 예시 3: CI 파이프라인 - Python (GitHub Actions)

```yaml
# .github/workflows/ci.yml

name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: '3.12'

jobs:
  lint:
    name: Lint & Format
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        run: pip install uv
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Ruff lint
        run: uv run ruff check src tests
      
      - name: Ruff format
        run: uv run ruff format --check src tests

  type-check:
    name: Type Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        run: pip install uv
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: MyPy
        run: uv run mypy src --strict

  architecture:
    name: Architecture Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        run: pip install uv
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: import-linter
        run: uv run lint-imports

  test:
    name: Test & Coverage
    runs-on: ubuntu-latest
    needs: [lint, type-check, architecture]
    
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install uv
        run: pip install uv
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Run tests
        run: uv run pytest --cov=src --cov-fail-under=95 --cov-report=xml
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test
          REDIS_URL: redis://localhost:6379
      
      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          files: coverage.xml
          fail_ci_if_error: true
```

---

## ✅ Stage 6 완료 체크리스트

### DNA 사용 규칙

- [ ] Logging DO/DON'T 작성
- [ ] Config DO/DON'T 작성
- [ ] Types DO/DON'T 작성
- [ ] Errors DO/DON'T 작성
- [ ] Database DO/DON'T 작성 (패밀리별)

### 품질 기준

- [ ] Zero Tolerance 기준 명시 (Ruff 0, MyPy 0, Coverage 95%)
- [ ] pyproject.toml [tool.ruff] 설정
- [ ] pyproject.toml [tool.mypy] 설정
- [ ] pyproject.toml [tool.pytest] 설정

### 자동화 설정

- [ ] .pre-commit-config.yaml 작성
- [ ] pre-commit install 실행
- [ ] .importlinter 설정
- [ ] lint-imports 검증

### CI/CD (선택)

- [ ] GitHub Actions workflow 작성
- [ ] PR 머지 게이트 설정
- [ ] 커버리지 리포트 설정

### 산출물 생성

- [ ] `06D-01_project_standards.md` 작성
- [ ] `06D-02_automation_config.md` 작성 (선택)
- [ ] 모든 설정 파일 프로젝트 루트에 배치

### 검증

- [ ] `pre-commit run --all-files` 통과
- [ ] `lint-imports` 통과
- [ ] 기존 코드 모두 규칙 준수 확인

---

## 🔗 Stage 6 → Stage 7 연결

### Stage 7에 전달하는 것

| 전달 항목 | 내용 | 용도 |
|----------|------|------|
| PROJECT_STANDARDS.md | DNA 사용 규칙 | 도메인 코드 작성 기준 |
| 자동화 설정 | pre-commit, CI | 품질 강제 |
| 아키텍처 규칙 | import-linter | 의존성 방향 강제 |

### Bridge 완료!

```
Bridge(Stage 4-6) 완료:

Stage 4: DNA 청사진 ✅
  └─ 무엇을 만들지 설계

Stage 5: DNA 구현 ✅
  └─ 실제 코드 작성

Stage 6: Project Standards ✅ ← 지금 여기!
  └─ 강제 규칙 + 자동화

결과:
├─ src/core/ DNA 모듈 완성
├─ PROJECT_STANDARDS.md 규칙 문서
├─ pre-commit, import-linter 자동화
└─ CI 파이프라인 (선택)

이제 도메인 코드를 안전하게 작성할 수 있는 "환경" 완성!
```

### Stage 7 미리보기

```
Stage 7: Project Blueprint
├─ 도메인 모델 설계 (Entity, Value Object, Aggregate)
├─ API 설계 (엔드포인트, 요청/응답)
├─ 데이터베이스 스키마
└─ DNA 환경 위에서 도메인 상세 설계
```

---

## ⏪ 이전 Stage 검증 및 수정 프로토콜

### 검증 시점
- Stage 6 시작 전 필수 체크 (Bridge 완성 직전!)
- 자동화 설정 전 DNA 구현과 교차 검증

### 검증 대상

| Stage | 산출물 | 검증 항목 |
|-------|--------|----------|
| Stage 1 | 01C-01_*.md | 표준이 NFR 우선순위 반영? |
| Stage 2 | 02C-01_*.md | 표준이 기술 제약 반영? |
| Stage 3 | 03A-*_*.md | 표준이 ADR 결정 반영? |
| Stage 4 | 04B-01_*.md | 표준이 DNA 청사진 반영? |
| Stage 5 | 05D-01_*.md | 구현된 DNA와 표준 일치? |

### 오류 발견 시 프로토콜 (Bridge 완성 전 마지막 검증!)

```
Stage 6에서 Stage 1-5 오류 발견 시:

Step 1: 오류 발견 및 문서화
├─ 발견 위치: 표준 [섹션] 작성 중
├─ 오류 내용: [구체적 설명]
├─ 영향 Stage: Stage [1-5]
└─ 기록: 06D-01에 "발견된 이슈" 추가

⚠️ Stage 6은 Bridge 완성 직전!
├─ 여기서 오류 수정 = 비용 최소
├─ Stage 7 이후 발견 = 비용 급증
└─ 철저한 검증 필수!

Step 2: 영향 범위 파악
├─ DNA 구현(Stage 5) 수정 필요?
├─ 청사진(Stage 4) 수정 필요?
├─ ADR(Stage 3) 수정 필요?
└─ 재작업 예상: [X]시간

Step 3: 해당 Stage로 이동 → 수정

Step 4: 중간 Stage 전파 (Stage 4-5)

Step 5: Stage 6 재진행
├─ 수정된 DNA로 표준 재검토
└─ 자동화 설정 재검증

Step 6: Bridge 완성 검증 → Stage 7 전달 ✅
```

### 흔한 오류 패턴

| 오류 유형 | 예시 | 해결 |
|----------|------|------|
| DNA-표준 불일치 | 로깅 함수명 불일치 | Stage 5 구현 또는 표준 수정 |
| ADR 미반영 | 코드 스타일 ADR과 표준 불일치 | 표준 수정 |
| 자동화 불가 | 규칙은 있으나 검증 방법 없음 | 규칙 재정의 또는 커스텀 린터 |

### 추적성

```
수정 이력: docs/revision_log.md
표준 참조: PROJECT_STANDARDS.md에 ADR 링크 포함
```

---

## 💡 핵심 원칙 요약

### Project Standards의 3대 영역

```
1. DNA 사용 규칙 (DO/DON'T)
────────────────────────────────
각 DNA 시스템마다:
├─ DO: 필수 사용법 + 코드 예시
├─ DON'T: 금지 사항 + 이유
└─ Ruff/MyPy 규칙 코드

2. 품질 기준 (Zero Tolerance)
────────────────────────────────
절대 타협 없는 기준:
├─ Ruff: 0 violations
├─ MyPy: 0 errors
├─ pytest: 0 failures
└─ Coverage: 95%+

3. 자동화 설정 (강제 메커니즘)
────────────────────────────────
3단계 강제:
├─ Day 1: pre-commit (로컬)
├─ Week 2: import-linter (아키텍처)
└─ Month 1+: CI/CD (파이프라인)
```

### 규칙 vs 강제

```
규칙만 있으면:
├─ 문서는 존재하지만 아무도 안 읽음
├─ 코드 리뷰에서 "이번만 넘어가죠"
└─ 3개월 후 "누가 이렇게 한 거야?!" 😱

규칙 + 강제:
├─ 커밋 자체가 차단됨
├─ 개발자가 즉시 수정
├─ 코드 리뷰 불필요 (자동 강제)
└─ 운영 환경 100% 안전 ✅
```

### 자동화 성숙도 로드맵

```
Day 1: pre-commit
├─ Ruff (린팅 + 포맷팅)
├─ MyPy (타입 체크)
└─ 기본 테스트

Week 2: import-linter
├─ 레이어 의존성 강제
└─ 역방향 의존성 차단

Month 1+: CI/CD
├─ PR 머지 게이트
├─ 커버리지 리포트
└─ 배포 파이프라인
```

---

**Remember**: 
- 규칙 없는 자동화 = 무엇을 강제할지 모름
- 자동화 없는 규칙 = 아무도 안 지킴
- 둘 다 있어야 = 100% 품질 보장
- Bridge 완료 = 도메인 코드 작성 환경 완성!

*Stage 6으로 Bridge(Stage 4-6)가 완료됩니다. 이제 Stage 7부터 도메인 코드를 안전하게 작성할 수 있습니다.*


================================================================================

📄 FILE: 07G-00_blueprint_guide.md
--------------------------------------------------------------------------------

# Stage 7: 프로젝트 블루프린트 가이드 (Project Blueprint Guide)

> **목적**: 모든 ADR을 통합하여 도메인 전체 설계도 작성 (코드 작성 직전 단계)
>
> **버전**: v4.1 (2025-12-03)
>
> - v4.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
> - v2.0 (2025-11-12): 입력/출력 문서 추가
> - v1.0 (2025-11-10): 초기 버전

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage 7 실행 가이드) ← 지금 여기!
```

**참조 문서**:
- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` **Part 6.1**

---

## 🤔 왜 Project Blueprint가 필요한가?

### ADR vs Blueprint

```
ADR (Stage 3):
├─ "무엇을" 결정했는지
├─ "왜" 그렇게 결정했는지
├─ 개별 결정 단위 (하나의 주제)
└─ 예: "PostgreSQL을 선택한다"

Blueprint (Stage 7):
├─ "어떻게" 구현할 것인지
├─ 모든 ADR을 통합한 전체 그림
├─ 구체적인 구현 명세
└─ 예: "users 테이블 스키마, orders API 엔드포인트..."

관계:
ADR-001 (PostgreSQL) ─┐
ADR-002 (JWT 인증)   ─┼──→ Blueprint (전체 설계도)
ADR-003 (KIS API)    ─┘
```

### Blueprint 없이 구현하면?

```
❌ ADR만 보고 구현:

개발자 A: "ADR에 PostgreSQL 쓴다고 했으니 테이블 만들자"
  → users 테이블: id, name, email

개발자 B: "나도 users 테이블 필요한데..."
  → users 테이블: user_id, username, email_address

결과:
├─ 테이블 스키마 불일치
├─ 필드명 혼란 (id vs user_id, name vs username)
├─ 나중에 대규모 마이그레이션 필요
└─ "처음부터 설계했으면..." 😱
```

```
✅ Blueprint 기반 구현:

07B-01_project_blueprint.md:
────────────────────────────────
## 3. 도메인 모델

### 3.1 User 엔티티
| 필드 | 타입 | 설명 |
|------|------|------|
| id | UUID | PK, core.types.UserId |
| email | str | Unique, EmailStr |
| created_at | datetime | UTC |
| updated_at | datetime | UTC |

참조: ADR-003 (PostgreSQL), PROJECT_STANDARDS.md Ln 45-60

개발자 A, B 모두:
  → 동일한 스키마 구현
  → 동일한 타입 사용 (UserId)
  → 일관된 코드베이스 ✅
```

### 비유: 건축 설계도

```
ADR = 건축 결정:
├─ "콘크리트 구조로 한다" (ADR-001)
├─ "3층 건물로 한다" (ADR-002)
└─ "지하 주차장을 둔다" (ADR-003)

Blueprint = 건축 설계도:
├─ 1층 평면도: 로비, 회의실, 화장실 위치
├─ 2층 평면도: 사무실 배치
├─ 3층 평면도: 임원실, 서버실
├─ 배관도: 수도, 전기, 통신
├─ 구조도: 기둥, 보, 벽체 위치
└─ 모든 치수, 자재 명시

→ 설계도 없이 "콘크리트로 3층 짓자"만 있으면?
  시공자마다 다르게 해석해서 건물이 엉망!
```

---

## 📥 입력 문서

### Stage 3-6에서 전달받는 것

| 파일 | 핵심 내용 | 이 Stage에서 사용 |
|------|----------|-----------------|
| `03A-*_*.md` | 모든 ADR (DNA + 도메인) | 결정 사항 통합 |
| `06D-01_project_standards.md` | 프로젝트 표준 | 규칙 참조 |
| `01C-01_*.md` | 패밀리 분류 | 시스템 특성 확인 |
| `02C-01_*.md` | NFR 우선순위 | 품질 속성 확인 |

---

## 📤 출력 문서

### 필수 산출물

```
docs/
├── 07B-01_project_blueprint.md    # THE 산출물 (전체 설계도)
└── 07S-01_domain_diagrams/        # 도메인별 다이어그램 (선택)
    ├── system_architecture.md
    ├── data_flow.md
    └── entity_relationship.md
```

---

## 🔧 Blueprint 9대 섹션

### 섹션 구조

```
07B-01_project_blueprint.md
────────────────────────────────

1. 시스템 개요        ← 무엇을 만드는가?
2. 아키텍처 구조      ← 전체 구조는?
3. 도메인 모델        ← 핵심 객체는?
4. API 설계          ← 외부 인터페이스는?
5. 데이터베이스 설계   ← 데이터 저장은?
6. 외부 연동          ← 외부 시스템은?
7. 에러 처리          ← 실패 시 대응은?
8. 보안              ← 인증/인가는?
9. 다음 단계          ← Stage 8 연결
```

---

## 📋 작성 단계 (Part 1-4)

### Part 1: 시스템 개요 + 아키텍처 (1시간)

#### 섹션 1: 시스템 개요

```markdown
## 1. 시스템 개요

### 1.1 목적
주식 자동매매 플랫폼 - 사용자가 정의한 전략에 따라 KIS API를 통해 자동으로 주식을 매매

### 1.2 범위
- 포함: 주문 관리, 포트폴리오 조회, 전략 실행, 알림
- 제외: 백테스팅, 리스크 관리 (v2.0 예정)

### 1.3 핵심 기능
| 기능 | 설명 | 우선순위 |
|------|------|---------|
| 주문 생성 | 매수/매도 주문 | P0 |
| 주문 조회 | 주문 상태 확인 | P0 |
| 포트폴리오 | 보유 종목 조회 | P0 |
| 전략 실행 | 자동매매 전략 | P1 |
| 알림 | 체결 알림 | P1 |

### 1.4 패밀리 분류
- **패밀리**: A-A-B (CRUD/트랜잭션)
- **근거**: 금융 거래 → 강한 일관성 필수
- **참조**: 01C-01_family_classification.md
```

#### 섹션 2: 아키텍처 구조

```markdown
## 2. 아키텍처 구조

### 2.1 레이어 구조

```
┌─────────────────────────────────────────────────────────┐
│                    Presentation Layer                    │
│              (API Framework + WebSocket)                 │
├─────────────────────────────────────────────────────────┤
│                    Application Layer                     │
│                (Use Cases / Services)                    │
├─────────────────────────────────────────────────────────┤
│                      Domain Layer                        │
│             (Entities, Value Objects, Events)            │
├─────────────────────────────────────────────────────────┤
│                   Infrastructure Layer                   │
│     (Database, External APIs, Cache, Messaging)         │
├─────────────────────────────────────────────────────────┤
│                      Core Layer                          │
│        (DNA Systems - Logging, Config, Types...)         │
└─────────────────────────────────────────────────────────┘
```

### 2.2 의존성 방향

```
Presentation → Application → Domain ← Infrastructure
                               ↑
                             Core
```

- **규칙**: 안쪽으로만 의존 (Domain이 중심)
- **강제**: import-linter (Stage 6 설정)
- **참조**: ADR-004 하이브리드 아키텍처

### 2.3 컴포넌트 구조

```
src/
├── core/           # DNA 시스템 (Stage 5 완료)
├── domain/         # 도메인 레이어
│   ├── orders/     # 주문 도메인
│   ├── portfolio/  # 포트폴리오 도메인
│   └── strategy/   # 전략 도메인
├── application/    # 애플리케이션 레이어
│   ├── orders/     # 주문 유스케이스
│   ├── portfolio/  # 포트폴리오 유스케이스
│   └── strategy/   # 전략 유스케이스
├── infrastructure/ # 인프라 레이어
│   ├── database/   # 리포지토리 구현
│   ├── external/   # 외부 API 클라이언트
│   └── messaging/  # 이벤트 발행
└── api/            # 프레젠테이션 레이어
    ├── routes/     # API 라우터
    ├── schemas/    # 요청/응답 스키마
    └── middleware/ # 미들웨어
```
```

### Part 2: 도메인 모델 설계 (2시간)

#### 섹션 3: 도메인 모델

```markdown
## 3. 도메인 모델

### 3.1 엔티티 (Entities)

#### User 엔티티
| 필드 | 타입 | 설명 | 제약 |
|------|------|------|------|
| id | UserId (UUID) | PK | core.types.UserId |
| email | EmailStr | 로그인 이메일 | Unique |
| hashed_password | str | bcrypt 해시 | - |
| is_active | bool | 활성 상태 | Default: True |
| created_at | datetime | 생성 시간 | UTC |
| updated_at | datetime | 수정 시간 | UTC |

**참조**: PROJECT_STANDARDS.md (네이밍 규칙)

#### Order 엔티티 (Aggregate Root)
| 필드 | 타입 | 설명 | 제약 |
|------|------|------|------|
| id | OrderId (UUID) | PK | core.types.OrderId |
| user_id | UserId | FK → users | Not Null |
| symbol | str | 종목 코드 | 6자리 |
| side | OrderSide | 매수/매도 | Enum |
| order_type | OrderType | 지정가/시장가 | Enum |
| quantity | int | 주문 수량 | > 0 |
| price | Money | 주문 가격 | >= 0 |
| status | OrderStatus | 주문 상태 | Enum |
| kis_order_id | str | KIS 주문번호 | Nullable |
| created_at | datetime | 생성 시간 | UTC |
| updated_at | datetime | 수정 시간 | UTC |

**도메인 규칙**:
- 시장가 주문 시 price = 0
- status 전이: pending → submitted → filled/cancelled
- 취소는 pending/submitted 상태에서만 가능

**참조**: ADR-101 주문 도메인

#### Portfolio 엔티티
| 필드 | 타입 | 설명 | 제약 |
|------|------|------|------|
| id | PortfolioId (UUID) | PK | - |
| user_id | UserId | FK → users | Unique |
| total_value | Money | 총 평가액 | >= 0 |
| cash_balance | Money | 현금 잔고 | >= 0 |
| updated_at | datetime | 갱신 시간 | UTC |

### 3.2 값 객체 (Value Objects)

#### Money
```
Value Object: Money
├─ amount: Decimal (>= 0)
├─ currency: String (ISO 4217, 기본값: "KRW")
└─ 연산: add, subtract (동일 통화만)
```

**참조**: core/types/ 디렉토리 (Stage 5 구현)

#### OrderSide
```
Enum: OrderSide
├─ BUY = "buy"
└─ SELL = "sell"
```

#### OrderStatus
```
Enum: OrderStatus
├─ PENDING = "pending"           # 생성됨
├─ SUBMITTED = "submitted"       # 거래소 제출됨
├─ FILLED = "filled"             # 체결됨
├─ PARTIALLY_FILLED = "partial"  # 부분 체결
├─ CANCELLED = "cancelled"       # 취소됨
└─ REJECTED = "rejected"         # 거부됨
```

### 3.3 집계 (Aggregates)

#### Order Aggregate
```
Order (Root)
├─ OrderId
├─ UserId (참조)
├─ Money (가격)
├─ OrderStatus
└─ 도메인 메서드
   ├─ submit(): pending → submitted
   ├─ fill(): submitted → filled
   └─ cancel(): pending/submitted → cancelled
```

**불변 규칙**:
- Order는 항상 유효한 상태 전이만 허용
- 취소된 주문은 다시 활성화 불가
- filled 상태에서 수정 불가

### 3.4 도메인 이벤트

| 이벤트 | 발행 시점 | 페이로드 |
|-------|---------|---------|
| OrderCreated | 주문 생성 시 | order_id, user_id, symbol |
| OrderSubmitted | KIS 제출 성공 시 | order_id, kis_order_id |
| OrderFilled | 체결 완료 시 | order_id, filled_price, filled_at |
| OrderCancelled | 취소 완료 시 | order_id, reason |
```



### Part 3: API + 데이터베이스 설계 (2시간)

#### 섹션 4: API 설계

```markdown
## 4. API 설계

### 4.1 엔드포인트 목록

#### Orders API
| Method | Path | 설명 | 인증 |
|--------|------|------|-----|
| POST | /api/v1/orders | 주문 생성 | Required |
| GET | /api/v1/orders | 주문 목록 조회 | Required |
| GET | /api/v1/orders/{id} | 주문 상세 조회 | Required |
| DELETE | /api/v1/orders/{id} | 주문 취소 | Required |

#### Portfolio API
| Method | Path | 설명 | 인증 |
|--------|------|------|-----|
| GET | /api/v1/portfolio | 포트폴리오 조회 | Required |
| GET | /api/v1/portfolio/positions | 보유 종목 조회 | Required |

#### Auth API
| Method | Path | 설명 | 인증 |
|--------|------|------|-----|
| POST | /api/v1/auth/login | 로그인 | - |
| POST | /api/v1/auth/refresh | 토큰 갱신 | Required |

**참조**: ADR-101 API 버저닝

### 4.2 요청/응답 스키마

#### POST /api/v1/orders - 주문 생성

**Request**:
```
CreateOrderRequest:
├─ symbol: String (6자리 숫자, 종목 코드)
├─ side: OrderSide (BUY | SELL)
├─ order_type: OrderType (MARKET | LIMIT)
├─ quantity: Integer (> 0)
└─ price: Decimal? (>= 0, 지정가 주문 시 필수)

검증 규칙:
└─ order_type == LIMIT → price 필수
```

**Response** (201 Created):
```
OrderResponse:
├─ id: UUID
├─ symbol: String
├─ side: OrderSide
├─ order_type: OrderType
├─ quantity: Integer
├─ price: Decimal?
├─ status: OrderStatus
└─ created_at: DateTime

CreateOrderResponse:
├─ order: OrderResponse
└─ message: String ("주문이 생성되었습니다")
```

**Error Responses**:
| Status | Error Code | 설명 |
|--------|-----------|------|
| 400 | 1001 | 검증 오류 (잘못된 종목 코드 등) |
| 401 | 9401 | 인증 필요 |
| 422 | 1002 | 처리 불가 (잔고 부족 등) |
| 502 | 2001 | KIS API 오류 |

**참조**: core/errors/codes.py (Stage 5 구현)

### 4.3 인증 흐름

```
1. 로그인 요청
   POST /api/v1/auth/login
   Body: { "email": "...", "password": "..." }

2. 토큰 발급
   Response: { "access_token": "...", "refresh_token": "...", "expires_in": 3600 }

3. API 요청
   Header: Authorization: Bearer {access_token}

4. 토큰 만료 시
   POST /api/v1/auth/refresh
   Header: Authorization: Bearer {refresh_token}
```

**참조**: ADR-011 보안 (JWT)
```

#### 섹션 5: 데이터베이스 설계

```markdown
## 5. 데이터베이스 설계

### 5.1 테이블 스키마

#### users 테이블
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) NOT NULL UNIQUE,
    hashed_password VARCHAR(255) NOT NULL,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- 인덱스
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at);
```

#### orders 테이블
```sql
CREATE TABLE orders (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id),
    symbol VARCHAR(10) NOT NULL,
    side VARCHAR(10) NOT NULL,  -- buy, sell
    order_type VARCHAR(20) NOT NULL,  -- limit, market
    quantity INTEGER NOT NULL CHECK (quantity > 0),
    price DECIMAL(15, 2),
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    kis_order_id VARCHAR(50),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- 인덱스
CREATE INDEX idx_orders_user_id ON orders(user_id);
CREATE INDEX idx_orders_status ON orders(status);
CREATE INDEX idx_orders_created_at ON orders(created_at DESC);
CREATE INDEX idx_orders_symbol ON orders(symbol);

-- 복합 인덱스 (자주 사용되는 쿼리)
CREATE INDEX idx_orders_user_status ON orders(user_id, status);
```

#### portfolios 테이블
```sql
CREATE TABLE portfolios (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL UNIQUE REFERENCES users(id),
    total_value DECIMAL(15, 2) NOT NULL DEFAULT 0,
    cash_balance DECIMAL(15, 2) NOT NULL DEFAULT 0,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- 인덱스
CREATE INDEX idx_portfolios_user_id ON portfolios(user_id);
```

#### positions 테이블 (보유 종목)
```sql
CREATE TABLE positions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    portfolio_id UUID NOT NULL REFERENCES portfolios(id),
    symbol VARCHAR(10) NOT NULL,
    quantity INTEGER NOT NULL CHECK (quantity >= 0),
    avg_price DECIMAL(15, 2) NOT NULL,
    current_price DECIMAL(15, 2),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    UNIQUE(portfolio_id, symbol)
);

-- 인덱스
CREATE INDEX idx_positions_portfolio_id ON positions(portfolio_id);
CREATE INDEX idx_positions_symbol ON positions(symbol);
```

### 5.2 ERD (Entity Relationship Diagram)

```
┌─────────────┐       ┌─────────────┐
│   users     │       │   orders    │
├─────────────┤       ├─────────────┤
│ id (PK)     │───────│ user_id (FK)│
│ email       │   1:N │ symbol      │
│ ...         │       │ status      │
└─────────────┘       └─────────────┘
      │
      │ 1:1
      ▼
┌─────────────┐       ┌─────────────┐
│ portfolios  │       │ positions   │
├─────────────┤       ├─────────────┤
│ id (PK)     │───────│portfolio_id │
│ user_id (FK)│   1:N │ symbol      │
│ total_value │       │ quantity    │
└─────────────┘       └─────────────┘
```

### 5.3 마이그레이션 전략

```
Alembic 사용:

migrations/
├── versions/
│   ├── 001_create_users.py
│   ├── 002_create_orders.py
│   ├── 003_create_portfolios.py
│   └── 004_create_positions.py
└── env.py

명령어:
# 마이그레이션 생성
alembic revision --autogenerate -m "create users table"

# 마이그레이션 적용
alembic upgrade head

# 롤백
alembic downgrade -1
```

**참조**: ADR-003 PostgreSQL
```

### Part 4: 외부 연동 + 에러/보안 (1시간)

#### 섹션 6: 외부 연동

```markdown
## 6. 외부 연동

### 6.1 KIS API 연동

#### 인증 흐름
```
1. OAuth 토큰 발급
   POST https://openapi.koreainvestment.com:9443/oauth2/tokenP
   Body: { "grant_type": "client_credentials", "appkey": "...", "appsecret": "..." }

2. 토큰 저장
   - Redis에 캐시 (TTL: 23시간)
   - 만료 1시간 전 자동 갱신

3. API 호출
   Header: authorization: Bearer {access_token}
           appkey: {appkey}
           appsecret: {appsecret}
```

#### 주문 API
| 기능 | 엔드포인트 | Method |
|------|----------|--------|
| 주문 | /uapi/domestic-stock/v1/trading/order-cash | POST |
| 정정 | /uapi/domestic-stock/v1/trading/order-rvsecncl | POST |
| 취소 | /uapi/domestic-stock/v1/trading/order-rvsecncl | POST |
| 체결 조회 | /uapi/domestic-stock/v1/trading/inquire-daily-ccld | GET |

#### Rate Limiting
```
제한: 초당 20회

대응 전략:
├─ Rate Limiter: 15회/초 (5회 여유)
├─ 요청 큐잉: 초과 시 대기열
├─ 벌크 최적화: 가능한 배치 조회
└─ 참조: ADR-001 KIS API 제한
```

#### 에러 처리
| KIS 코드 | 의미 | 대응 |
|---------|------|------|
| EGW00001 | 토큰 만료 | 자동 갱신 후 재시도 |
| EGW00002 | 권한 없음 | KISAPIError 발생 |
| APBK0013 | 잔고 부족 | ValidationError 변환 |

**참조**: core/external/kis_client.py
```

#### 섹션 7: 에러 처리

```markdown
## 7. 에러 처리

### 7.1 에러 코드 체계

```
1xxx: 도메인 에러 (비즈니스 로직)
├─ 1001: 검증 오류
├─ 1002: 리소스 없음
├─ 1003: 상태 충돌
├─ 1004: 잔고 부족
└─ 1005: 주문 취소 불가

2xxx: 외부 API 에러
├─ 2001: KIS API 오류
├─ 2002: KIS Rate Limit
└─ 2003: KIS 인증 실패

9xxx: 시스템 에러
├─ 9001: 내부 서버 오류
├─ 9002: 데이터베이스 오류
└─ 9003: 캐시 오류
```

### 7.2 에러 응답 형식

```json
{
  "error": {
    "code": "1002",
    "message": "주문을 찾을 수 없습니다",
    "details": {
      "resource": "Order",
      "identifier": "550e8400-e29b-41d4-a716-446655440000"
    }
  }
}
```

### 7.3 재시도 전략

| 에러 유형 | 재시도 | 전략 |
|----------|-------|------|
| 네트워크 오류 | 예 | Exponential backoff (1s, 2s, 4s) |
| Rate Limit | 예 | 고정 대기 (1s) |
| 인증 오류 | 예 | 토큰 갱신 후 1회 |
| 비즈니스 오류 | 아니오 | 즉시 실패 반환 |

**참조**: core/errors/exceptions.py (Stage 5 구현)
```

#### 섹션 8: 보안

```markdown
## 8. 보안

### 8.1 인증 (Authentication)

#### JWT 구조
```json
// Access Token (1시간)
{
  "sub": "user-uuid",
  "email": "user@example.com",
  "exp": 1699999999,
  "iat": 1699996399,
  "type": "access"
}

// Refresh Token (7일)
{
  "sub": "user-uuid",
  "exp": 1700599999,
  "iat": 1699996399,
  "type": "refresh"
}
```

#### 토큰 저장
- Access Token: 클라이언트 메모리 (XSS 방지)
- Refresh Token: HttpOnly Cookie (CSRF 방지)

### 8.2 인가 (Authorization)

#### RBAC (Role-Based Access Control)
| Role | 권한 |
|------|-----|
| user | 본인 주문 CRUD, 본인 포트폴리오 조회 |
| admin | 모든 사용자 조회, 시스템 설정 |

#### 리소스 소유권 검증
```
주문 조회 시 소유권 검증 (의사코드):

order = repository.get(order_id)
IF order.user_id != current_user.id:
    THROW ForbiddenError("접근 권한이 없습니다")
```

### 8.3 데이터 보호

| 데이터 | 보호 방법 |
|-------|---------|
| 비밀번호 | bcrypt 해시 (cost=12) |
| API 키 | 환경 변수, 절대 로깅 금지 |
| 개인정보 | 로그 마스킹 (이메일 앞 3자만) |

**참조**: ADR-011 보안
```

#### 섹션 9: 다음 단계

```markdown
## 9. 다음 단계

### Stage 8 (Task Breakdown) 전달 사항

| 섹션 | Task 분해 대상 |
|------|--------------|
| 3. 도메인 모델 | User, Order, Portfolio 엔티티 구현 |
| 4. API 설계 | Orders, Portfolio, Auth API 구현 |
| 5. 데이터베이스 | 테이블 생성, 마이그레이션 |
| 6. 외부 연동 | KIS 클라이언트 구현 |

### 예상 Task 수

```
도메인 레이어:     5-8 Tasks
애플리케이션 레이어: 4-6 Tasks
인프라 레이어:     3-5 Tasks
API 레이어:       4-6 Tasks
────────────────────────────
총:              16-25 Tasks
```

### Stage 8 작업 방향

```
Blueprint 섹션 → Tasks:

섹션 3 (도메인 모델):
├─ Task: User 엔티티 + 테스트
├─ Task: Order 엔티티 + Aggregate 로직 + 테스트
├─ Task: Portfolio 엔티티 + Position + 테스트
└─ Task: 값 객체 + 열거형 + 테스트

섹션 4 (API):
├─ Task: Orders API 엔드포인트
├─ Task: Portfolio API 엔드포인트
├─ Task: Auth API 엔드포인트
└─ Task: 미들웨어 (인증, 로깅)
```
```



---

## 📄 Blueprint 템플릿

### 07B-01_project_blueprint.md

```markdown
# Project Blueprint

> **프로젝트**: [프로젝트명]
> **버전**: v1.0
> **작성일**: YYYY-MM-DD
> **패밀리**: [A-A-B / B-C-A / ...]

---

## 1. 시스템 개요

### 1.1 목적
[시스템이 해결하는 문제와 목표]

### 1.2 범위
- **포함**: [v1.0 범위]
- **제외**: [향후 버전 범위]

### 1.3 핵심 기능
| 기능 | 설명 | 우선순위 |
|------|------|---------|
| [기능1] | [설명] | P0 |
| [기능2] | [설명] | P1 |

### 1.4 참조
- 패밀리 분류: 01C-01_*.md
- NFR 우선순위: 02C-01_*.md

---

## 2. 아키텍처 구조

### 2.1 레이어 구조
[다이어그램]

### 2.2 의존성 방향
[의존성 규칙]

### 2.3 컴포넌트 구조
```
src/
├── core/           # DNA 시스템
├── domain/         # 도메인 레이어
├── application/    # 애플리케이션 레이어
├── infrastructure/ # 인프라 레이어
└── api/            # 프레젠테이션 레이어
```

### 2.4 참조
- 아키텍처 ADR: ADR-004

---

## 3. 도메인 모델

### 3.1 엔티티

#### [엔티티명]
| 필드 | 타입 | 설명 | 제약 |
|------|------|------|------|
| id | [타입] | PK | [제약] |

**도메인 규칙**:
- [규칙1]
- [규칙2]

### 3.2 값 객체
```
Value Object: [ValueObject]
├─ [필드1]: [타입]
└─ [필드2]: [타입]
```

### 3.3 집계 (Aggregates)
```
[AggregateRoot] (Root)
├─ [필드1]
├─ [필드2]
└─ 도메인 메서드
   ├─ [메서드1]()
   └─ [메서드2]()
```

### 3.4 도메인 이벤트
| 이벤트 | 발행 시점 | 페이로드 |
|-------|---------|---------|
| [이벤트명] | [시점] | [필드들] |

---

## 4. API 설계

### 4.1 엔드포인트 목록
| Method | Path | 설명 | 인증 |
|--------|------|------|-----|
| [METHOD] | [PATH] | [설명] | [Required/-] |

### 4.2 요청/응답 스키마

#### [엔드포인트명]
**Request**:
```
[RequestSchema]:
├─ [필드1]: [타입]
└─ [필드2]: [타입]
```

**Response**:
```
[ResponseSchema]:
├─ [필드1]: [타입]
└─ [필드2]: [타입]
```

### 4.3 참조
- API ADR: ADR-101

---

## 5. 데이터베이스 설계

### 5.1 테이블 스키마

#### [테이블명]
```sql
CREATE TABLE [table_name] (
    id UUID PRIMARY KEY,
    [field] [type] [constraints],
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- 인덱스
CREATE INDEX idx_[name] ON [table]([column]);
```

### 5.2 ERD
[다이어그램]

### 5.3 참조
- 데이터베이스 ADR: ADR-003

---

## 6. 외부 연동

### 6.1 [외부 시스템명]

#### 인증 흐름
[인증 방법]

#### API 목록
| 기능 | 엔드포인트 | Method |
|------|----------|--------|
| [기능] | [URL] | [METHOD] |

#### Rate Limiting
[제한 및 대응 전략]

### 6.2 참조
- 외부 연동 ADR: ADR-001

---

## 7. 에러 처리

### 7.1 에러 코드 체계
```
1xxx: 도메인 에러
2xxx: 외부 API 에러
9xxx: 시스템 에러
```

### 7.2 에러 응답 형식
```json
{
  "error": {
    "code": "[코드]",
    "message": "[메시지]",
    "details": {}
  }
}
```

### 7.3 재시도 전략
| 에러 유형 | 재시도 | 전략 |
|----------|-------|------|
| [유형] | [예/아니오] | [전략] |

---

## 8. 보안

### 8.1 인증 (Authentication)
[JWT / OAuth / 등]

### 8.2 인가 (Authorization)
[RBAC / ABAC / 등]

### 8.3 데이터 보호
| 데이터 | 보호 방법 |
|-------|---------|
| [데이터] | [방법] |

### 8.4 참조
- 보안 ADR: ADR-011

---

## 9. 다음 단계

### Stage 8 전달 사항
- 도메인 모델 → 엔티티 구현 Tasks
- API 설계 → 엔드포인트 구현 Tasks
- 데이터베이스 → 마이그레이션 Tasks
```

---

## ✏️ 작성 예시: 주식 거래 플랫폼 (요약)

### 예시: 도메인 모델 섹션

```markdown
## 3. 도메인 모델

### 3.1 Order 엔티티 (Aggregate Root)

| 필드 | 타입 | 설명 | 제약 |
|------|------|------|------|
| id | OrderId (UUID) | PK | core.types.OrderId |
| user_id | UserId | FK → users | Not Null |
| symbol | str | 종목 코드 | 6자리 정규식 |
| side | OrderSide | 매수/매도 | Enum: buy, sell |
| order_type | OrderType | 주문 유형 | Enum: limit, market |
| quantity | int | 수량 | > 0 |
| price | Money | 가격 | >= 0, 시장가는 None |
| status | OrderStatus | 상태 | Enum |
| kis_order_id | str | KIS 주문번호 | Nullable |
| created_at | datetime | 생성 시간 | UTC |
| updated_at | datetime | 수정 시간 | UTC |

**도메인 규칙**:
1. 시장가 주문 시 price = None
2. status 전이 규칙:
   - pending → submitted (KIS 제출 시)
   - submitted → filled (체결 시)
   - submitted → cancelled (취소 시)
   - pending → cancelled (취소 시)
3. filled 또는 cancelled 상태에서 수정 불가
4. 취소는 pending/submitted 상태에서만 가능

**Aggregate 메서드** (의사코드):
```
Order:
  submit(external_order_id):
    PRE: status == PENDING
    POST: status = SUBMITTED, emit OrderSubmitted
    
  fill(filled_price, filled_at):
    PRE: status == SUBMITTED
    POST: status = FILLED, emit OrderFilled
    
  cancel(reason):
    PRE: status IN (PENDING, SUBMITTED)
    POST: status = CANCELLED, emit OrderCancelled
```

**참조**:
- ADR-101: 주문 도메인 설계
- core/types: UserId, OrderId, Money
- PROJECT_STANDARDS.md: 네이밍 규칙
- **언어별 구현**: docs/manuals/ 참조
```

### 예시: API 설계 섹션

```markdown
## 4. API 설계

### 4.2 POST /api/v1/orders - 주문 생성

**Request Schema**:
```
CreateOrderRequest:
├─ symbol: String (6자리 숫자, 종목 코드)
│   └─ pattern: "^[0-9]{6}$"
├─ side: OrderSide (BUY | SELL)
├─ order_type: OrderType (MARKET | LIMIT)
├─ quantity: Integer (> 0)
└─ price: Decimal? (>= 0, 시장가는 null)

검증 규칙:
├─ order_type == LIMIT → price 필수
└─ order_type == MARKET → price null 필수
```

**예시 요청**:
```json
{
    "symbol": "005930",
    "side": "buy",
    "order_type": "limit",
    "quantity": 10,
    "price": 70000
}
```

**Response Schema** (201 Created):
```
OrderResponse:
├─ id: UUID
├─ symbol: String
├─ side: OrderSide
├─ order_type: OrderType
├─ quantity: Integer
├─ price: Decimal?
├─ status: OrderStatus
├─ external_order_id: String?
├─ created_at: DateTime
└─ updated_at: DateTime

CreateOrderResponse:
├─ order: OrderResponse
└─ message: String
```

**예시 응답**:
```json
{
    "order": {
        "id": "550e8400-e29b-41d4-a716-446655440000",
        "symbol": "005930",
        "side": "buy",
        "order_type": "limit",
        "quantity": 10,
        "price": 70000,
        "status": "pending",
        "external_order_id": null,
        "created_at": "2025-12-03T10:30:00Z",
        "updated_at": "2025-12-03T10:30:00Z"
    },
    "message": "주문이 생성되었습니다"
}
```

**Error Responses**:
```json
// 400 Bad Request - 검증 오류
{
    "error": {
        "code": "1001",
        "message": "종목 코드 형식이 올바르지 않습니다",
        "details": {
            "field": "symbol",
            "value": "12345",
            "expected": "6자리 숫자"
        }
    }
}

// 422 Unprocessable Entity - 잔고 부족
{
    "error": {
        "code": "1004",
        "message": "잔고가 부족합니다",
        "details": {
            "required": 700000,
            "available": 500000
        }
    }
}

// 502 Bad Gateway - 외부 API 오류
{
    "error": {
        "code": "2001",
        "message": "외부 API 호출에 실패했습니다",
        "details": {
            "external_code": "EGW00001",
            "external_message": "토큰이 만료되었습니다"
        }
    }
}
```

**라우터 구현 가이드** (의사코드):
```
ENDPOINT POST /api/v1/orders
  INPUT: CreateOrderRequest, current_user (인증됨)
  OUTPUT: CreateOrderResponse (201 Created)
  
  STEPS:
    1. 로깅: "주문 생성 요청", user_id, symbol, side
    2. 서비스 호출: order_service.create_order(...)
    3. 로깅: "주문 생성 완료", order_id
    4. 응답 반환
    
  에러 처리:
    ├─ ValidationError → 400
    ├─ InsufficientBalanceError → 422
    └─ ExternalAPIError → 502
```

**언어별 구현 예시**: docs/manuals/ 참조
```

---

## ✅ Stage 7 완료 체크리스트

### 시스템 개요 (섹션 1)

- [ ] 목적 명확히 작성
- [ ] 범위 (포함/제외) 정의
- [ ] 핵심 기능 + 우선순위 (P0/P1/P2)
- [ ] 패밀리 분류 참조

### 아키텍처 구조 (섹션 2)

- [ ] 레이어 다이어그램
- [ ] 의존성 방향 규칙
- [ ] 컴포넌트 구조 (디렉토리)
- [ ] 아키텍처 ADR 참조

### 도메인 모델 (섹션 3)

- [ ] 모든 엔티티 정의 (필드, 타입, 제약)
- [ ] 도메인 규칙 명시
- [ ] 값 객체 정의
- [ ] Aggregate 경계 + 메서드
- [ ] 도메인 이벤트 목록

### API 설계 (섹션 4)

- [ ] 엔드포인트 목록 (Method, Path, 인증)
- [ ] 요청/응답 스키마 (타입 검증 포함)
- [ ] 에러 응답 형식
- [ ] 인증 흐름

### 데이터베이스 설계 (섹션 5)

- [ ] 테이블 스키마 (SQL)
- [ ] 인덱스 전략
- [ ] ERD
- [ ] 마이그레이션 전략

### 외부 연동 (섹션 6)

- [ ] 외부 시스템 인증 흐름
- [ ] API 목록
- [ ] Rate Limiting 대응
- [ ] 에러 처리 매핑

### 에러 처리 (섹션 7)

- [ ] 에러 코드 체계
- [ ] 에러 응답 형식
- [ ] 재시도 전략

### 보안 (섹션 8)

- [ ] 인증 방식 (JWT 구조)
- [ ] 인가 방식 (RBAC/ABAC)
- [ ] 데이터 보호 방법

### 산출물 생성

- [ ] `07B-01_project_blueprint.md` 작성
- [ ] Stage 8 전달 사항 정리

---

## 🔗 Stage 7 → Stage 8 연결

### Stage 8에 전달하는 것

| 전달 항목 | 내용 | 용도 |
|----------|------|------|
| Blueprint 섹션 3 | 도메인 모델 | 엔티티 구현 Tasks |
| Blueprint 섹션 4 | API 설계 | 엔드포인트 구현 Tasks |
| Blueprint 섹션 5 | 데이터베이스 | 마이그레이션 Tasks |
| Blueprint 섹션 6 | 외부 연동 | 클라이언트 구현 Tasks |

### Stage 8 미리보기

```
Stage 8: Task Breakdown

목표: Blueprint를 AI가 한 세션에 완료할 수 있는 크기로 분해

분해 기준:
├─ 체크리스트: 100-150줄 범위
├─ 예상 시간: 2-4시간
├─ 컨텍스트: 80-90K 토큰 이내
└─ 독립적 테스트 가능

예상 Task 수:
├─ 도메인 레이어: 5-8 Tasks
├─ 애플리케이션 레이어: 4-6 Tasks
├─ 인프라 레이어: 3-5 Tasks
└─ API 레이어: 4-6 Tasks
────────────────────────────────
총: 16-25 Tasks
```

---

## ⏪ 이전 Stage 검증 및 수정 프로토콜 (가장 Critical!)

### 왜 Stage 7이 가장 Critical한가?

```
Stage 7 = 통합의 정점 (Integration Apex)
────────────────────────────────────────────

Stage 1-6의 모든 결과물이 여기서 통합:
├─ Stage 1: 패밀리, NFR → Blueprint 전체 방향
├─ Stage 2: 제약, 충돌 → 기술 선택 반영
├─ Stage 3: ADR → 모든 결정 참조
├─ Stage 4: DNA 청사진 → 기반 시스템 참조
├─ Stage 5: DNA 구현 → core/ 모듈 참조
└─ Stage 6: 표준 → 규칙 준수 확인

⚠️ Stage 7에서 오류 미발견 시:
├─ Stage 8: 잘못된 Task 분해
├─ Stage 9: 잘못된 코드 구현
└─ 전체 재작업 필요 (10시간+)

✅ Stage 7에서 오류 수정 시:
├─ Blueprint만 수정 (2-3시간)
├─ Stage 8-9 정상 진행
└─ 비용 최소화
```

### 검증 시점
- Stage 7 시작 전 필수 체크 (모든 Stage!)
- 각 섹션 작성 완료 후 ADR과 교차 검증
- 전체 Blueprint 완료 후 최종 검증

### 검증 대상 (전체 Stage!)

| Stage | 산출물 | 검증 항목 |
|-------|--------|----------|
| Stage 1 | 01C-01_*.md | 패밀리 특성이 Blueprint에 반영? |
| Stage 1 | 01C-01_*.md | NFR 우선순위가 API/DB 설계에 반영? |
| Stage 2 | 02C-01_*.md | 기술 제약이 기술 선택에 반영? |
| Stage 2 | 02C-01_*.md | 충돌 해결이 트레이드오프로 반영? |
| Stage 3 | 03A-*_*.md | 모든 ADR이 Blueprint에 참조/반영? |
| Stage 4 | 04B-01_*.md | DNA 청사진이 core/ 참조로 반영? |
| Stage 5 | 05D-01_*.md | DNA 구현이 사용 예시로 반영? |
| Stage 6 | 06D-01_*.md | 표준 규칙이 코드 예시에 준수? |

### 오류 발견 시 프로토콜 (6단계)

```
Stage 7에서 Stage 1-6 오류 발견 시:

Step 1: 오류 발견 및 문서화
├─ 발견 위치: Blueprint 섹션 [N]
├─ 오류 내용: [구체적 설명]
├─ 영향 Stage: Stage [1-6]
├─ 심각도: [Critical/Major/Minor]
└─ 기록: 07B-01에 "발견된 이슈" 섹션 추가

Step 2: 영향 범위 파악 (가장 중요!)
├─ 직접 영향: Stage [N]
├─ 간접 영향: Stage [N+1] ~ Stage 6
├─ Blueprint 영향 섹션: [해당 섹션 번호]
├─ 재작업 예상 시간: [X]시간
└─ 기록: 영향 범위 문서화

Step 3: 해당 Stage로 이동 → 수정
├─ Stage [N] 산출물 수정
├─ 수정 이력 기록
├─ 버전 업데이트 (v1.0 → v1.1)
└─ 수정 완료 검증

Step 4: 중간 Stage 전파 (N+1 ~ 6)
├─ 각 Stage 산출물 영향 확인
├─ 필요 시 연쇄 수정
├─ 수정 이력 기록
└─ 일관성 검증

Step 5: Stage 7 재진행
├─ 수정된 입력으로 Blueprint 해당 섹션 재작성
├─ 전체 Blueprint 일관성 검토
└─ 9대 섹션 교차 검증

Step 6: 재진행 결과 검증
├─ 오류가 해결되었는지 확인
├─ 새로운 문제 발생 여부 확인
├─ 최종 승인
└─ Stage 8 전달 ✅
```

### 섹션별 흔한 오류 패턴

| 섹션 | 오류 유형 | 영향 Stage | 해결 |
|------|----------|-----------|------|
| 섹션 2 (아키텍처) | 레이어 정의 불일치 | Stage 4 | DNA 청사진 수정 |
| 섹션 3 (도메인) | 엔티티 필드 ADR 불일치 | Stage 3 | ADR 수정 또는 도메인 수정 |
| 섹션 4 (API) | NFR 성능 요구 미반영 | Stage 1 | NFR 현실화 또는 API 최적화 |
| 섹션 5 (DB) | 기술 제약 미반영 | Stage 2 | DB 기술 재선택 |
| 섹션 6 (외부 연동) | ADR 누락 (Rate Limit 등) | Stage 3 | ADR 추가 |
| 섹션 7 (에러) | 에러 코드 표준 불일치 | Stage 6 | 표준 수정 |
| 섹션 8 (보안) | 인증 ADR 미반영 | Stage 3 | ADR 확인 후 반영 |

### 추적성 (Critical!)

```
수정 이력 파일: docs/revision_log.md

예시:
────────────────────────────────────────────
## 2025-12-03 (Stage 7 Blueprint 작성 중)

### Issue #003: Order 취소 API 누락
- **발견 Stage**: Stage 7 Blueprint 섹션 4
- **영향 Stage**: Stage 3 ADR
- **오류**: Order 취소 기능 ADR 없음
- **수정**: ADR-017 "Order 취소 정책" 추가
- **영향 범위**: 
  - Stage 3: ADR-017 추가
  - Stage 7: 섹션 4에 DELETE /orders/{id} 추가
- **수정자**: Jason
- **검증**: AI 검증 완료
────────────────────────────────────────────

Blueprint 참조:
각 섹션에 관련 ADR 명시적 참조:
"참조: ADR-101 (Order 엔티티 설계)"
"참조: ADR-017 (Order 취소 정책)"
```

---

## 💡 핵심 원칙 요약

### Blueprint의 목적

```
ADR (Stage 3):
├─ "무엇을" 결정했는지
├─ "왜" 그렇게 결정했는지
└─ 개별 결정 단위

Blueprint (Stage 7):
├─ "어떻게" 구현할 것인지
├─ 모든 ADR을 통합한 전체 그림
├─ 구체적인 구현 명세
└─ 코드 작성 직전 단계

관계: 여러 ADR → 하나의 Blueprint
```

### 9대 섹션

```
1. 시스템 개요        ← 무엇을 만드는가?
2. 아키텍처 구조      ← 전체 구조는?
3. 도메인 모델        ← 핵심 객체는? (가장 중요!)
4. API 설계          ← 외부 인터페이스는?
5. 데이터베이스 설계   ← 데이터 저장은?
6. 외부 연동          ← 외부 시스템은?
7. 에러 처리          ← 실패 시 대응은?
8. 보안              ← 인증/인가는?
9. 다음 단계          ← Stage 8 연결
```

### SoT (Skeleton-of-Thought) 적용

```
Step 1: 목차 (뼈대) 생성
────────────────────────────────
9대 섹션 목차 먼저 작성

Step 2: 각 섹션 병렬 확장
────────────────────────────────
세션 1: 1-3 섹션 작성 (개요, 아키텍처, 도메인)
세션 2: 4-6 섹션 작성 (API, DB, 외부 연동)
세션 3: 7-9 섹션 작성 (에러, 보안, 다음 단계)

Step 3: 전체 일관성 검토
────────────────────────────────
├─ ADR 참조 확인
├─ PROJECT_STANDARDS 참조 확인
└─ 섹션 간 모순 확인
```

---

**Remember**: 
- ADR은 "결정", Blueprint는 "설계도"
- Blueprint 없이 구현 = 개발자마다 다른 해석
- 9대 섹션으로 모든 측면 커버
- Stage 8에서 실행 가능한 Task로 분해

*Blueprint는 모든 ADR을 통합하여 "코드 작성 직전 단계"의 완전한 설계도입니다.*


================================================================================

📄 FILE: 08G-00_task_breakdown_guide.md
--------------------------------------------------------------------------------

# Stage 8: 작업 분해 가이드 (Task Breakdown Guide)

> **목적**: Blueprint를 AI가 한 세션에 완료할 수 있는 크기로 분해
>
> **버전**: v4.1 (2025-12-03)
>
> - v4.0 (2025-12-03): Gemini 연구 기반 전면 재작성, 01_DNA_METHODOLOGY_DETAILED.md 기준
> - v2.0 (2025-11-12): 입력/출력 문서 추가
> - v1.0 (2025-11-10): 초기 버전

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage 8 실행 가이드) ← 지금 여기!
```

**참조 문서**:
- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` Part 6.2

---

## 🎯 DNA 핵심 원칙 1: AI 최적 크기

### Stage 8이 DNA 방법론의 변환점인 이유

```
Stage 1-7: 인간 중심 (Human-Driven)
────────────────────────────────────
├─ 패밀리 분류, NFR, ADR, Blueprint
├─ 문서 크기 제한 없음
├─ 인간의 이해와 의사결정 중심
└─ 컨텍스트 = 인간의 기억력

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Stage 8: 변환점 (Transformation Point) ← 여기!
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Stage 8-9: AI 중심 (AI-Driven)
────────────────────────────────────
├─ Task Breakdown, 9-Step Checklist
├─ AI 컨텍스트 한계 고려 필수!
├─ AI가 100% 성공할 수 있는 크기
└─ 컨텍스트 = 모델별 안전 범위
```

### 80-90K 토큰 = 100-150줄 체크리스트

```
왜 이 크기인가?

AI 컨텍스트 윈도우 (예: 200K 토큰)
├─ 시스템 프롬프트: ~30K 토큰
├─ 대화 히스토리: ~20K 토큰
├─ 참조 문서 (Blueprint, Standards): ~50K 토큰
├─ 체크리스트 + 코드: ~20K 토큰
└─ 응답 생성 여유: ~80K 토큰 ← 실제 작업 공간!

체크리스트 → 토큰 변환:
├─ 1줄 ≈ 10-15 토큰 (평균)
├─ 100줄 ≈ 1,000-1,500 토큰
├─ 150줄 ≈ 1,500-2,250 토큰
└─ 코드 예시 포함 시 x2-3배

결론:
├─ 체크리스트: 100-150줄 (1,500-2,000 토큰)
├─ 참조 코드: 200-300줄 (3,000-4,500 토큰)
├─ 생성할 코드: 100-200줄 (1,500-3,000 토큰)
└─ 총: ~10K 토큰 = 여유 있게 처리 가능 ✅
```

### 크기 판단 공식

```
FUNCTION is_optimal_task_size(task):
    """Task 크기가 AI 최적인지 판단"""
    
    # 1. 체크리스트 줄 수
    checklist_lines = estimate_checklist_lines(task)
    IF NOT (80 <= checklist_lines <= 180):
        RETURN False  # 80줄 미만 = 너무 작음, 180줄 초과 = 너무 큼
    
    # 2. 참조 문서 크기
    reference_tokens = estimate_reference_tokens(task)
    IF reference_tokens > 50,000:
        RETURN False  # 참조 문서가 너무 많음
    
    # 3. 예상 생성 코드
    code_lines = estimate_code_lines(task)
    IF code_lines > 300:
        RETURN False  # 생성할 코드가 너무 많음
    
    # 4. 테스트 포함 여부
    IF NOT task.includes_tests:
        RETURN False  # 테스트 없는 Task는 불완전
    
    RETURN True

# 적용 예시
is_optimal_task_size(Task("User 엔티티 + 테스트"))  # True (120줄)
is_optimal_task_size(Task("전체 도메인 구현"))      # False (500줄+)
is_optimal_task_size(Task("Enum 하나 추가"))       # False (30줄)
```

### 크기가 맞지 않을 때

| 상황 | 증상 | 해결책 |
|------|------|--------|
| **너무 큼** | 180줄 초과, 4시간+ | 분할 (기능별, 레이어별) |
| **너무 작음** | 80줄 미만, 1시간- | 합치기 (관련 기능끼리) |
| **참조 과다** | Blueprint 전체 필요 | 필요 섹션만 발췌 |
| **의존성 복잡** | 3개+ Task 선행 필요 | 의존성 재설계 |

---

## 🤔 왜 Task Breakdown이 필요한가?

### Blueprint vs Task

```
Blueprint (Stage 7):
├─ 전체 시스템 설계도 (1,000+ 줄)
├─ 모든 도메인, API, DB 설계
├─ AI가 한 번에 처리 불가능!
└─ 컨텍스트 한계 (200K 토큰)

Task (Stage 8):
├─ 하나의 집중된 작업 (2-4시간)
├─ 체크리스트: 100-150줄
├─ AI가 완벽하게 처리 가능!
└─ 독립적 테스트 가능
```

### Task 없이 구현하면?

```
❌ Blueprint 전체를 한 번에:

AI: "Blueprint 보고 전체 구현할게요!"

Session 1:
├─ Order 엔티티 구현 시작
├─ ...중간에 User 필요해서 User도 구현
├─ ...DB 연결도 필요해서 추가
├─ 컨텍스트 80% 소진 😰
└─ "나머지는 다음에..."

Session 2:
├─ "이전 세션에서 뭘 했더라?" 🤔
├─ 중복 코드 작성
├─ 스타일 불일치
└─ 테스트 누락

결과:
├─ 일관성 없는 코드
├─ 테스트 커버리지 50% 미만
├─ "처음부터 다시 해야 하나..." 😱
```

```
✅ Task 단위로 분해 후 구현:

08T-01_task_breakdown.md:
────────────────────────────────
Task 001: User 엔티티 + 테스트 (2h)
Task 002: Order 엔티티 + Aggregate (3h)
Task 003: 값 객체 + 열거형 (1.5h)
...

Session 1: Task 001
├─ 목표: User 엔티티만 집중
├─ 입력: Blueprint Section 3.1
├─ 출력: src/domain/user + tests/
├─ 완료! ✅ (타입 체커 0, 린터 0, Coverage 95%)

Session 2: Task 002
├─ 목표: Order 엔티티만 집중
├─ 입력: Blueprint Section 3.1, Task 001 완료
├─ 출력: src/domain/order.py + tests/
├─ 완료! ✅

결과:
├─ 각 Task 100% 완료
├─ 일관된 품질
├─ 전체 커버리지 95%+
└─ "레고 블럭처럼 조립 완료!" 🎉
```

### 비유: 이사 짐 싸기

```
❌ 한 번에 이사:
"모든 짐을 한 박스에!"
→ 박스 터짐, 물건 파손, 찾기 어려움

✅ 체계적 포장:
박스 1: 주방용품 (그릇, 컵)
박스 2: 서재 (책, 문구)
박스 3: 침실 (침구, 옷)
→ 분류 명확, 찾기 쉬움, 안전

Task = 라벨 붙은 이사 박스!
├─ 내용물 명확 (목표)
├─ 크기 적절 (2-4시간)
├─ 독립적 운반 (의존성 최소)
└─ 쉽게 확인 (테스트)
```

---

## 📥 입력 문서

### Stage 7에서 전달받는 것

| 파일 | 핵심 내용 | 이 Stage에서 사용 |
|------|----------|-----------------|
| `07B-01_project_blueprint.md` | 전체 설계도 (9개 섹션) | Task 분해 대상 |
| `06D-01_project_standards.md` | 프로젝트 표준 | Task별 표준 적용 |

---

## 📤 출력 문서

### 필수 산출물

```
docs/
└── 08T-01_task_breakdown.md    # THE 산출물 (작업 분해 목록)
```

---

## 🎯 좋은 Task의 4가지 조건

### 조건 1: 적절한 크기

```
체크리스트 기준:
├─ 100-150줄 범위 (120줄 내외 권장)
├─ 예상 시간: 2-4시간
├─ 컨텍스트: 80-90K 토큰 이내
└─ 💡 숫자는 참고! 작업을 완전하게 설명하는 게 우선

크기 판단 기준:
┌─────────────────┬─────────────┬─────────────┐
│ 구분            │ 너무 작음   │ 적절        │ 너무 큼     │
├─────────────────┼─────────────┼─────────────┼─────────────┤
│ 체크리스트      │ 50줄 미만   │ 100-150줄   │ 200줄 초과  │
│ 예상 시간       │ 1시간 미만  │ 2-4시간     │ 5시간 초과  │
│ 파일 수         │ 1개 미만    │ 1-3개       │ 5개 초과    │
│ 테스트 수       │ 2개 미만    │ 5-15개      │ 20개 초과   │
└─────────────────┴─────────────┴─────────────┴─────────────┘
```

### 조건 2: 독립성

```
좋은 Task:
├─ 다른 Task 없이 테스트 가능
├─ 명확한 입력/출력
├─ 자체 완결적
└─ 롤백 가능 (실패해도 다른 Task 영향 없음)

나쁜 Task:
├─ "Order 만들려면 User 먼저 해야 하고..."
├─ "이건 다음 Task에서 마무리할게요"
├─ "테스트는 통합 테스트로 한 번에..."
└─ 얽힌 의존성 = 실패의 도미노
```

### 조건 3: 검증 가능

```
좋은 Task:
├─ 테스트 작성 가능
├─ 성공/실패 판단 명확
├─ 품질 기준 적용 가능
│   ├─ 타입 체커 0 errors
│   ├─ 린터 0 violations
│   └─ Coverage 95%+
└─ "이 Task 완료 = 이 기능 작동"

나쁜 Task:
├─ "일단 코드 짜고 나중에 테스트"
├─ "완료 조건: 대충 돌아가면 됨"
├─ 품질 검증 불가
└─ "되는 것 같은데...?" 🤔
```

### 조건 4: 가치 있음

```
좋은 Task:
├─ 완료 시 실제 기능 동작
├─ 데모 가능
├─ 진행 상황 확인 가능
└─ "Task 5개 완료 = 25% 진행"

나쁜 Task:
├─ "설정 파일만 만들기" (가치 없음)
├─ "나중에 쓸 유틸리티 함수" (당장 불필요)
├─ 완료해도 아무것도 작동 안 함
└─ "Task 5개 했는데 뭐가 된 거지?"
```

---

## 🔄 DNA 핵심 원칙 2: 완전해질 때까지 반복

### "부족함이 없어질 때까지"의 의미

```
Task Breakdown의 목표:
├─ AI가 체크리스트만 보고 100% 완료 가능
├─ 추가 질문 없이 독립 실행 가능
├─ 모호함, 누락, 불완전함 = 0
└─ "완전한" Task만 Stage 9로 전달

완전하지 않은 Task의 증상:
❌ "Blueprint 참조"만 있고 구체적 내용 없음
❌ "적절히 구현"같은 모호한 표현
❌ 입력/출력 중 하나라도 누락
❌ 완료 조건이 주관적
❌ 테스트 케이스 미정의
```

### 3단계 검증 프로토콜

```
모든 Task는 3단계 검증을 통과해야 함:

┌─────────────────────────────────────────────────────────┐
│ 검증 1: 크기 (Size Check)                               │
├─────────────────────────────────────────────────────────┤
│ □ 체크리스트 예상 줄 수: 80-180줄?                        │
│ □ 예상 시간: 2-4시간?                                    │
│ □ 생성 파일 수: 1-4개?                                   │
│ □ 테스트 케이스 수: 3-15개?                              │
│                                                         │
│ 실패 시 → 분할 또는 합치기                                │
└─────────────────────────────────────────────────────────┘
            ↓ 통과
┌─────────────────────────────────────────────────────────┐
│ 검증 2: 의존성 (Dependency Check)                       │
├─────────────────────────────────────────────────────────┤
│ □ 선행 Task 명확히 정의?                                 │
│ □ 순환 의존성 없음?                                      │
│ □ 병렬 실행 가능 Task 식별?                              │
│ □ 핵심 경로 계산 가능?                                   │
│                                                         │
│ 실패 시 → 의존성 재설계                                   │
└─────────────────────────────────────────────────────────┘
            ↓ 통과
┌─────────────────────────────────────────────────────────┐
│ 검증 3: 완전성 (Completeness Check)                     │
├─────────────────────────────────────────────────────────┤
│ □ 목표: 한 문장으로 명확?                                 │
│ □ 입력: 모든 참조 문서/코드 명시?                         │
│ □ 출력: 생성될 파일 경로 명시?                            │
│ □ 제약: MUST/MUST NOT 명시?                             │
│ □ 완료 조건: 측정 가능? (타입 체커 0, 린터 0, Coverage 95%) │
│ □ 테스트: 구체적 케이스 3개 이상?                         │
│                                                         │
│ 실패 시 → Task 상세 보완 후 재검증                        │
└─────────────────────────────────────────────────────────┘
            ↓ 통과
        Stage 9로 전달 ✅
```

### 재작업 사례: "주문 도메인" Task

```
1차 시도 (불완전):
────────────────────────────────────
Task: 주문 도메인 구현
목표: Order 관련 기능 구현
입력: Blueprint
출력: 주문 관련 파일들

검증 1 실패: 크기 불명확 (몇 줄? 몇 시간?)
검증 3 실패: 목표 모호, 출력 불명확

2차 시도 (분할 후에도 불완전):
────────────────────────────────────
Task 002: Order 엔티티 구현
목표: Order 클래스 작성
입력: Blueprint Section 3.1
출력: src/domain/order.py

검증 3 실패: 테스트 누락, 완료 조건 주관적

3차 시도 (완전!):
────────────────────────────────────
Task 002: Order 엔티티 + Aggregate + 테스트
목표: Order Aggregate Root 구현 (엔티티 + 상태 전이 + 도메인 이벤트)
입력: 
  - Blueprint Section 3.1 (Order 필드)
  - Blueprint Section 3.3 (Aggregate 규칙)
  - core/types (OrderId, Money, OrderStatus)
출력:
  - src/domain/entities/order.py
  - tests/unit/domain/test_order.py
제약:
  - MUST: 상태 전이 로직 (pending → submitted → filled)
  - MUST: 도메인 이벤트 발행
  - MUST NOT: DB 접근 코드
완료 조건:
  - 타입 체커 0 errors
  - 린터 0 violations  
  - Coverage 95%+
  - 상태 전이 테스트 4개 포함
테스트 케이스:
  - test_order_creation
  - test_order_submit_success
  - test_order_submit_invalid_state
  - test_order_fill_success
  - test_order_cancel_success
  - test_order_cancel_already_filled

검증 1 통과: 120줄, 3시간, 2파일, 6테스트 ✅
검증 2 통과: 의존성 없음 ✅
검증 3 통과: 모든 항목 명시 ✅

→ Stage 9로 전달!
```

---

## 📋 작성 단계 (Part 1-4)

### Part 1: Blueprint 섹션별 Task 도출 (1시간)

#### Step 1: Blueprint 9개 섹션 → Task 후보

```
Blueprint 섹션 → Task 후보:

섹션 3 (도메인 모델):
├─ Task: User 엔티티 + 테스트
├─ Task: Order 엔티티 + Aggregate + 테스트
├─ Task: Portfolio + Position 엔티티 + 테스트
└─ Task: 값 객체 + 열거형 + 테스트

섹션 4 (API):
├─ Task: Orders API 엔드포인트 (CRUD)
├─ Task: Portfolio API 엔드포인트
├─ Task: Auth API 엔드포인트
└─ Task: 미들웨어 (인증, 로깅, 에러 처리)

섹션 5 (데이터베이스):
├─ Task: 마이그레이션 (users, orders 테이블)
├─ Task: 마이그레이션 (portfolios, positions 테이블)
└─ Task: 리포지토리 구현

섹션 6 (외부 연동):
├─ Task: KIS API 클라이언트 (인증)
├─ Task: KIS API 클라이언트 (주문)
└─ Task: Rate Limiter + 재시도 로직
```

#### Step 2: Task 크기 검증

```
# 각 Task 크기 검증

FUNCTION validate_task_size(task):
    """Task 크기가 적절한지 검증"""
    
    # 체크리스트 예상 줄 수
    checklist_lines = estimate_checklist_lines(task)
    IF checklist_lines < 80:
        RETURN "너무 작음 - 다른 Task와 합치기"
    IF checklist_lines > 180:
        RETURN "너무 큼 - 분할 필요"
    
    # 예상 시간
    estimated_hours = estimate_hours(task)
    IF estimated_hours < 1.5:
        RETURN "너무 작음"
    IF estimated_hours > 5:
        RETURN "너무 큼"
    
    RETURN "적절함 ✅"

# 예시
validate_task_size("User 엔티티 + 테스트")  # → "적절함 ✅" (2시간)
validate_task_size("전체 API 구현")          # → "너무 큼" (20시간)
validate_task_size("Enum 하나 추가")         # → "너무 작음" (20분)
```

### Part 2: RDoLT 적용 - 난이도별 분류 (30분)

#### RDoLT: Recursive Decomposition of Logical Thoughts

```
난이도 3단계:

Level 1 - Easy (기본 기능):
────────────────────────────────
├─ 단순 CRUD
├─ 기본 모델 정의
├─ 단순 API 엔드포인트
├─ 명확한 로직
└─ 의존성 없음 또는 최소

예: Task 001 (User 엔티티), Task 003 (값 객체)

Level 2 - Intermediate (상호작용):
────────────────────────────────
├─ 엔티티 간 관계
├─ 트랜잭션 로직
├─ 서비스 계층 통합
├─ 검증 로직
└─ Easy Task에 의존

예: Task 005 (주문 생성 서비스), Task 007 (API 엔드포인트)

Level 3 - Final (엣지 케이스):
────────────────────────────────
├─ 에러 처리 고도화
├─ 동시성 제어
├─ 성능 최적화
├─ 보안 검증
├─ 예외 상황 처리
└─ Intermediate Task에 의존

예: Task 015 (주문 동시성 처리), Task 016 (KIS API 연동)

작업 순서:
Easy → Intermediate → Final
(기반 먼저, 복잡한 것 나중)
```

#### 분류 예시

```
주식 거래 플랫폼 Task 분류:

Phase 1: Easy (기반)
────────────────────────────────
001. User 엔티티 + 테스트         [2h] [의존성: 없음]
002. Order 엔티티 + Aggregate     [3h] [의존성: 없음]
003. Portfolio 엔티티 + Position  [2.5h] [의존성: 없음]
004. 값 객체 + 열거형             [1.5h] [의존성: 없음]
005. 마이그레이션 (users, orders) [2h] [의존성: 001, 002]

Phase 2: Intermediate (상호작용)
────────────────────────────────
006. User 리포지토리              [2h] [의존성: 001, 005]
007. Order 리포지토리             [2.5h] [의존성: 002, 005]
008. 주문 생성 서비스             [4h] [의존성: 007, 004]
009. 주문 조회 서비스             [2h] [의존성: 007]
010. Auth API (로그인, 토큰)      [3h] [의존성: 006]
011. Orders API (CRUD)           [3.5h] [의존성: 008, 009]

Phase 3: Final (엣지 케이스)
────────────────────────────────
012. 인증 미들웨어 + 권한 검증     [3h] [의존성: 010]
013. KIS API 클라이언트 (인증)    [3h] [의존성: 없음]
014. KIS API 클라이언트 (주문)    [4h] [의존성: 013, 008]
015. 주문 동시성 처리             [4h] [의존성: 008, 014]
016. Rate Limiter + 재시도       [3h] [의존성: 013]
017. 전체 통합 테스트             [3h] [의존성: 모든 Task]
```

### Part 3: 의존성 다이어그램 작성 (30분)

#### 의존성 시각화

```
의존성 다이어그램:

Phase 1 (Easy):
┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐
│ 001 │  │ 002 │  │ 003 │  │ 004 │
│User │  │Order│  │Port.│  │Value│
└──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘
   │        │        │        │
   └────────┼────────┼────────┘
            │        │
            ▼        │
         ┌─────┐     │
         │ 005 │     │
         │Migr.│     │
         └──┬──┘     │
            │        │
Phase 2:    ▼        ▼
         ┌─────┐  ┌─────┐
         │ 006 │  │ 007 │
         │U.Rep│  │O.Rep│
         └──┬──┘  └──┬──┘
            │        │
            ▼        ▼
         ┌─────┐  ┌─────┐
         │ 010 │  │ 008 │──→ ┌─────┐
         │Auth │  │O.Svc│    │ 009 │
         └──┬──┘  └──┬──┘    │O.Qry│
            │        │       └─────┘
Phase 3:    ▼        ▼
         ┌─────┐  ┌─────┐  ┌─────┐
         │ 012 │  │ 014 │  │ 015 │
         │Auth │  │KIS  │  │Conc.│
         │Midw.│  │Order│  └─────┘
         └─────┘  └──┬──┘
                     │
                  ┌──┴──┐
                  │ 013 │
                  │KIS  │
                  │Auth │
                  └─────┘
```

#### 핵심 경로 (Critical Path)

```
핵심 경로: 전체 일정을 결정하는 최장 경로

001 (User, 2h)
  ↓
005 (Migration, 2h)
  ↓
006 (User Repo, 2h)
  ↓
010 (Auth API, 3h)
  ↓
012 (Auth Middleware, 3h)
────────────────────────
총: 12시간 (최소 4일)

병렬 실행 가능:
├─ 002, 003, 004는 001과 동시에
├─ 007, 008, 009는 005 이후 006과 병렬
└─ 013, 016은 독립적으로 언제든지
```

### Part 4: Task 상세 정의 (1시간)

#### 각 Task 상세 작성

```markdown
## Task 001: User 엔티티 + 테스트

### 메타 정보
- **ID**: 001
- **난이도**: Easy (Level 1)
- **예상 시간**: 2시간
- **의존성**: 없음

### 목표
User 엔티티 클래스 구현 및 단위 테스트 작성

### 입력
- Blueprint Section 3.1 (User 엔티티)
- PROJECT_STANDARDS.md (네이밍 규칙)
- core/types (UserId, EmailStr)

### 출력
- `src/domain/entities/user.py`
- `tests/unit/domain/test_user.py`
- 커버리지 95%+

### 제약
- MUST: 검증 라이브러리 사용 (타입 안전 모델)
- MUST: UserId (UUID) 타입 사용
- MUST: created_at, updated_at UTC 시간
- MUST NOT: ORM 직접 사용 (Infrastructure 레이어)

### 완료 조건
- [ ] 타입 체커 0 errors
- [ ] 린터 0 violations
- [ ] 테스트 프레임워크 통과
- [ ] Coverage 95%+

---

## Task 002: Order 엔티티 + Aggregate + 테스트

### 메타 정보
- **ID**: 002
- **난이도**: Easy (Level 1)
- **예상 시간**: 3시간
- **의존성**: 없음 (Task 001과 병렬 가능)

### 목표
Order Aggregate Root 구현 (엔티티 + 도메인 로직 + 테스트)

### 입력
- Blueprint Section 3.1 (Order 엔티티)
- Blueprint Section 3.3 (Aggregate)
- core/types (OrderId, Money, OrderStatus)

### 출력
- `src/domain/entities/order.py`
- `tests/unit/domain/test_order.py`
- 커버리지 95%+

### 제약
- MUST: Aggregate Root 패턴 적용
- MUST: 상태 전이 로직 (pending → submitted → filled)
- MUST: 도메인 이벤트 발행 (OrderCreated, OrderSubmitted)
- MUST NOT: 데이터베이스 접근 코드

### 완료 조건
- [ ] 타입 체커 0 errors
- [ ] 린터 0 violations
- [ ] 테스트 프레임워크 통과
- [ ] 상태 전이 테스트 포함
- [ ] Coverage 95%+
```



---

## 📄 Task Breakdown 템플릿

### 08T-01_task_breakdown.md

```markdown
# Task Breakdown

> **프로젝트**: [프로젝트명]
> **버전**: v1.0
> **작성일**: YYYY-MM-DD
> **Blueprint 참조**: 07B-01_project_blueprint.md

---

## 개요

| 항목 | 값 |
|------|---|
| 총 Task 수 | [N]개 |
| 예상 총 시간 | [X]시간 |
| 예상 세션 수 | [Y]세션 (Task당 1세션) |
| 핵심 경로 | Task 001 → 005 → 008 → 014 |

---

## Phase 1: Easy (기반)

> 의존성 없음, 병렬 실행 가능

| ID | Task | 예상 | 의존성 | Blueprint 참조 |
|----|------|------|--------|---------------|
| 001 | [Task명] | [X]h | 없음 | Section 3.1 |
| 002 | [Task명] | [X]h | 없음 | Section 3.1 |
| ... | ... | ... | ... | ... |

---

## Phase 2: Intermediate (상호작용)

> Phase 1 완료 후 진행

| ID | Task | 예상 | 의존성 | Blueprint 참조 |
|----|------|------|--------|---------------|
| 006 | [Task명] | [X]h | 001, 005 | Section 4.2 |
| 007 | [Task명] | [X]h | 002, 005 | Section 4.2 |
| ... | ... | ... | ... | ... |

---

## Phase 3: Final (엣지 케이스)

> Phase 2 완료 후 진행

| ID | Task | 예상 | 의존성 | Blueprint 참조 |
|----|------|------|--------|---------------|
| 012 | [Task명] | [X]h | 010 | Section 8.1 |
| 015 | [Task명] | [X]h | 008, 014 | Section 6.1 |
| ... | ... | ... | ... | ... |

---

## 의존성 다이어그램

```
Phase 1:
┌─────┐  ┌─────┐  ┌─────┐
│ 001 │  │ 002 │  │ 003 │
└──┬──┘  └──┬──┘  └──┬──┘
   │        │        │
   └────────┼────────┘
            ▼
         ┌─────┐
         │ 005 │
         └──┬──┘
            │
Phase 2:    ▼
         ┌─────┐
         │ 008 │
         └──┬──┘
            │
Phase 3:    ▼
         ┌─────┐
         │ 014 │
         └─────┘
```

---

## Task 상세

### Task 001: [Task명]

#### 메타 정보
- **ID**: 001
- **난이도**: Easy
- **예상 시간**: [X]시간
- **의존성**: 없음

#### 목표
[한 문장으로 명확하게]

#### 입력
- Blueprint Section [X.X]
- PROJECT_STANDARDS.md
- [추가 참조]

#### 출력
- `[파일 경로]`
- `[테스트 파일 경로]`
- 커버리지 95%+

#### 제약
- MUST: [필수 사항]
- MUST NOT: [금지 사항]

#### 완료 조건
- [ ] 타입 체커 0 errors
- [ ] 린터 0 violations
- [ ] 테스트 프레임워크 통과
- [ ] Coverage 95%+

---

### Task 002: [Task명]

[같은 형식으로 반복...]

---

## 우선순위 및 일정

### 핵심 경로 (Critical Path)

```
001 → 005 → 008 → 014 → 017
 2h    2h    4h    4h    3h = 15시간 (최소 4일)
```

### 병렬 실행 가능

```
Day 1: 001, 002, 003, 004 (병렬)
Day 2: 005, 013 (병렬)
Day 3: 006, 007 (병렬)
Day 4: 008, 009, 010 (병렬)
Day 5: 011, 012, 016 (병렬)
Day 6: 014, 015 (병렬)
Day 7: 017 (통합)
```

---

## 다음 단계

→ Stage 9: 각 Task마다 9-Step Checklist 작성
→ 체크리스트 파일: `09L-001_*.md`, `09L-002_*.md`, ...
```

---

## ✏️ 작성 예시: 주식 거래 플랫폼

### 예시 1: 전체 Task Breakdown

```markdown
# Task Breakdown - 주식 거래 플랫폼

> **프로젝트**: Stock Trading Platform
> **버전**: v1.0
> **작성일**: 2025-12-03
> **Blueprint 참조**: 07B-01_project_blueprint.md

---

## 개요

| 항목 | 값 |
|------|---|
| 총 Task 수 | 17개 |
| 예상 총 시간 | 48시간 |
| 예상 세션 수 | 17세션 |
| 핵심 경로 | 001 → 005 → 006 → 010 → 012 (12h) |

---

## Phase 1: Easy (기반)

> 의존성 없음, 병렬 실행 가능

| ID | Task | 예상 | 의존성 | Blueprint 참조 |
|----|------|------|--------|---------------|
| 001 | User 엔티티 + 테스트 | 2h | 없음 | Section 3.1 |
| 002 | Order 엔티티 + Aggregate | 3h | 없음 | Section 3.1, 3.3 |
| 003 | Portfolio + Position 엔티티 | 2.5h | 없음 | Section 3.1 |
| 004 | 값 객체 + 열거형 | 1.5h | 없음 | Section 3.2 |
| 005 | 마이그레이션 (users, orders) | 2h | 001, 002 | Section 5.1 |

**Phase 1 소계**: 11시간

---

## Phase 2: Intermediate (상호작용)

> Phase 1 완료 후 진행

| ID | Task | 예상 | 의존성 | Blueprint 참조 |
|----|------|------|--------|---------------|
| 006 | User 리포지토리 | 2h | 001, 005 | Section 5.1 |
| 007 | Order 리포지토리 | 2.5h | 002, 005 | Section 5.1 |
| 008 | 주문 생성 서비스 | 4h | 004, 007 | Section 4.2 |
| 009 | 주문 조회 서비스 | 2h | 007 | Section 4.2 |
| 010 | Auth API (로그인, 토큰) | 3h | 006 | Section 4.1, 8.1 |
| 011 | Orders API (CRUD) | 3.5h | 008, 009 | Section 4.1 |

**Phase 2 소계**: 17시간

---

## Phase 3: Final (엣지 케이스)

> Phase 2 완료 후 진행

| ID | Task | 예상 | 의존성 | Blueprint 참조 |
|----|------|------|--------|---------------|
| 012 | 인증 미들웨어 + 권한 검증 | 3h | 010 | Section 8.2 |
| 013 | KIS API 클라이언트 (인증) | 3h | 없음 | Section 6.1 |
| 014 | KIS API 클라이언트 (주문) | 4h | 008, 013 | Section 6.1 |
| 015 | 주문 동시성 처리 | 4h | 008, 014 | Section 6.1 |
| 016 | Rate Limiter + 재시도 | 3h | 013 | Section 6.1 |
| 017 | 전체 통합 테스트 | 3h | 모든 Task | - |

**Phase 3 소계**: 20시간

---

## 의존성 다이어그램

```
Phase 1 (Easy):
┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐
│ 001 │  │ 002 │  │ 003 │  │ 004 │
│User │  │Order│  │Port.│  │Value│
│ 2h  │  │ 3h  │  │2.5h │  │1.5h │
└──┬──┘  └──┬──┘  └──┬──┘  └──┬──┘
   │        │        │        │
   └────┬───┴────────┘        │
        │                     │
        ▼                     │
     ┌─────┐                  │
     │ 005 │                  │
     │Migr.│                  │
     │ 2h  │                  │
     └──┬──┘                  │
        │                     │
        ├──────────────┬──────┘
        │              │
Phase 2 ▼              ▼
     ┌─────┐        ┌─────┐
     │ 006 │        │ 007 │
     │U.Rep│        │O.Rep│
     │ 2h  │        │2.5h │
     └──┬──┘        └──┬──┘
        │              │
        ▼              ▼
     ┌─────┐        ┌─────┐───→ ┌─────┐
     │ 010 │        │ 008 │     │ 009 │
     │Auth │        │O.Svc│     │O.Qry│
     │ 3h  │        │ 4h  │     │ 2h  │
     └──┬──┘        └──┬──┘     └──┬──┘
        │              │           │
        │              └─────┬─────┘
Phase 3 ▼                    ▼
     ┌─────┐              ┌─────┐
     │ 012 │              │ 011 │
     │Auth │              │Order│
     │Midw.│              │ API │
     │ 3h  │              │3.5h │
     └─────┘              └─────┘

                ┌─────┐
                │ 013 │ ← 독립 (Phase 3 시작 가능)
                │KIS  │
                │Auth │
                │ 3h  │
                └──┬──┘
                   │
        ┌──────────┼──────────┐
        │          │          │
        ▼          ▼          ▼
     ┌─────┐    ┌─────┐    ┌─────┐
     │ 014 │    │ 015 │    │ 016 │
     │KIS  │    │Conc.│    │Rate │
     │Order│    │ 4h  │    │Limit│
     │ 4h  │    └─────┘    │ 3h  │
     └─────┘               └─────┘
                   │
                   ▼
                ┌─────┐
                │ 017 │
                │Integ│
                │Test │
                │ 3h  │
                └─────┘
```

---

## 우선순위 및 일정

### 핵심 경로 (Critical Path)

```
001 (2h) → 005 (2h) → 006 (2h) → 010 (3h) → 012 (3h)
─────────────────────────────────────────────────────
총: 12시간 = 최소 3일 (하루 4시간 기준)
```

### 병렬 실행 계획

```
Day 1: 
├─ 001 User 엔티티 (2h)
├─ 002 Order 엔티티 (3h) ← 병렬
├─ 003 Portfolio 엔티티 (2.5h) ← 병렬
└─ 004 값 객체 (1.5h) ← 병렬

Day 2:
├─ 005 마이그레이션 (2h)
└─ 013 KIS API 인증 (3h) ← 병렬 (독립)

Day 3:
├─ 006 User 리포지토리 (2h)
├─ 007 Order 리포지토리 (2.5h) ← 병렬
└─ 016 Rate Limiter (3h) ← 병렬 (013 의존)

Day 4:
├─ 008 주문 생성 서비스 (4h)
├─ 009 주문 조회 서비스 (2h) ← 병렬
└─ 010 Auth API (3h) ← 병렬

Day 5:
├─ 011 Orders API (3.5h)
├─ 012 인증 미들웨어 (3h) ← 병렬
└─ 014 KIS API 주문 (4h) ← 병렬

Day 6:
├─ 015 주문 동시성 처리 (4h)
└─ 017 전체 통합 테스트 (3h)
```

**총 예상**: 6일 (하루 4-5시간, 2-3세션)
```

### 예시 2: 개별 Task 상세

```markdown
## Task 008: 주문 생성 서비스

### 메타 정보
- **ID**: 008
- **난이도**: Intermediate (Level 2)
- **예상 시간**: 4시간
- **의존성**: 004 (값 객체), 007 (Order 리포지토리)

### 목표
주문 생성 유스케이스 구현 - 검증, 생성, 이벤트 발행

### 입력
- Blueprint Section 4.2 (POST /api/v1/orders)
- Blueprint Section 3.3 (Order Aggregate)
- PROJECT_STANDARDS.md (서비스 레이어 규칙)
- core/logging, core/errors

### 출력
```
src/application/orders/
├── __init__.py
├── commands.py          # CreateOrderCommand
├── services.py          # OrderService.create_order()
└── exceptions.py        # OrderCreationError

tests/unit/application/orders/
├── __init__.py
└── test_order_service.py
```

### 제약
- MUST: CreateOrderCommand (타입 안전 모델) 사용
- MUST: Order Aggregate 도메인 규칙 적용
- MUST: OrderCreated 이벤트 발행
- MUST: 잔고 검증 포함
- MUST: 트랜잭션 경계 명확히
- MUST NOT: 직접 DB 접근 (리포지토리 사용)
- MUST NOT: API 레이어 의존

### 핵심 로직 (의사코드)

```
CLASS OrderService:
    CONSTRUCTOR(order_repo, portfolio_repo, event_publisher, logger)
    
    METHOD create_order(command: CreateOrderCommand) -> Order:
        """주문 생성"""
        logger.info("주문 생성 시작", user_id=command.user_id)
        
        # 1. 잔고 검증
        portfolio = portfolio_repo.get_by_user_id(command.user_id)
        IF NOT portfolio.has_sufficient_balance(command.total_amount):
            THROW InsufficientBalanceError(
                required=command.total_amount,
                available=portfolio.cash_balance
            )
        
        # 2. Order Aggregate 생성
        order = Order.create(
            user_id=command.user_id,
            symbol=command.symbol,
            side=command.side,
            order_type=command.order_type,
            quantity=command.quantity,
            price=command.price
        )
        
        # 3. 저장
        order_repo.save(order)
        
        # 4. 이벤트 발행
        FOR EACH event IN order.domain_events:
            event_publisher.publish(event)
        
        logger.info("주문 생성 완료", order_id=order.id)
        RETURN order
```

**언어별 구현 예시**: docs/manuals/ 참조

### 테스트 케이스 (설계)

```
테스트 클래스: OrderServiceTest

1. test_create_order_success: 정상 주문 생성
   Given: 유효한 CreateOrderCommand (symbol, side, order_type, quantity, price)
   When: service.create_order(command) 호출
   Then: 
     - order.status == PENDING
     - order.symbol == 입력값
     - OrderCreated 이벤트 발행됨

2. test_create_order_insufficient_balance: 잔고 부족 시 실패
   Given: portfolio.cash_balance = 100,000원, 필요 금액 = 7,000,000원
   When: service.create_order(command) 호출
   Then: InsufficientBalanceError 발생

3. test_create_order_market_type_no_price: 시장가 주문은 가격 없음
   Given: order_type=MARKET, price=null
   When: service.create_order(command) 호출
   Then: order.price == null

4. test_create_order_limit_type_requires_price: 지정가 주문은 가격 필수
   Given: order_type=LIMIT, price=null
   When: service.create_order(command) 호출
   Then: ValidationError 발생
```

**언어별 테스트 구현**: docs/manuals/ 참조

### 완료 조건
- [ ] 타입 체커 0 errors
- [ ] 린터 0 violations
- [ ] 테스트 프레임워크 통과 (4개 테스트 케이스)
- [ ] Coverage 95%+
- [ ] 잔고 검증 로직 작동
- [ ] 도메인 이벤트 발행
- [ ] 로깅 (INFO: 시작/완료, ERROR: 실패)
```



---

## ✅ Stage 8 완료 체크리스트

### Blueprint 분석

- [ ] Blueprint 9개 섹션 검토
- [ ] 각 섹션에서 Task 후보 도출
- [ ] Task 크기 검증 (100-150줄 체크리스트)

### Task 분류 (RDoLT)

- [ ] Phase 1 (Easy) Task 정의
- [ ] Phase 2 (Intermediate) Task 정의
- [ ] Phase 3 (Final) Task 정의
- [ ] 각 Task 난이도 적절성 확인

### 의존성 분석

- [ ] 각 Task 의존성 명시
- [ ] 의존성 다이어그램 작성
- [ ] 핵심 경로 (Critical Path) 식별
- [ ] 병렬 실행 가능 Task 식별

### Task 상세 정의

- [ ] 각 Task 메타 정보 (ID, 난이도, 예상 시간)
- [ ] 각 Task 목표 (한 문장)
- [ ] 각 Task 입력/출력 명시
- [ ] 각 Task 제약 (MUST/MUST NOT)
- [ ] 각 Task 완료 조건 (타입 체커 0, 린터 0, Coverage 95%)

### 일정 계획

- [ ] 핵심 경로 시간 계산
- [ ] 병렬 실행 계획
- [ ] 일별 Task 배치

### 산출물

- [ ] `08T-01_task_breakdown.md` 작성
- [ ] Stage 9 전달 준비

---

## 🔗 Stage 8 → Stage 9 연결

### Stage 9에 전달하는 것

| 전달 항목 | 내용 | 용도 |
|----------|------|------|
| Task 목록 | 001~017 (17개) | 체크리스트 작성 대상 |
| Task 상세 | 목표, 입출력, 제약 | 체크리스트 내용 |
| 의존성 | Task 간 관계 | 작업 순서 |

### Stage 9 미리보기

```
Stage 9: 9-Step Checklist + 구현

목표: 각 Task마다 TDD 기반 9-Step 체크리스트 작성

9-Step 구조:
────────────────────────────────
Step 1: 목표 이해 📖
Step 2: 테스트 작성 🧪 (TDD - Red)
Step 3: 구현 🔨 (TDD - Green)
Step 4: 정적 검증 🔍 (린터, 타입 체커)
Step 5: 리팩토링 ✨ (TDD - Refactor)
Step 6: 커버리지 📊 (95%+)
Step 7: 통합 확인 🔗
Step 8: 문서화 📝
Step 9: 완료 확인 ✅

체크리스트 파일:
├─ 09L-001_user_entity.md
├─ 09L-002_order_entity.md
├─ 09L-003_portfolio_entity.md
├─ ...
└─ 09L-017_integration_test.md
```

### 체크리스트 크기 예상

```
각 Task별 체크리스트:

Task 001 (User 엔티티):
├─ Step 1: 10줄
├─ Step 2: 30줄 (테스트 코드)
├─ Step 3: 25줄 (구현 코드)
├─ Step 4: 5줄 (명령어)
├─ Step 5: 10줄
├─ Step 6: 5줄
├─ Step 7: 5줄
├─ Step 8: 5줄
└─ Step 9: 5줄
────────────────────────────
총: ~100줄 ✅

Task 008 (주문 생성 서비스):
├─ Step 1: 15줄
├─ Step 2: 50줄 (테스트 코드)
├─ Step 3: 40줄 (구현 코드)
├─ Step 4: 5줄
├─ Step 5: 15줄
├─ Step 6: 5줄
├─ Step 7: 10줄
├─ Step 8: 5줄
└─ Step 9: 5줄
────────────────────────────
총: ~150줄 ✅
```

---

## 💡 핵심 원칙 요약

### 좋은 Task의 4가지 조건

```
1. 적절한 크기:
   ├─ 체크리스트: 100-150줄
   ├─ 예상 시간: 2-4시간
   └─ 컨텍스트: 80-90K 토큰 이내

2. 독립성:
   ├─ 다른 Task 없이 테스트 가능
   ├─ 자체 완결적
   └─ 롤백 가능

3. 검증 가능:
   ├─ Type Check 0 errors
   ├─ Lint 0 violations
   └─ Coverage 95%+

4. 가치 있음:
   ├─ 완료 시 실제 기능 작동
   └─ 진행 상황 확인 가능
```

### RDoLT 적용

```
Level 1 - Easy (기반):
├─ 단순 모델, 기본 CRUD
├─ 의존성 없음
└─ 예: User 엔티티, 값 객체

Level 2 - Intermediate (상호작용):
├─ 엔티티 간 관계, 서비스
├─ Easy Task에 의존
└─ 예: 주문 생성 서비스, API

Level 3 - Final (엣지 케이스):
├─ 동시성, 외부 연동, 보안
├─ Intermediate Task에 의존
└─ 예: KIS API 연동, 동시성 처리

순서: Easy → Intermediate → Final
```

### Task Breakdown 작성 흐름

```
Blueprint (1,000+ 줄)
        ↓
    섹션별 분석
        ↓
    Task 후보 도출
        ↓
    크기 검증 (100-150줄?)
        ↓
    RDoLT 분류 (Easy/Intermediate/Final)
        ↓
    의존성 분석
        ↓
    핵심 경로 계산
        ↓
    병렬 실행 계획
        ↓
    Task 상세 정의
        ↓
08T-01_task_breakdown.md (16-25 Tasks)
        ↓
    Stage 9: 체크리스트
```

---

## 🎯 Task 크기 판단 가이드

### 크기가 적절한지 확인하는 질문

```
1. 체크리스트 예상 줄 수?
   - 80줄 미만 → 너무 작음 (합치기)
   - 80-180줄 → 적절 ✅
   - 180줄 초과 → 너무 큼 (분할)

2. 예상 시간?
   - 1.5시간 미만 → 너무 작음
   - 2-4시간 → 적절 ✅
   - 5시간 초과 → 너무 큼

3. 생성되는 파일 수?
   - 0개 → 가치 없음
   - 1-3개 → 적절 ✅
   - 5개 초과 → 너무 큼

4. 테스트 케이스 수?
   - 2개 미만 → 너무 작음
   - 5-15개 → 적절 ✅
   - 20개 초과 → 너무 큼

5. 독립적으로 테스트 가능?
   - Yes → 적절 ✅
   - No → 분할 또는 의존성 재검토
```

### 분할 패턴

```
너무 큰 Task 분할 예시:

❌ "Order 도메인 전체 구현" (20시간)
    ↓ 분할
✅ Task 002: Order 엔티티 + Aggregate (3h)
✅ Task 007: Order 리포지토리 (2.5h)
✅ Task 008: 주문 생성 서비스 (4h)
✅ Task 009: 주문 조회 서비스 (2h)
✅ Task 011: Orders API (3.5h)

분할 기준:
├─ 레이어별 분할 (Domain → Application → API)
├─ 기능별 분할 (생성 → 조회 → 수정 → 삭제)
└─ 의존성별 분할 (기반 → 활용)
```

### 합치기 패턴

```
너무 작은 Task 합치기 예시:

❌ Task A: "OrderStatus Enum 정의" (20분)
❌ Task B: "OrderType Enum 정의" (20분)
❌ Task C: "Money 값 객체 정의" (30분)
    ↓ 합치기
✅ Task 004: 값 객체 + 열거형 (1.5h)

합치기 기준:
├─ 같은 레이어
├─ 같은 도메인
├─ 의존성 없음 (서로 독립)
└─ 총 시간 2-4시간 범위
```

---

## 🧩 DNA 핵심 원칙 3: 기능별 분해 + 연결부 + 조립

### 레이어별 vs 기능별 분해

```
❌ 레이어별 분해 (Anti-pattern):
────────────────────────────────────
Task 001: 모든 엔티티 (Domain Layer)
Task 002: 모든 리포지토리 (Infrastructure Layer)
Task 003: 모든 서비스 (Application Layer)
Task 004: 모든 API (Presentation Layer)

문제점:
├─ Task 001 완료해도 "작동하는 기능" 없음
├─ Task 004까지 가야 첫 기능 작동
├─ 중간 검증 불가
├─ 실패 시 전체 재작업
└─ "레고 블럭만 있고 조립된 것 없음"

✅ 기능별 분해 (Best Practice):
────────────────────────────────────
Task 001: User 기능 (Entity + Repo + Service + API)
Task 002: Order 생성 기능 (Entity + Repo + Service + API)
Task 003: Order 조회 기능 (Repo + Service + API)
Task 004: Order 취소 기능 (Service + API)

장점:
├─ Task 001 완료 = User 기능 작동!
├─ 각 Task 완료 시 데모 가능
├─ 중간 검증 가능
├─ 실패 시 해당 기능만 재작업
└─ "조립된 레고 작품이 하나씩 완성"
```

### 기능별 분해 비교표

| 관점 | 레이어별 분해 | 기능별 분해 |
|------|-------------|-----------|
| **Task 완료 시** | 레이어 일부 완성 | 기능 완성 (End-to-End) |
| **테스트** | 단위 테스트만 | 단위 + 통합 테스트 |
| **데모** | 불가능 | 가능 (API 호출 가능) |
| **실패 영향** | 전체 지연 | 해당 기능만 지연 |
| **병렬화** | 어려움 | 쉬움 (기능별 독립) |
| **진행 측정** | 모호함 | 명확함 ("3/10 기능 완료") |

### 연결부 (Interface) 설계

```
기능별 분해 시 연결부가 핵심!

❌ 연결부 없이 분해:
Task 001: User 기능 (UserService 직접 구현)
Task 002: Order 기능 (UserService 필요... 어떻게?)

✅ 연결부 먼저 정의:
Task 000: 인터페이스 정의 (연결부)
├─ IUserRepository
├─ IOrderRepository
├─ IUserService
└─ IOrderService

Task 001: User 기능 (IUserRepository, IUserService 구현)
Task 002: Order 기능 (IUserService 주입받아 사용)
```

### 연결부 설계 방법

```
domain/interfaces/ (Task 000에서 정의)

Interface: IUserRepository
├─ get_by_id(user_id) → User?
├─ get_by_email(email) → User?
└─ save(user) → void

Interface: IOrderRepository
├─ get_by_id(order_id) → Order?
├─ get_by_user_id(user_id) → List<Order>
└─ save(order) → void

Interface: IUserService
├─ get_user(user_id) → User
└─ create_user(command) → User

Interface: IOrderService
├─ create_order(command) → Order
└─ get_order(order_id) → Order

* 언어별 구현: docs/manuals/ 참조
  - Python: Protocol/ABC
  - TypeScript: interface
  - Java: interface
  - Go: implicit interface
```

### 조립 전략

```
조립 순서 (기능별 분해 후):

Phase 1: 연결부 정의 (Task 000)
────────────────────────────────────
├─ 모든 인터페이스 정의
├─ 타입 힌트만 있는 빈 껍데기
├─ 예상 시간: 1-2시간
└─ 이후 모든 Task가 이 인터페이스 사용

Phase 2: 핵심 기능 (Task 001-005)
────────────────────────────────────
├─ 각 기능별 End-to-End 구현
├─ 인터페이스 구현체 작성
├─ Mock으로 다른 기능 대체
└─ 각 Task 완료 시 해당 기능 작동

Phase 3: 연결 (Task 006-008)
────────────────────────────────────
├─ Mock → 실제 구현체 교체
├─ 기능 간 통합 테스트
├─ E2E 테스트 추가
└─ 전체 시스템 작동 확인
```

### 조립 예시: 주문 생성 기능

```
Task 002: Order 생성 기능 (의사코드)

1. 인터페이스 사용 (Task 000에서 정의된 것):
   - IOrderRepository
   - IUserRepository

2. 서비스 구현:
   CLASS OrderService:
     CONSTRUCTOR(order_repo: IOrderRepository, user_repo: IUserRepository)
     
     METHOD create_order(command):
       // User 검증 (IUserRepository 사용)
       user = user_repo.get_by_id(command.user_id)
       IF NOT user:
         THROW UserNotFoundError
       
       // Order 생성
       order = Order.create(...)
       
       // 저장 (IOrderRepository 사용)
       order_repo.save(order)
       RETURN order

3. 테스트 (Mock 사용):
   TEST create_order:
     // Mock 리포지토리
     user_repo = Mock(IUserRepository)
     user_repo.get_by_id → returns User(...)
     
     order_repo = Mock(IOrderRepository)
     
     service = OrderService(order_repo, user_repo)
     order = service.create_order(command)
     
     ASSERT order.status == PENDING
     ASSERT order_repo.save called once
```

### 수정된 Task Breakdown 예시 (기능별)

```
# 기존 (레이어별) → 수정 (기능별)

기존:
├─ Task 001: User 엔티티
├─ Task 002: Order 엔티티
├─ Task 003: Portfolio 엔티티
├─ Task 004: 값 객체
├─ Task 005: 마이그레이션
├─ Task 006: User 리포지토리
├─ Task 007: Order 리포지토리
├─ Task 008: 주문 생성 서비스
├─ Task 009: 주문 조회 서비스
├─ Task 010: Auth API
├─ Task 011: Orders API
...

수정:
├─ Task 000: 인터페이스 정의 (모든 Protocol)     [1.5h]
├─ Task 001: User 기능 (Entity→Repo→Service→API) [4h]
├─ Task 002: Auth 기능 (Login, Token, Refresh)   [3h]
├─ Task 003: Order 생성 기능 (E2E)               [4h]
├─ Task 004: Order 조회 기능 (E2E)               [2.5h]
├─ Task 005: Order 취소 기능 (E2E)               [2.5h]
├─ Task 006: Portfolio 기능 (E2E)                [3h]
├─ Task 007: KIS 연동 기능 (E2E)                 [4h]
├─ Task 008: 기능 간 통합                        [3h]
└─ Task 009: E2E 테스트                          [2.5h]

총: 30시간 (10 Tasks) vs 48시간 (17 Tasks)
효율성: 37.5% 향상!
```

---

## ⏪ DNA 핵심 원칙 4: 역방향 수정 프로토콜

### 이전 Stage 오류 발견 시나리오

```
Stage 8 작업 중 발견할 수 있는 오류:

시나리오 1: Blueprint 불완전
────────────────────────────────────
"Task 분해하려는데 Blueprint에 Order 취소 API가 없네?"
→ Stage 7 Blueprint 수정 필요

시나리오 2: ADR 누락
────────────────────────────────────
"외부 결제 API 연동이 필요한데 ADR에 결정 안 되어 있네?"
→ Stage 3 ADR 추가 필요

시나리오 3: NFR 재검토
────────────────────────────────────
"Task 분해하니까 실시간 요구사항이 더 중요했네?"
→ Stage 2 NFR 우선순위 수정 필요

시나리오 4: 패밀리 재분류
────────────────────────────────────
"협업 기능이 핵심인데 CRUD 패밀리로 분류했었네?"
→ Stage 1 패밀리 재분류 필요 (드뭄)
```

### 6단계 수정 프로토콜

```
Stage 8에서 이전 Stage 오류 발견 시:

Step 1: 오류 발견 및 문서화
────────────────────────────────────
├─ 발견 위치: Stage 8 Task Breakdown
├─ 오류 내용: [구체적 설명]
├─ 영향 받는 Stage: Stage [N]
└─ 기록: 08T-01_task_breakdown.md에 "발견된 이슈" 섹션 추가

Step 2: 영향 범위 파악
────────────────────────────────────
├─ 직접 영향: Stage [N]
├─ 간접 영향: Stage [N+1] ~ Stage 7
├─ 재작업 예상 시간: [X]시간
└─ 기록: 영향 범위 문서화

Step 3: 해당 Stage로 이동 → 수정
────────────────────────────────────
├─ Stage [N] 산출물 수정
├─ 수정 이력 기록
├─ 버전 업데이트 (v1.0 → v1.1)
└─ 수정 완료 검증

Step 4: 중간 Stage 전파 (N+1 ~ 7)
────────────────────────────────────
├─ 각 Stage 산출물 영향 확인
├─ 필요 시 수정
├─ 수정 이력 기록
└─ 일관성 검증

Step 5: Stage 8 재진행
────────────────────────────────────
├─ 수정된 입력으로 Task Breakdown 재작성
├─ 3단계 검증 프로토콜 재실행
└─ 완전성 확인

Step 6: 재진행 결과 검증
────────────────────────────────────
├─ 오류가 해결되었는지 확인
├─ 새로운 문제 발생 여부 확인
├─ 최종 승인
└─ Stage 9 전달
```

### 추적성 (Traceability)

```
수정 이력 관리:

파일: docs/revision_log.md
────────────────────────────────────
# Revision Log

## 2025-12-03 (Stage 8 작업 중 발견)

### Issue #001: Order 취소 API 누락
- **발견 Stage**: Stage 8 Task Breakdown
- **영향 Stage**: Stage 7 Blueprint
- **수정 내용**: Section 4.1에 DELETE /orders/{id} 추가
- **영향 범위**: Stage 8 Task 목록에 "Order 취소 기능" 추가
- **수정자**: Jason
- **검증**: AI 검증 완료

### Issue #002: 외부 결제 API ADR 누락
- **발견 Stage**: Stage 8 Task Breakdown
- **영향 Stage**: Stage 3 ADR
- **수정 내용**: ADR-015 "외부 결제 API 연동" 추가
- **영향 범위**: 
  - Stage 4: DNA Blueprint에 결제 관련 DNA 추가
  - Stage 7: Blueprint Section 6 외부 연동 추가
  - Stage 8: Task 목록에 결제 기능 추가
- **수정자**: Jason
- **검증**: AI 검증 완료
```

### 예시: Stage 7 작성 중 Stage 3 ADR 오류 발견

```
상황:
Stage 7 Blueprint 작성 중 "KIS API Rate Limiting" 결정이
ADR에 없음을 발견

6단계 프로토콜 적용:

Step 1: 오류 문서화
├─ 발견: Stage 7 Blueprint Section 6.1 작성 중
├─ 오류: KIS API Rate Limiting 전략 ADR 없음
├─ 영향: Stage 3
└─ 기록: 07B-01에 "발견된 이슈" 추가

Step 2: 영향 범위
├─ 직접: Stage 3 (ADR 추가 필요)
├─ 간접: Stage 4-6 (영향 없음, DNA 변경 불필요)
├─ 재작업: 2시간
└─ 기록 완료

Step 3: Stage 3 수정
├─ ADR-016 "KIS API Rate Limiting" 작성
├─ 결정: 초당 15회 제한, 재시도 전략
├─ 버전: v1.0
└─ 검증 완료

Step 4: 중간 Stage 전파
├─ Stage 4-6: 변경 불필요 확인
└─ 스킵

Step 5: Stage 7 재진행
├─ Blueprint Section 6.1 Rate Limiting 추가
├─ ADR-016 참조 추가
└─ 완료

Step 6: 검증
├─ Rate Limiting 설계 완료 확인
├─ 새로운 문제 없음
└─ Stage 8 전달 가능 ✅
```

---

**Remember**: 
- Blueprint는 전체 그림, Task는 레고 블럭
- 좋은 Task = 적절한 크기 + 독립성 + 검증 가능 + 가치
- RDoLT: Easy → Intermediate → Final 순서
- 핵심 경로 파악 = 일정 예측 가능
- Stage 9에서 각 Task마다 9-Step 체크리스트 작성

*Task Breakdown은 "AI가 100% 성공할 수 있는 작업 단위"를 만드는 과정입니다.*


================================================================================

📄 FILE: 09G-00_checklist_guide.md
--------------------------------------------------------------------------------

# Stage9: 작업 체크리스트 작성 가이드(9-Step Checklist)

> **목적**: Stage 9 - TDD 기반 9-Step Checklist로 모든 기능 구현, 0 violations, 95%+ coverage 보장
>
> **버전**: v4.1 (2025-12-03)
> - v2.0: Stage 9 범위 명시, 입력/출력 문서 추가

---

## 🌐 언어 중립성 안내

이 가이드는 **언어 무관 개념 + Python 생태계 예시**로 구성됩니다:

```
개념 (언어 무관):
├─ 9-Step TDD Checklist 구조
├─ 코드 스켈레톤 작성 원칙
├─ 테스트 케이스 설계 방법
└─ 품질 검증 기준 (0 violations, 95%+ coverage)

예시 (Python 생태계):
├─ pytest, Ruff, MyPy 명령어
├─ Pydantic, structlog 코드
└─ Python 문법 스켈레톤

다른 언어:
└─ 해당 언어 매뉴얼 참조
```

**언어별 도구 대응표**:

| 언어       | Linter        | Type Checker | Test Framework | Coverage     |
|-----------|---------------|--------------|----------------|--------------|
| Python    | ruff          | mypy         | pytest         | pytest-cov   |
| TypeScript| eslint        | tsc          | jest           | jest         |
| Rust      | clippy        | rustc        | cargo test     | tarpaulin    |
| Go        | golangci-lint | go vet       | go test        | go test      |
| Java      | checkstyle    | javac        | junit          | jacoco       |

**적용 방법**: 예시의 도구 이름만 해당 언어 도구로 교체하면 됩니다.

```

---

## 📚 이 가이드의 위치

```
DNA 방법론 문서 체계:

Tier 1: 00_CORE_METHODOLOGY.md (전체 맥락)
           ↓
Tier 2: 01_DNA_METHODOLOGY_DETAILED.md (상세 원리)
           ↓
Tier 3: 이 문서 (Stage 8 실행 가이드) ← 지금 여기!
```

**참조 문서**:

- **원리 이해**: `01_DNA_METHODOLOGY_DETAILED.md` **Part 6.3**

---

## 📥 입력 문서 (Stage 8에서 받은 것)

#### 1. **`08T-01_task_breakdown.md`** (필수)
- 작업 목록 (Task 001~N)
- **활용**: 각 Task마다 Checklist 생성

#### 2. **`06D-01_project_standards.md`** (참고)
- 프로젝트 표준
- **활용**: Checklist에 표준 반영

---

## 📤 출력 문서 (이 Stage에서 생성해야 할 문서)

### 필수 문서

각 Task마다 1개씩 Checklist 생성:

#### 1. **`09L-01_task_001_checklist.md`**
#### 2. **`09L-02_task_002_checklist.md`**
#### 3. **`09L-03_task_003_checklist.md`**
...

**내용** (TDD 9-Step):
```markdown
# Task 001 Checklist: Order Entity 구현

## Step 1: 목표 이해 ✅
- [ ] Task 문서 읽기 (08T-01 Task 001)
- [ ] ADR-116 읽기
- [ ] 표준 확인 (Naming, Validation)
- [ ] 성공 기준 명확히

## Step 2: 테스트 작성 ✅
- [ ] `tests/test_order_entity.*` 생성
- [ ] 실패하는 테스트 작성
- [ ] Test 실행 → RED 확인

## Step 3: 구현 ✅
- [ ] `src/domains/order/models.*` 생성
- [ ] Order 클래스 작성
- [ ] Test 실행 → GREEN 확인

## Step 4: 정적 검증 ✅
- [ ] Lint (0 violations)
- [ ] Type Check (0 errors)

## Step 5: 단위 테스트 실행 ✅
- [ ] Test tests/test_order_entity.*
- [ ] coverage report (95%+)

## Step 6: 리팩토링 ✅
- [ ] 중복 코드 제거
- [ ] 명명 개선
- [ ] 테스트 재실행

## Step 7: 종합 테스트 ✅
- [ ] 통합 테스트 (필요시)
- [ ] E2E 테스트 (필요시)

## Step 8: 문서화 ✅
- [ ] Docstring 작성
- [ ] README 업데이트 (필요시)

## Step 9: 커밋 ✅
- [ ] git add .
- [ ] git commit -m "..."
- [ ] PR 생성 (필요시)
```

**특징**:
- AI가 체크박스 하나씩 완료
- 0 violations 보장
- 95%+ coverage 보장

---

## 🔄 다음 Stage로 전달되는 것

Stage 9 → 구현:
- ✅ 작업별 체크리스트
- ✅ TDD 9-Step 실행 가이드
- ✅ 품질 보장 메커니즘

구현 단계에서는:
- Checklist를 따라 단계별 구현
- 모든 검증 통과 확인
- 완성된 코드 + 테스트 + 문서

---

## 🎯 DNA 핵심 원칙 1: AI 최적 크기와 Stage 9

### Stage 9 = AI 실행의 최종 단계

```
DNA 방법론 흐름에서 Stage 9의 위치:
────────────────────────────────────────────────────────

Stage 1-7: Human-Driven (인간 중심)
├─ 패밀리 분류, NFR, ADR, Blueprint
├─ 문서 크기 제한 없음
└─ 인간의 이해와 의사결정 중심

Stage 8: 변환점 (Transformation Point)
├─ Blueprint → Task 분해
├─ AI 컨텍스트 한계 고려 시작
└─ Task 크기: 2-4시간, 체크리스트 100-150줄

Stage 9: AI 실행 (AI Execution) ← 여기!
────────────────────────────────────────────────────────
├─ Task → 9-Step Checklist
├─ AI가 직접 실행하는 최종 산출물
├─ 체크리스트가 AI의 "작업 지시서"
└─ 완전해야 AI가 100% 성공!
```

### 왜 체크리스트는 100-150줄인가?

```
체크리스트 크기의 과학적 근거:
────────────────────────────────────────────────────────

AI 컨텍스트 윈도우 (예: 200K 토큰)
├─ 시스템 프롬프트: ~30K 토큰
├─ 대화 히스토리: ~20K 토큰
├─ Task 문서 + Blueprint 참조: ~30K 토큰
├─ Checklist: ~15K 토큰 (100-150줄)
├─ 생성할 코드: ~20K 토큰
└─ 응답 생성 여유: ~85K 토큰 ✅

체크리스트 줄 수 → 토큰 변환:
├─ 체크리스트 1줄 ≈ 10-15 토큰
├─ 코드 스켈레톤 포함 시 ≈ 20 토큰/줄
├─ 100줄 = ~1,500 토큰
├─ 150줄 = ~2,500 토큰
└─ 코드 예시 포함 시 ~5,000-10,000 토큰

결론:
├─ 100줄: 간단한 Task (Entity, 값 객체)
├─ 120줄: 표준 Task (Service, Repository)
├─ 150줄: 복잡한 Task (외부 연동, 동시성)
└─ 180줄+: 분할 필요! ⚠️
```

### 체크리스트 크기 판단 공식

```
FUNCTION is_optimal_checklist_size(checklist):
    """Checklist 크기가 AI 최적인지 판단"""
    
    // 1. 줄 수 검증
    total_lines = checklist.count_lines()
    IF NOT (80 <= total_lines <= 180):
        RETURN FALSE
    
    // 2. 9-Step 완전성
    IF checklist.steps.length != 9:
        RETURN FALSE
    
    // 3. 코드 스켈레톤 포함
    code_skeleton_lines = checklist.count_code_lines()
    IF code_skeleton_lines < 20:  // 최소 스켈레톤
        RETURN FALSE
    IF code_skeleton_lines > 100:  // 너무 많음
        RETURN FALSE
    
    // 4. 테스트 케이스 포함
    test_cases = checklist.count_test_cases()
    IF NOT (3 <= test_cases <= 10):
        RETURN FALSE
    
    RETURN TRUE
```

### 크기별 체크리스트 예시

| Task 유형 | 예상 줄 수 | 코드 스켈레톤 | 테스트 케이스 |
|----------|----------|------------|------------|
| Entity (단순) | 80-100줄 | 20-30줄 | 3-5개 |
| Service (표준) | 100-130줄 | 30-50줄 | 5-8개 |
| API Endpoint | 110-140줄 | 40-60줄 | 5-8개 |
| 외부 연동 | 130-160줄 | 50-70줄 | 6-10개 |
| 동시성 처리 | 140-180줄 | 60-80줄 | 8-12개 |

---

## 🔄 DNA 핵심 원칙 2: 완전해질 때까지 반복 (Checklist 관점)

### "완전한 Checklist"란?

```
완전한 Checklist의 조건:
────────────────────────────────────────────────────────

AI가 Checklist만 보고 100% Task 완료 가능:
├─ 추가 질문 없음 (모든 정보 포함)
├─ 외부 문서 참조 불필요 (인라인 복사)
├─ 모호함 0 (구체적 명령어)
├─ 누락 0 (9-Step 모두 완전)
└─ 불완전함 0 (검증 가능한 완료 조건)

반대로, 불완전한 Checklist:
├─ ❌ "PROJECT_STANDARDS.md 참조하세요"
├─ ❌ "적절히 구현하세요"
├─ ❌ "필요한 테스트 작성"
├─ ❌ Step 3만 상세하고 나머지 간략
└─ → AI 실패 → 재작업 → 시간 낭비!
```

### 3단계 검증 프로토콜 (Checklist용)

```
┌─────────────────────────────────────────────────────────┐
│ 검증 1: 크기                                           │
├─────────────────────────────────────────────────────────┤
│ □ 총 줄 수: 80-180줄 범위?                              │
│ □ 코드 스켈레톤: 20-100줄?                              │
│ □ 테스트 케이스: 3-10개?                                │
│ □ 자주 하는 실수: 3-5개?                                │
│                                                         │
│ 실패 시 → 분할 (너무 큼) 또는 보완 (너무 작음)           │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│ 검증 2: 자급자족성                                      │
├─────────────────────────────────────────────────────────┤
│ □ 외부 문서 참조 없음? (인라인 복사?)                    │
│ □ 프로젝트 표준 인라인?                                 │
│ □ ADR 핵심 내용 인라인?                                 │
│ □ 모든 명령어 복사-붙여넣기 가능?                        │
│                                                         │
│ 실패 시 → 필요한 내용 인라인 복사                        │
└─────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────┐
│ 검증 3: 실행 가능성                                     │
├─────────────────────────────────────────────────────────┤
│ □ Step 1: 입출력 명확?                                  │
│ □ Step 2: 테스트 케이스 구체적? (코드 포함?)             │
│ □ Step 3: 구현 스켈레톤 있음? (복붙 아닌 가이드)         │
│ □ Step 4-5: 검증 명령어 복사 가능?                      │
│ □ Step 6-9: 완료 조건 측정 가능?                        │
│                                                         │
│ 실패 시 → 해당 Step 보완                                │
└─────────────────────────────────────────────────────────┘
                        ↓
          모든 검증 통과 → AI 실행 준비 완료! ✅
```

### Checklist 완전성 체크리스트

```
Checklist 완전성 검증:
────────────────────────────────────────────────────────

Step별 완전성:

□ Step 1 (목표 이해):
  ├─ Task 목표가 명확히 복사됨?
  ├─ 입출력이 구체적으로 정의됨?
  └─ 성공 기준이 측정 가능?

□ Step 2 (테스트 작성):
  ├─ 테스트 케이스 3개 이상?
  ├─ Given-When-Then 구조?
  ├─ 실제 코드 스켈레톤 포함?
  └─ 성공/실패/엣지 케이스 모두?

□ Step 3 (구현):
  ├─ 프로젝트 표준 인라인?
  ├─ 구현 스켈레톤 (복붙 아닌 가이드)?
  ├─ 자주 하는 실수 ❌/✅?
  └─ 파일 경로 명확?

□ Step 4 (정적 검증):
  ├─ Lint 명령어 복사 가능?
  ├─ Type Check 명령어 복사 가능?
  └─ 예상 출력 명시?

□ Step 5 (테스트 실행):
  ├─ Test 명령어 복사 가능?
  ├─ coverage 명령어 포함?
  └─ 95%+ 기준 명시?

□ Step 6-9 (마무리):
  ├─ 리팩토링 체크리스트?
  ├─ 문서화 범위?
  └─ 커밋 메시지 형식?

모두 ✅ → 완전한 Checklist!
하나라도 ❌ → 보완 필요
```

### 재작업 사례: "JWT 토큰 생성" Checklist

```
❌ 1차 시도 (불완전):
────────────────────────────────────────────────────────

## Step 3: 구현
- create_token 함수 구현
- PROJECT_STANDARDS.md 참조

문제점:
├─ 외부 문서 참조 (자급자족 X)
├─ 구현 스켈레톤 없음
├─ 어떤 라이브러리? 어떤 알고리즘?
└─ AI가 추측해야 함 → 실패 가능성 높음

검증 결과: 검증 2 실패 (자급자족성 X)
────────────────────────────────────────────────────────

🔄 2차 시도 (보완):
────────────────────────────────────────────────────────

## Step 3: 구현

### 3.1 프로젝트 표준 (인라인)

#### 로깅 (PROJECT_STANDARDS Line 12-25)
- logger.info("event_name", key=value) 형식
- print() 금지

#### 설정 (PROJECT_STANDARDS Line 30-45)
- config.get_secret("JWT_SECRET_KEY") 사용
- 하드코딩 금지

### 3.2 구현 스켈레톤

```
// src/auth/token.* (언어별 확장자)

FUNCTION create_token(user_id: String) -> String:
    """JWT 토큰 생성.
    
    Args:
        user_id: 사용자 ID
    Returns:
        JWT 토큰 (1시간 유효)
    """
    payload = {
        "user_id": user_id,
        "exp": now() + 1_hour
    }
    secret_key = config.get_secret("JWT_SECRET_KEY")
    token = jwt.encode(payload, secret_key, algorithm="HS256")
    logger.info("token_created", user_id=user_id)
    RETURN token

// 언어별 구현 예시: docs/manuals/ 참조
```

### 3.3 자주 하는 실수

❌ exp를 초 단위로 제공:
payload["exp"] = 3600

✅ datetime으로 제공:
payload["exp"] = now() + 1_hour

검증 결과: 모든 검증 통과! ✅
────────────────────────────────────────────────────────
```

---

## 🧩 DNA 핵심 원칙 3: 기능별 구조 + 연결부 명시 (Stage 9 관점)

### Stage 9에서 "기능별"의 의미

```
Stage 8 (Task Breakdown):
├─ 레이어별 X → 기능별 O
├─ Task 완료 = 기능 완료 (E2E)
└─ 예: Task 001 = User 기능 전체

Stage 9 (Checklist):
────────────────────────────────────────────────────────
├─ 9-Step으로 기능 구현
├─ 각 Step이 "기능의 일부"
├─ Step 완료 = 검증 가능한 진행
└─ 연결부 (Interface) 명시!

핵심 차이:
├─ Stage 8: "어떤 기능을 만들까?" (What)
└─ Stage 9: "그 기능을 어떻게 만들까?" (How)
```

### 연결부 (Interface) 명시의 중요성

```
Checklist에서 연결부가 중요한 이유:
────────────────────────────────────────────────────────

Task가 다른 Task에 의존할 때:
├─ Task 001: User 엔티티
├─ Task 005: Order 생성 서비스 (User 필요!)
└─ Task 005 Checklist에 User 인터페이스 명시 필수!

예시 - Task 005 Checklist:

## Step 1: 목표 이해

### 의존성 (다른 Task에서 제공)

**User 인터페이스 (Task 001 완료 후 사용 가능)**:
```
// 이 인터페이스는 Task 001에서 구현됨
// Task 005에서는 이 인터페이스만 알면 됨

Entity: User
├─ id: UserId
├─ email: String
└─ created_at: DateTime

Interface: IUserRepository
└─ find_by_id(user_id) → User?
```

### 이 Task의 출력 (다른 Task에 제공)

**OrderService 인터페이스**:
```
// Task 005에서 구현할 것
// Task 010 (주문 조회)에서 사용할 것

Interface: IOrderService
└─ create_order(user_id, items) → Order
```

이렇게 하면:
├─ Task 001 미완료 → Mock으로 테스트 가능
├─ Task 005 완료 → 실제 User 연결
└─ AI가 의존성을 명확히 이해
```

### Mock 사용 전략

```
Mock을 활용한 독립적 Checklist:
────────────────────────────────────────────────────────

## Step 2: 테스트 작성

### 의존성 Mock

// tests/test_order_service.* (언어별 확장자)

FIXTURE mock_user_repository:
    """User 의존성 Mock (Task 001 미완료 시 사용)"""
    repo = Mock(IUserRepository)
    repo.find_by_id → returns User(
        id="user-123",
        email="test@example.com",
        created_at=now()
    )
    RETURN repo

TEST create_order_success(mock_user_repository):
    // Given
    service = OrderService(user_repo=mock_user_repository)
    
    // When
    order = service.create_order(
        user_id="user-123",
        items=[OrderItem(product_id="prod-1", quantity=2)]
    )
    
    // Then
    ASSERT order.user_id == "user-123"
    ASSERT mock_user_repository.find_by_id called once

장점:
├─ Task 001 미완료해도 Task 005 테스트 가능
├─ 병렬 작업 가능
├─ 인터페이스 계약 명확
└─ 나중에 Mock → 실제 구현체 교체만!
```

### Checklist 연결부 섹션 템플릿

```markdown
## Step 1: 목표 이해

### 1.1 Task 목표
{Task 문서에서 복사}

### 1.2 의존성 (다른 Task에서 제공받는 것)

| Task ID | 제공 인터페이스 | 상태 |
|---------|---------------|------|
| Task 001 | IUserRepository | ✅ 완료 / 🔄 Mock 사용 |
| Task 003 | Money 값 객체 | ✅ 완료 |

**인터페이스 정의** (Task 미완료 시 Mock용):
```python
class IUserRepository(Protocol):
    def find_by_id(self, user_id: UserId) -> User | None: ...
```

### 1.3 이 Task의 출력 (다른 Task에 제공할 것)

| 제공 인터페이스 | 사용할 Task |
|---------------|------------|
| IOrderService | Task 010, 015 |

**인터페이스 정의**:
```python
class IOrderService(Protocol):
    def create_order(...) -> Order: ...
```
```

---

## 1. 개요

### 목적
**Task 문서 (100줄) → 9-Step Checklist (실행 가능한 작업 지시서)**

Task 문서는 "무엇을" 만들지 정의하고, Checklist는 "어떻게" 만들지 실행 단계를 제공합니다.

### Checklist의 역할
```
Task 문서 (설계도)
    ↓
Checklist (작업 지시서)
    ↓
AI 에이전트 실행 (구현)
    ↓
완성된 코드 + 테스트 + 문서
```

### 완성 기준
- ✅ **실행 가능성**: AI가 이 Checklist만으로 Task를 완수할 수 있어야 함
- ✅ **자급자족성**: Task 문서 + Checklist만 있으면 Blueprint 없이도 작업 가능
- ✅ **검증 가능성**: 각 Step의 완료 여부를 명확히 확인 가능

---

## 2. 정보 밀도 균형점 ⚖️

### 2-1. 왜 500 lines인가?

**너무 많으면 (1,400+ lines)**:
```markdown
❌ 전체 구현 코드 400 lines 포함
❌ 전체 테스트 코드 200 lines 포함
❌ 모든 에러 처리, 엣지 케이스 포함
→ Agent가 읽기 부담스러움
→ 복붙만 하게 되어 TDD 불가능
```

**너무 적으면 (200 lines)**:
```markdown
❌ "Task 문서 Section 7 참조하세요"
❌ "PROJECT_STANDARDS.md 읽어보세요"
→ Agent가 문서 왕복하며 읽어야 함
→ 집중력 분산, 비효율적
```

**균형점 (500 lines)**: ✅
```markdown
✅ 구현 스켈레톤 (40 lines) - 핵심 로직 구조만
✅ 테스트 스켈레톤 (30 lines/케이스) - Given-When-Then + 기본 assert
✅ 자주 하는 실수 (15 lines/패턴) - ❌/✅ Before/After
✅ 프로젝트 표준 인라인 (30 lines) - 이 Task 관련만
→ Agent가 체크리스트만 보고 작업 완료
→ 스켈레톤이라 Agent가 채우며 TDD 가능
```

---

### 2-2. 구현 코드는 얼마나?

**"정보 밀도 균형점"이란?**

체크리스트에 제공하는 정보의 양과 상세도의 최적 지점입니다:
- **너무 적으면**: AI가 추측하여 프로젝트 표준 위반
- **너무 많으면**: AI가 복붙만 하여 TDD 불가능, 학습 효과 없음
- **균형점**: AI가 스스로 채우며 구현할 수 있는 "스켈레톤" 수준

이를 4단계 Level로 구체화하여, Level 3 (스켈레톤)이 균형점임을 시연합니다.

---

**Level 1: 인터페이스 계약** (20 lines) - **필수**
```python
def create_token(user_id: str) -> str:
    """JWT 액세스 토큰 생성.

    Args:
        user_id: 사용자 ID
    Returns:
        JWT 토큰 (1시간 유효)
    Raises:
        ValueError: user_id 빈 문자열
    """
```
→ "무엇을" 만들지 정의. Agent가 추측 불가능.

**Level 2: 아키텍처 제약** (10 lines) - **필수**
```python
# PyJWT 라이브러리 사용
# HS256 알고리즘만
# config.get_secret("JWT_SECRET_KEY") 사용
# structlog로 로깅
```
→ 프로젝트별 제약. Agent가 추측하면 틀림.

**Level 3: 구현 스켈레톤** (40 lines) - **균형점!** ✅
```python
def create_token(user_id: str) -> str:
    payload = {"user_id": user_id, "exp": datetime.utcnow() + timedelta(hours=1)}
    secret_key = config.get_secret("JWT_SECRET_KEY")
    token = jwt.encode(payload, secret_key, algorithm="HS256")
    logger.info("token_generated", user_id=user_id)
    return token
```
→ 핵심 로직 구조만. Agent가 에러 처리, validation 추가.

**Level 4: 전체 구현** (200+ lines) - **과함!** ❌
```python
def create_token(user_id: str) -> str:
    try:
        if not user_id:
            raise ValueError("user_id cannot be empty")
        if not isinstance(user_id, str):
            raise TypeError("user_id must be string")
        # ... 100+ lines of error handling
        # ... 50+ lines of edge case handling
    except Exception as e:
        logger.exception("unexpected_error")
        raise
```
→ 모든 엣지 케이스 포함. Agent가 복붙만 함. TDD 불가능.

**선택: Level 3 (스켈레톤)** - 이유:
- Agent가 스스로 채우며 구현 (학습 효과)
- TDD 가능 (테스트 실패 → 수정 → 통과 반복)
- "Necessary Information Only" 원칙 준수

---

### 2-3. 테스트 코드는 얼마나?

**Level 1: Given-When-Then 시나리오만** (10 lines) - **불충분** ❌
```python
def test_create_token_success():
    """Given: 유효한 user_id
       When: create_token 호출
       Then: JWT 토큰 반환"""
```
→ 구체적인 assert 없음. Agent가 어떻게 검증할지 모름.

**Level 2: 테스트 스켈레톤** (30 lines) - **균형점!** ✅
```python
def test_create_token_success():
    """Given: 유효한 user_id
       When: create_token 호출
       Then: JWT 토큰 반환"""
    # Given
    user_id = "test-user-123"
    generator = TokenGenerator()

    # When
    token = generator.create_token(user_id)

    # Then
    assert isinstance(token, str)
    decoded = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
    assert decoded["user_id"] == user_id
    # Agent가 exp 검증 등 추가
```
→ 기본 assert 구조 제공. Agent가 세밀한 검증 추가.

**Level 3: 완전한 테스트** (100+ lines) - **과함!** ❌
```python
def test_create_token_success():
    # ... 50 lines of setup
    # ... 30 lines of execution
    # ... 20 lines of verification
```
→ 모든 검증 포함. Agent가 복붙만 함.

**선택: Level 2 (스켈레톤)** - 이유:
- Given-When-Then 구조 명확
- 기본 assert로 방향 제시
- Agent가 세밀한 검증 추가 (TDD)

---

### 2-4. 자주 하는 실수는?

**Level 1: 항목만 나열** (5 lines) - **불충분** ❌
```
실수 1: exp를 초 단위로 제공
실수 2: SECRET_KEY 하드코딩
```
→ 뭐가 잘못됐는지만. 어떻게 고쳐야 할지 모름.

**Level 2: ❌/✅ Before/After** (15 lines) - **균형점!** ✅
```python
실수 1: exp를 초 단위로 제공
❌ payload["exp"] = 3600
✅ payload["exp"] = datetime.utcnow() + timedelta(hours=1)

실수 2: SECRET_KEY 하드코딩
❌ SECRET_KEY = "my-secret-123"
✅ secret_key = config.get_secret("JWT_SECRET_KEY")
```
→ 명확한 대비. Agent가 즉시 이해.

**Level 3: 이유 + 디버깅** (30+ lines) - **과함!** ❌
```
실수 1: exp를 초 단위로 제공

❌ 잘못된 코드: ...
왜 잘못됐나? ...
어떻게 발견하나? ...
✅ 올바른 코드: ...
추가 고려사항: ...
```
→ 너무 장황. Agent가 읽기 부담.

**선택: Level 2 (Before/After)** - 이유:
- 3-5 lines로 간결
- 즉시 비교 가능
- 패턴 명확

---

### 2-5. 프로젝트 표준은 어떻게?

**Option 1: 범용 문서 참조** ❌
```markdown
## Step 3: 구현
**프로젝트 표준**: PROJECT_STANDARDS.md 참조하세요
```
→ Agent가 800 lines 문서를 언제 읽나?

**Option 2: 인라인 복사** ✅ (균형점!)
```markdown
## Step 3: 구현

### 3.1 이 Task의 프로젝트 표준

#### 로깅 (PROJECT_STANDARDS.md Line 12-25)
- logger.info("event_name", key=value) 형식
- print() 금지
- 모든 주요 작업 로깅

#### 설정 (PROJECT_STANDARDS.md Line 30-45)
- config.get_secret("KEY_NAME") 사용
- 하드코딩 금지
- 환경변수로 관리

#### 에러 (PROJECT_STANDARDS.md Line 50-68)
- CustomError 상속
- structlog로 로깅
- 사용자에게 명확한 메시지
```
→ 체크리스트에 인라인. Agent가 왕복 불필요.
→ Line 참조 유지 (추적 가능성)
→ "이 Task 관련" 부분만 (Necessary Information Only)

**선택: Option 2 (인라인)** - 이유:
- 체크리스트만으로 자급자족
- 다른 문서 참조 불필요
- 30 lines 정도로 적정

---

### 2-6. 체크리스트 크기 계산

```
Step 1: 목표 이해 (50 lines)
  - Task 목표, 입출력, 성공 기준

Step 2: 테스트 작성 (100 lines)
  - Given-When-Then 시나리오 3-5개
  - 테스트 스켈레톤 (각 20-30 lines)

Step 3: 구현 (200 lines) ← 가장 많음
  - 3.1 프로젝트 표준 인라인 (30)
  - 3.2 함수 시그니처 (20)
  - 3.3 구현 스켈레톤 (40)
  - 3.4 자주 하는 실수 (60)
  - 3.5 구현 위치 (10)

Step 4: 정적 검증 (30 lines)
  - ruff, mypy, import-linter 명령어
  - 예상 출력

Step 5: 테스트 실행 (40 lines)
  - pytest + coverage 명령어
  - 예상 출력

Step 6-9: 리팩토링/재테스트/문서화/커밋 (80 lines)

총합: 50 + 100 + 200 + 30 + 40 + 80 = 500 lines
```

---

### 2-7. 파일 분리와 Line 참조

**큰 문서 = 문제 아님!**

```markdown
# 청사진이 5,000 lines? 괜찮아!

blueprints/
├── 01_auth_system.md (500 lines)
├── 02_payment_system.md (600 lines)
├── 03_notification_system.md (450 lines)
...

# Task 작성 시:
청사진 참조: blueprints/01_auth_system.md Line 145-178
→ 500 lines 문서의 33 lines만 읽으면 됨!

# Checklist 작성 시:
그 33 lines를 인라인으로 복사
→ Agent는 체크리스트만 읽음!
```

**PROJECT_STANDARDS.md가 800 lines? 괜찮아!**

```markdown
standards/
├── 01_logging.md (150 lines)
├── 02_configuration.md (120 lines)
├── 03_error_handling.md (180 lines)
├── 04_database.md (200 lines)
...

# Task 작성 시:
표준 참조: standards/01_logging.md Line 12-25
→ 150 lines 문서의 13 lines만!

# Checklist 작성 시:
그 13 lines를 Step 3.1에 인라인
→ Agent는 체크리스트만 읽음!
```

**핵심**:
- 큰 문서는 파일로 분리 (각 200-500 lines)
- Line 참조로 정확한 부분만 지정
- 체크리스트에 인라인 복사
- Agent는 최종적으로 체크리스트 500 lines만 읽음

---

## 3. 9-Step 구조 이해

### 전체 흐름
```
┌─────────────────────────────────────────────┐
│ Phase 1: 이해 + 테스트 설계 (Step 1-2)          │
│ - 목표 명확화                                  │
│ - 테스트 케이스 작성 (TDD)                      │
├─────────────────────────────────────────────┤
│ Phase 2: 구현 + 1차 검증 (Step 3-4)            │
│ - 핵심 로직 구현                               │
│ - 정적 검증 (ruff, mypy, import-linter)       │
├─────────────────────────────────────────────┤
│ Phase 3: 테스트 + 품질 개선 (Step 5-7)          │
│ - 테스트 실행 (pytest 95%+ coverage)          │
│ - 리팩토링                                    │
│ - 재테스트                                    │
├─────────────────────────────────────────────┤
│ Phase 4: 문서화 + 제출 (Step 8-9)             │
│ - Docstring + 사용 예시                       │
│ - Git commit                                │
└─────────────────────────────────────────────┘
```

### 핵심 원칙

**TDD (Test-Driven Development) ↔ 9-Step 매핑**

9-Step은 전통적인 Red-Green-Refactor 사이클을 확장한 것입니다:

```
Red-Green-Refactor (TDD 3단계):
├─ Red: 실패하는 테스트 작성
│    → Step 2: 테스트 작성
├─ Green: 최소 구현으로 통과
│    → Step 3: 구현
│    → Step 4: 정적 검증
│    → Step 5: 테스트 실행
└─ Refactor: 코드 개선
     → Step 6: 리팩토링
     → Step 7: 재테스트

추가 단계 (품질 보장):
├─ Step 1: 목표 이해 (사전 준비)
├─ Step 8: 문서화 (사후 정리)
└─ Step 9: 커밋 (최종 제출)
```

**Zero-Tolerance Quality**
- Step 4: ruff 0, mypy 0, import-linter 0
- Step 5: pytest 95%+ coverage
- Step 6-7: 품질 개선 + 재검증

**Documentation First**
- Step 8: Docstring (Google 스타일)
- 사용 예시 코드 포함

---

## 3. 9-Step 상세 가이드

### Step 1: 목표 이해

**질문**: "이 Task로 무엇을 만들 것인가?"

**산출물**:
- Task 목표 명확화
- 성공 기준 정의
- Task 문서 완전 이해

**Checklist 작성법**:
```markdown
## Step 1: 목표 이해

### Task 목표
{Task 문서의 Section 4 입력/출력을 그대로 복사}

예시:
- **입력**: user_id: str
- **출력**: token: str (JWT 액세스 토큰, 1시간 유효)

### 성공 기준
{Task 문서의 Section 6 완성 기준을 그대로 복사}

예시:
- [ ] create_token(user_id) 함수 완전 작동
- [ ] pytest 테스트 3개 통과 (성공/만료/잘못된 시크릿)
- [ ] ruff 0, mypy 0, coverage 95%+
```

**도구**: Task 문서

---

### Step 2: 테스트 작성

**질문**: "어떻게 동작을 검증할 것인가?"

**산출물**:
- Given-When-Then 테스트 케이스
- 성공/실패/엣지 케이스 포함
- pytest 파일 생성

**Checklist 작성법**:
````markdown
## Step 2: 테스트 작성

### 테스트 케이스

**성공 케이스**:

```python
def test_create_token_success():
    # Given: 유효한 사용자 ID
    user_id = "user123"

    # When: 토큰 생성
    token = create_token(user_id)

    # Then: 유효한 JWT 토큰 반환
    assert isinstance(token, str)
    decoded = jwt.decode(token, settings.jwt_secret, algorithms=["HS256"])
    assert decoded["user_id"] == user_id
```

**실패 케이스**:

```python
def test_create_token_expired():
    # Given: 만료된 토큰
    token = create_expired_token("user123")

    # When: 토큰 검증
    # Then: ExpiredSignatureError 발생
    with pytest.raises(jwt.ExpiredSignatureError):
        jwt.decode(token, settings.jwt_secret, algorithms=["HS256"])
```

**엣지 케이스**:

```python
def test_create_token_invalid_secret():
    # Given: 잘못된 시크릿
    token = create_token("user123")

    # When: 잘못된 시크릿으로 검증
    # Then: InvalidSignatureError 발생
    with pytest.raises(jwt.InvalidSignatureError):
        jwt.decode(token, "wrong_secret", algorithms=["HS256"])
```
### 파일 생성

- `tests/test_jwt_token.py` 생성
- 위 테스트 케이스 3개 작성
````

**도구**: pytest, Task 문서 Section 6 (완성 기준)

---

### Step 3: 구현

**질문**: "핵심 로직을 어떻게 구현할 것인가?"

**산출물**:

- 실제 구현 코드 (스켈레톤 수준)
- Type hints 포함
- 프로젝트 표준 인라인 복사

**Checklist 작성법**:

````markdown
## Step 3: 구현

### 3.1 이 Task의 프로젝트 표준 (인라인 복사!)

{Task 문서 Section 6의 프로젝트 표준을 그대로 복사}

예시:

#### 로깅 (PROJECT_STANDARDS_01_로깅.md Line 12-25)
- `logger.info("event_name", key=value)` 형식 사용
- `print()` 절대 금지
- 모든 주요 작업 (생성, 수정, 삭제) 로깅 필수
- 에러는 `logger.error()` 또는 `logger.exception()` 사용

#### 설정 (PROJECT_STANDARDS_02_설정.md Line 30-45)
- 모든 SECRET은 `config.get_secret("KEY_NAME")` 사용
- 하드코딩 절대 금지
- `.env` 파일에서 환경변수 관리
- Pydantic Settings 클래스 사용

#### 에러 처리 (PROJECT_STANDARDS_03_에러.md Line 50-68)
- 프로젝트 CustomError 클래스 상속
- 모든 예외 structlog로 로깅
- 사용자에게 명확한 에러 메시지 전달

### 3.2 함수 시그니처

{Task 문서 Section 7의 함수 시그니처}

```python
def create_token(user_id: str) -> str:
    """JWT 액세스 토큰 생성.

    Args:
        user_id: 사용자 고유 ID

    Returns:
        JWT 토큰 문자열 (1시간 유효)

    Raises:
        ValueError: user_id가 빈 문자열인 경우
    """
```

### 3.3 구현 힌트 (스켈레톤!)

{Task 문서 Section 7의 구현 힌트를 Level 3 스켈레톤으로}

**핵심**: 전체 코드 아니고 40 lines 스켈레톤만!

```python
from datetime import datetime, timedelta
import jwt
from src.config import settings

def create_token(user_id: str) -> str:
    """JWT 액세스 토큰 생성."""
    # 1. Payload 구성
    payload = {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=1),
    }

    # 2. SECRET_KEY 가져오기
    secret_key = config.get_secret("JWT_SECRET_KEY")

    # 3. 토큰 생성
    token = jwt.encode(payload, secret_key, algorithm="HS256")

    # 4. 로깅
    logger.info("token_generated", user_id=user_id)

    return token
```

**Agent가 추가해야 할 것**:
- user_id validation (빈 문자열 체크)
- 에러 처리 (try-except)
- 추가 payload 필드 (iat, jti 등)

### 3.4 자주 하는 실수 (이 Task 특화)

{Task 문서 Section 8의 실수 패턴을 ❌/✅ 형식으로}

**실수 1: exp를 초 단위로 제공**
```python
❌ payload["exp"] = 3600  # 1970년 1월 1일 1시간 후로 해석됨!
✅ payload["exp"] = datetime.utcnow() + timedelta(hours=1)
```

**실수 2: SECRET_KEY 하드코딩**
```python
❌ SECRET_KEY = "my-secret-key-123"
✅ secret_key = config.get_secret("JWT_SECRET_KEY")
```

**실수 3: print() 사용**
```python
❌ print(f"Token generated for {user_id}")
✅ logger.info("token_generated", user_id=user_id)
```

**실수 4: algorithm 파라미터 누락**
```python
❌ jwt.encode(payload, secret_key)  # 알고리즘 기본값 변경될 수 있음
✅ jwt.encode(payload, secret_key, algorithm="HS256")
```

### 3.5 구현 위치

{Task 문서 Section 7의 구현 위치}

- **파일**: `src/auth/jwt.py`
- **함수**: `create_token(user_id: str) -> str`
- **테스트**: `tests/auth/test_jwt_token.py`
````

**도구**: Task 문서 Section 6, 7, 8

---

### Step 4: 정적 검증

**질문**: "코드 품질이 표준을 만족하는가?"

**산출물**:
- ruff 0 violations
- mypy 0 errors
- import-linter 0 violations

**Checklist 작성법**:

````markdown
## Step 4: 정적 검증

### 검증 명령어

```bash
# 1. Ruff 검사 (코드 스타일)
ruff check src/auth/jwt.py tests/test_jwt_token.py
# 기대: All checks passed!

# 2. MyPy 검사 (타입 안전성)
mypy src/auth/jwt.py tests/test_jwt_token.py
# 기대: Success: no issues found

# 3. Import Linter 검사 (아키텍처 규칙)
import-linter
# 기대: All contracts passed!
```

### 위반 발견 시 조치

**Ruff 위반**:

```bash
ruff check --fix src/auth/jwt.py
```

**MyPy 에러**:

- Type hints 추가 또는 수정
- `# type: ignore` 사용 금지

**Import Linter 위반**:

- 계층 위반 수정 (domain → infrastructure 금지)
````

**도구**: ruff, mypy, import-linter

---

### Step 5: 테스트 실행

**질문**: "테스트가 통과하고 커버리지가 충분한가?"

**산출물**:
- 모든 테스트 통과
- 95%+ test coverage
- pytest 리포트

**Checklist 작성법**:

````markdown
## Step 5: 테스트 실행

### 테스트 실행 명령어

```bash
# 전체 테스트 실행 + 커버리지
pytest tests/test_jwt_token.py \
    --cov=src/auth/jwt \
    --cov-report=term-missing \
    --cov-fail-under=95
```

### 기대 결과

```
tests/test_jwt_token.py::test_create_token_success PASSED
tests/test_jwt_token.py::test_create_token_expired PASSED
tests/test_jwt_token.py::test_create_token_invalid_secret PASSED

---------- coverage: platform darwin, python 3.11 ----------
Name                Stmts   Miss  Cover   Missing
-------------------------------------------------
src/auth/jwt.py        12      0   100%
-------------------------------------------------
TOTAL                  12      0   100%
```

### 커버리지 부족 시 조치

- Missing 라인 확인
- 추가 테스트 케이스 작성
- 95% 이상 달성할 때까지 반복
````

**도구**: pytest, pytest-cov

---

### Step 6: 리팩토링

**질문**: "코드를 더 명확하고 유지보수 가능하게 개선할 수 있는가?"

**산출물**:
- 개선된 코드 구조
- 중복 제거
- 명확한 변수명

**Checklist 작성법**:

````markdown
## Step 6: 리팩토링

### 리팩토링 체크리스트

**코드 구조**:
- [ ] 함수 길이 50줄 이하
- [ ] 중첩 depth 3 이하
- [ ] 하나의 함수는 하나의 책임만

**가독성**:
- [ ] 변수명이 명확한가? (`t` → `token`, `u` → `user_id`)
- [ ] 매직 넘버 제거 (3600 → `HOUR_IN_SECONDS`)
- [ ] 복잡한 조건문 함수로 추출

**중복 제거**:
- [ ] 반복되는 코드 함수로 추출
- [ ] 공통 상수 별도 정의

### 리팩토링 예시

**Before**:
```python
def create_token(user_id: str) -> str:
    p = {"user_id": user_id, "exp": datetime.utcnow() + timedelta(hours=1)}
    return jwt.encode(p, settings.jwt_secret, algorithm="HS256")
```

**After**:

```python
TOKEN_EXPIRY_HOURS = 1
JWT_ALGORITHM = "HS256"

def create_token(user_id: str) -> str:
    """JWT 액세스 토큰 생성."""
    payload = _create_payload(user_id)
    return jwt.encode(payload, settings.jwt_secret, algorithm=JWT_ALGORITHM)

def _create_payload(user_id: str) -> dict:
    """JWT payload 생성."""
    return {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=TOKEN_EXPIRY_HOURS),
    }
```
````

**도구**: ruff (자동 리팩토링), IDE refactoring tools

---

### Step 7: 재테스트

**질문**: "리팩토링 후에도 모든 테스트가 통과하는가?"

**산출물**:
- 리팩토링 후 테스트 통과 확인
- 회귀 버그 없음 검증

**Checklist 작성법**:

```markdown
## Step 7: 재테스트

### 전체 검증 재실행

```bash
# 1. 정적 검증
ruff check src/auth/jwt.py tests/test_jwt_token.py
mypy src/auth/jwt.py tests/test_jwt_token.py
import-linter

# 2. 테스트 + 커버리지
pytest tests/test_jwt_token.py \
    --cov=src/auth/jwt \
    --cov-report=term-missing \
    --cov-fail-under=95

### 최종 확인

- [ ] ruff 0 violations
- [ ] mypy 0 errors
- [ ] import-linter 0 violations
- [ ] pytest 모든 테스트 통과
- [ ] coverage 95%+ 달성

### 실패 시 조치

- Step 6 리팩토링 재검토
- 깨진 테스트 수정
- 모든 검증 통과할 때까지 Step 6-7 반복
```

**도구**: ruff, mypy, import-linter, pytest

---

### Step 8: 문서화

**질문**: "다른 개발자가 이 코드를 쉽게 사용할 수 있는가?"

**산출물**:
- Google 스타일 docstring
- 사용 예시 코드
- 필요 시 README 업데이트

**Checklist 작성법**:

````markdown
## Step 8: 문서화

### Docstring 작성 (Google 스타일)

```python
def create_token(user_id: str) -> str:
    """JWT 액세스 토큰을 생성합니다.

    Args:
        user_id: 사용자 고유 ID (UUID 또는 문자열)

    Returns:
        JWT 토큰 문자열. 1시간 후 만료됩니다.

    Raises:
        ValueError: user_id가 빈 문자열인 경우

    Example:
        >>> token = create_token("user123")
        >>> print(token)
        'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...'

        >>> # 토큰 검증
        >>> decoded = jwt.decode(token, settings.jwt_secret, algorithms=["HS256"])
        >>> print(decoded["user_id"])
        'user123'
    """
    if not user_id:
        raise ValueError("user_id cannot be empty")

    payload = _create_payload(user_id)
    return jwt.encode(payload, settings.jwt_secret, algorithm=JWT_ALGORITHM)
```

### 사용 예시 (README.md 또는 별도 파일)

## JWT 토큰 생성 사용법

### 기본 사용

```python
from src.auth.jwt import create_token

# 토큰 생성
token = create_token("user123")

# API 응답에 포함
response = {
    "access_token": token,
    "token_type": "Bearer",
    "expires_in": 3600,
}
```

### 주의사항
- 토큰은 1시간 후 자동 만료됩니다
- settings.jwt_secret은 환경변수로 설정해야 합니다
- Production에서는 반드시 HTTPS 사용
````

**도구**: Task 문서 Section 4 (입력/출력)

---

### Step 9: 커밋

**질문**: "변경사항을 Git에 안전하게 기록할 준비가 되었는가?"

**산출물**:
- Git commit with conventional commit message
- Pre-commit hooks 통과

**Checklist 작성법**:

````markdown
## Step 9: 커밋

### 커밋 전 최종 확인

```bash
# 변경된 파일 확인
git status

# 예상 결과:
# modified:   src/auth/jwt.py
# new file:   tests/test_jwt_token.py
```

### Git 커밋

```bash
# 파일 추가
git add src/auth/jwt.py tests/test_jwt_token.py

# Conventional Commit 메시지로 커밋
git commit -m "feat(auth): Add JWT token generation module

- Implement create_token() function with HS256 algorithm
- Add 3 test cases (success/expired/invalid secret)
- Achieve 100% test coverage
- Add comprehensive docstring with usage examples

Closes T2.1.1"
```

### Pre-commit Hook 검증

Pre-commit hooks가 자동 실행됩니다:

- ✅ ruff check
- ✅ mypy
- ✅ import-linter
- ✅ pytest --cov-fail-under=95

**모든 hook 통과 시**: 커밋 성공
**Hook 실패 시**: Step 4-7 재실행

### Conventional Commit 형식

- `feat`: 새 기능
- `fix`: 버그 수정
- `refactor`: 리팩토링
- `test`: 테스트 추가
- `docs`: 문서화
````

**도구**: git, pre-commit hooks

---

## 4. Checklist 템플릿

아래 템플릿을 복사해서 각 Task마다 Checklist를 작성하세요.

````markdown
# Checklist: {Task ID} - {Task 이름}

> **Task 문서**: `docs/tasks/{Task_ID}.md`
> **생성일**: YYYY-MM-DD
> **예상 소요**: {Task 문서 Section 8 참조}

---

## Step 1: 목표 이해

### Task 목표
{Task 문서 Section 4: 입력/출력}

### 성공 기준
{Task 문서 Section 6: 완성 기준}

---

## Step 2: 테스트 작성

### 테스트 케이스

**성공 케이스**:

```python
def test_{function_name}_success():
    # Given:

    # When:

    # Then:
```

**실패 케이스**:

```python
def test_{function_name}_failure():
    # Given:

    # When:

    # Then:
```

**엣지 케이스**:

```python
def test_{function_name}_edge():
    # Given:

    # When:

    # Then:
```

### 파일 생성

- `tests/test_{module}.py` 생성

---

## Step 3: 구현

### 구현 위치

{Task 문서 Section 7: 구현 힌트}

### 구현 코드

```python
{실제 구현 코드}
```

### 프로젝트 표준 준수

{Task 문서 Section 2: 프로젝트 표준 참조}

---

## Step 4: 정적 검증

### 검증 명령어

```bash
ruff check {파일 경로}
mypy {파일 경로}
import-linter
```

### 기대 결과

- [ ] ruff 0 violations
- [ ] mypy 0 errors
- [ ] import-linter 0 violations

---

## Step 5: 테스트 실행

### 테스트 실행 명령어

```bash
pytest {테스트 파일} \
    --cov={모듈 경로} \
    --cov-report=term-missing \
    --cov-fail-under=95
```

### 기대 결과

- [ ] 모든 테스트 통과
- [ ] Coverage 95%+ 달성

---

## Step 6: 리팩토링

### 리팩토링 체크리스트

- [ ] 함수 길이 50줄 이하
- [ ] 중첩 depth 3 이하
- [ ] 변수명 명확
- [ ] 매직 넘버 제거
- [ ] 중복 코드 제거

---

## Step 7: 재테스트

### 전체 검증 재실행

```bash
ruff check {파일들}
mypy {파일들}
import-linter
pytest {테스트 파일} --cov={모듈} --cov-fail-under=95
```

### 최종 확인

- [ ] ruff 0 violations
- [ ] mypy 0 errors
- [ ] import-linter 0 violations
- [ ] pytest 모든 테스트 통과
- [ ] coverage 95%+ 달성

---

## Step 8: 문서화

### Docstring (Google 스타일)

```python
def {function_name}({args}):
    """{한 줄 요약}.

    Args:
        {arg}: {설명}

    Returns:
        {반환값 설명}

    Raises:
        {예외}: {발생 조건}

    Example:
        >>> {사용 예시}
    """
```

### 사용 예시

```python
{실제 사용 예시 코드}
```

---

## Step 9: 커밋

### Git 커밋

```bash
git add {파일들}

git commit -m "feat({scope}): {요약}

- {변경사항 1}
- {변경사항 2}

Closes {Task ID}"
```

### Pre-commit Hook 검증

- [ ] ruff check 통과
- [ ] mypy 통과
- [ ] import-linter 통과
- [ ] pytest 통과

---

## 완료 확인

- [ ] 9 Steps 모두 완료
- [ ] 모든 품질 기준 만족
- [ ] Git commit 성공
````

---

## 5. 실전 예시: Task T2.1.1 → Checklist

Task 문서에서 Checklist로 변환하는 과정을 보여드립니다.

### Task 문서 (요약)

```
# Task T2.1.1: JWT 토큰 생성 모듈

## 1. 📘 청사진 참조
Blueprint Line 145-178

## 2. 📋 프로젝트 표준 참조
PROJECT_STANDARDS.md Line 12-25 (structlog)
PROJECT_STANDARDS.md Line 45-58 (Pydantic Settings)

## 3. 🔧 사용 도구
- PyJWT

## 4. 📦 입력/출력
**입력**: user_id: str
**출력**: token: str - JWT 액세스 토큰

## 5. 🔗 조립 정보
**이 블럭을 사용하는 Task**: T2.2.1, T2.2.3
**이 블럭이 사용하는 Task**: 없음

## 6. 🎯 완성 기준
- [ ] create_token(user_id) 함수 완전 작동
- [ ] pytest 테스트 3개 통과
- [ ] ruff 0, mypy 0, coverage 95%+

## 7. 💡 구현 힌트
```python
def create_token(user_id: str) -> str:
    payload = {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=1),
    }
    return jwt.encode(payload, settings.jwt_secret, algorithm="HS256")

## 8. ⏱️ 예상 작업 시간

2-3 hours
```

### Checklist (완성본)

````markdown
# Checklist: T2.1.1 - JWT 토큰 생성 모듈

> **Task 문서**: `docs/tasks/T2.1.1_JWT_Token_Generation.md`
> **생성일**: 2025-01-09
> **예상 소요**: 2-3 hours

---

## Step 1: 목표 이해

### Task 목표
- **입력**: `user_id: str` - 사용자 고유 ID
- **출력**: `token: str` - JWT 액세스 토큰 (1시간 유효)

### 성공 기준
- [ ] `create_token(user_id)` 함수 완전 작동
- [ ] pytest 테스트 3개 통과 (성공/만료/잘못된 시크릿)
- [ ] ruff 0, mypy 0, coverage 95%+

---

## Step 2: 테스트 작성

### 테스트 케이스

**성공 케이스**:
```python
def test_create_token_success():
    # Given: 유효한 사용자 ID
    user_id = "user123"

    # When: 토큰 생성
    token = create_token(user_id)

    # Then: 유효한 JWT 토큰 반환
    assert isinstance(token, str)
    decoded = jwt.decode(token, settings.jwt_secret, algorithms=["HS256"])
    assert decoded["user_id"] == user_id
    assert "exp" in decoded
```
**실패 케이스**:

```python
def test_create_token_expired():
    # Given: 만료된 토큰
    with freeze_time("2025-01-01 12:00:00"):
        token = create_token("user123")

    # When: 1시간 후 검증
    with freeze_time("2025-01-01 13:00:01"):
        # Then: ExpiredSignatureError 발생
        with pytest.raises(jwt.ExpiredSignatureError):
            jwt.decode(token, settings.jwt_secret, algorithms=["HS256"])
```

**엣지 케이스**:

```python
def test_create_token_invalid_secret():
    # Given: 유효한 토큰
    token = create_token("user123")

    # When: 잘못된 시크릿으로 검증
    # Then: InvalidSignatureError 발생
    with pytest.raises(jwt.InvalidSignatureError):
        jwt.decode(token, "wrong_secret", algorithms=["HS256"])
```

### 파일 생성

- `tests/auth/test_jwt_token.py` 생성
- 위 테스트 케이스 3개 작성

---

## Step 3: 구현

### 구현 위치

- **파일**: `src/auth/jwt.py`
- **함수**: `create_token(user_id: str) -> str`

### 구현 코드

```python
"""JWT 토큰 생성 및 검증 모듈."""
from datetime import datetime, timedelta
import jwt
from src.config import settings

# 상수 정의
TOKEN_EXPIRY_HOURS = 1
JWT_ALGORITHM = "HS256"


def create_token(user_id: str) -> str:
    """JWT 액세스 토큰을 생성합니다.

    Args:
        user_id: 사용자 고유 ID

    Returns:
        JWT 토큰 문자열 (1시간 유효)

    Raises:
        ValueError: user_id가 빈 문자열인 경우
    """
    if not user_id:
        raise ValueError("user_id cannot be empty")

    payload = _create_payload(user_id)
    return jwt.encode(payload, settings.jwt_secret, algorithm=JWT_ALGORITHM)


def _create_payload(user_id: str) -> dict:
    """JWT payload를 생성합니다.

    Args:
        user_id: 사용자 고유 ID

    Returns:
        JWT payload 딕셔너리
    """
    return {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=TOKEN_EXPIRY_HOURS),
    }
```

### 프로젝트 표준 준수

**참조**: Task 문서 Section 2

- ✅ **structlog**: 에러 발생 시 structlog 사용 (이 모듈은 에러 로깅 불필요)
- ✅ **Pydantic Settings**: `settings.jwt_secret` 사용
- ✅ **Type hints**: 100% 타입 힌트 적용

---

## Step 4: 정적 검증

### 검증 명령어

```bash
# 1. Ruff 검사
ruff check src/auth/jwt.py tests/auth/test_jwt_token.py

# 2. MyPy 검사
mypy src/auth/jwt.py tests/auth/test_jwt_token.py

# 3. Import Linter 검사
import-linter
```

### 기대 결과

- [ ] ruff 0 violations
- [ ] mypy 0 errors
- [ ] import-linter 0 violations (auth 모듈은 domain 계층 의존성 없음)

### 위반 발견 시 조치

**Ruff 위반 예시**:

```bash
# 자동 수정
ruff check --fix src/auth/jwt.py
```

**MyPy 에러 예시**:

```python
# ❌ Before
def create_token(user_id):
    return jwt.encode(...)

# ✅ After
def create_token(user_id: str) -> str:
    return jwt.encode(...)
```

---

## Step 5: 테스트 실행

### 테스트 실행 명령어

```bash
pytest tests/auth/test_jwt_token.py \
    --cov=src/auth/jwt \
    --cov-report=term-missing \
    --cov-fail-under=95 \
    -v
```

### 기대 결과

```
tests/auth/test_jwt_token.py::test_create_token_success PASSED         [ 33%]
tests/auth/test_jwt_token.py::test_create_token_expired PASSED         [ 66%]
tests/auth/test_jwt_token.py::test_create_token_invalid_secret PASSED  [100%]

---------- coverage: platform darwin, python 3.11 ----------
Name                Stmts   Miss  Cover   Missing
-------------------------------------------------
src/auth/jwt.py        15      0   100%
-------------------------------------------------
TOTAL                  15      0   100%

Required test coverage of 95% reached. Total coverage: 100.00%
```

### 체크리스트

- [ ] 모든 테스트 통과 (3/3)
- [ ] Coverage 95%+ 달성 (100%)
- [ ] Missing 라인 없음

---

## Step 6: 리팩토링

### 리팩토링 체크리스트

**코드 구조**:

- [x] 함수 길이 50줄 이하 (create_token: 10줄, _create_payload: 5줄)
- [x] 중첩 depth 3 이하 (최대 depth: 1)
- [x] 하나의 함수는 하나의 책임만

**가독성**:

- [x] 변수명이 명확한가? (payload, user_id 모두 명확)
- [x] 매직 넘버 제거 (TOKEN_EXPIRY_HOURS, JWT_ALGORITHM 상수화)
- [x] 복잡한 조건문 함수로 추출 (해당 없음)

**중복 제거**:

- [x] 반복되는 코드 함수로 추출 (_create_payload 분리)
- [x] 공통 상수 별도 정의 (모듈 최상단에 정의)

### 개선 사항

**개선 전** (Task 문서 구현 힌트):

```python
def create_token(user_id: str) -> str:
    payload = {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=1),
    }
    return jwt.encode(payload, settings.jwt_secret, algorithm="HS256")
```

**개선 후** (Step 3 구현):

- ✅ 상수 분리 (`TOKEN_EXPIRY_HOURS`, `JWT_ALGORITHM`)
- ✅ Payload 생성 함수 분리 (`_create_payload`)
- ✅ Validation 추가 (`user_id` 빈 문자열 체크)
- ✅ Docstring 추가 (Google 스타일)

---

## Step 7: 재테스트

### 전체 검증 재실행

```bash
# 1. 정적 검증
ruff check src/auth/jwt.py tests/auth/test_jwt_token.py
mypy src/auth/jwt.py tests/auth/test_jwt_token.py
import-linter

# 2. 테스트 + 커버리지
pytest tests/auth/test_jwt_token.py \
    --cov=src/auth/jwt \
    --cov-report=term-missing \
    --cov-fail-under=95
```

### 최종 확인

- [ ] ruff 0 violations ✅
- [ ] mypy 0 errors ✅
- [ ] import-linter 0 violations ✅
- [ ] pytest 모든 테스트 통과 (3/3) ✅
- [ ] coverage 100% 달성 ✅

### 회귀 테스트

리팩토링으로 인한 동작 변경 없음 확인:

- [ ] `create_token("user123")` 여전히 유효한 토큰 반환
- [ ] 만료 시간 여전히 1시간
- [ ] 알고리즘 여전히 HS256

---

## Step 8: 문서화

### Docstring (Google 스타일)

**이미 Step 3에서 작성 완료**:

```python
def create_token(user_id: str) -> str:
    """JWT 액세스 토큰을 생성합니다.

    Args:
        user_id: 사용자 고유 ID

    Returns:
        JWT 토큰 문자열 (1시간 유효)

    Raises:
        ValueError: user_id가 빈 문자열인 경우
    """
```

### 사용 예시 추가 (Docstring에 Example 섹션)

```python
def create_token(user_id: str) -> str:
    """JWT 액세스 토큰을 생성합니다.

    Args:
        user_id: 사용자 고유 ID

    Returns:
        JWT 토큰 문자열 (1시간 유효)

    Raises:
        ValueError: user_id가 빈 문자열인 경우

    Example:
        >>> from src.auth.jwt import create_token
        >>> token = create_token("user123")
        >>> print(token[:20])  # 토큰 앞부분 출력
        'eyJhbGciOiJIUzI1NiI...'

        >>> # 토큰 검증 예시
        >>> import jwt
        >>> from src.config import settings
        >>> decoded = jwt.decode(token, settings.jwt_secret, algorithms=["HS256"])
        >>> print(decoded["user_id"])
        'user123'
    """
```

### README 업데이트 (필요 시)

`docs/auth/JWT_USAGE.md` 생성:

```markdown
# JWT 토큰 사용 가이드

## 개요
이 모듈은 HS256 알고리즘을 사용하여 JWT 액세스 토큰을 생성합니다.

## 기본 사용법

### 토큰 생성
\```python
from src.auth.jwt import create_token

token = create_token("user123")
print(f"Generated token: {token}")
\```

### 토큰 검증
\```python
import jwt
from src.config import settings

try:
    decoded = jwt.decode(token, settings.jwt_secret, algorithms=["HS256"])
    user_id = decoded["user_id"]
    print(f"Valid token for user: {user_id}")
except jwt.ExpiredSignatureError:
    print("Token expired")
except jwt.InvalidSignatureError:
    print("Invalid token")
\```

## 설정

### 환경 변수
\```bash
# .env 파일
JWT_SECRET=your-secret-key-here
\```

### Settings 클래스
\```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    jwt_secret: str

settings = Settings()
\```

## 주의사항
- ⚠️ `JWT_SECRET`은 최소 32자 이상 강력한 암호를 사용하세요
- ⚠️ Production 환경에서는 반드시 HTTPS를 사용하세요
- ⚠️ 토큰은 1시간 후 자동 만료됩니다 (Refresh token 구현 권장)

## 관련 Task
- **T2.2.1**: JWT 토큰 검증 모듈
- **T2.2.3**: Login 엔드포인트 (이 모듈 사용)
```

---

## Step 9: 커밋

### 커밋 전 최종 확인

```bash
# 변경된 파일 확인
git status

# 예상 결과:
# new file:   src/auth/jwt.py
# new file:   tests/auth/test_jwt_token.py
# new file:   docs/auth/JWT_USAGE.md
```

### Git 커밋

```bash
# 파일 추가
git add src/auth/jwt.py tests/auth/test_jwt_token.py docs/auth/JWT_USAGE.md

# Conventional Commit 메시지로 커밋
git commit -m "feat(auth): Add JWT token generation module

- Implement create_token() function with HS256 algorithm
- Add TOKEN_EXPIRY_HOURS and JWT_ALGORITHM constants
- Extract _create_payload() for better testability
- Add 3 test cases: success, expired, invalid secret
- Achieve 100% test coverage
- Add comprehensive docstring with usage examples
- Create JWT usage guide documentation

Standards compliance:
- ruff 0 violations
- mypy 0 errors
- import-linter 0 violations
- pytest coverage 100%

Closes T2.1.1"
```

### Pre-commit Hook 검증

Pre-commit hooks 자동 실행:

```
[ruff] ................................................ Passed
[mypy] ................................................ Passed
[import-linter] ....................................... Passed
[pytest] .............................................. Passed
  - All tests passed (3/3)
  - Coverage: 100%
[commit-msg] .......................................... Passed
```

### 커밋 성공 확인

```bash
git log -1 --oneline
# f8a9c21 feat(auth): Add JWT token generation module

git show --stat
# 파일 변경 내역 확인
```

---

## 완료 확인

- [x] Step 1: 목표 이해 완료
- [x] Step 2: 테스트 3개 작성 완료
- [x] Step 3: 구현 완료 (create_token, _create_payload)
- [x] Step 4: 정적 검증 통과 (ruff 0, mypy 0, import-linter 0)
- [x] Step 5: 테스트 실행 통과 (100% coverage)
- [x] Step 6: 리팩토링 완료 (상수 분리, 함수 분리)
- [x] Step 7: 재테스트 통과 (모든 검증 재확인)
- [x] Step 8: 문서화 완료 (docstring + README)
- [x] Step 9: Git 커밋 성공

### 최종 산출물

✅ `src/auth/jwt.py` - JWT 토큰 생성 모듈 (100% coverage)
✅ `tests/auth/test_jwt_token.py` - 테스트 3개 (모두 통과)
✅ `docs/auth/JWT_USAGE.md` - 사용 가이드
✅ Git commit `f8a9c21` - Task T2.1.1 완료

**Task T2.1.1 완료! 다음 Task로 진행 가능.**
````

---

## 6. Checklist 작성 완료 검증

```markdown
### 완성도 체크리스트

**기본 요구사항**:

- [ ] 9-Step 모두 포함
- [ ] 각 Step마다 질문, 산출물, 도구 명시
- [ ] Task 문서와 명확히 연결 (Section 참조)

**실행 가능성**:

- [ ] AI가 이 Checklist만으로 작업 가능
- [ ] 모든 명령어가 실행 가능 (복사-붙여넣기 가능)
- [ ] 검증 기준이 명확 (✅/❌ 판단 가능)

**Task 문서 연결**:

- [ ] Section 1 (청사진) → Step 1 목표 이해
- [ ] Section 2 (표준) → Step 3, 4 준수 확인
- [ ] Section 3 (도구) → Step 2-5 사용
- [ ] Section 4 (입출력) → Step 1 목표, Step 8 문서화
- [ ] Section 5 (조립) → Step 1 이해 (의존성 파악)
- [ ] Section 6 (완성 기준) → Step 1, 7 검증
- [ ] Section 7 (구현 힌트) → Step 3 구현
- [ ] Section 8 (예상 시간) → Checklist 메타정보

**품질 검증**:

- [ ] Step 4: ruff, mypy, import-linter 명령어 정확
- [ ] Step 5: pytest coverage 명령어 정확
- [ ] Step 6-7: 리팩토링 후 재검증 포함
- [ ] Step 9: Conventional commit 형식 준수

### 흔한 실수 체크

**❌ 피해야 할 패턴**:

- Step 2에서 테스트 작성 없이 "테스트 작성 예정" 표시
- Step 3 구현이 너무 추상적 (실제 코드 없음)
- Step 4-7 검증 명령어 누락
- Step 8 docstring 없이 "문서화 완료" 표시
- Step 9 커밋 메시지가 Conventional Commit 형식 위반

**✅ 올바른 패턴**:

- 모든 Step에 실제 코드 또는 명령어 포함
- 검증 기준이 숫자로 명확 (ruff 0, coverage 95%+)
- Task 문서 내용을 직접 복사-참조
- 예시 코드가 실행 가능
```

## 7. Checklist와 Task 문서의 관계

### 정보 흐름

```markdown
Blueprint (5000 lines, 전체 설계)
    ↓
Task 문서 (100 lines, 이 작업만)
    ├─ Section 1: 청사진 참조 → "Blueprint Line 145-178만 읽어"
    ├─ Section 2: 표준 참조 → "PROJECT_STANDARDS.md Line 12-25만 읽어"
    ├─ Section 3: 도구 → "PyJWT 사용해"
    ├─ Section 4: 입출력 → "user_id 받아서 token 반환해"
    ├─ Section 5: 조립 → "T2.2.1, T2.2.3이 이걸 사용해"
    ├─ Section 6: 완성 기준 → "함수 작동 + 테스트 3개 + 0 위반"
    ├─ Section 7: 구현 힌트 → "이렇게 만들어"
    └─ Section 8: 예상 시간 → "2-3시간"
    ↓
Checklist (실행 지시서)
    ├─ Step 1: Task 문서 이해
    ├─ Step 2: 테스트 작성 (Given-When-Then)
    ├─ Step 3: 구현 (Section 7 힌트 사용)
    ├─ Step 4: 정적 검증 (ruff, mypy, import-linter)
    ├─ Step 5: 테스트 실행 (pytest coverage)
    ├─ Step 6: 리팩토링
    ├─ Step 7: 재테스트
    ├─ Step 8: 문서화
    └─ Step 9: 커밋
    ↓
완성된 코드 + 테스트 + 문서
```
### Necessary Information Only 원칙

**Blueprint (5000 lines)**:
- AI가 읽을 필요 없음 (너무 많음)
- Task 문서가 필요한 부분만 추출함

**Task 문서 (100 lines)**:
- AI가 읽어야 함
- "무엇을" 만들지 정의

**Checklist (실행 단계)**:
- AI가 따라야 함
- "어떻게" 만들지 단계별 지시

**핵심**: AI는 Blueprint를 직접 읽지 않고, Task 문서와 Checklist만으로 작업 완수 가능

---

## ⏪ 이전 Stage 검증 및 수정 프로토콜

### 검증 시점
- 각 Task Checklist 실행 전 Task 문서 검증
- 실행 중 Task 정의 문제 발견 시 즉시 중단

### 검증 대상

| Stage | 산출물 | 검증 항목 |
|-------|--------|----------|
| Stage 8 | 08T-01_*.md | Task 정의가 명확하고 완전? |
| Stage 8 | Task 상세 | 입력/출력/제약/완료 조건 명시? |
| Stage 8 | 의존성 | 선행 Task 완료 상태? |

### 오류 발견 시 프로토콜

```
Stage 9에서 Stage 8 오류 발견 시:

Step 1: Checklist 실행 중단
├─ 발견 위치: Checklist Step [N]
├─ 오류 내용: [구체적 설명]
├─ Task ID: [해당 Task]
└─ 기록: 실행 로그에 기록

Step 2: 오류 유형 판단
├─ Task 크기 문제: 너무 큼/작음 → Stage 8 분할/합치기
├─ Task 정의 불완전: 입출력 누락 → Stage 8 보완
├─ 의존성 오류: 선행 Task 미완료 → 순서 조정
├─ Blueprint 문제: 설계 자체 오류 → Stage 7로 이동!
└─ 분류 완료

Step 3: 해당 Stage로 이동 → 수정
├─ Stage 8 Task 문서 수정
├─ 또는 Stage 7 Blueprint 수정 (심각한 경우)
└─ 수정 검증

Step 4: Stage 9 재진행
├─ 수정된 Task로 Checklist 재작성
├─ Step 1부터 재실행
└─ 품질 기준 확인

Step 5: 검증 → 다음 Task ✅
```

### 흔한 오류 패턴

| 오류 유형 | 예시 | 해결 |
|----------|------|------|
| Task 과대 | Checklist 200줄 초과 | Stage 8에서 분할 |
| 입력 누락 | 참조 파일 경로 없음 | Stage 8 Task 보완 |
| 완료 조건 모호 | "적절히 구현" | Stage 8에서 구체화 |
| 의존성 미해결 | 선행 Task 미완료 | 순서 조정 후 재진행 |

### 추적성

```
수정 이력: docs/revision_log.md
Checklist 버전: v1.0 → v1.1 (수정 시 버전 업)
```

---

## 8. 추가 참고 자료

### 관련 문서
- **CORE_METHODOLOGY.md Section 3**: 9-Step Checklist 상세 설명
- **TASK_BREAKDOWN_GUIDE.md**: Task 문서 작성 방법
- **PROJECT_STANDARDS.md**: 프로젝트 표준 (structlog, Pydantic, 아키텍처 규칙)

### 도구 문서
- **pytest**: https://docs.pytest.org/
- **ruff**: https://docs.astral.sh/ruff/
- **mypy**: https://mypy.readthedocs.io/
- **import-linter**: https://import-linter.readthedocs.io/

### Conventional Commit

```
<type>(<scope>): <subject>

<body>

<footer>
```
**Type**:

- `feat`: 새 기능
- `fix`: 버그 수정
- `refactor`: 리팩토링
- `test`: 테스트 추가
- `docs`: 문서화

**Scope**: 변경된 모듈 (auth, payment, user 등)

**Footer**: `Closes T2.1.1` 형식으로 Task 참조

---

## 마무리

이 가이드를 사용하여:
1. **Task 문서 읽기** (TASK_BREAKDOWN_GUIDE 참조)
2. **Checklist 템플릿 복사** (Section 4)
3. **9-Step 순서대로 작성** (Section 3 참조)
4. **실전 예시 참고** (Section 5)
5. **검증 체크리스트 확인** (Section 6)

**핵심 원칙**:
- ✅ **실행 가능**: 모든 명령어가 복사-붙여넣기 가능
- ✅ **자급자족**: Task 문서 + Checklist만으로 완수 가능
- ✅ **검증 가능**: 0 violations, 95%+ coverage 명확히 확인

Happy coding! 🚀


================================================================================



# DNA Family Tech Matrix - 7가지 패밀리별 기술 스택 옵션
# 생성일: 2025-12-10
# 포함된 파일 수: 8

================================================================================

📄 FILE: 00_overview.md
--------------------------------------------------------------------------------

# 패밀리별 기술 매트릭스 디렉토리 안내

**작성일**: 2025-11-14 11:56  
**목적**: DNA 방법론 v4.0의 7가지 아키텍처 패밀리별 기술 선택 가이드

---

## 🎯 이 디렉토리의 역할

### DNA 방법론에서의 위치

```
Stage 1: 핵심 정의 (Core Definition)
  - 패밀리 구분 (3-Layer Decision Tree)
  ↓
🔥 여기! 패밀리별 기술 매트릭스 🔥
  ↓
Stage 2: 구현 방법 (Implementation Method)
  - Layer 3 제약사항 조사
  - NFR 우선순위 결정
  - 5단계 설계 프로세스
  ↓
Stage 3: ADR 작성 (Architecture Decision Records)
  - DNA 시스템 ADR
  - 도메인 특화 ADR
```

### 3가지 핵심 역할

#### 1. 패밀리별 필수 기술 자동 결정
- 패밀리 코드 (예: B-C-A) → 필수 DNA 시스템 도출
- 개발자가 "뭘 써야 하지?"를 고민하지 않도록
- 검증된 기술 조합 제시

#### 2. DNA 시스템 vs 도메인 기술 구분
- **DNA 시스템**: 패밀리가 강제하는 필수 요소 (공통 인프라)
- **도메인 기술**: 프로젝트 특성에 따라 선택 (서비스 로직)
- ADR 작성 범위 명확화

#### 3. 다음 단계로 자연스럽게 연결
- 기술 선택 → Stage 3 ADR 작성
- ADR → Stage 4 청사진 작성
- 체계적 의사결정 프로세스

---

## 🧬 DNA 11개 시스템

DNA 방법론의 핵심은 **11개의 표준 시스템**입니다. 모든 소프트웨어 프로젝트는 이 11개 시스템의 조합으로 구성됩니다.

### 11개 시스템 목록

| # | 시스템 이름 | 역할 | 모든 패밀리 필수? |
|---|------------|------|-----------------|
| **1** | Testing System | 테스트 전략, TDD, 품질 검증 | ✅ 필수 |
| **2** | Code Quality | 코딩 표준, Linting, 포맷팅 | ✅ 필수 |
| **3** | Architecture | 모듈 구조, 의존성 관리, 경계 강제 | ✅ 필수 |
| **4** | Type System | 타입 안전성, 정적 분석 | ✅ 필수 |
| **5** | Error Handling | 에러 처리 전략, 롤백, 복구 | ✅ 필수 |
| **6** | Configuration | 환경 설정, Feature Flags, Secrets | ✅ 필수 |
| **7** | Identity & Access | 인증, 권한, 사용자 관리 | ⚠️ 조건부 |
| **8** | Observability | 로깅, 모니터링, 추적, 메트릭 | ✅ 필수 |
| **9** | API Gateway | 요청 라우팅, Rate Limiting, 인증 | ⚠️ 조건부 |
| **10** | Resilience | 장애 허용, Circuit Breaker, Retry | ✅ 필수 |
| **11** | Performance | 벤치마크, 프로파일링, 최적화 | ✅ 필수 |

**조건부 시스템 설명**:
- **Identity & Access (#7)**: 사용자가 있는 시스템만 필요 (라이브러리/CLI는 불필요)
- **API Gateway (#9)**: 네트워크 API가 있는 시스템만 필요 (로컬 라이브러리는 불필요)

### DNA 시스템 vs 메인 서비스 기술

이 디렉토리의 각 패밀리 파일은 **두 종류의 기술**을 다룹니다:

**1. DNA 시스템 관련 기술** (모든 프로젝트 공통)
- Testing 프레임워크 (pytest, Jest)
- Code Quality 도구 (ESLint, Ruff)
- Observability 도구 (winston, structlog)
- 등등...

**2. 메인 서비스 기술** (패밀리별로 다름)
- A-A-B: RDBMS, 캐시, 메시징
- B-C-A: 스트리밍 플랫폼, 시계열 DB, 캐시
- B-B-B: Vector DB, 검색엔진, Embedding
- 등등...

---

## 📂 7개 패밀리 파일 구조

각 패밀리는 **3차원 코드**로 분류됩니다:

| 파일 | 패밀리 코드 | 패밀리 이름 | 대표 사례 |
|------|------------|------------|-----------|
| `01_ultra_high_frequency_trading_tech_options.md` | **A-A-A** | 초고속 거래 | NASDAQ (14μs), HFT |
| `02_transaction_crud_tech_options.md` | **A-A-B** | 트랜잭션/CRUD | Amazon 주문, Stripe 결제 |
| `03_collaboration_sync_tech_options.md` | **B-A-A** | 협업/동기화 | Google Docs, Figma |
| `04_search_recommendation_tech_options.md` | **B-B-B** | 검색/추천 | Elasticsearch, AI 외부메모리 |
| `05_real_time_streaming_tech_options.md` | **B-C-A** | 실시간 스트리밍 | Netflix RDG, Uber GPS |
| `06_analytics_batch_tech_options.md` | **B-A-C** | 분석/배치 | Snowflake, BigQuery |
| `07_safety_critical_iot_tech_options.md` | **A-B-A** | 안전-임계 IoT | 산업 제어, 긴급 경보 |

### 패밀리별 필요 DNA 시스템 매트릭스

| DNA 시스템 | A-A-A | A-A-B | B-A-A | B-B-B | B-C-A | B-A-C | A-B-A |
|-----------|-------|-------|-------|-------|-------|-------|-------|
| 1. Testing | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
| 2. Code Quality | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
| 3. Architecture | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
| 4. Type System | ⭐⭐⭐ | ✅ | ✅ | ✅ | ✅ | ✅ | ⭐⭐⭐ |
| 5. Error Handling | ✅ | ⭐⭐⭐ | ✅ | ✅ | ✅ | ✅ | ⭐⭐⭐ |
| 6. Configuration | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
| 7. Identity & Access | ❌ | ⭐⭐⭐ | ⭐⭐⭐ | ✅ | ✅ | ✅ | ⚠️ |
| 8. Observability | ⭐⭐⭐ | ✅ | ✅ | ✅ | ⭐⭐⭐ | ✅ | ⭐⭐⭐ |
| 9. API Gateway | ❌ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ✅ | ✅ | ⭐⭐⭐ |
| 10. Resilience | ⭐⭐⭐ | ⭐⭐⭐ | ✅ | ✅ | ⭐⭐⭐ | ✅ | ⭐⭐⭐ |
| 11. Performance | ⭐⭐⭐ | ✅ | ⭐⭐⭐ | ✅ | ⭐⭐⭐ | ✅ | ✅ |

**범례**:
- ✅ 필수 (기본 수준)
- ⭐⭐⭐ 매우 중요 (높은 우선순위, 특별한 주의 필요)
- ⚠️ 조건부 (프로젝트 특성에 따라)
- ❌ 불필요 (해당 패밀리에서 거의 사용 안 함)

**패밀리별 특징**:
- **A-A-A (초고속 거래)**: Type System, Performance, Observability 극대화
- **A-A-B (트랜잭션)**: Identity, API Gateway, Error Handling, Resilience 중요
- **B-A-A (협업)**: Identity, API Gateway, Performance (실시간 동기화)
- **B-B-B (검색)**: API Gateway (검색 API), Identity (접근 제어)
- **B-C-A (스트리밍)**: Observability, Resilience, Performance (메시지 처리량)
- **B-A-C (분석)**: 기본 DNA 시스템으로 충분
- **A-B-A (IoT)**: Type System, Error Handling, Observability, Resilience 중요

### 패밀리별 메인 서비스 기술

각 패밀리는 DNA 시스템 외에 **메인 서비스 기술**이 필요합니다:

| 패밀리 | 메인 서비스 핵심 기술 | 이유 |
|-------|-------------------|------|
| **A-A-A** | FPGA, 코로케이션, RDMA 네트워킹 | 마이크로초급 레이턴시 필수 |
| **A-A-B** | RDBMS, 캐시, 메시징 | ACID 트랜잭션 + 성능 + 비동기 |
| **B-A-A** | CRDT/OT 엔진, WebSocket, 동기화 DB | 실시간 협업 + 충돌 해결 |
| **B-B-B** | Vector DB, Embedding 모델, 검색엔진 | 유사도 검색 + 랭킹 |
| **B-C-A** | 스트리밍 플랫폼, 시계열 DB, 캐시 | 대용량 이벤트 처리 |
| **B-A-C** | 데이터 웨어하우스, ETL, BI 도구 | 대규모 배치 분석 |
| **A-B-A** | MQTT, SCADA, 센서 융합 | IoT 프로토콜 + 실시간 제어 |

---

### 3차원 코드 의미

**첫 번째 글자 (실패의 파급력)**:
- **A** (Critical): 치명적 - 실패 시 생명/재산/시장 손실
- **B** (Graceful): 점진적 - 실패 시 성능 저하, 계속 작동 가능

**두 번째 글자 (데이터의 형태)**:
- **A** (Structured): 구조화 - 고정 스키마, 명확한 관계
- **B** (Semi-Structured): 반구조화 - 유연한 스키마, JSON/XML
- **C** (Unstructured): 비구조화 - 스키마 없음, 이벤트/로그

**세 번째 글자 (응답 시점)**:
- **A** (Real-time): 밀리초 - 즉각 응답 (< 100ms)
- **B** (Interactive): 수초 - 사람이 기다릴 수 있는 속도 (1~10초)
- **C** (Batch): 배치 - 스케줄 기반 (시간/일 단위)

---

## 📖 각 파일의 구조 (4-Part)

모든 패밀리 파일은 동일한 구조를 따릅니다:

### Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐
- 각 차원(A/B/C)이 강제하는 기술적 요구사항
- 검증 사례 (Netflix, Google, Uber 등)
- **이 패밀리에 필요한 DNA 시스템** (11개 중 선택)
- **메인 서비스 필수 기술** (2~5개)

### Part 2: 메인 서비스 기술 선택 ⭐⭐⭐
- 각 메인 서비스 기술마다 **3가지 옵션** 제시:
  - 옵션 1: 고성능/고비용
  - 옵션 2: 균형 (중간)
  - 옵션 3: 저비용/경량
- 구체적 스펙, 비용, 장단점, 적합 사례
- 비교표 + 의사결정 플로우차트

### Part 2.5: DNA 시스템 기술 선택 (새로 추가) 🆕
- **이 패밀리에 특별히 중요한 DNA 시스템**에 대한 기술 옵션
- 예: A-A-A는 Performance 시스템이 매우 중요 → 벤치마크 도구 3가지 비교
- 예: A-A-B는 Identity 시스템이 중요 → 인증 솔루션 3가지 비교
- 모든 DNA 시스템을 다루지 않고, **⭐⭐⭐ 표시된 것만** 다룸

### Part 3: 도메인 선택 요소
- 패밀리와 무관하게 프로젝트별로 선택하는 기술
- 프론트엔드, 백엔드 언어, 인증 등
- 간결하게 (20~50줄)

### Part 4: Stage 2 통합
- Layer 3 제약사항 반영 예시
- NFR 충돌 해결 예시
- ADR 작성 준비 (DNA 시스템 vs 도메인 구분)

---

## 🚀 사용 방법

### Step 1: 패밀리 코드 확정
Stage 1에서 3-Layer Decision Tree로 패밀리 코드를 확정합니다.

**예시**:
```
Q1: 실패하면? → B (점진적, 일부 손실 허용)
Q2: 데이터 형태? → C (비구조화, 이벤트 스트림)
Q3: 응답 시점? → A (밀리초, 실시간)

→ 패밀리 코드: B-C-A (실시간 스트리밍)
```

### Step 2: 해당 패밀리 파일 열기
`05_real_time_streaming_tech_options.md` 파일을 엽니다.

### Step 3: Part 1 확인 - 필요한 시스템 파악
패밀리가 요구하는 두 종류의 시스템을 확인합니다.

**1. DNA 시스템** (11개 중 필요한 것):
```
✅ 필수: Testing, Code Quality, Architecture, Error Handling, Configuration, Observability, Resilience, Performance
⭐⭐⭐ 특별 중요: Performance (마이크로초 최적화), Type System (안전성)
❌ 불필요: Identity, API Gateway (네트워크 서비스 아님)
```

**2. 메인 서비스 기술** (패밀리 특화):
```
- FPGA/ASIC 하드웨어
- RDMA 네트워킹
- 커널 바이패스 스택
```

### Step 4: Part 2 확인 - 메인 서비스 기술 선택
각 메인 서비스 기술마다 3가지 옵션을 비교하고 선택합니다.

**FPGA 하드웨어 예시**:
- 옵션 1: Custom FPGA (초고성능, 매우 비쌈)
- 옵션 2: 상용 FPGA 카드 (고성능, 비쌈)
- 옵션 3: Software 최적화 (저렴, 마이크로초급 어려움)

비교표와 플로우차트를 참고하여 의사결정합니다.

### Step 4.5: Part 2.5 확인 - 중요 DNA 시스템 기술 선택 🆕
이 패밀리에서 **⭐⭐⭐ 표시된 DNA 시스템**의 기술을 선택합니다.

**Performance System 예시** (A-A-A에서 ⭐⭐⭐):
- 옵션 1: VTune (Intel, 전문가용)
- 옵션 2: perf (Linux 기본)
- 옵션 3: Custom Profiler

**Type System 예시** (A-A-A에서 ⭐⭐⭐):
- 옵션 1: Rust (소유권 시스템)
- 옵션 2: C++ (템플릿)
- 옵션 3: C (수동 관리)

### Step 5: Part 3 확인 - 도메인 기술 선택
프로젝트 특성에 따라 도메인 기술을 선택합니다.

**예시**:
- 백엔드: Node.js vs Python vs Go
- 프론트엔드: React vs Vue
- 인증: Auth0 vs Cognito

### Step 6: Part 4 활용 - Stage 2로 연결
- Layer 3 제약사항 반영 방법 참고
- NFR 충돌 해결 패턴 참고
- **DNA 시스템 ADR 목록 준비** (ADR-001 ~ ADR-011)
- **메인 서비스 ADR 목록 준비** (ADR-101 ~ ADR-1XX)
- **도메인 ADR 목록 준비** (ADR-201 ~ ADR-2XX)

---

## 🎓 핵심 원칙

### 1. 패밀리가 시스템 구조를 결정합니다
- 개발자의 "취향"이 아닌 **시스템 특성**이 필요한 시스템을 강제
- B-C-A 패밀리는 **무조건** 스트리밍 플랫폼 필요
- A-A-B 패밀리는 **무조건** ACID DB 필요
- A-A-A 패밀리는 **무조건** Performance 시스템 극대화 필요

### 2. 3가지 기술 계층 구분이 중요합니다
- **DNA 시스템**: 11개 표준 시스템, 모든 프로젝트 공통 기반 (ADR-001~011)
- **메인 서비스**: 패밀리가 강제하는 핵심 기술 (ADR-101~1XX)
- **도메인 기술**: 프로젝트 특화, 팀 역량/선호도 반영 (ADR-201~2XX)
- 구분하지 않으면 ADR이 뒤죽박죽!

### 3. DNA 시스템은 우선순위가 있습니다
- **✅ 필수**: 모든 패밀리에 기본 수준 필요
- **⭐⭐⭐ 특별 중요**: 해당 패밀리에서 높은 우선순위
- **⚠️ 조건부**: 프로젝트 특성에 따라
- **❌ 불필요**: 해당 패밀리에서 거의 사용 안 함

### 4. 실증 데이터 기반입니다
- 모든 기술 옵션은 **실제 프로덕션 사례** 검증
- 구체적 수치 (처리량, 레이턴시, 비용) 제시
- "빠름" ✗ → "p99 <10ms" ✓

### 4. 의사결정을 지원합니다
- 3가지 옵션 비교 (고/중/저)
- 비교표 + 플로우차트 제공
- "무엇을 선택할지" 명확히 안내

---

## ⚠️ 주의사항

### ❌ 이 파일들은 구현 가이드가 아닙니다
- 코드 예시 없음 (단 한 줄도!)
- 패턴 설명 최소화
- 도구 나열 최소화
- **목적**: 기술 **선택** 지원

### ✅ 구현은 공식 문서를 참고하세요
- PostgreSQL 설정 → PostgreSQL 공식 문서
- Kafka 튜닝 → Kafka 공식 문서
- Redis 패턴 → Redis 공식 문서

### 📝 Context7 MCP 활용
- 모든 기술 정보는 Context7에서 확보
- 출처 확인된 공식 문서만 사용
- 토큰 효율 6~10배 (WebSearch 대비)

---

## 🔗 다음 단계

### 패밀리 선택 완료 후
1. **Stage 2**: 구현 방법 설계
   - Layer 3 제약사항 조사
   - NFR 우선순위 결정
   - 5단계 설계 프로세스

2. **Stage 3**: ADR 작성
   - DNA 시스템 ADR (예: ADR-001 ~ ADR-011)
   - 도메인 특화 ADR (예: ADR-101 ~ ADR-1XX)

3. **Stage 4**: 청사진 작성
   - DNA 시스템 청사진 (common/ 폴더)
   - 도메인 청사진 (services/ 폴더)

4. **Stage 5~9**: 분해 → 체크리스트 → 구현

---

## 📊 완성도 검증

### 7개 패밀리 이론적 완전성
- 3×3×3 = 27가지 이론 조합 중
- ✅ **16개 조합** 프로덕션 검증
- ⭐ **7개 핵심 패밀리** 선정
- 실무 커버리지: **95%+**

### 검증 근거
- **SEI Quality Attributes Framework** 매핑
- **Martin Fowler Patterns** 조합
- **CAP/ACID/BASE Theorem** 반영
- Netflix, Google, Uber, Amazon 등 실증

---

## 💡 자주 묻는 질문

### Q1: 우리 시스템이 여러 패밀리에 걸쳐 있다면?
**A**: 하이브리드 시스템입니다. 각 하위 시스템별로 패밀리를 구분하세요.

**예시 - Netflix**:
- 스트리밍: B-C-A (실시간 스트리밍)
- 결제: A-A-B (트랜잭션/CRUD)
- 추천: B-B-B (검색/추천)

### Q2: 패밀리 코드가 애매하다면?
**A**: 가장 중요한 특성(코어 기능)을 기준으로 선택하세요.

**예시 - 주문 시스템**:
- 코어: 주문 트랜잭션 → A-A-B
- 부가: 실시간 알림 → B-C-A (별도 모듈)

### Q3: DNA 시스템, 메인 서비스, 도메인 기술 구분이 애매하다면?
**A**: 두 가지 기준으로 판단하세요.

**기준 1: 패밀리 변경 시 함께 바뀌는가?**
- **DNA 시스템**: 패밀리 무관, 모든 프로젝트 공통 (Testing, Observability 등)
- **메인 서비스**: A-A-B → B-C-A 변경 시 RDBMS → Kafka로 변경 필수
- **도메인 기술**: 패밀리 변경과 무관 (React → Vue 선택은 패밀리와 무관)

**기준 2: 11개 표준 시스템에 해당하는가?**
- **DNA 시스템**: Testing, Code Quality, Architecture, Type System, Error Handling, Configuration, Identity & Access, Observability, API Gateway, Resilience, Performance
- **메인 서비스**: 위 11개에 해당 안 함 (RDBMS, Kafka, Redis, CRDT 등)
- **도메인 기술**: 위 11개에 해당 안 함 (React, FastAPI, Auth0 등)

**예시**:
- PostgreSQL → 메인 서비스 (A-A-B 패밀리 강제)
- pytest → DNA 시스템 #1 (Testing)
- FastAPI → 도메인 기술 (프로젝트 선택)

### Q4: DNA 시스템 중 ⭐⭐⭐가 많은데 모두 다뤄야 하나요?
**A**: 아니요, Part 2.5에서는 **가장 중요한 1~3개만** 다룹니다.

**예시 - A-A-A**:
- ⭐⭐⭐ 4개: Type System, Observability, Resilience, Performance
- Part 2.5에서 다룰 것: Performance (가장 특수함), Type System (안전성 극대화)
- 나머지는 일반 DNA 시스템 가이드 참고

---

**이 디렉토리는 DNA 방법론의 핵심 연결고리입니다!**

패밀리 선택 → 기술 매트릭스 참고 → ADR 작성 → 청사진 작성 → 구현

체계적이고 검증된 기술 선택으로 프로젝트 성공률을 높이세요! 💪


================================================================================

📄 FILE: 01_ultra_high_frequency_trading_tech_options.md
--------------------------------------------------------------------------------

# 초고속 거래 패밀리 (A-A-A) - 기술 매트릭스

**작성일**: 2025-11-12  
**패밀리**: 초고속 거래 (A-A-A)  
**검증 사례**: NASDAQ X-Stream (37μs), HFT FPGA (480ns), CME Globex

---

## Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐

### 1.1 A-A-A 특성이 강제하는 것

#### A (치명적 실패) → ACID 트랜잭션 필수

**특성**:
- 단일 거래 오류가 시장 붕괴 유발
- 2010 플래시 크래시: 20분에 1조 달러 손실
- 마이크로초당 수백만 달러 손실 가능
- 롤백 불가능, 실패 방지가 핵심

**강제되는 기술적 요구**:
```
✅ ACID 트랜잭션 보장
✅ 결정론적 성능 (일관된 레이턴시)
✅ 동기식 복제
✅ 원자적 연산 (All-or-Nothing)
```

**검증 사례**:
- NASDAQ: 단일 주문 오류가 전체 시장 중단 유발
- Knight Capital (2012): 45분에 $440M 손실 (버그로 인한 잘못된 주문)

---

#### A (구조화 데이터) → 고정 스키마 필수

**특성**:
- 주문, 체결, 가격 - 엄격한 포맷
- 밀리초 내 검증 필수
- 규제 준수 (MiFID II, Reg NMS)
- 감사 추적 (Audit Trail)

**강제되는 기술적 요구**:
```
✅ 고정 스키마 (Fixed Schema)
✅ 컴파일 타임 타입 체크
✅ 빠른 직렬화 (Protobuf, FIX Protocol)
✅ 인덱싱 최적화
```

**검증 사례**:
- FIX Protocol: 금융 업계 표준 메시지 포맷
- NASDAQ ITCH: 바이너리 프로토콜, 고정 길이 메시지

---

#### A (마이크로초~밀리초) → 극단적 저지연 필수

**특성**:
- NASDAQ: 14-37μs 평균
- HFT FPGA: 480ns-2.6μs
- NYSE: 650μs 미만
- 마이크로초 단위 경쟁

**강제되는 기술적 요구**:
```
✅ 인메모리 연산
✅ 코로케이션 (Co-location)
✅ 커널 바이패스 네트워킹
✅ FPGA/하드웨어 가속
✅ NUMA 최적화
```

**검증 사례**:
- Citadel, Jump Trading: FPGA 기반 480ns 달성 (IEEE 검증)
- SIX Swiss Exchange: 37μs 평균 레이턴시

---

### 1.2 이 패밀리에 필요한 DNA 시스템 및 메인 서비스

#### DNA 11개 시스템 중 필요한 것

A-A-A 패밀리는 다음 DNA 시스템이 필요합니다:

| DNA 시스템 | 중요도 | 이유 |
|-----------|-------|------|
| 1. Testing | ✅ 필수 | 레이턴시 회귀 방지 |
| 2. Code Quality | ✅ 필수 | 결정론적 코드 품질 |
| 3. Architecture | ✅ 필수 | 저지연 모듈 분리 |
| 4. **Type System** | **⭐⭐⭐ 매우 중요** | **Zero-cost abstraction, 컴파일 타임 검증** |
| 5. Error Handling | ✅ 필수 | 패닉 없는 에러 처리 |
| 6. Configuration | ✅ 필수 | 런타임 설정 변경 최소화 |
| 7. Identity & Access | ✅ 필수 | 거래 인증/인가 |
| 8. **Observability** | **⭐⭐⭐ 매우 중요** | **마이크로초급 프로파일링, 핫스팟 추적** |
| 9. API Gateway | ⚠️ 조건부 | 외부 연동 시 필요 |
| 10. Resilience | ✅ 필수 | 장애 복구, Circuit Breaker |
| 11. **Performance** | **⭐⭐⭐ 매우 중요** | **레이턴시 벤치마크, 회귀 방지** |

**특별히 중요한 DNA 시스템 (⭐⭐⭐)**:
- **Type System**: Rust/C++ zero-cost abstraction, GC 없는 메모리 관리 필수
- **Observability**: 마이크로초급 추적, 하드웨어 카운터, CPU 캐시 미스 분석
- **Performance**: 나노초급 벤치마크, 레이턴시 회귀 CI/CD 통합

→ **Part 2.5에서 이 3가지 DNA 시스템의 기술 옵션을 다룹니다.**

#### 메인 서비스 필수 요소 (패밀리 강제)

A-A-A 패밀리는 다음 3가지 시스템 요소를 **반드시** 포함해야 합니다:

#### 1. 인메모리 DB (ACID 지원) (필수!)
**역할**: 거래 상태 저장, ACID 보장
**이유**: 치명적 실패(A) + 마이크로초(A)
**선택지**: VoltDB, Redis Enterprise (ACID), Aerospike

#### 2. 저지연 메시징 (필수!)
**역할**: 주문, 체결, 시장 데이터 전송
**이유**: 구조화(A) + 마이크로초(A)
**선택지**: Aeron, Chronicle Queue, 직접 구현

#### 3. 하드웨어 가속 (선택적이지만 나노초 경쟁 시 필수)
**역할**: 극한의 레이턴시 달성 (나노초~마이크로초)
**이유**: 마이크로초(A) - 경쟁 우위 확보
**선택지**: FPGA, Kernel Bypass (DPDK), RDMA
**참고**: 마이크로초 이하 목표 시 필수, 수 마이크로초 허용 시 선택적

---

## Part 2: 메인 서비스 기술 선택 ⭐⭐⭐

### 2.1 인메모리 DB (ACID) 선택

**패밀리 요구**:
- 마이크로초~밀리초 레이턴시
- ACID 트랜잭션 보장
- 고정 스키마, 빠른 쿼리
- 결정론적 성능

---

#### 옵션 1: VoltDB

**핵심 스펙**:
- **쓰기 처리량**: 초당 100만+ 트랜잭션
- **레이턴시**: 평균 <10ms, p99 <20ms
- **ACID**: 완전한 ACID 지원
- **확장**: 수평 확장 (파티셔닝)

**비용**:
- **Community**: 무료 (제한적)
- **Enterprise**: 월 $5,000~$20,000+ (노드당)

**장점**:
- ⚡ 초고속 인메모리 ACID
- 🔧 SQL 지원 (표준 쿼리)
- 📈 선형 확장 (노드 추가)
- 💪 결정론적 성능

**단점**:
- 💰 높은 라이선스 비용
- 🧑‍💻 전문 지식 필요
- 📊 메모리 제한 (모든 데이터 RAM)
- 🔧 복잡한 튜닝

**적합한 경우**:
- 거래소 수준 (NASDAQ, CME)
- 초당 100만+ 트랜잭션
- ACID 필수
- 예산 $100K+ /year

**검증 사례**: 금융 거래소, 리스크 관리 시스템

---

#### 옵션 2: Redis Enterprise (ACID 모듈)

**핵심 스펙**:
- **레이턴시**: 마이크로초급 (150μs GET)
- **처리량**: 초당 120만 트랜잭션
- **ACID**: RediSearch + RedisJSON (부분적)
- **지속성**: AOF, RDB 스냅샷

**비용**:
- **Redis Stack**: 무료 (제한적)
- **Redis Enterprise**: 월 $3,000~$15,000
- **클라우드**: $0.063~$0.126/hour per GB

**장점**:
- ⚡ 극한의 속도 (마이크로초)
- 🔧 간단한 운영
- 💵 VoltDB 대비 저렴
- 🌐 클라우드 네이티브

**단점**:
- 📊 제한적 ACID (단일 키)
- 💾 메모리 기반 (비쌈)
- 🔧 SQL 미지원 (스크립트 필요)
- ⚠️ 복잡한 트랜잭션 어려움

**적합한 경우**:
- 소규모 HFT 펌
- 단순한 거래 로직
- 마이크로초 필수
- 예산 $50K~$200K /year

**검증 사례**: 중소 HFT, 가격 피드 캐싱

---

#### 옵션 3: Aerospike (Enterprise)

**핵심 스펙**:
- **쓰기 처리량**: 초당 100만+ 쓰기
- **레이턴시**: 밀리초 미만 (SSD)
- **ACID**: Strong Consistency 옵션
- **하이브리드**: RAM + SSD

**비용**:
- **Community**: 무료 (단일 노드)
- **Enterprise**: 월 $5,000~$15,000 (노드당)

**장점**:
- 🚀 초고속 쓰기
- 💰 하이브리드 스토리지 (저렴)
- 📈 페타바이트 확장
- 💪 강한 일관성

**단점**:
- 🔧 SQL 미지원
- 📊 복잡한 트랜잭션 제한
- 🧑‍💻 운영 복잡도
- 💰 Enterprise 고가

**적합한 경우**:
- 대량 데이터 (TB~PB)
- 밀리초급 허용 (마이크로초 불필요)
- 비용 효율성
- 장기 데이터 보관

**검증 사례**: 광고 기술, 사기 탐지, 일부 HFT

---

#### 인메모리 DB 비교표

| 항목 | VoltDB | Redis Enterprise | Aerospike |
|------|--------|------------------|-----------|
| **레이턴시** | <10ms | 150μs | <1ms |
| **ACID** | 완전 지원 | 제한적 | Strong Consistency |
| **SQL** | ✅ | ❌ | ❌ |
| **확장성** | 노드 추가 | 샤딩 | 페타바이트 |
| **비용** | $5K~$20K/월 | $3K~$15K/월 | $5K~$15K/월 |

**의사결정 가이드**:
```
완전한 ACID + SQL 필수? → VoltDB
  └─ NO
     ↓
마이크로초 필수? → Redis Enterprise
  └─ NO
     ↓
대량 데이터 (TB+)? → Aerospike
  └─ NO → Redis Enterprise
```

---

### 2.2 저지연 메시징 선택

**패밀리 요구**:
- 마이크로초~밀리초 레이턴시
- 결정론적 성능
- 순서 보장
- 높은 처리량

---

#### 옵션 1: Aeron (Real Logic)

**핵심 스펙**:
- **레이턴시**: 수십 마이크로초 (LAN)
- **처리량**: 초당 수백만 메시지
- **전송**: UDP 유니캐스트/멀티캐스트, IPC
- **언어**: Java, C, C++

**비용**:
- **오픈소스**: 무료 (Apache 2.0)
- **지원**: $10,000~$50,000/year (Real Logic)

**장점**:
- ⚡ 극한의 저지연 (마이크로초)
- 🔧 오픈소스, 무료
- 💪 결정론적 성능
- 🌐 멀티캐스트 지원

**단점**:
- 🧑‍💻 높은 학습 곡선
- 🔧 직접 운영 필요
- 📚 제한적 생태계
- ⚠️ UDP 기반 (네트워크 의존)

**적합한 경우**:
- HFT, 거래소
- 마이크로초 필수
- 멀티캐스트 시장 데이터
- 전담 DevOps 팀

**검증 사례**: 대형 HFT 펌, 거래소 인프라

---

#### 옵션 2: Chronicle Queue

**핵심 스펙**:
- **레이턴시**: 마이크로초급
- **처리량**: 초당 수백만 메시지
- **지속성**: 메모리 매핑 파일
- **언어**: Java, C++

**비용**:
- **오픈소스**: 무료 (제한적)
- **Enterprise**: $20,000~$100,000/year

**장점**:
- ⚡ 초저지연 (마이크로초)
- 💾 지속성 (MMF 기반)
- 🔧 Java 친화적
- 📚 풍부한 문서

**단점**:
- 💰 Enterprise 고가
- 🔧 단일 머신 제한
- 📊 네트워크 전송 별도 구현
- 🧑‍💻 전문 지식 필요

**적합한 경우**:
- 단일 서버 HFT
- Java 기반 시스템
- 이벤트 소싱 필요
- 예산 $50K~$200K /year

**검증 사례**: 금융 기관, HFT 펌

---

#### 옵션 3: 직접 구현 (Kernel Bypass + Shared Memory)

**핵심 스펙**:
- **레이턴시**: 수백 나노초 (가능)
- **처리량**: 하드웨어 한계
- **기술**: DPDK, RDMA, Shared Memory
- **언어**: C, C++, Rust

**비용**:
- **개발 비용**: $200,000~$1M (6~12개월)
- **운영**: 전담 팀 필요

**장점**:
- ⚡ 최저 레이턴시 (나노초 가능)
- 🔧 완전한 제어
- 🏆 경쟁 우위
- 💪 맞춤형 최적화

**단점**:
- 💰 막대한 개발 비용
- 🧑‍💻 최고 수준 전문가 필수
- ⏱️ 긴 개발 기간 (6~12개월)
- 🔧 유지보수 부담

**적합한 경우**:
- 최상위 HFT 펌 (Citadel, Jump)
- 나노초 경쟁
- 예산 $1M+ /year
- 전담 인프라 팀

**검증 사례**: Citadel, Jump Trading, Virtu Financial

---

#### 저지연 메시징 비교표

| 항목 | Aeron | Chronicle Queue | 직접 구현 |
|------|-------|-----------------|-----------|
| **레이턴시** | 수십 μs | 수 μs | 수백 ns |
| **처리량** | 수백만 msg/s | 수백만 msg/s | 하드웨어 한계 |
| **지속성** | 선택적 | ✅ | 맞춤형 |
| **비용** | 무료 | $20K~$100K/년 | $200K~$1M 개발 |
| **운영** | ⚙️⚙️ 중간 | ⚙️⚙️⚙️ 높음 | ⚙️⚙️⚙️ 매우 높음 |

**의사결정 가이드**:
```
나노초 필수? → 직접 구현
  └─ NO
     ↓
예산 < $50K/년? → Aeron
  └─ NO
     ↓
Java 기반 + 지속성? → Chronicle Queue
  └─ NO → Aeron
```

---

### 2.3 하드웨어 가속 선택 (선택적)

**패밀리 요구**:
- 나노초~마이크로초 레이턴시
- 결정론적 성능
- 경쟁 우위

---

#### 옵션 1: FPGA (Field-Programmable Gate Array)

**핵심 스펙**:
- **레이턴시**: 480ns~2.6μs (검증)
- **처리량**: 수백만 msg/s
- **전력**: 25~75W
- **개발**: Verilog, VHDL, HLS

**비용**:
- **FPGA 보드**: $5,000~$50,000
- **개발 비용**: $500,000~$2M (12~18개월)
- **코로케이션**: $10,000~$50,000/월

**장점**:
- ⚡ 최저 레이턴시 (나노초)
- 💪 병렬 처리
- 🔧 재프로그래밍 가능
- 🏆 경쟁 우위

**단점**:
- 💰 막대한 비용
- 🧑‍💻 희귀한 전문가 필요
- ⏱️ 긴 개발 주기
- 🔧 디버깅 어려움

**적합한 경우**:
- 최상위 HFT 펌
- 나노초 경쟁
- 예산 $5M+ /year
- 전담 FPGA 팀

**검증 사례**: Citadel (480ns), Jump Trading, HFT 펌

---

#### 옵션 2: Kernel Bypass (DPDK, Solarflare)

**핵심 스펙**:
- **레이턴시**: 수 마이크로초
- **처리량**: 초당 수백만 패킷
- **기술**: DPDK, Solarflare OpenOnload
- **언어**: C, C++

**비용**:
- **오픈소스**: 무료 (DPDK)
- **Solarflare NIC**: $1,000~$5,000
- **개발 비용**: $100,000~$500,000 (3~6개월)

**장점**:
- ⚡ 저지연 (마이크로초)
- 💰 FPGA 대비 저렴
- 🔧 소프트웨어 개발
- 📚 커뮤니티 지원

**단점**:
- 🧑‍💻 전문 지식 필요
- 🔧 하드웨어 의존성
- 📊 FPGA 대비 느림
- ⚠️ 유지보수 복잡

**적합한 경우**:
- 중상위 HFT 펌
- 마이크로초 목표
- 예산 $500K~$2M /year
- 소프트웨어 팀

**검증 사례**: 중형 HFT 펌, 자영업 트레이더

---

#### 옵션 3: RDMA (Remote Direct Memory Access)

**핵심 스펙**:
- **레이턴시**: 1~5 마이크로초
- **처리량**: 100 Gbps+
- **기술**: InfiniBand, RoCE
- **언어**: C, C++

**비용**:
- **RDMA NIC**: $500~$2,000
- **InfiniBand 스위치**: $10,000~$50,000
- **개발 비용**: $50,000~$200,000

**장점**:
- ⚡ 저지연 (마이크로초)
- 🚀 높은 대역폭 (100 Gbps)
- 💰 합리적 비용
- 📈 클러스터 확장

**단점**:
- 🔧 특수 네트워크 장비 필요
- 🧑‍💻 RDMA 전문 지식
- 📊 FPGA 대비 느림
- 🌐 데이터센터 제약

**적합한 경우**:
- 클러스터 간 통신
- 고대역폭 + 저지연
- 예산 $200K~$1M /year
- 온프레미스 데이터센터

**검증 사례**: 거래소 백엔드, 리스크 시스템

---

#### 하드웨어 가속 비교표

| 항목 | FPGA | Kernel Bypass | RDMA |
|------|------|---------------|------|
| **레이턴시** | 480ns~2.6μs | 수 μs | 1~5μs |
| **개발 비용** | $500K~$2M | $100K~$500K | $50K~$200K |
| **전문성** | 매우 희귀 | 희귀 | 중간 |
| **확장성** | 제한적 | 중간 | 높음 |
| **적합** | 나노초 경쟁 | 마이크로초 목표 | 클러스터 |

**의사결정 가이드**:
```
나노초 필수 + 예산 $5M+? → FPGA
  └─ NO
     ↓
마이크로초 + 단일 서버? → Kernel Bypass
  └─ NO
     ↓
클러스터 간 통신? → RDMA
  └─ NO → Kernel Bypass
```

---

## Part 2.5: 핵심 DNA 시스템 기술 선택 ⭐⭐⭐

이 패밀리에서 특별히 중요한 DNA 시스템(⭐⭐⭐)에 대한 기술 선택입니다.

### 2.5.1 Type System (DNA #4) - Zero-Cost Abstraction ⭐⭐⭐

**패밀리 요구**:
- GC 없는 결정론적 메모리 관리
- Zero-cost abstraction (런타임 오버헤드 0)
- 컴파일 타임 최적화 최대화
- 인라인 강제, 가상 함수 제거
- 캐시 지역성 최적화

---

#### 옵션 1: Rust

**핵심 스펙**:
- **메모리 관리**: Ownership + Borrow Checker (GC 없음)
- **최적화**: LLVM 백엔드, 인라인 강제
- **안전성**: 컴파일 타임 메모리 안전성
- **성능**: C/C++ 동등 (Zero-cost abstraction)

**비용**: 오픈소스 (무료)

**장점**:
- 🔧 메모리 안전성 + 성능 동시 달성
- 🔧 No GC pause (결정론적)
- 🔧 LLVM 최적화 (auto-vectorization)
- 🔧 현대적 타입 시스템 (ADT, 패턴 매칭)

**단점**:
- ⚠️ 학습 곡선 (Borrow Checker)
- ⚠️ 기존 C++ 라이브러리 FFI 필요
- ⚠️ 금융 업계 도입 초기 단계
- ⚠️ 일부 최적화 패턴 표현 어려움

**적합한 경우**:
- 신규 시스템 개발
- 메모리 안전성 + 성능 동시 필요
- 현대적 도구체인 선호
- 팀 Rust 학습 의지 있음

**검증 사례**: Cloudflare, Discord, AWS Firecracker

---

#### 옵션 2: C++ (Modern C++17/20)

**핵심 스펙**:
- **메모리 관리**: RAII, unique_ptr, 수동 최적화
- **최적화**: 템플릿 메타프로그래밍, constexpr
- **컴파일러**: GCC, Clang, MSVC (고도 최적화)
- **성능**: 최고 수준 (수십 년 최적화)

**비용**: 오픈소스 (무료)

**장점**:
- 🔧 금융 업계 표준 (수십 년)
- 🔧 방대한 라이브러리 생태계
- 🔧 템플릿 메타프로그래밍 (컴파일 타임 계산)
- 🔧 숙련된 개발자 풀

**단점**:
- ⚠️ 메모리 안전성 보장 없음
- ⚠️ 복잡한 언어 (UB, 암묵적 변환)
- ⚠️ 빌드 시간 (템플릿 과다 시)
- ⚠️ ABI 호환성 이슈

**적합한 경우**:
- 기존 C++ 코드베이스
- 팀 C++ 전문성
- 금융 업계 검증된 패턴 필요
- 레거시 라이브러리 활용

**검증 사례**: NASDAQ, CME, Goldman Sachs, Bloomberg

---

#### 옵션 3: C (ANSI C11)

**핵심 스펙**:
- **메모리 관리**: 완전 수동 (malloc/free)
- **최적화**: 어셈블리 수준 제어
- **오버헤드**: 최소 (런타임 거의 없음)
- **이식성**: 모든 플랫폼

**비용**: 오픈소스 (무료)

**장점**:
- 🔧 최소 오버헤드 (런타임 없음)
- 🔧 어셈블리 수준 제어
- 🔧 FPGA 드라이버 직접 작성
- 🔧 모든 플랫폼 지원

**단점**:
- ⚠️ 안전성 전무 (수동 관리)
- ⚠️ 추상화 부족 (보일러플레이트)
- ⚠️ 버그 발생 확률 높음
- ⚠️ 개발 속도 느림

**적합한 경우**:
- FPGA 드라이버 개발
- 어셈블리 수준 제어 필수
- 극한의 최소 오버헤드
- 임베디드 시스템

**검증 사례**: Linux 커널, DPDK, FPGA 드라이버

---

**Type System 의사결정 플로우차트**:
```
신규 시스템 + 메모리 안전성? → Rust
  └─ NO
     ↓
기존 C++ 코드베이스? → C++ Modern
  └─ NO
     ↓
FPGA 드라이버 또는 극한 제어? → C
```

---

### 2.5.2 Observability (DNA #8) - 마이크로초급 프로파일링 ⭐⭐⭐

**패밀리 요구**:
- 마이크로초~나노초 수준 추적
- 하드웨어 카운터 접근 (CPU cycles, cache miss)
- 핫스팟 식별 (함수별 레이턴시)
- 프로덕션 오버헤드 최소화 (<1%)
- 레이턴시 분포 분석 (p50, p99, p999)

---

#### 옵션 1: Intel VTune Profiler

**핵심 스펙**:
- **정밀도**: CPU 사이클 수준 (나노초)
- **하드웨어**: CPU 카운터, 캐시 분석, NUMA
- **분석**: 핫스팟, 마이크로아키텍처, 메모리
- **오버헤드**: 1-5% (샘플링 모드)

**비용**: 무료 (Intel 프로세서)

**장점**:
- 🔧 CPU 사이클 수준 정밀 분석
- 🔧 캐시 미스, 브랜치 예측 분석
- 🔧 GUI + CLI 모두 지원
- 🔧 무료 (Intel CPU)

**단점**:
- ⚠️ Intel CPU 전용
- ⚠️ 프로덕션 사용 어려움 (GUI 의존)
- ⚠️ 학습 곡선
- ⚠️ AMD 미지원

**적합한 경우**:
- Intel 서버 환경
- 개발/테스트 환경 분석
- CPU 마이크로아키텍처 최적화
- 캐시 최적화 필요

**검증 사례**: Intel 내부, 금융 거래소

---

#### 옵션 2: Linux perf + 커스텀 계측

**핵심 스펙**:
- **정밀도**: 마이크로초 (하드웨어 카운터)
- **하드웨어**: perf_events (Intel, AMD, ARM)
- **분석**: 샘플링, 트레이싱, 카운터
- **오버헤드**: <1% (샘플링)

**비용**: 오픈소스 (무료)

**장점**:
- 🔧 모든 CPU 아키텍처 지원
- 🔧 프로덕션 사용 가능
- 🔧 커널 레벨 통합
- 🔧 eBPF 확장 가능

**단점**:
- ⚠️ CLI 기반 (GUI 제한적)
- ⚠️ 분석 자동화 직접 구현
- ⚠️ 커스텀 계측 필요
- ⚠️ 학습 곡선

**적합한 경우**:
- 멀티 아키텍처 환경
- 프로덕션 모니터링
- eBPF 확장 계획
- 자동화 파이프라인

**검증 사례**: Netflix, Google, Meta

---

#### 옵션 3: 커스텀 인라인 계측

**핵심 스펙**:
- **정밀도**: RDTSC 기반 (나노초)
- **오버헤드**: ~20ns per measurement
- **분석**: 직접 구현 (히스토그램, 분포)
- **통합**: 코드 인라인

**비용**: 개발 비용만

**장점**:
- 🔧 나노초 수준 정밀도
- 🔧 최소 오버헤드 (~20ns)
- 🔧 완전한 제어
- 🔧 프로덕션 상시 실행

**단점**:
- ⚠️ 직접 구현 필요
- ⚠️ 유지보수 부담
- ⚠️ 분석 도구 직접 제작
- ⚠️ 코드 침습적

**적합한 경우**:
- 나노초급 측정 필수
- HFT 전문 팀
- 프로덕션 상시 모니터링
- 외부 도구 오버헤드 불가

**검증 사례**: HFT 전문 회사, Jump Trading

---

**Observability 의사결정 플로우차트**:
```
개발 환경 + Intel CPU? → VTune
  └─ NO
     ↓
프로덕션 + 멀티 아키텍처? → perf + eBPF
  └─ NO
     ↓
나노초급 + 상시 모니터링? → 커스텀 RDTSC
```

---

### 2.5.3 Performance (DNA #11) - 레이턴시 벤치마크 ⭐⭐⭐

**패밀리 요구**:
- 나노초~마이크로초 정밀 측정
- 레이턴시 회귀 감지 (CI/CD 통합)
- 통계적 유의성 검증
- JIT 워밍업 제거
- 결정론적 벤치마크

---

#### 옵션 1: Criterion.rs (Rust)

**핵심 스펙**:
- **정밀도**: 나노초 (RDTSC 기반)
- **통계**: 부트스트랩, 신뢰구간, 회귀 감지
- **리포트**: HTML, 그래프, 비교
- **CI 통합**: GitHub Actions, GitLab CI

**비용**: 오픈소스 (무료)

**장점**:
- 🔧 통계적 회귀 감지 자동
- 🔧 HTML 리포트 (시각화)
- 🔧 CI/CD 쉬운 통합
- 🔧 워밍업 자동 처리

**단점**:
- ⚠️ Rust 전용
- ⚠️ C++ 코드 FFI 필요
- ⚠️ 일부 고급 설정 제한
- ⚠️ 대규모 벤치마크 시 느림

**적합한 경우**:
- Rust 프로젝트
- 자동 회귀 감지 필요
- CI/CD 통합 우선
- 통계적 신뢰성 필요

**검증 사례**: Rust 생태계 표준

---

#### 옵션 2: Google Benchmark (C++)

**핵심 스펙**:
- **정밀도**: 나노초 (RDTSC, 클록)
- **통계**: 평균, 표준편차, 복잡도 분석
- **리포트**: JSON, CSV, 콘솔
- **CI 통합**: CMake, Bazel

**비용**: 오픈소스 (무료)

**장점**:
- 🔧 C++ 업계 표준
- 🔧 Google 검증
- 🔧 복잡도 분석 (Big-O)
- 🔧 템플릿 기반 확장

**단점**:
- ⚠️ 통계적 회귀 감지 수동
- ⚠️ 리포트 도구 별도 필요
- ⚠️ 워밍업 수동 처리
- ⚠️ CI 통합 직접 구현

**적합한 경우**:
- C++ 프로젝트
- 복잡도 분석 필요
- Google 도구체인 사용
- 템플릿 확장 계획

**검증 사례**: Google, Bloomberg, Chromium

---

#### 옵션 3: 커스텀 RDTSC 벤치마크

**핵심 스펙**:
- **정밀도**: CPU 사이클 (1ns 미만)
- **오버헤드**: 최소 (~10ns)
- **제어**: 완전한 제어
- **통합**: 직접 구현

**비용**: 개발 비용만

**장점**:
- 🔧 최고 정밀도 (CPU 사이클)
- 🔧 최소 오버헤드
- 🔧 완전한 제어
- 🔧 프로덕션 통합 가능

**단점**:
- ⚠️ 직접 구현 필요
- ⚠️ 통계 분석 직접 구현
- ⚠️ 유지보수 부담
- ⚠️ CPU 아키텍처 의존

**적합한 경우**:
- 나노초 미만 정밀도
- HFT 전문 팀
- 외부 도구 오버헤드 불가
- 프로덕션 측정 필수

**검증 사례**: HFT 전문 회사

---

**Performance 의사결정 플로우차트**:
```
Rust 프로젝트 + 자동 회귀 감지? → Criterion.rs
  └─ NO
     ↓
C++ 프로젝트 + 복잡도 분석? → Google Benchmark
  └─ NO
     ↓
나노초 미만 + 완전 제어? → 커스텀 RDTSC
```

---

## Part 3: 도메인 선택 요소 (프로젝트별)

이 요소들은 **패밀리와 무관**하게 프로젝트 요구사항에 따라 선택합니다.

### 3.1 프론트엔드 프레임워크

**선택지**:
- React, Angular (관리 도구, 대시보드)
- 모바일: React Native, Flutter (트레이더 앱)

**선택 기준**:
- HFT는 프론트엔드 최소화 (관리 도구만)
- 트레이딩 플랫폼은 실시간 차트 필수

**A-A-A 영향**: 최소 (백오피스만)

---

### 3.2 백엔드 언어/프레임워크

**선택지**:
- **C++**: 최고 성능, 마이크로초 제어 (HFT 표준)
- **Java**: VoltDB/Chronicle 통합, GC 튜닝 필수
- **Rust**: 메모리 안전 + 성능 (신규 프로젝트)
- Go: 동시성, 네트워크 (주변 시스템)

**선택 기준**:
- 핫 패스 (Hot Path): C++ 또는 Rust 필수
- 백오피스: Java, Go 허용
- 팀 역량 vs 성능 요구 트레이드오프

**A-A-A 영향**: **매우 큼** - 언어 선택이 레이턴시 결정  
(C++: 나노초~마이크로초, Java: 수 마이크로초, Python: 불가능)

---

### 3.3 인증/권한

**선택지**:
- OAuth2 + JWT (표준)
- LDAP/Active Directory (엔터프라이즈)
- Custom (초고보안)

**선택 기준**:
- 거래 API: 강력한 인증 (X.509, API Key)
- 관리 도구: 표준 인증 (OAuth2)
- 감사 추적 (Audit Trail) 필수

**A-A-A 영향**: 중간 (API 보안 중요)

---

### 3.4 모니터링/로깅

**선택지**:
- **Prometheus + Grafana**: 표준 메트릭
- **커스텀 시스템**: 마이크로초 단위 추적, 오버헤드 최소화
- ELK Stack: 로그 집계 (백오피스)

**선택 기준**:
- 핫 패스: 비동기 로깅, 샘플링 필수 (오버헤드 <1%)
- 백오피스: 표준 도구 허용
- 감사 추적: 규제 준수 (MiFID II, Reg NMS)

**A-A-A 영향**: **큼** - 모니터링 오버헤드가 레이턴시 영향  
(1% 오버헤드 = 수백 나노초 추가)

---

## Part 4: Stage 2 통합

### 4.1 Layer 3 제약 반영 예시

**시나리오**: 소규모 HFT 스타트업

**Layer 3 제약 발견**:
- 거래소 API: 코로케이션 필수 ($50K/월)
- 규제: MiFID II, Reg NMS 준수
- 예산: $500K/년 (전체)
- 팀: 3명 (Java 경험, FPGA 없음)

**기술 선택 영향**:
```
인메모리 DB:
- VoltDB (선호) → Redis Enterprise
- 이유: 예산 제약 ($20K/월 vs $5K/월)

저지연 메시징:
- FPGA (불가능) → Aeron
- 이유: 팀 역량, 예산

하드웨어 가속:
- FPGA (불가능) → Kernel Bypass (DPDK)
- 이유: Java 팀이지만 C++ 학습 가능, 예산

코로케이션:
- 필수: $50K/월 (거래소 인접)
- 이유: 마이크로초 필수
```

---

### 4.2 충돌 해결 예시

**NFR 목표 vs Layer 3 제약**:

**충돌 1**: 레이턴시 A (나노초) + 예산 제약
- **NFR**: 나노초 레이턴시
- **제약**: 예산 $500K/년 (FPGA 불가능)
- **해결**: FPGA 포기 → Kernel Bypass (DPDK)
- **트레이드오프**: 
  - ⚠️ 레이턴시 480ns → 수 μs (10~20배 느림)
  - ⚠️ 경쟁 열위 (최상위 HFT 대비)
  - ✅ 개발 비용 $2M → $500K (75% 절감)
  - ✅ 개발 기간 18개월 → 6개월

---

**충돌 2**: ACID A + 코로케이션 비용
- **NFR**: 완전한 ACID 트랜잭션
- **제약**: 코로케이션 $50K/월 (VoltDB 비용 부담)
- **해결**: VoltDB → Redis Enterprise (ACID 모듈)
- **트레이드오프**:
  - ⚠️ 완전한 ACID → 제한적 ACID (단일 키)
  - ⚠️ SQL 지원 상실 (쿼리 복잡도 증가)
  - ✅ 비용 $20K/월 → $5K/월 (75% 절감)
  - ✅ 레이턴시 <10ms → 150μs (66% 개선)

---

**충돌 3**: 팀 역량 + FPGA
- **NFR**: 나노초 레이턴시 (FPGA 필요)
- **제약**: Java 팀, FPGA 전문가 없음
- **해결**: 옵션 A: 외주 FPGA 개발 / 옵션 B: Kernel Bypass 내재화
- **트레이드오프 (옵션 A - 외주)**:
  - ✅ 나노초 레이턴시 달성 (480ns)
  - ⚠️ 비용 $1M~$2M (외주 개발)
  - ⚠️ 의존성 (외주사에 종속)
  - ⚠️ 유지보수 어려움
- **트레이드오프 (옵션 B - 내재화)**:
  - ⚠️ 레이턴시 수 μs (FPGA 대비 느림)
  - ✅ 비용 $100K~$500K (내부 개발)
  - ✅ 팀 역량 축적 (C++ 전문성)
  - ✅ 장기 유지보수 가능

**선택**: 옵션 B (Kernel Bypass 내재화)  
**이유**: 예산 제약 + 팀 역량 축적 우선

---

### 4.3 ADR 작성 준비

**선택한 기술 스택 정리**:
```
Bootstrap 필수:
✅ 인메모리 DB: Redis Enterprise (ACID 모듈)
✅ 저지연 메시징: Aeron
✅ 하드웨어 가속: Kernel Bypass (DPDK)

도메인 선택:
✅ 백엔드: Java (Spring Boot) + C++ (핫패스)
✅ 프론트엔드: React (관리 도구)
✅ 모니터링: 자체 구현 (오버헤드 최소화)
```

**ADR 작성 대상**:
1. 인메모리 DB 선택 (VoltDB vs Redis Enterprise)
2. 저지연 메시징 선택 (Aeron vs Chronicle)
3. 하드웨어 가속 전략 (DPDK vs FPGA)
4. 코로케이션 전략 (거래소 인접 배치)
5. 규제 준수 방안 (MiFID II, Reg NMS)

---

## 📚 참고 자료

### 거래소 레이턴시 벤치마크
- [NASDAQ X-Stream: 37μs](https://www.nasdaq.com/solutions/x-stream-global-trade-engine)
- [SIX Swiss Exchange: 14μs](https://www.six-group.com/)
- [CME Globex](https://www.cmegroup.com/trading/globex.html)

### FPGA 검증 사례
- IEEE: HFT FPGA 480ns~2.6μs (학술 논문)
- Citadel, Jump Trading (공개 정보 제한적)

### 인메모리 DB 벤치마크
- [VoltDB Performance](https://www.voltdb.com/company/performance/)
- [Redis Benchmark](https://redis.io/docs/latest/operate/oss_and_stack/management/optimization/benchmarks/)

### 저지연 메시징
- [Aeron](https://github.com/real-logic/aeron)
- [Chronicle Queue](https://chronicle.software/chronicle-queue/)

### 하드웨어 가속
- [DPDK](https://www.dpdk.org/)
- [Solarflare](https://www.xilinx.com/products/boards-and-kits/alveo.html)
- [RDMA](https://en.wikipedia.org/wiki/Remote_direct_memory_access)

### 규제 문서
- [MiFID II](https://www.esma.europa.eu/policy-rules/mifid-ii-and-mifir)
- [Reg NMS](https://www.sec.gov/rules/final/34-51808.pdf)

---

**마지막 업데이트**: 2025-11-12  
**다음 검토**: 2026-02-12 (기술 스택 업데이트 반영)


================================================================================

📄 FILE: 02_transaction_crud_tech_options.md
--------------------------------------------------------------------------------

# 트랜잭션/CRUD 패밀리 (A-A-B) - 기술 매트릭스

**작성일**: 2024-11-12  
**패밀리**: 트랜잭션/CRUD (A-A-B)  
**검증 사례**: Amazon 주문 시스템, Booking.com 예약, Stripe 결제, SAP ERP

---

## Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐

### 1.1 A-A-B 특성이 강제하는 것

#### A (치명적 실패) → ACID 트랜잭션 필수

**특성**:
- 부분 성공 불가 (All-or-Nothing)
- 실패 = 재정 손실, 재고 불일치, 규제 위반
- 완전 롤백 메커니즘 필수
- 감사 추적 (Audit Trail) 의무

**강제되는 기술적 요구**:
```
✅ ACID 트랜잭션 DB 필수
✅ 격리 수준 제어 (Isolation Level)
✅ 분산 트랜잭션 조율 (2PC, Saga)
✅ 롤백 & 복구 메커니즘
✅ 데이터 무결성 제약
```

**검증 사례**:
- Amazon: 주문-재고-결제 트랜잭션, 실패 시 전체 롤백, 연간 수십억 건 처리
- Stripe: 결제 100% 정확성, PCI DSS 준수, 이중 청구 방지
- Booking.com: 객실 예약 트랜잭션, 초과 예약 방지

---

#### A (구조화 데이터) → 관계형 스키마 필수

**특성**:
- 명확한 엔티티 관계 (Order ↔ Customer ↔ Product)
- 참조 무결성 (Foreign Key Constraints)
- 복잡한 JOIN 쿼리 빈번
- 정규화된 스키마 설계

**강제되는 기술적 요구**:
```
✅ 관계형 데이터베이스 (RDBMS)
✅ 외래 키 제약 조건
✅ 스키마 마이그레이션 도구
✅ 인덱싱 전략
✅ 쿼리 최적화
```

**검증 사례**:
- Booking.com: 객실-호텔-예약-고객 복잡한 관계, 수백 개 테이블 JOIN
- SAP ERP: 수천 개 테이블 간 참조 무결성, 30년+ 스키마 진화

---

#### B (수초 응답) → 읽기 최적화 전략 필수

**특성**:
- 200ms~3초 응답 목표 (사용자 경험)
- 읽기 : 쓰기 = 90:10 (읽기 중심)
- 밀리초급 불필요 (A-A-A와 차이)
- 3초+ 지연 시 57% 사용자 이탈

**강제되는 기술적 요구**:
```
✅ 캐시 레이어 (Redis, Memcached)
✅ 읽기 복제본 (Read Replicas)
✅ 인덱스 전략 (B-tree, Hash)
✅ 쿼리 최적화 & 모니터링
✅ Connection Pooling
```

**검증 사례**:
- Amazon: 100ms 지연 = 매출 1% 손실 ($1.6B/년 추정)
- 산업 평균: 47% 사용자가 2초 내 로딩 기대, 3초+ 시 이탈

---

### 1.2 이 패밀리에 필요한 DNA 시스템 및 메인 서비스

#### DNA 11개 시스템 중 필요한 것

A-A-B 패밀리는 다음 DNA 시스템이 필요합니다:

| DNA 시스템 | 중요도 | 이유 |
|-----------|-------|------|
| 1. Testing | ✅ 필수 | 트랜잭션 로직 검증 |
| 2. Code Quality | ✅ 필수 | 비즈니스 로직 품질 |
| 3. Architecture | ✅ 필수 | 도메인 모듈 분리 |
| 4. Type System | ✅ 필수 | 엔티티 타입 안전성 |
| 5. **Error Handling** | **⭐⭐⭐ 매우 중요** | **트랜잭션 롤백, 보상 트랜잭션** |
| 6. Configuration | ✅ 필수 | DB 연결, 트랜잭션 타임아웃 |
| 7. **Identity & Access** | **⭐⭐⭐ 매우 중요** | **사용자 인증, RBAC, 감사 로그** |
| 8. Observability | ✅ 필수 | 쿼리 성능, 트랜잭션 추적 |
| 9. **API Gateway** | **⭐⭐⭐ 매우 중요** | **Rate Limiting, 인증, 버전 관리** |
| 10. **Resilience** | **⭐⭐⭐ 매우 중요** | **Circuit Breaker, 재시도, 타임아웃** |
| 11. Performance | ✅ 필수 | 쿼리 최적화, 인덱싱 |

**특별히 중요한 DNA 시스템 (⭐⭐⭐)**:
- **Identity & Access**: 사용자 인증 실패 = 보안 침해, RBAC 없으면 권한 관리 불가
- **API Gateway**: Rate limiting 없으면 DDoS 공격, 버전 관리 없으면 배포 중단
- **Error Handling**: 트랜잭션 롤백 실패 = 데이터 불일치, 보상 트랜잭션 필수
- **Resilience**: 외부 API 장애 시 전체 시스템 다운 방지

→ **Part 2.5에서 이 4가지 중 3가지 DNA 시스템의 기술 옵션을 다룹니다.**

#### 메인 서비스 필수 요소 (패밀리 강제)

A-A-B 패밀리는 다음 3가지 메인 서비스 기술을 **반드시** 포함해야 합니다:

#### 1. 관계형 데이터베이스 (필수!)
**역할**: ACID 트랜잭션, 참조 무결성, 복잡한 쿼리
**이유**: 치명적 실패(A) + 구조화 데이터(A)
**선택지**: PostgreSQL, MySQL, CockroachDB

#### 2. 캐시 레이어 (필수!)
**역할**: 읽기 성능 최적화 (<200ms)
**이유**: 수초 응답(B) + 높은 읽기 비율 (90%+)
**선택지**: Redis, Memcached

#### 3. 메시징 시스템 (강력 권장)
**역할**: 비동기 작업, 서비스 분리, 확장성
**이유**: 마이크로서비스 아키텍처, 이벤트 기반 통신
**선택지**: RabbitMQ, Kafka, AWS SQS

---

## Part 2: 메인 서비스 기술 선택 ⭐⭐⭐

### 2.1 관계형 데이터베이스 선택

**패밀리 요구**:
- ACID 트랜잭션 보장
- Serializable 격리 수준 지원
- 참조 무결성 제약
- 복잡한 JOIN 쿼리 성능
- 읽기/쓰기 확장성

---

#### 옵션 1: PostgreSQL

**핵심 스펙**:
- **읽기**: 50,000~100,000 QPS (최적화 시)
- **쓰기**: 15,000~30,000 TPS (SSD 기준)
- **트랜잭션 격리**: Serializable 완벽 지원
- **동시 연결**: 100~500 (PgBouncer로 10,000+)
- **데이터 크기**: 수백 TB (단일 인스턴스)

**비용**:
- **Self-hosted**: $0 (오픈소스)
- **AWS RDS**: $0.115/hour (db.t3.medium), 월 ~$84
- **Managed (Supabase)**: $25/월 (Hobby), $599/월 (Pro)
- **Enterprise**: $500~$5,000/월 (규모별)

**장점**:
- ⚡ 고급 ACID 지원: Serializable 격리 수준 완벽 구현
- 🔧 JSON/JSONB: 하이브리드 데이터 유연성
- 📈 성숙한 확장: 읽기 복제본, 파티셔닝, 샤딩
- 🌐 20년+ 검증: 엔터프라이즈급 안정성
- 🛠️ 풍부한 생태계: 마이그레이션, 모니터링 도구

**단점**:
- 🔧 복잡한 튜닝: 수백 개 설정 파라미터
- 📚 학습 곡선: 고급 기능 숙달 시간 필요
- 💰 고급 기능 비용: Replication, Clustering

**적합한 경우**:
- 복잡한 비즈니스 로직 (수십~수백 개 테이블)
- JSON과 관계형 혼합 데이터
- 장기 프로젝트 (10년+ 지원)
- 엔터프라이즈급 안정성 필요
- Serializable 트랜잭션 필수

**검증 사례**: Instagram (수십억 행), Discord (초당 120만 메시지), Stripe, Apple

---

#### 옵션 2: MySQL

**핵심 스펙**:
- **읽기**: 60,000~120,000 QPS (MyISAM, 단순 쿼리)
- **쓰기**: 10,000~20,000 TPS (InnoDB)
- **트랜잭션 격리**: Read Committed (기본), Serializable (제한)
- **동시 연결**: 100~300
- **데이터 크기**: 수십 TB (권장)

**비용**:
- **Self-hosted**: $0 (오픈소스)
- **AWS RDS**: $0.102/hour (db.t3.medium), 월 ~$74
- **Managed (PlanetScale)**: $15/월 (Scaler), $39/월 (Scaler Pro)
- **Enterprise**: $300~$3,000/월

**장점**:
- 📚 성숙도: LAMP 스택, 30년 역사
- 🔧 단순 설정: PostgreSQL 대비 쉬운 초기 설정
- 💰 저렴한 호스팅: 공유 호스팅 옵션 다수
- ⚡ 읽기 최적화: 단순 쿼리 고속 처리
- 🌐 광범위 채택: WordPress, Drupal 기본

**단점**:
- 🔒 제한적 트랜잭션: Serializable 성능 이슈
- 📊 약한 JSON 지원: PostgreSQL JSONB 대비 부족
- 🔧 고급 인덱스 부족: 부분 인덱스, 함수 인덱스 제한

**적합한 경우**:
- 읽기 중심 워크로드 (90%+ SELECT)
- 단순한 스키마 (수십 개 테이블)
- 예산 제약 (<$100/월)
- 팀이 MySQL 경험 풍부
- Read Committed 충분

**검증 사례**: Facebook (초기), WordPress (3천만 사이트), Shopify, GitHub (초기)

---

#### 옵션 3: CockroachDB

**핵심 스펙**:
- **읽기**: 30,000~50,000 QPS (단일 리전)
- **쓰기**: 10,000~15,000 TPS (다중 리전 시 감소)
- **트랜잭션 격리**: Serializable (분산 환경)
- **레이턴시**: +10~50ms (리전 간 증가)
- **데이터 크기**: PB급 (자동 샤딩)

**비용**:
- **Serverless**: $1 per 1M Request Units, 월 ~$50 (소규모)
- **Dedicated**: $0.50/vCPU/hour, 월 ~$360 (3노드 최소)
- **Enterprise**: $1,000~$10,000/월 (규모별)

**장점**:
- 🌐 전역 분산 ACID: 다중 리전 Serializable 트랜잭션
- 📈 자동 샤딩: 무한 수평 확장
- 🔄 PostgreSQL 호환: 기존 쿼리 재사용
- ☁️ 클라우드 네이티브: Kubernetes 친화적
- 🛡️ 내장 복제: 자동 failover

**단점**:
- 💰 높은 비용: PostgreSQL 대비 3~5배
- ⏱️ 레이턴시 증가: 분산 합의 오버헤드
- 🔧 운영 복잡도: 분산 시스템 전문 지식
- 📊 제한적 생태계: PostgreSQL 대비 도구 부족

**적합한 경우**:
- 글로벌 분산 필수 (다중 리전)
- 무한 확장 필요 (PB급 데이터)
- 지역 간 트랜잭션 빈번
- 예산 여유 ($500+/월)
- 클라우드 네이티브 환경

**검증 사례**: Bose, Lush Cosmetics, SpaceX Starlink, Hard Rock Digital

---

#### 데이터베이스 비교표

| 항목 | PostgreSQL | MySQL | CockroachDB |
|------|-----------|-------|-------------|
| **읽기 QPS** | 50K~100K | 60K~120K | 30K~50K |
| **쓰기 TPS** | 15K~30K | 10K~20K | 10K~15K |
| **격리 수준** | ⭐⭐⭐ Serializable | ⭐⭐ Read Committed | ⭐⭐⭐ Serializable (분산) |
| **비용 (중규모)** | $100~$300/월 | $80~$250/월 | $360~$1K/월 |
| **JSON 지원** | ⭐⭐⭐ 우수 | ⭐⭐ 보통 | ⭐⭐⭐ 우수 |
| **다중 리전** | 복제본 | 복제본 | ⭐⭐⭐ 네이티브 |
| **확장성** | 읽기 복제본 | 읽기 복제본 | 수평 자동 |
| **생태계** | ⭐⭐⭐ 풍부 | ⭐⭐⭐ 풍부 | ⭐⭐ 성장 중 |

**의사결정 가이드**:
```
글로벌 다중 리전 필수? → CockroachDB
  └─ NO
     ↓
Serializable 트랜잭션 필수?
  ├─ YES → PostgreSQL
  └─ NO
     ↓
예산 < $100/월?
  ├─ YES
  │  ├─ 복잡한 쿼리? → PostgreSQL (Managed)
  │  └─ 읽기 중심? → MySQL
  │
  └─ NO → PostgreSQL (장기 투자)
```

---

### 2.2 캐시 레이어 선택

**패밀리 요구**:
- 읽기 레이턴시 <10ms
- 높은 처리량 (100K+ ops/sec)
- TTL 관리
- 세션 저장 지원

---

#### 옵션 1: Redis

**핵심 스펙**:
- **레이턴시**: 0.15ms (GET, p99)
- **처리량**: 100,000~200,000 ops/sec (단일 인스턴스)
- **자료구조**: String, Hash, List, Set, Sorted Set, Stream, HyperLogLog
- **영속성**: RDB 스냅샷, AOF (Append-Only File)
- **메모리**: 1GB~수백 GB

**비용**:
- **Self-hosted**: $0 (오픈소스)
- **AWS ElastiCache**: $0.034/hour (cache.t3.micro), 월 ~$25
- **Redis Cloud**: $7/월 (250MB), $200/월 (10GB)
- **Enterprise**: $500~$5,000/월 (HA, 다중 리전)

**장점**:
- ⚡ 초고속: 0.15ms 평균 레이턴시
- 🔧 다양한 자료구조: 복잡한 캐싱 패턴 지원
- 📡 Pub/Sub: 실시간 알림 가능
- 💾 영속성: 재시작 후 데이터 복구
- 🌐 풍부한 클라이언트: 모든 주요 언어 지원

**단점**:
- 💰 메모리 기반: 디스크 대비 비쌈 (GB당)
- 🔧 단일 스레드: CPU 코어 1개만 활용
- 🛠️ 운영 복잡도: 클러스터링, 샤딩 수동 관리

**적합한 경우**:
- 세션 관리 필수
- API 응답 캐싱
- Rate Limiting
- Leaderboards, Counters
- Pub/Sub 필요
- 복잡한 자료구조 활용

**검증 사례**: Twitter (120만 TPS), GitHub, Stack Overflow, Pinterest

---

#### 옵션 2: Memcached

**핵심 스펙**:
- **레이턴시**: <0.1ms (마이크로초급)
- **처리량**: 120,000+ ops/sec
- **자료구조**: Key-Value만
- **영속성**: 없음 (휘발성)
- **메모리**: 1GB~수백 GB

**비용**:
- **Self-hosted**: $0 (오픈소스)
- **AWS ElastiCache**: $0.017/hour (cache.t3.micro), 월 ~$12
- **월 예상**: $30~$500

**장점**:
- 💰 Redis 대비 50% 저렴
- ⚡ 극도로 빠름: 마이크로초 레이턴시
- 🔧 멀티스레드: CPU 코어 활용 우수
- 🛠️ 단순함: 설정 & 운영 간단

**단점**:
- 📊 단순 자료구조: Key-Value만 지원
- 💾 영속성 없음: 재시작 시 데이터 손실
- 📡 Pub/Sub 없음: 이벤트 알림 불가
- 🔒 제한적 고급 기능: 트랜잭션, Lua 스크립트 없음

**적합한 경우**:
- 단순 Key-Value 캐싱만
- 예산 최소화 (<$50/월)
- 높은 동시성 필요 (멀티스레드)
- 영속성 불필요
- Facebook, Twitter 초기 규모

**검증 사례**: Facebook (역사적), Wikipedia, YouTube (콘텐츠 캐싱)

---

#### 캐시 비교표

| 항목 | Redis | Memcached |
|------|-------|-----------|
| **레이턴시** | 0.15ms | <0.1ms |
| **자료구조** | ⭐⭐⭐ 다양 | Key-Value만 |
| **영속성** | ⭐⭐ 옵션 있음 | ❌ 없음 |
| **비용** | 중간 | ⭐⭐⭐ 낮음 (50% 저렴) |
| **Pub/Sub** | ✅ | ❌ |
| **멀티스레드** | ❌ (단일) | ⭐⭐⭐ 우수 |
| **운영 복잡도** | 중간 | ⭐⭐⭐ 낮음 |

**의사결정 가이드**:
```
세션 관리 필요? → Redis
  └─ NO
     ↓
Pub/Sub 필요? → Redis
  └─ NO
     ↓
복잡한 자료구조? → Redis
  └─ NO
     ↓
예산 < $30/월? → Memcached
  └─ NO → Redis (범용)
```

---

### 2.3 메시징 시스템 선택

**패밀리 요구**:
- 비동기 작업 처리
- 서비스 간 분리
- At-Least-Once 전달 보장
- Task Queue 기능

---

#### 옵션 1: RabbitMQ

**핵심 스펙**:
- **처리량**: 10,000~50,000 msg/sec (단일 노드)
- **레이턴시**: 1~10ms (p99)
- **메시지 크기**: <128KB 권장, 512MB 최대
- **보장**: At-Least-Once, Persistent Queue
- **프로토콜**: AMQP 0-9-1

**비용**:
- **Self-hosted**: $0 (오픈소스)
- **CloudAMQP**: $13/월 (Tiger, 1M msg/월), $40/월 (Panda)
- **AWS AmazonMQ**: $0.50/hour (~$360/월, 3노드)
- **Enterprise**: $500~$3,000/월

**장점**:
- 📚 성숙도: 15년+ 검증, 엔터프라이즈급
- 🔧 유연한 라우팅: Exchange (Direct, Topic, Fanout, Headers)
- 💾 메시지 영속성: 디스크 저장 지원
- 🛠️ 관리 UI: 웹 기반 모니터링 & 관리
- 🌐 다양한 클라이언트: 모든 주요 언어

**단점**:
- 📉 제한적 확장: 클러스터링 복잡
- ⏱️ 부하 시 레이턴시: 큐 깊이 증가 시 성능 저하
- 🔧 운영 복잡도: 클러스터, Federation 수동 관리

**적합한 경우**:
- 전통적 메시징 패턴 (Queue, Pub/Sub)
- 복잡한 라우팅 규칙
- 메시지 영속성 필수
- 중소 규모 (초당 5만 미만)
- 예산 $50~$500/월

**검증 사례**: T-Mobile, Heroku, BBC, Reddit, Trivago

---

#### 옵션 2: Apache Kafka

**핵심 스펙**:
- **처리량**: 200K~2M msg/sec (클러스터)
- **레이턴시**: p99.9 <10ms
- **메시지 크기**: 1MB 기본, 10MB+ 설정 가능
- **보장**: At-Least-Once 기본, Exactly-Once 선택
- **보관**: 일~월 단위 (설정 가능)

**비용**:
- **Self-hosted**: $2,000~$10,000+/월 (3노드)
- **AWS MSK**: $0.21~$0.84/hour per vCPU, $3,000~$10,000/월
- **Confluent Cloud**: $5,000~$20,000/월 (eCKU 기반)

**장점**:
- ⚡ 초고속: 수백만 msg/sec
- 📈 무제한 확장: 파티션 추가로 선형 확장
- 💾 장기 보관: 이벤트 재생 가능
- 🔧 이벤트 소싱: 불변 로그 기반 아키텍처
- 🌐 풍부한 생태계: Kafka Connect, Kafka Streams

**단점**:
- 💰 높은 비용: RabbitMQ 대비 10배+
- 🧑‍💻 전문 인력: Kafka 전문가 필수
- ⏱️ 배포 시간: 1~4주 (self-hosted)
- 🔧 운영 복잡도: ZooKeeper, Replication 관리

**적합한 경우**:
- 초대규모 (초당 10만+ 메시지)
- 이벤트 소싱 아키텍처
- 장기 이벤트 재생 필요
- 대기업, 미션 크리티컬
- 예산 $5K+/월

**검증 사례**: LinkedIn, Netflix, Uber, Airbnb, Spotify

---

#### 옵션 3: AWS SQS

**핵심 스펙**:
- **처리량**: 3,000 msg/sec (Standard), 300 msg/sec (FIFO)
- **레이턴시**: 수십 ms
- **메시지 크기**: 256KB 최대
- **보장**: At-Least-Once (Standard), Exactly-Once (FIFO)
- **보관**: 최대 14일

**비용**:
- **Standard**: $0.40 per 1M requests
- **FIFO**: $0.50 per 1M requests
- **월 예상** (100만 msg): $40~$500

**장점**:
- 🤖 완전 관리형: 운영 부담 제로
- 💵 사용량 기반 과금: 예측 가능
- 🔗 AWS 통합: Lambda, EC2, ECS 쉬운 연동
- 📈 자동 확장: 무제한 처리량 (Standard)
- 🛡️ 높은 가용성: 99.9% SLA

**단점**:
- 🔒 AWS 종속: 멀티 클라우드 불가
- ⏱️ 제한적 처리량: FIFO 300 msg/sec
- 📊 단순 기능: Exchange, Routing 없음
- 💰 대규모 비용: 수억 메시지 시 급증

**적합한 경우**:
- AWS 중심 인프라
- 운영 간소화 최우선
- 중소 규모 (초당 3천 미만)
- 빠른 MVP 출시
- 예산 유연성

**검증 사례**: NASA JPL, Capital One, Change.org, BMW

---

#### 메시징 시스템 비교표

| 항목 | RabbitMQ | Kafka | AWS SQS |
|------|----------|-------|---------|
| **처리량** | 10K~50K/s | 200K~2M/s | 3K/s (Standard) |
| **레이턴시** | 1~10ms | <10ms | 수십 ms |
| **비용 (중규모)** | $50~$500/월 | $3K~$10K/월 | $40~$500/월 |
| **배포** | 1~3일 | 1~4주 | 즉시 |
| **운영** | ⚙️⚙️ 중간 | ⚙️⚙️⚙️ 높음 | ⚙️ 낮음 (관리형) |
| **메시지 보관** | 단기 | 일~월 | 최대 14일 |
| **확장성** | 제한적 | 무제한 | 자동 |
| **라우팅** | ⭐⭐⭐ 풍부 | Topic 기반 | 단순 |

**의사결정 가이드**:
```
처리량 > 10만/s? → Kafka
  └─ NO
     ↓
AWS 전용 OK? → SQS
  └─ NO → RabbitMQ
     ↓
운영 간소화 최우선? → SQS
  └─ NO
     ↓
복잡한 라우팅? → RabbitMQ
  └─ NO → SQS
```

---

## Part 2.5: 중요 DNA 시스템 기술 선택 🆕

이 섹션에서는 A-A-B 패밀리에서 **⭐⭐⭐ 매우 중요한 DNA 시스템 3가지**의 기술 옵션을 다룹니다.

### 2.5.1 Identity & Access (DNA #7) - 사용자 인증 및 권한 관리 ⭐⭐⭐

**패밀리 요구**:
- 사용자 인증 (OAuth2, OpenID Connect, SAML)
- RBAC (Role-Based Access Control) - 세밀한 권한 관리
- MFA (Multi-Factor Authentication) - 보안 강화
- 감사 로그 (Audit Trail) - 규제 준수
- 세션 관리 - 수초 응답 시간 유지

---

#### 옵션 1: Auth0

**핵심 스펙**:
- **처리량**: 100억+ 인증/월 (전역 처리)
- **레이턴시**: <50ms (글로벌 CDN)
- **가용성**: 99.99% SLA (Enterprise)
- **비용**: Free (25K MAU), Essentials $32/월 (500 MAU), Professional $220/월 (1K MAU), Enterprise $2,500/월

**장점**:
- 완전 관리형 (Managed SaaS), 운영 부담 제로
- 25K MAU까지 무료 (소규모 프로젝트 이상적)
- Universal Login, Passwordless, Social Login 즉시 사용
- 즉시 배포 가능 (5분 설정)
- 풍부한 SDK (React, Vue, Node.js, Python, Java 등)
- MFA, Bot Detection, Brute-Force Protection 내장
- 규제 준수 (GDPR, SOC2, ISO27001)

**단점**:
- MAU 제한으로 대규모 시 비용 급증 (10K MAU = $1,250~$1,595/월)
- 벤더 락인 (Okta 인수 후 가격 변동 우려)
- Enterprise 기능 (로그 내보내기, 고급 보안) 고가
- 커스터마이징 제한 (Rules/Actions로 일부 해결)

**적합한 경우**:
- 빠른 프로덕션 배포 (1주 이내)
- 운영 인력 부족 (DevOps 최소화)
- B2C 애플리케이션 (소셜 로그인 필수)
- 스타트업 (25K MAU 무료 활용)
- 규제 준수 필수 (HIPAA, PCI DSS)

**검증 사례**: Atlassian, Mozilla, Mazda, Schneider Electric

---

#### 옵션 2: AWS Cognito

**핵심 스펙**:
- **처리량**: 수백만 MAU 지원 (자동 스케일)
- **레이턴시**: <10ms (단일 리전)
- **가용성**: 99.9% SLA
- **비용**: Lite $0.0055/MAU (10K 무료), Essentials $0.015/MAU (10K 무료), Plus $0.02/MAU

**장점**:
- AWS 네이티브 통합 (Lambda, API Gateway, DynamoDB)
- 10K MAU 무료 (Lite, Essentials), 추가 비용 낮음
- 서버리스, 완전 관리형
- Cognito Identity Pools로 AWS 리소스 직접 접근
- IAM 통합 보안
- 예측 가능한 가격 (MAU 기반)

**단점**:
- AWS 벤더 락인 (멀티 클라우드 불가)
- UI/UX 제한적 (Hosted UI 커스터마이징 어려움)
- 문서 복잡함 (User Pools vs Identity Pools 혼란)
- Advanced Security Features 추가 비용 ($0.05/MAU)
- 크로스 리전 복제 미지원 (많은 사용자 요청 중)

**적합한 경우**:
- AWS 중심 인프라 (Lambda, API Gateway 사용)
- 서버리스 아키텍처
- 중간 규모 (10K~100K MAU)
- 예산 민감 (10K 무료 활용)
- 빠른 MVP 출시

**검증 사례**: 수많은 AWS 고객 (공개 사례 적음)

---

#### 옵션 3: Keycloak (Self-hosted / Managed)

**핵심 스펙**:
- **처리량**: 수만~수십만 MAU (클러스터 크기에 따라)
- **레이턴시**: <100ms (Self-hosted)
- **가용성**: 99.9%+ (HA 클러스터)
- **비용**: $0 (오픈소스) + 인프라 $510~$1,250/월 (Self-hosted), Managed $200~$1,000/월

**장점**:
- 완전한 커스터마이징 (소스 코드 접근)
- MAU 무제한 (인프라 비용만)
- 벤더 락인 없음 (온프레미스, 멀티 클라우드)
- 표준 프로토콜 (OIDC, OAuth2, SAML) 완벽 지원
- Active Directory, LDAP 통합
- Red Hat 상용 지원 가능 (Red Hat SSO)

**단점**:
- 높은 운영 부담 (HA 클러스터, DB, 모니터링)
- 배포 복잡도 (2~6개월 소요)
- 전문 인력 필요 (IAM 엔지니어 1~2명)
- 인프라 비용 (3×4 vCPU VM + 2×2 vCPU VM = $910/월)
- 유지보수 비용 (주 3시간 = $360/월)
- 러닝 커브 높음

**적합한 경우**:
- 대규모 사용자 (100K+ MAU, MAU 당 비용 회피)
- 온프레미스 필수 (금융, 정부, 의료)
- 완전한 제어 필요 (커스텀 인증 흐름)
- 장기 프로젝트 (5년+)
- 운영 역량 있는 팀

**검증 사례**: Red Hat, Cisco, CERN, 유럽 정부 기관

---

**의사결정 플로우차트**:
```
AWS 올인 환경?
├─ YES → 예산 < $500/월?
│   ├─ YES → AWS Cognito (옵션 2)
│   └─ NO → Auth0 (옵션 1)
└─ NO → MAU > 100K?
    ├─ YES → 운영 역량 있나?
    │   ├─ YES → Keycloak (옵션 3)
    │   └─ NO → Auth0 Enterprise (옵션 1)
    └─ NO → 빠른 배포 필요?
        ├─ YES → Auth0 (옵션 1)
        └─ NO → Keycloak Managed (옵션 3)
```

---

## Part 3: 도메인 선택 요소 (프로젝트별)

이 요소들은 **패밀리와 무관**하게 프로젝트 요구사항에 따라 선택합니다.

### 3.1 프론트엔드 프레임워크
- React, Vue, Angular, Svelte
- (패밀리 영향 없음, 팀 선호도 & 프로젝트 요구사항)

### 3.2 백엔드 언어/프레임워크
- Node.js (Express, NestJS), Python (FastAPI, Django), Java (Spring Boot), Go, C# (.NET)
- (패밀리 영향 적음, 팀 역량 & 성능 요구사항 우선)

### 3.3 인증/권한
- Auth0, AWS Cognito, Keycloak, Firebase Auth
- (패밀리 무관, 보안 요구사항 & 예산)

### 3.4 모니터링/로깅
- Prometheus + Grafana, ELK Stack, Datadog, New Relic, CloudWatch
- (패밀리 무관, 운영 선호도 & 예산)

### 3.5 ORM/쿼리 빌더
- TypeORM, Prisma, Sequelize (Node.js), SQLAlchemy (Python), JPA/Hibernate (Java)
- (DB 선택에 영향받음, 언어별 생태계)

---

## Part 4: Stage 2 통합

### 4.1 Layer 3 제약 반영 예시

**시나리오**: 전자상거래 주문 시스템

**Layer 3 제약 발견**:
- **팀 역량**: Python 팀 (Java 경험 부족)
- **인프라**: AWS 전용, 온프레미스 불가
- **예산**: 월 $500 이하
- **규정**: PCI DSS 준수 (결제 정보)

**기술 선택 영향**:
```
데이터베이스:
- CockroachDB (선호) → PostgreSQL RDS
- 이유: 예산 제약 ($360 vs $100), 다중 리전 불필요

캐시:
- Redis 유지
- 이유: 세션 관리 필수, PCI DSS 암호화 지원

메시징:
- Kafka (선호) → AWS SQS
- 이유: 예산 & 운영 간소화, AWS 전용 인프라
```

**재설계된 아키텍처**:
```
Frontend (React) → API Gateway
                      ↓
              Lambda (Python)
                      ↓
    PostgreSQL RDS + Redis ElastiCache + SQS
```

---

### 4.2 충돌 해결 예시

**NFR 목표 vs Layer 3 제약**:

**충돌 1**: 100% 정확성 A + 예산 $500/월
- **NFR**: Serializable 트랜잭션, 다중 리전
- **제약**: 예산 부족 (CockroachDB $360 최소)
- **해결**: PostgreSQL Serializable + 읽기 복제본 ($150/월)
  - 트레이드오프: 다중 리전 포기, 단일 리전 HA

**충돌 2**: 200ms 응답 A + Python 팀
- **NFR**: 캐싱, 읽기 복제본, 인덱싱
- **제약**: Python ORM 성능 (vs Java/Go)
- **해결**: Redis 적극 활용 + Async Python (FastAPI)
  - 읽기 90% 캐시 Hit, DB 부하 10%로 감소

**충돌 3**: 확장성 B + 메시징 경험 없음
- **NFR**: 비동기 처리, 서비스 분리
- **제약**: RabbitMQ/Kafka 학습 시간 부족
- **해결**: AWS SQS + Lambda (관리형)
  - 트레이드오프: AWS 종속, 처리량 제한 (3K/s)

---

### 4.3 ADR 작성 준비

**선택한 기술 스택 정리**:
```
Bootstrap 필수:
✅ DB: PostgreSQL RDS (db.t3.medium)
✅ 캐시: Redis ElastiCache (cache.t3.medium)
✅ 메시징: AWS SQS (Standard)

도메인 선택:
✅ 백엔드: Python 3.12 + FastAPI
✅ ORM: SQLAlchemy + Alembic
✅ 프론트엔드: React 18 + TypeScript
✅ 인증: AWS Cognito
✅ 모니터링: CloudWatch + Grafana
```

**ADR 작성 대상**:
1. **ADR-001**: PostgreSQL vs CockroachDB 선택 (예산 제약)
2. **ADR-002**: AWS SQS vs RabbitMQ 선택 (운영 간소화)
3. **ADR-003**: Redis 캐싱 전략 (Cache-Aside vs Write-Through)
4. **ADR-004**: Read Replicas 구성 (읽기 부하 분산)
5. **ADR-005**: Serializable 격리 수준 적용 범위 (성능 vs 정확성)

**각 ADR 포함 내용**:
- Context: 비즈니스 요구사항 & Layer 3 제약
- Decision: 선택한 기술 & 이유
- Consequences: 장단점, 트레이드오프
- Alternatives: 고려했던 다른 옵션

---

## 📚 참고 자료

### 벤치마크
- [PostgreSQL Performance Tuning](https://www.postgresql.org/docs/current/performance-tips.html)
- [MySQL Performance Documentation](https://dev.mysql.com/doc/refman/8.0/en/optimization.html)
- [Redis Benchmarks](https://redis.io/docs/latest/operate/oss_and_stack/management/optimization/benchmarks/)
- [RabbitMQ Performance Measurements](https://www.rabbitmq.com/blog/2012/04/25/rabbitmq-performance-measurements-part-2)

### 비용 계산기
- [AWS Pricing Calculator](https://calculator.aws.amazon.com/)
- [PlanetScale Pricing](https://planetscale.com/pricing)
- [Supabase Pricing](https://supabase.com/pricing)
- [Redis Cloud Pricing](https://redis.io/pricing/)

### 공식 문서
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [MySQL Documentation](https://dev.mysql.com/doc/)
- [CockroachDB Documentation](https://www.cockroachlabs.com/docs/)
- [Redis Documentation](https://redis.io/documentation)
- [RabbitMQ Documentation](https://www.rabbitmq.com/documentation.html)
- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [AWS SQS Documentation](https://docs.aws.amazon.com/sqs/)

### 검증 사례
- Amazon: [Amazon's Architecture](https://aws.amazon.com/architecture/)
- Stripe: [Stripe Engineering Blog](https://stripe.com/blog/engineering)
- Booking.com: [Booking.com Tech Blog](https://blog.booking.com/)
- Instagram: [Instagram Engineering Blog](https://instagram-engineering.com/)

---

**마지막 업데이트**: 2024-11-12  
**다음 검토**: 2025-02-12 (기술 스택 업데이트 반영)


### 2.5.2 API Gateway (DNA #9) - 라우팅 및 Rate Limiting ⭐⭐⭐

**패밀리 요구**:
- Rate Limiting - DDoS 방지, 서비스 보호
- 인증/권한 통합 - Identity 시스템과 연동
- API 버전 관리 - 배포 중단 없는 업그레이드
- 로드 밸런싱 - 트래픽 분산
- 모니터링 & 로깅 - 성능 추적, 디버깅

---

#### 옵션 1: Kong API Gateway

**핵심 스펙**:
- **처리량**: 100,000+ RPS (단일 노드)
- **레이턴시**: p99 <10ms (프록시 오버헤드)
- **Rate Limiting**: 초당 요청, 분당, 시간당 제한 가능
- **플러그인**: 50+ 공식 플러그인, 커스텀 Lua 플러그인
- **가용성**: 99.99% (클러스터 모드)

**비용**:
- **Kong Gateway OSS**: $0 (오픈소스)
- **Kong Konnect Free**: $0 (10 서비스)
- **Kong Konnect Plus**: $249/월 (무제한 서비스)
- **Kong Konnect Enterprise**: $2,500+/월 (고급 보안, 지원)
- **Self-hosted 인프라**: $200~$600/월 (3노드 HA)

**장점**:
- 고성능 (Nginx 기반, LuaJIT)
- 풍부한 플러그인 생태계 (인증, Rate Limiting, Transformation)
- Kubernetes 네이티브 (Kong Ingress Controller)
- 활발한 커뮤니티, 15년+ 검증
- Declarative 설정 (YAML/JSON)
- 멀티 프로토콜 (HTTP, gRPC, WebSocket, TCP/UDP)
- DB-less 모드 지원 (설정 파일 기반)

**단점**:
- Lua 학습 필요 (커스텀 플러그인 시)
- Enterprise 기능 고가 (RBAC, 분석)
- 클러스터 설정 복잡도 (PostgreSQL/Cassandra 필요)
- 메모리 사용량 높음 (150~300MB per 인스턴스)

**적합한 경우**:
- Kubernetes 환경 (Ingress Controller)
- 고성능 필수 (100K+ RPS)
- 플러그인 확장성 필요
- 오픈소스 우선 (벤더 락인 회피)
- 장기 프로젝트 (5년+)

**검증 사례**: NASA, Cisco, Samsung, Yahoo, T-Mobile

---

#### 옵션 2: AWS API Gateway

**핵심 스펙**:
- **처리량**: 10,000 RPS (기본), Throttling 설정 가능
- **레이턴시**: <50ms (통합 지연 포함)
- **Rate Limiting**: 계정당, API당, 메서드당 설정
- **통합**: Lambda, EC2, HTTP 엔드포인트
- **가용성**: 99.95% SLA (REST API), 99.99% (HTTP API)

**비용**:
- **HTTP API**: $1.00 per 1M requests
- **REST API**: $3.50 per 1M requests
- **WebSocket API**: $1.00 per 1M messages
- **월 예상** (100만 요청): $1~$3.50
- **추가 비용**: 데이터 전송, CloudWatch 로그

**장점**:
- 완전 관리형 (운영 부담 제로)
- AWS 네이티브 통합 (Lambda, Cognito, IAM)
- 자동 스케일링 (무제한 트래픽)
- 빠른 배포 (5~10분 설정)
- 저렴한 비용 (HTTP API $1/1M 요청)
- API Keys, Usage Plans 내장
- OpenAPI 스펙 지원

**단점**:
- AWS 벤더 락인 (멀티 클라우드 불가)
- 10K RPS 초과 시 AWS 지원팀 요청 필요
- 고급 Rate Limiting 제한적 (IP 기반만)
- WebSocket 30분 연결 제한
- 복잡한 변환 로직 어려움
- Latency 증가 가능 (통합 오버헤드)

**적합한 경우**:
- AWS 중심 인프라
- 서버리스 아키텍처 (Lambda)
- 빠른 MVP 출시 (1주 이내)
- 운영 최소화 우선
- 중소 규모 (10K RPS 이하)

**검증 사례**: Expedia, Coca-Cola, Change.org (공식 사례 다수)

---

#### 옵션 3: Traefik

**핵심 스펙**:
- **처리량**: 50,000~80,000 RPS (단일 노드)
- **레이턴시**: p99 <5ms (매우 낮은 오버헤드)
- **Rate Limiting**: 평균 요청률, 버스트 제한
- **자동 발견**: Docker, Kubernetes, Consul 자동 감지
- **가용성**: 99.9%+ (HA 구성 시)

**비용**:
- **Traefik OSS**: $0 (오픈소스)
- **Traefik Enterprise**: $2,000~$10,000/년 (클러스터당)
- **Self-hosted 인프라**: $100~$400/월 (2~3노드)

**장점**:
- 클라우드 네이티브 (Kubernetes, Docker 자동 발견)
- 자동 HTTPS (Let's Encrypt)
- 실시간 설정 업데이트 (재시작 불필요)
- 매우 가벼움 (50MB 메모리)
- Go 기반 (단일 바이너리, 배포 간편)
- 직관적 웹 UI (Traefik Dashboard)
- 멀티 프로토콜 (HTTP, gRPC, TCP, UDP)

**단점**:
- 플러그인 생태계 작음 (Kong 대비)
- 문서 분산 (v1, v2, v3 차이)
- Enterprise 기능 제한적 (Rate Limiting은 Enterprise만)
- 커뮤니티 작음 (Kong 대비)
- 고급 Rate Limiting 부족 (Redis 기반 분산 X)

**적합한 경우**:
- Kubernetes/Docker 환경
- 마이크로서비스 아키텍처
- 가벼운 게이트웨이 선호
- 자동 발견 필수
- 예산 최소화 (<$500/월)

**검증 사례**: Zed, Containous, 수많은 K8s 프로젝트

---

#### API Gateway 비교표

| 항목 | Kong | AWS API Gateway | Traefik |
|------|------|-----------------|---------|
| **처리량** | 100K+ RPS | 10K RPS (기본) | 50K~80K RPS |
| **레이턴시** | <10ms | <50ms | <5ms |
| **비용 (중규모)** | $200~$600/월 | $100~$500/월 | $100~$400/월 |
| **Rate Limiting** | ⭐⭐⭐ 고급 | ⭐⭐ 기본 | ⭐⭐ 기본 |
| **플러그인** | ⭐⭐⭐ 풍부 | AWS 통합 | ⭐⭐ 제한적 |
| **K8s 통합** | ⭐⭐⭐ 네이티브 | 가능 | ⭐⭐⭐ 네이티브 |
| **운영** | ⚙️⚙️ 중간 | ⚙️ 낮음 (관리형) | ⚙️⚙️ 중간 |
| **벤더 락인** | ❌ 없음 | ⚠️ AWS | ❌ 없음 |

**의사결정 플로우차트**:
```
AWS 올인 환경?
├─ YES → 서버리스 (Lambda)?
│   ├─ YES → AWS API Gateway (옵션 2)
│   └─ NO → Kong (옵션 1)
└─ NO → Kubernetes 환경?
    ├─ YES → 예산 < $500/월?
    │   ├─ YES → Traefik (옵션 3)
    │   └─ NO → 처리량 > 80K RPS?
    │       ├─ YES → Kong (옵션 1)
    │       └─ NO → Traefik (옵션 3)
    └─ NO → 플러그인 필수?
        ├─ YES → Kong (옵션 1)
        └─ NO → Traefik (옵션 3)
```

---

### 2.5.3 Error Handling (DNA #5) - 트랜잭션 롤백 및 보상 ⭐⭐⭐

**패밀리 요구**:
- 트랜잭션 롤백 메커니즘 - 전체 작업 취소
- 보상 트랜잭션 (Compensating Transaction) - 분산 트랜잭션 실패 복구
- 3-Level 에러 전략 - Domain, Application, Infrastructure 구분
- Context 전파 - 에러 원인 추적
- 타입 안전성 - 컴파일 타임 검증 (선택적)

---

#### 옵션 1: Custom Error Types (언어 표준)

**핵심 스펙**:
- **타입 안전성**: TypeScript/Rust에서 완벽한 타입 체킹
- **성능**: 제로 오버헤드 (런타임 비용 없음)
- **유연성**: 프로젝트 요구사항에 정확히 맞춤
- **학습 곡선**: 중간 (타입 시스템 이해 필요)

**비용**:
- $0 (언어 표준 기능)

**장점**:
- 완전한 제어 (에러 구조, 메시지 형식)
- 타입 안전성 (컴파일 타임 검증)
- 도메인 특화 에러 (비즈니스 로직 반영)
- 제로 의존성 (외부 라이브러리 불필요)
- 성능 최적화 가능
- IDE 자동완성 지원
- 디버깅 용이 (명확한 에러 타입)

**단점**:
- 보일러플레이트 코드 많음
- 각 에러마다 타입 정의 필요
- 팀 컨벤션 통일 어려움
- 에러 변환 수동 구현
- Backtrace 수동 관리

**적합한 경우**:
- 복잡한 도메인 로직 (수십 개 에러 타입)
- 타입 안전성 최우선
- 외부 의존성 최소화
- 팀 역량 높음 (타입 시스템 숙달)
- 장기 프로젝트 (유지보수 고려)

**검증 사례**: 대부분의 TypeScript/Rust 엔터프라이즈 프로젝트

**예시 (TypeScript)**:
```typescript
// 도메인별 에러 정의
class OrderError extends Error {
  constructor(
    message: string,
    public code: string,
    public details?: unknown
  ) {
    super(message);
    this.name = 'OrderError';
  }
}

class PaymentError extends Error {
  constructor(
    message: string,
    public transactionId: string,
    public amount: number
  ) {
    super(message);
    this.name = 'PaymentError';
  }
}

// 사용 예시
async function createOrder(data: OrderData): Promise<Order> {
  if (!data.items.length) {
    throw new OrderError('Empty order', 'ORDER_EMPTY');
  }
  
  try {
    const payment = await processPayment(data);
    return await saveOrder(data, payment);
  } catch (e) {
    if (e instanceof PaymentError) {
      // 보상 트랜잭션: 재고 복구
      await restoreInventory(data.items);
      throw new OrderError(
        'Payment failed',
        'PAYMENT_FAILED',
        { transactionId: e.transactionId }
      );
    }
    throw e;
  }
}
```

---

#### 옵션 2: thiserror (Rust 전용)

**핵심 스펙**:
- **타입 안전성**: 완벽한 컴파일 타임 검증
- **성능**: Zero-cost abstraction
- **derive 매크로**: 자동 Error trait 구현
- **Backtrace**: 자동 캡처 (nightly)

**비용**:
- $0 (오픈소스)

**장점**:
- 간결한 코드 (#[derive(Error)] 한 줄)
- 자동 Display 구현 (포맷 문자열)
- 자동 From 구현 (#[from] 속성)
- Backtrace 자동 전파
- 타입 안전성 (Result<T, E>)
- 제로 런타임 오버헤드
- IDE 자동완성 우수

**단점**:
- Rust 전용 (다른 언어 불가)
- nightly 컴파일러 필요 (Backtrace 기능)
- derive 매크로 학습 필요
- 복잡한 에러 계층 시 코드 길어짐

**적합한 경우**:
- Rust 프로젝트
- 타입 안전성 최우선
- 보일러플레이트 최소화
- 고성능 필수 (금융, 실시간)
- 팀이 Rust 숙련

**검증 사례**: Tokio, Serde, Actix, rust-analyzer

**예시 (Rust)**:
```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum OrderError {
    #[error("order is empty")]
    EmptyOrder,
    
    #[error("payment failed: {transaction_id}")]
    PaymentFailed {
        transaction_id: String,
        #[from]
        source: PaymentError,
    },
    
    #[error("inventory insufficient for item {item_id}")]
    InsufficientInventory {
        item_id: String,
        required: u32,
        available: u32,
    },
}

#[derive(Error, Debug)]
#[error("payment error: {message}")]
pub struct PaymentError {
    message: String,
    amount: f64,
}

// 사용 예시
async fn create_order(data: OrderData) -> Result<Order, OrderError> {
    if data.items.is_empty() {
        return Err(OrderError::EmptyOrder);
    }
    
    let payment = process_payment(&data)
        .await?; // PaymentError 자동 변환 (From impl)
    
    save_order(data, payment).await
}
```

---

#### 옵션 3: anyhow (Rust 전용)

**핵심 스펙**:
- **유연성**: 모든 에러 타입 수용
- **Context**: 에러 체인, 메시지 추가
- **Backtrace**: 자동 캡처
- **간편함**: 빠른 프로토타이핑

**비용**:
- $0 (오픈소스)

**장점**:
- 극도로 간단 (anyhow::Result<T> 만으로 충분)
- Context 체이닝 (.context() 메서드)
- Downcast 지원 (특정 에러 타입 검사)
- Backtrace 자동 포함
- ? 연산자 편리 (모든 에러 자동 전파)
- 빠른 프로토타이핑
- 학습 곡선 낮음

**단점**:
- 타입 안전성 약함 (anyhow::Error는 trait object)
- 라이브러리에 부적합 (API 경계에서 타입 정보 손실)
- 에러 타입 구별 어려움 (Downcast 필요)
- 애플리케이션 전용 (라이브러리는 thiserror 권장)

**적합한 경우**:
- 빠른 프로토타이핑 (MVP, POC)
- 애플리케이션 코드 (라이브러리 아님)
- 간편함 최우선
- 에러 타입 구별 불필요
- 팀이 Rust 초보

**검증 사례**: 많은 Rust CLI 도구, 애플리케이션

**예시 (Rust)**:
```rust
use anyhow::{Context, Result, bail};

async fn create_order(data: OrderData) -> Result<Order> {
    if data.items.is_empty() {
        bail!("Order cannot be empty");
    }
    
    let payment = process_payment(&data)
        .await
        .context("Failed to process payment")?;
    
    save_order(data, payment)
        .await
        .with_context(|| {
            format!("Failed to save order for user {}", data.user_id)
        })
}

// 에러 핸들링
match create_order(data).await {
    Ok(order) => println!("Order created: {}", order.id),
    Err(e) => {
        eprintln!("Error: {:?}", e);
        // 에러 체인 출력
        for cause in e.chain() {
            eprintln!("  Caused by: {}", cause);
        }
    }
}
```

---

#### Error Handling 비교표

| 항목 | Custom Types | thiserror | anyhow |
|------|--------------|-----------|--------|
| **타입 안전성** | ⭐⭐⭐ 완벽 | ⭐⭐⭐ 완벽 | ⭐⭐ 약함 |
| **보일러플레이트** | ⚠️ 많음 | ⭐⭐⭐ 적음 | ⭐⭐⭐ 최소 |
| **학습 곡선** | 중간 | 중간 | ⭐⭐⭐ 낮음 |
| **성능** | ⭐⭐⭐ 최고 | ⭐⭐⭐ 최고 | ⭐⭐ 약간 오버헤드 |
| **Backtrace** | 수동 | ⭐⭐⭐ 자동 | ⭐⭐⭐ 자동 |
| **Context 전파** | 수동 | 수동 | ⭐⭐⭐ 자동 |
| **라이브러리 적합** | ⭐⭐⭐ 우수 | ⭐⭐⭐ 우수 | ❌ 부적합 |
| **언어 지원** | 모든 언어 | Rust만 | Rust만 |

**의사결정 플로우차트 (Rust 프로젝트)**:
```
라이브러리 개발?
├─ YES → thiserror (옵션 2)
└─ NO → 빠른 프로토타이핑?
    ├─ YES → anyhow (옵션 3)
    └─ NO → 복잡한 에러 계층?
        ├─ YES → 타입 안전성 필수?
        │   ├─ YES → thiserror (옵션 2)
        │   └─ NO → anyhow (옵션 3)
        └─ NO → 간편함 우선?
            ├─ YES → anyhow (옵션 3)
            └─ NO → thiserror (옵션 2)
```

**의사결정 플로우차트 (TypeScript/JavaScript)**:
```
Custom Error Types (옵션 1) 사용
- 표준 Error 클래스 확장
- 도메인별 에러 클래스 정의
- Result<T, E> 패턴 고려 (ts-results 라이브러리)
```

---



================================================================================

📄 FILE: 03_collaboration_sync_tech_options.md
--------------------------------------------------------------------------------

# 협업/동기화 패밀리 (B-A-A) - 기술 매트릭스

**작성일**: 2025-11-12  
**패밀리**: 협업/동기화 (B-A-A)  
**검증 사례**: Google Docs (OT), Figma (CRDT), Notion (블록 편집)

---

## Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐

### 1.1 B-A-A 특성이 강제하는 것

#### B (점진적 실패) → 최종 일관성 필수

**특성**:
- 일부 사용자가 일시적으로 구형 데이터 표시 허용
- 낙관적 업데이트 (Optimistic UI)
- 충돌 자동 해결 또는 수동 병합
- Eventual Consistency

**강제되는 기술적 요구**:
```
✅ 충돌 해결 메커니즘 (CRDT, OT, Last-Write-Wins)
✅ 버전 관리 시스템
✅ 동기화 프로토콜
✅ 오프라인 편집 지원
```

**검증 사례**:
- Google Docs: Operational Transformation, 200ms 네트워크 지연 허용
- Notion: 블록 기반 최종 일관성, 낙관적 업데이트

---

#### A (구조화 데이터) → 스키마 기반 DB 필수

**특성**:
- 문서, 텍스트, 구조화된 블록
- 고정 스키마 또는 반구조화 JSON
- 트랜잭션 보장 (일부)
- 관계형 쿼리

**강제되는 기술적 요구**:
```
✅ RDBMS (PostgreSQL, MySQL)
✅ Document versioning
✅ Foreign key constraints
✅ ACID 트랜잭션 (선택적)
```

**검증 사례**:
- Notion: 블록 기반 구조, PostgreSQL 백엔드
- Figma: 파일 메타데이터 RDBMS 저장, 디자인 변경은 별도 처리

---

#### A (밀리초~초 응답) → 실시간 통신 필수

**특성**:
- 0~200ms 체감 지연 (사용자 느낌)
- 양방향 실시간 통신
- 다중 사용자 동시 작업
- 변경 사항 즉시 전파

**강제되는 기술적 요구**:
```
✅ WebSocket 또는 유사 기술
✅ Pub/Sub 메커니즘
✅ 사용자 프레즌스 추적
✅ 인메모리 캐시
```

**검증 사례**:
- Figma: WebSocket 기반, 문서당 별도 프로세스, 밀리초급 응답
- Linear: 실시간 이슈 업데이트, 다중 사용자 동시 편집

---

### 1.2 이 패밀리에 필요한 DNA 시스템 및 메인 서비스

#### DNA 11개 시스템 중 필요한 것

B-A-A 패밀리는 다음 DNA 시스템이 필요합니다:

| DNA 시스템 | 중요도 | 이유 |
|-----------|-------|------|
| 1. Testing | ✅ 필수 | CRDT/OT 로직 검증 |
| 2. Code Quality | ✅ 필수 | 비동기 코드 품질 유지 |
| 3. Architecture | ✅ 필수 | 동기화 모듈 분리 |
| 4. Type System | ✅ 필수 | 문서 구조 타입 안전성 |
| 5. Error Handling | ✅ 필수 | 연결 끊김, 충돌 처리 |
| 6. Configuration | ✅ 필수 | WebSocket 설정, 타임아웃 |
| 7. **Identity & Access** | **⭐⭐⭐ 매우 중요** | **실시간 프레즌스, 세션 공유, 권한 동기화** |
| 8. Observability | ✅ 필수 | 동시 편집자 수, 동기화 지연 모니터링 |
| 9. **API Gateway** | **⭐⭐⭐ 매우 중요** | **WebSocket 터널링, 양방향 통신, 백프레셔** |
| 10. Resilience | ✅ 필수 | 재연결, 충돌 복구 |
| 11. **Performance** | **⭐⭐⭐ 매우 중요** | **0ms 체감 레이턴시, 동시 편집자 벤치마크** |

**특별히 중요한 DNA 시스템 (⭐⭐⭐)**:
- **Identity & Access**: 다중 디바이스 세션 동기화, 사용자 프레즌스 추적 필수
- **API Gateway**: WebSocket 프록시, 연결 관리, 로드 밸런싱 필수
- **Performance**: Google Docs 수준 (200ms 네트워크 허용) 달성 위해 지속적 최적화

→ **Part 2.5에서 이 3가지 DNA 시스템의 기술 옵션을 다룹니다.**

#### 메인 서비스 필수 요소 (패밀리 강제)

B-A-A 패밀리는 다음 4가지 메인 서비스 기술을 **반드시** 포함해야 합니다:

#### 1. RDBMS (필수!)
**역할**: 권위 있는 상태 저장, 메타데이터 관리
**이유**: 구조화 데이터(A) + 트랜잭션 보장
**선택지**: PostgreSQL, MySQL, CockroachDB

#### 2. WebSocket/실시간 통신 (필수!)
**역할**: 양방향 실시간 데이터 전송
**이유**: 밀리초 응답(A) + 다중 사용자 동시 작업
**선택지**: Socket.io, Native WebSocket, Server-Sent Events

#### 3. 동기화 엔진 (필수!)
**역할**: 충돌 해결, 상태 병합
**이유**: 점진적 실패(B) + 최종 일관성
**선택지**: Yjs, Automerge, 자체 구현(OT/CRDT)

#### 4. 캐시 레이어 (필수!)
**역할**: 빠른 읽기, 사용자 프레즌스 추적
**이유**: 밀리초 응답(A)
**선택지**: Redis, Memcached

---

## Part 2: 메인 서비스 기술 선택 ⭐⭐⭐

### 2.1 RDBMS 선택

**패밀리 요구**:
- 권위 있는 상태 저장
- 버전 히스토리 관리
- 메타데이터 쿼리
- 트랜잭션 보장

---

#### 옵션 1: PostgreSQL

**핵심 스펙**:
- **처리량**: 초당 1만~10만 트랜잭션 (pgbench 기준)
- **레이턴시**: 평균 15ms (TPC-B 벤치마크)
- **동시 접속**: 100~1000 커넥션 (connection pooling)
- **스토리지**: TB급 문서, JSON 네이티브 지원

**비용**:
- **Self-hosted**: 월 $100~$1,000 (t3.medium~m5.xlarge)
- **AWS RDS**: 월 $70~$2,000 (db.t3.medium~db.r5.xlarge)
- **Azure Database**: 월 $60~$1,800

**장점**:
- 🔧 Full SQL 지원, 복잡한 쿼리 가능
- 📦 JSON/JSONB 네이티브, 반구조화 데이터 유연
- 🔒 ACID 트랜잭션, 데이터 무결성
- 🌐 풍부한 생태계, 검증된 안정성

**단점**:
- 📈 수직 확장 중심, 수평 확장 어려움
- 💰 관리형 서비스 비용 높음
- 🔧 세밀한 튜닝 필요 (인덱스, 쿼리 최적화)

**적합한 경우**:
- 중대형 프로젝트 (1,000+ 동시 사용자)
- 복잡한 쿼리 필요 (보고서, 분석)
- JSON 문서 + 관계형 혼합
- ACID 보장 필수

**검증 사례**: Notion, Linear, Dropbox Paper

---

#### 옵션 2: MySQL

**핵심 스펙**:
- **처리량**: 초당 5,000~50,000 트랜잭션
- **레이턴시**: 평균 10~20ms
- **동시 접속**: 100~500 커넥션 권장
- **스토리지**: TB급, InnoDB 엔진

**비용**:
- **Self-hosted**: 월 $50~$800
- **AWS RDS**: 월 $50~$1,500
- **Google Cloud SQL**: 월 $40~$1,200

**장점**:
- 💰 저렴한 비용, 널리 사용됨
- 🚀 빠른 읽기 성능 (InnoDB)
- 🔧 간단한 설정, 낮은 학습 곡선
- 📚 방대한 커뮤니티, 레퍼런스

**단점**:
- 📊 PostgreSQL 대비 부족한 기능 (JSON, Full-text)
- 🔒 트랜잭션 처리 제한적
- 📈 대규모 확장 어려움

**적합한 경우**:
- 소중형 프로젝트 (100~1,000 사용자)
- 예산 $500/월 이하
- 단순한 스키마
- 빠른 MVP 출시

**검증 사례**: Basecamp, GitHub (초기), WordPress 기반 협업 도구

---

#### 옵션 3: CockroachDB

**핵심 스펙**:
- **처리량**: 초당 10만+ 트랜잭션 (분산 환경)
- **레이턴시**: 평균 10~50ms (지역 간 100ms+)
- **확장**: 선형 수평 확장
- **가용성**: 99.99% (멀티 리전)

**비용**:
- **Serverless**: $1/GB 저장, $0.50/10M RU
- **Dedicated**: 월 $295~$5,000+
- **Self-hosted**: 월 $500~$3,000 (3노드 클러스터)

**장점**:
- 📈 무제한 수평 확장
- 🌍 멀티 리전, 지리적 분산
- 🔒 강한 일관성 + 고가용성
- 🔄 PostgreSQL 호환 (95%)

**단점**:
- 💰 높은 비용 (대규모 시)
- ⏱️ 지역 간 레이턴시 증가
- 🔧 복잡한 운영 (분산 시스템)
- 🆕 상대적 신생, 생태계 작음

**적합한 경우**:
- 글로벌 서비스 (멀티 리전 필수)
- 무제한 확장 필요
- 고가용성 99.99%+ 요구
- 예산 $5,000/월+ 가능

**검증 사례**: Figma (부분적), LaunchDarkly

---

#### RDBMS 비교표

| 항목 | PostgreSQL | MySQL | CockroachDB |
|------|-----------|-------|-------------|
| **처리량** | 10K~100K/s | 5K~50K/s | 100K+/s |
| **레이턴시** | 15ms | 10~20ms | 10~50ms |
| **확장** | 수직 | 수직 | 수평 |
| **비용** | $100~$2K/월 | $50~$1.5K/월 | $500~$5K/월 |
| **운영** | ⚙️⚙️ 중간 | ⚙️ 낮음 | ⚙️⚙️⚙️ 높음 |
| **JSON 지원** | JSONB (우수) | JSON (제한) | JSONB (우수) |

**의사결정 가이드**:
```
글로벌 멀티 리전? → CockroachDB
  └─ NO
     ↓
복잡한 쿼리/JSON 많음? → PostgreSQL
  └─ NO
     ↓
예산 <$500/월? → MySQL
  └─ NO → PostgreSQL
```

---

### 2.2 WebSocket/실시간 통신 선택

**패밀리 요구**:
- 양방향 실시간 통신
- 다중 사용자 지원
- 낮은 레이턴시 (<100ms)
- 자동 재연결

---

#### 옵션 1: Socket.io

**핵심 스펙**:
- **레이턴시**: 50~150ms (네트워크 포함)
- **동시 접속**: 1만~10만 (단일 서버)
- **fallback**: HTTP Long-polling 자동
- **처리량**: 초당 10만+ 메시지

**비용**:
- **Self-hosted**: 월 $100~$1,000 (t3.medium~m5.xlarge)
- **Heroku**: 월 $25~$500 (Dyno)
- **DigitalOcean**: 월 $12~$160

**장점**:
- 🚀 자동 재연결, Fallback 내장
- 🔧 Room, Namespace 기능 내장
- 📦 풍부한 에코시스템, 클라이언트 라이브러리
- 🔗 Broadcasting, Acknowledgements 간편

**단점**:
- 💰 메모리 사용 높음 (연결당 ~100KB)
- 📈 대규모는 Redis Adapter 필요
- ⚡ native WebSocket 대비 약간 느림
- 🔧 프로토콜 오버헤드

**적합한 경우**:
- 중소 규모 (1,000~10,000 동시 접속)
- 빠른 개발 우선
- Fallback 필수 (방화벽 환경)
- Room 기능 활용

**검증 사례**: Figma (초기), Slack (초기), 다수 스타트업

---

#### 옵션 2: Native WebSocket

**핵심 스펙**:
- **레이턴시**: 10~50ms (네트워크 포함)
- **동시 접속**: 5만~20만 (단일 서버)
- **처리량**: 초당 50만+ 메시지
- **메모리**: 연결당 ~10KB

**비용**:
- **Self-hosted**: 월 $50~$800 (경량)
- **AWS ELB**: 월 $20~$300 (트래픽 기반)
- **Nginx**: 월 $30~$500 (프록시)

**장점**:
- ⚡ 최고 성능, 최소 오버헤드
- 💰 낮은 메모리 사용
- 🔧 완전한 제어, 커스터마이징 가능
- 📡 표준 프로토콜, 브라우저 네이티브

**단점**:
- 🔨 Room, Broadcasting 직접 구현
- 🔄 재연결 로직 수동 구현
- 📦 생태계 작음, 보일러플레이트 많음
- 🚫 Fallback 없음

**적합한 경우**:
- 대규모 (10,000+ 동시 접속)
- 최고 성능 필수
- 커스텀 프로토콜 필요
- 직접 제어 선호

**검증 사례**: Google Docs (WebSocket + 자체 프로토콜), Figma (현재)

---

#### 옵션 3: Server-Sent Events (SSE)

**핵심 스펙**:
- **레이턴시**: 50~200ms
- **동시 접속**: 1만~5만 (단일 서버)
- **방향**: 서버 → 클라이언트 단방향
- **Fallback**: HTTP 기반, 방화벽 통과 용이

**비용**:
- **Self-hosted**: 월 $50~$500
- **Cloudflare Workers**: 월 $5~$50 (100K 요청)
- **Vercel**: 월 $20~$300

**장점**:
- 🔥 단순함, HTTP 기반
- 🔓 방화벽 통과 용이
- 🔄 자동 재연결 내장
- 💰 저렴한 비용

**단점**:
- 🚫 단방향 (서버 → 클라이언트만)
- 📈 제한된 확장성
- 🔧 클라이언트 → 서버는 HTTP POST
- ⏱️ 상대적 높은 레이턴시

**적합한 경우**:
- 단방향 업데이트만 (알림, 피드)
- 소규모 (100~1,000 사용자)
- 방화벽 제약 심함
- 단순한 아키텍처 선호

**검증 사례**: GitHub (알림), Linear (일부 업데이트)

---

#### WebSocket 비교표

| 항목 | Socket.io | Native WebSocket | SSE |
|------|----------|------------------|-----|
| **레이턴시** | 50~150ms | 10~50ms | 50~200ms |
| **동시 접속** | 10K~100K | 50K~200K | 10K~50K |
| **방향** | 양방향 | 양방향 | 단방향 |
| **비용** | $100~$1K/월 | $50~$800/월 | $50~$500/월 |
| **복잡도** | ⚙️ 낮음 | ⚙️⚙️⚙️ 높음 | ⚙️ 낮음 |

**의사결정 가이드**:
```
양방향 필수? 
  └─ NO → SSE
  └─ YES
     ↓
동시 접속 > 10,000? → Native WebSocket
  └─ NO
     ↓
빠른 개발 우선? → Socket.io
  └─ NO → Native WebSocket
```

---

### 2.3 동기화 엔진 선택

**패밀리 요구**:
- 충돌 자동 해결
- 오프라인 편집 지원
- 버전 관리
- 효율적 델타 동기화

---

#### 옵션 1: Yjs (CRDT)

**핵심 스펙**:
- **동기화 방식**: CRDT (Conflict-free Replicated Data Types)
- **레이턴시**: <10ms (로컬 병합)
- **네트워크**: Binary encoding, 효율적 델타
- **자료구조**: Text, Map, Array, XML

**비용**:
- **오픈소스**: 무료
- **Hocuspocus (서버)**: Self-hosted, 월 $50~$500
- **Y-Sweet (관리형)**: 월 $100~$2,000

**장점**:
- ⚡ 수학적으로 보장된 수렴
- 🔄 오프라인 편집 완벽 지원
- 📦 풍부한 자료구조, 확장 가능
- 🔧 Provider 다양 (WebSocket, WebRTC, IndexedDB)

**단점**:
- 📚 학습 곡선, CRDT 이해 필요
- 💾 메모리 사용 높음 (히스토리 보관)
- 🔧 복잡한 충돌 시나리오 예측 어려움
- 🚫 의미 보존 제한 (텍스트 편집 외)

**적합한 경우**:
- 텍스트 편집 중심 (문서, 코드)
- 오프라인 필수
- 자동 충돌 해결 우선
- 대규모 동시 편집

**검증 사례**: Notion (블록), CodeMirror, ProseMirror 통합

---

#### 옵션 2: Automerge (CRDT)

**핵심 스펙**:
- **동기화 방식**: CRDT (JSON-like)
- **레이턴시**: <20ms (로컬 병합)
- **네트워크**: Columnar encoding, 압축
- **자료구조**: JSON 호환 (Object, Array, Text)

**비용**:
- **오픈소스**: 무료
- **Automerge-Repo (서버)**: Self-hosted, 월 $50~$300

**장점**:
- 📄 JSON 친화적, 익숙한 API
- 🔒 강한 일관성, 수학적 보장
- 🔧 Time-travel, 버전 히스토리
- 🌐 P2P 동기화 지원

**단점**:
- ⏱️ 상대적 느림 (Yjs 대비)
- 💾 높은 메모리 사용 (전체 히스토리)
- 📦 생태계 작음, 커뮤니티 작음
- 🆕 상대적 신생, 프로덕션 사례 적음

**적합한 경우**:
- JSON 문서 중심 (설정, 메타데이터)
- Time-travel 필요
- P2P 아키텍처
- 강한 일관성 보장

**검증 사례**: Actual Budget, Pushpin, 일부 분산 앱

---

#### 옵션 3: 자체 구현 (OT/Last-Write-Wins)

**핵심 스펙**:
- **동기화 방식**: Operational Transformation 또는 LWW
- **레이턴시**: <5ms (로컬 적용)
- **네트워크**: 커스텀 프로토콜
- **복잡도**: 높음, 직접 구현

**비용**:
- **개발 비용**: 1~6개월 (엔지니어 투입)
- **운영 비용**: 월 $50~$500 (서버)

**장점**:
- 🎯 완전한 제어, 도메인 최적화
- ⚡ 최고 성능 가능 (최적화 시)
- 💰 라이선스 비용 없음
- 🔧 커스텀 충돌 전략

**단점**:
- 🔨 높은 개발 비용, 유지보수 부담
- 🐛 버그 위험, 엣지 케이스 많음
- 📚 전문 지식 필요 (OT, CRDT)
- ⏱️ 긴 개발 시간 (1~6개월)

**적합한 경우**:
- 특수 요구사항 (CRDT로 불가능)
- 장기 프로젝트, 전담 팀
- 레거시 시스템 통합
- 특정 도메인 로직

**검증 사례**: Google Docs (OT), Figma (LWW + 중앙 서버)

---

#### 동기화 엔진 비교표

| 항목 | Yjs | Automerge | 자체 구현 |
|------|-----|-----------|----------|
| **병합 속도** | <10ms | <20ms | <5ms (최적화 시) |
| **메모리** | 높음 | 매우 높음 | 낮음~중간 |
| **충돌 해결** | 자동 (CRDT) | 자동 (CRDT) | 수동/커스텀 |
| **개발 비용** | 낮음 | 낮음 | 매우 높음 |
| **생태계** | 풍부 | 작음 | 없음 |

**의사결정 가이드**:
```
텍스트 편집 중심? → Yjs
  └─ NO
     ↓
JSON 문서 + Time-travel? → Automerge
  └─ NO
     ↓
특수 요구사항 + 전담 팀? → 자체 구현
  └─ NO → Yjs (범용)
```

---

### 2.4 캐시 레이어 선택

**패밀리 요구**:
- 밀리초 미만 응답
- 사용자 프레즌스 추적
- 세션 관리
- Pub/Sub

---

#### 옵션 1: Redis

**핵심 스펙**:
- **레이턴시**: 0.15ms (GET)
- **처리량**: 초당 120만 트랜잭션
- **자료구조**: String, Hash, List, Set, Sorted Set (5가지)
- **기능**: Pub/Sub, 지속성 (AOF, RDB)

**비용**:
- **Self-hosted**: 월 $50~$500
- **AWS ElastiCache**: 월 $50~$1,000
- **Redis Cloud**: 월 $30~$2,000

**장점**:
- ⚡ 초고속, 다양한 자료구조
- 🔔 Pub/Sub 내장, Broadcasting 용이
- 💾 지속성 옵션, 데이터 손실 방지
- 📦 풍부한 클라이언트 라이브러리

**단점**:
- 💰 메모리 기반, 비용 높음
- 🔧 단일 스레드, CPU 1코어만 사용
- 📈 클러스터 설정 복잡 (대규모 시)

**적합한 경우**:
- 대부분의 협업 시스템
- Pub/Sub 필요
- 복잡한 캐시 로직
- 사용자 프레즌스 추적

**검증 사례**: GitHub, Figma, Linear

---

#### 옵션 2: Memcached

**핵심 스펙**:
- **레이턴시**: <0.1ms
- **처리량**: 초당 100만+ operations
- **자료구조**: Key-Value만
- **멀티 스레드**: CPU 멀티코어 활용

**비용**:
- **Self-hosted**: 월 $30~$300
- **AWS ElastiCache**: 월 $30~$500

**장점**:
- ⚡ 극도로 빠름, 단순함
- 💰 저렴한 비용
- 🔧 멀티 스레드, CPU 효율
- 📉 낮은 메모리 오버헤드

**단점**:
- 📊 단순한 자료구조 (Key-Value만)
- 🚫 Pub/Sub 없음
- 💾 지속성 없음, 재시작 시 데이터 손실

**적합한 경우**:
- 단순 캐싱만
- 최소 비용
- 초고속 필수
- Pub/Sub 불필요

---

#### 캐시 비교표

| 항목 | Redis | Memcached |
|------|-------|-----------|
| **레이턴시** | 0.15ms | <0.1ms |
| **자료구조** | 다양 | Key-Value |
| **Pub/Sub** | 있음 | 없음 |
| **비용** | 중간 | 낮음 |

**의사결정 가이드**:
```
Pub/Sub 필요? → Redis
  └─ NO
     ↓
복잡한 자료구조? → Redis
  └─ NO → Memcached
```

---

## Part 2.5: 특별히 중요한 DNA 시스템 기술 선택 ⭐⭐⭐

### 2.5.1 Identity & Access (DNA #7) - 실시간 세션 관리 ⭐⭐⭐

**패밀리 요구**:
- 다중 디바이스 세션 동기화
- 사용자 프레즌스 실시간 추적
- WebSocket 연결별 인증
- 권한 변경 즉시 반영

---

#### 옵션 1: Auth0

**핵심 스펙**:
- **인증 지연**: <100ms (토큰 검증)
- **동시 세션**: 무제한 (Enterprise)
- **기능**: OAuth2, SAML, MFA, 소셜 로그인
- **가용성**: 99.99% SLA (Enterprise)

**비용**:
- **Free**: 25,000 MAU
- **Essential**: $35/월 (500 MAU)
- **Professional**: $240/월 (1,000 MAU)
- **Enterprise**: 맞춤형 (무제한 MAU)

**장점**:
- 🚀 빠른 통합 (1~3일)
- 🔐 완벽한 OAuth2/OIDC 지원
- 📊 실시간 유저 프레즌스 API
- 🔧 Actions/Rules로 커스터마이징

**단점**:
- 💰 MAU 증가 시 비용 급증
- 🔒 벤더 종속
- ⏱️ 토큰 갱신 지연 (WebSocket 문제)

**적합한 경우**:
- 빠른 MVP 출시
- 10,000+ MAU 규모
- 소셜 로그인 필수
- 운영 리소스 최소화

**검증 사례**: Figma, Notion, Linear

---

#### 옵션 2: AWS Cognito

**핵심 스펙**:
- **인증 지연**: <50ms (토큰 검증)
- **동시 세션**: 10,000/user pool (조정 가능)
- **기능**: OAuth2, SAML, MFA, Lambda 트리거
- **가용성**: 99.9% SLA

**비용**:
- **Free**: 50,000 MAU
- **이후**: $0.0055/MAU (50K~100K)
- **예상** (10K MAU): 무료
- **예상** (100K MAU): ~$275/월

**장점**:
- 💰 저렴한 비용 (50K MAU 무료)
- 🔗 AWS 서비스 완벽 통합
- 🔧 Lambda 트리거로 커스터마이징
- 📈 무제한 확장

**단점**:
- 🔒 AWS 종속
- 🔧 UI 커스터마이징 제한
- 📚 복잡한 설정 (다른 솔루션 대비)

**적합한 경우**:
- AWS 중심 인프라
- 대규모 (100K+ MAU)
- 비용 민감
- Lambda 활용 가능 팀

**검증 사례**: Slack, Airbnb, Capital One

---

#### 옵션 3: Keycloak (Self-hosted)

**핵심 스펙**:
- **인증 지연**: <20ms (로컬)
- **동시 세션**: 무제한 (인프라 의존)
- **기능**: OAuth2, SAML, LDAP, 커스텀 프로바이더
- **라이선스**: 오픈소스 (Apache 2.0)

**비용**:
- **오픈소스**: 무료
- **인프라**: 월 $100~$500 (2~4 노드)
- **Red Hat SSO (상용)**: 맞춤형

**장점**:
- 💰 라이선스 무료
- 🔧 완전한 커스터마이징
- 🔐 온프레미스 가능 (규제 준수)
- 🌐 LDAP/AD 통합

**단점**:
- 🔧 높은 운영 부담
- 📚 학습 곡선 가파름
- ⏱️ 배포 시간 1~2주+

**적합한 경우**:
- 온프레미스 필수
- LDAP/AD 통합 필수
- 규제 산업 (금융, 의료)
- DevOps 팀 존재

**검증 사례**: Deutsche Bank, Bosch, 유럽 정부

---

#### Identity & Access 비교표

| 항목 | Auth0 | Cognito | Keycloak |
|------|-------|---------|----------|
| **비용 (10K MAU)** | $240+/월 | 무료 | $100~$500 |
| **배포 시간** | 1~3일 | 3~5일 | 1~2주 |
| **운영 부담** | ⚙️ 낮음 | ⚙️ 중간 | ⚙️⚙️⚙️ 높음 |
| **커스터마이징** | 중간 | 중간 | 높음 |

**의사결정 플로우차트**:
```
온프레미스 필수? → Keycloak
  └─ NO
     ↓
AWS 중심 + 비용 민감? → Cognito
  └─ NO
     ↓
빠른 통합 우선? → Auth0
```

---

### 2.5.2 API Gateway (DNA #9) - WebSocket 프록시 ⭐⭐⭐

**패밀리 요구**:
- WebSocket 연결 프록시
- 연결별 인증 토큰 검증
- 로드 밸런싱 (sticky session)
- 백프레셔 관리

---

#### 옵션 1: Kong Gateway

**핵심 스펙**:
- **처리량**: 초당 100K+ 요청
- **레이턴시**: <10ms 추가 (프록시)
- **WebSocket**: 네이티브 지원
- **플러그인**: 100+ (인증, Rate Limit)

**비용**:
- **오픈소스**: 무료
- **Enterprise**: $35K+/년
- **Konnect (Cloud)**: $300/월~

**장점**:
- ⚡ 최고 성능, Nginx 기반
- 🔧 풍부한 플러그인 생태계
- 🔗 WebSocket 네이티브 지원
- 📊 상세한 메트릭스

**단점**:
- 💰 Enterprise 고비용
- 🔧 운영 복잡도 중간
- 📚 플러그인 개발 Lua 필요

**적합한 경우**:
- 대규모 (10K+ 동시 접속)
- 복잡한 라우팅 필요
- 다양한 인증 방식 통합
- 온프레미스/클라우드 하이브리드

**검증 사례**: Figma, Nasdaq, Honeywell

---

#### 옵션 2: AWS API Gateway + ALB

**핵심 스펙**:
- **처리량**: 초당 10K 요청/리전 (기본)
- **레이턴시**: 20~50ms 추가
- **WebSocket**: API Gateway WebSocket API 지원
- **연결**: 2시간 idle 타임아웃

**비용**:
- **REST API**: $3.50/백만 요청
- **WebSocket**: $1.00/백만 메시지 + $0.25/백만 연결분
- **예상** (1M 연결/월): ~$300/월

**장점**:
- 🔗 AWS 서비스 완벽 통합
- 🚀 서버리스, 운영 부담 최소
- 📈 자동 확장
- 🔐 IAM, Cognito 통합

**단점**:
- 🔒 AWS 종속
- ⏱️ 2시간 연결 제한 (재연결 필요)
- 💰 대규모 시 비용 증가

**적합한 경우**:
- AWS 중심 인프라
- 서버리스 아키텍처
- 중규모 (1K~10K 동시 접속)
- Lambda 백엔드

**검증 사례**: Slack, Discord (부분적)

---

#### 옵션 3: Traefik

**핵심 스펙**:
- **처리량**: 초당 50K+ 요청
- **레이턴시**: <5ms 추가
- **WebSocket**: 네이티브 지원
- **라이선스**: 오픈소스 (MIT)

**비용**:
- **오픈소스**: 무료
- **Enterprise**: $500+/월
- **인프라**: 월 $50~$200

**장점**:
- 💰 오픈소스 무료
- 🔧 Kubernetes 네이티브
- ⚡ 빠른 성능
- 🔄 동적 설정 (Hot reload)

**단점**:
- 📦 Kong 대비 적은 플러그인
- 📊 모니터링 기능 제한적
- 🔧 고급 기능은 Enterprise

**적합한 경우**:
- Kubernetes 환경
- 비용 민감
- 단순한 라우팅
- 소중규모 (100~5K 동시 접속)

**검증 사례**: Slack (부분적), 다수 스타트업

---

#### API Gateway 비교표

| 항목 | Kong | AWS API GW | Traefik |
|------|------|------------|---------|
| **레이턴시** | <10ms | 20~50ms | <5ms |
| **비용** | $0~$35K+/년 | $300+/월 | $0~$500/월 |
| **WebSocket** | 네이티브 | 2시간 제한 | 네이티브 |
| **운영** | ⚙️⚙️ 중간 | ⚙️ 낮음 | ⚙️ 낮음 |

**의사결정 플로우차트**:
```
AWS 서버리스 선호? → AWS API Gateway
  └─ NO
     ↓
Kubernetes 환경 + 비용 민감? → Traefik
  └─ NO
     ↓
대규모 + 복잡한 라우팅? → Kong
```

---

### 2.5.3 Performance (DNA #11) - 동시 편집 벤치마킹 ⭐⭐⭐

**패밀리 요구**:
- 0ms 체감 레이턴시 검증
- 동시 편집자 수 벤치마크
- CRDT/OT 병합 성능 측정
- 메모리 사용량 프로파일링

---

#### 옵션 1: k6 (Load Testing)

**핵심 스펙**:
- **프로토콜**: HTTP, WebSocket, gRPC
- **확장**: 분산 테스트, Cloud 지원
- **스크립트**: JavaScript
- **메트릭**: p95, p99, 처리량, 에러율

**비용**:
- **오픈소스**: 무료
- **k6 Cloud**: $99~$999/월

**장점**:
- 🔌 WebSocket 네이티브 지원
- 📊 상세한 레이턴시 메트릭
- 🔧 JavaScript 스크립트 (친숙)
- ☁️ Cloud 분산 테스트

**단점**:
- 🔧 브라우저 테스트 제한적
- 📦 CRDT 로직 직접 구현 필요

**적합한 경우**:
- WebSocket 레이턴시 테스트
- CI/CD 통합 부하 테스트
- 동시 접속자 시뮬레이션

**검증 사례**: Grafana, GitLab, Notion

---

#### 옵션 2: Lighthouse + WebVitals

**핵심 스펙**:
- **측정**: LCP, FID, CLS, TTI
- **환경**: 브라우저 (Chrome)
- **통합**: CI/CD, Playwright
- **포맷**: JSON, HTML 리포트

**비용**:
- **오픈소스**: 무료
- **인프라**: 없음 (클라이언트 측)

**장점**:
- 💰 완전 무료
- 📊 사용자 체감 성능 측정
- 🔧 CI/CD 자동화 용이
- 🌐 Core Web Vitals 표준

**단점**:
- 🚫 WebSocket 직접 측정 불가
- 📊 서버 측 메트릭 없음
- 🔧 협업 시나리오 제한적

**적합한 경우**:
- 프론트엔드 성능 최적화
- SEO/Core Web Vitals
- 초기 로딩 시간 최적화

**검증 사례**: Google, Vercel

---

#### 옵션 3: Custom Profiling (Yjs Benchmarks)

**핵심 스펙**:
- **측정**: CRDT 병합 시간, 메모리, 네트워크
- **환경**: Node.js, Browser
- **Yjs 공식**: yjs-benchmarks 저장소
- **포맷**: JSON, Markdown

**비용**:
- **오픈소스**: 무료
- **개발 시간**: 1~3일

**장점**:
- 🎯 CRDT 특화 벤치마크
- 📊 병합 성능 정밀 측정
- 🔧 Yjs/Automerge 직접 비교
- 💾 메모리 프로파일링

**단점**:
- 🔨 직접 구현 필요
- 📚 CRDT 이해 필요
- 🔧 유지보수 부담

**적합한 경우**:
- CRDT 엔진 선택
- 동기화 알고리즘 최적화
- 메모리 사용량 최적화

**검증 사례**: Yjs, Automerge 공식 벤치마크

---

#### Performance 비교표

| 항목 | k6 | Lighthouse | Custom |
|------|-----|-----------|--------|
| **WebSocket** | ✅ 지원 | ❌ 미지원 | ✅ 지원 |
| **CRDT 측정** | ❌ 직접 구현 | ❌ 미지원 | ✅ 특화 |
| **비용** | $0~$999/월 | 무료 | 무료 |
| **난이도** | ⚙️ 낮음 | ⚙️ 낮음 | ⚙️⚙️ 중간 |

**의사결정 플로우차트**:
```
CRDT 병합 성능 측정? → Custom Profiling
  └─ NO
     ↓
프론트엔드 Core Web Vitals? → Lighthouse
  └─ NO
     ↓
WebSocket 부하 테스트? → k6
```

---

## Part 3: 도메인 선택 요소 (프로젝트별)

이 요소들은 **패밀리와 무관**하게 프로젝트 요구사항에 따라 선택합니다.

### 3.1 프론트엔드 프레임워크
- React, Vue, Svelte, Solid (패밀리 영향 없음, 프로젝트 선호도)

### 3.2 백엔드 언어/프레임워크
- Node.js (Express, NestJS, Fastify)
- Python (FastAPI, Django)
- Go (Gin, Echo)
(패밀리 영향 적음, 팀 역량 우선)

### 3.3 인증/권한
- Auth0, Clerk, Supabase Auth, Firebase Auth
(패밀리 무관, 보안 요구사항)

### 3.4 모니터링/로깅
- Prometheus + Grafana, Datadog, New Relic
(패밀리 무관, 운영 선호도)

---

## Part 4: Stage 2 통합

### 4.1 Layer 3 제약 반영 예시

**시나리오**: 디자인 협업 도구

**Layer 3 제약 발견**:
- 규제: GDPR, 유럽 데이터 저장 의무
- 팀: Node.js 경험, Python 없음
- 인프라: AWS 중심, 멀티 리전 불필요
- 비용: 초기 예산 $2,000/월

**기술 선택 영향**:
```
RDBMS:
- CockroachDB (선호) → PostgreSQL
- 이유: 멀티 리전 불필요, 비용 절감 ($5K → $2K/월)

동기화:
- 자체 구현 (선호) → Yjs
- 이유: 개발 기간 단축 (6개월 → 1주), 검증된 CRDT
```

---

### 4.2 충돌 해결 예시

**NFR 목표 vs Layer 3 제약**:

**충돌 1**: 글로벌 확장 A + 예산 제한
- NFR: 멀티 리전, 99.99% 가용성
- 제약: 예산 $2,000/월
- **해결**: PostgreSQL + Read Replica (리전별)
  - 트레이드오프: 단일 리전 쓰기, 99.9% SLA (99.99% 포기)

**충돌 2**: 오프라인 필수 A + 개발 기간
- NFR: 오프라인 편집, CRDT 자동 병합
- 제약: 3개월 출시
- **해결**: Yjs 도입 (자체 구현 포기)
  - 트레이드오프: 커스텀 충돌 전략 불가, 라이브러리 의존성

---

### 4.3 ADR 작성 준비

**선택한 기술 스택 정리**:
```
Bootstrap 필수:
✅ RDBMS: PostgreSQL (AWS RDS)
✅ WebSocket: Socket.io
✅ 동기화: Yjs
✅ 캐시: Redis (AWS ElastiCache)

도메인 선택:
✅ 백엔드: Node.js + NestJS
✅ 프론트엔드: React + TypeScript
✅ 인증: Clerk
✅ 모니터링: Datadog
```

**ADR 작성 대상**:

Bootstrap ADR:
1. PostgreSQL 선택 (MySQL, CockroachDB 대비)
2. Socket.io 선택 (Native WebSocket 대비)
3. Yjs 선택 (Automerge, 자체 구현 대비)
4. Redis 선택 (Memcached 대비)

도메인 ADR:
5. NestJS 선택 (Express 대비)
6. React 선택 (Vue, Svelte 대비)
7. Clerk 선택 (Auth0 대비)

---

## 📚 참고 자료

### 벤치마크
- [PostgreSQL pgbench 공식 문서](https://www.postgresql.org/docs/current/pgbench.html)
- [Socket.io Performance Tuning](https://socket.io/docs/v4/performance-tuning/)
- [Yjs Performance Benchmarks](https://github.com/yjs/yjs#benchmarks)

### 비용 계산기
- [AWS RDS Pricing](https://aws.amazon.com/rds/postgresql/pricing/)
- [CockroachDB Pricing](https://www.cockroachlabs.com/pricing/)
- [AWS ElastiCache Pricing](https://aws.amazon.com/elasticache/pricing/)

### 공식 문서
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [MySQL Documentation](https://dev.mysql.com/doc/)
- [CockroachDB Documentation](https://www.cockroachlabs.com/docs/)
- [Socket.io Documentation](https://socket.io/docs/)
- [Yjs Documentation](https://docs.yjs.dev/)
- [Automerge Documentation](https://automerge.org/docs/)
- [Redis Documentation](https://redis.io/documentation)

### 검증 사례
- Figma: [Rust + WebSocket 아키텍처](https://www.figma.com/blog/)
- Google Docs: [Operational Transformation](https://googledocs.blogspot.com/)
- Notion: [블록 기반 편집](https://www.notion.so/blog/)

---

**마지막 업데이트**: 2025-11-12  
**다음 검토**: 2026-02-12 (기술 스택 업데이트 반영)


================================================================================

📄 FILE: 04_search_recommendation_tech_options.md
--------------------------------------------------------------------------------

# 검색/추천 패밀리 (B-B-B) - 기술 매트릭스

**작성일**: 2025-11-12  
**패밀리**: 검색/추천 (B-B-B)  
**검증 사례**: Elasticsearch (Zillow), Vector DB (RAG 앱), 추천 엔진

---

## Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐

### 1.1 B-B-B 특성이 강제하는 것

#### B (점진적 실패) → 점진적 품질 저하 허용

**특성**:
- 일부 결과 누락 허용 (전부 또는 전무가 아님)
- 관련성 점수 기반 순위
- 타임아웃 시 부분 결과 반환
- Eventual consistency

**강제되는 기술적 요구**:
```
✅ Circuit breaker, fallback 메커니즘
✅ 관련성 스코어링 (relevance scoring)
✅ 타임아웃 처리
✅ 캐시 레이어 (구형 결과 반환)
```

**검증 사례**:
- Elasticsearch: 검색 스레드 풀 거부 시 에러, 하지만 시스템 계속 작동
- Zillow 추천: 실시간 추천 실패 시 캐시된 추천 반환

---

#### B (반구조화 데이터) → 유연한 스키마 필수

**특성**:
- JSON 문서, 다양한 필드 구조
- 동적 필드 추가/제거
- 중첩 객체, 배열
- 스키마 진화

**강제되는 기술적 요구**:
```
✅ Document store (JSON 네이티브)
✅ 동적 매핑 (dynamic mapping)
✅ Sparse vectors (희소 벡터)
✅ 유연한 인덱싱
```

**검증 사례**:
- Elasticsearch: 상품 카탈로그, 각 상품마다 다른 속성 (전자제품 vs 의류)
- Vector DB: 다양한 길이의 텍스트 임베딩

---

#### B (수초 응답) → 빠른 검색 필수

**특성**:
- 50ms~10초 (단순→복잡 쿼리)
- 사용자 대기 가능 범위
- 관련성 우선, 속도 차선
- 병렬 쿼리 최적화

**강제되는 기술적 요구**:
```
✅ 역인덱스 (inverted index)
✅ 샤딩, 파티셔닝
✅ 쿼리 캐싱
✅ 인메모리 구조
```

**검증 사례**:
- Elasticsearch: 50-100ms 단순 쿼리, 100ms-10초 복잡 집계
- Zillow: 100ms 미만 실시간 추천, 11.5-25.6% 레이턴시 감소

---

### 1.2 이 패밀리에 필요한 DNA 시스템 및 메인 서비스

#### DNA 11개 시스템 중 필요한 것

B-B-B 패밀리는 다음 DNA 시스템이 필요합니다:

| DNA 시스템 | 중요도 | 이유 |
|-----------|-------|------|
| 1. Testing | ✅ 필수 | 검색 로직 검증 |
| 2. Code Quality | ✅ 필수 | 코드 품질 유지 |
| 3. Architecture | ✅ 필수 | 검색/추천 모듈 분리 |
| 4. Type System | ✅ 필수 | 쿼리 타입 안전성 |
| 5. Error Handling | ✅ 필수 | 타임아웃, 폴백 전략 |
| 6. Configuration | ✅ 필수 | 인덱스 설정, 쿼리 파라미터 |
| 7. Identity & Access | ✅ 필수 | 사용자별 검색 권한 |
| 8. Observability | ✅ 필수 | 쿼리 성능 모니터링 |
| 9. **API Gateway** | **⭐⭐⭐ 매우 중요** | **검색 쿼리 최적화, 페이지네이션, 필터링 핵심** |
| 10. Resilience | ✅ 필수 | Circuit breaker, 폴백 |
| 11. Performance | ✅ 필수 | 인덱싱, 쿼리 최적화 |

**특별히 중요한 DNA 시스템 (⭐⭐⭐)**:
- **API Gateway**: 복잡한 검색 쿼리 파싱, 페이지네이션, 필터링, 정렬 등 검색 UX의 핵심. GraphQL vs REST vs Elasticsearch DSL 직접 노출 여부가 시스템 복잡도를 좌우함.

→ **Part 2.5에서 이 DNA 시스템의 기술 옵션을 다룹니다.**

#### 메인 서비스 필수 요소 (패밀리 강제)

B-B-B 패밀리는 다음 3가지 메인 서비스 기술을 **반드시** 포함해야 합니다:

#### 1. 검색 엔진 (필수!)
**역할**: Full-text search, 관련성 스코어링
**이유**: 반구조화 데이터(B) + 빠른 검색(B)
**선택지**: Elasticsearch, Typesense, Meilisearch

#### 2. Vector DB (AI/RAG 시 필수, 아니면 불필요)
**역할**: 의미적 검색 (semantic search)
**이유**: 반구조화(B) + 의미 기반 관련성
**선택지**: Pinecone, Weaviate, pgvector
**주의**: Keyword 검색만 하면 불필요

#### 3. 캐시 레이어 (필수!)
**역할**: 핫 쿼리 결과 캐싱
**이유**: 수초 응답(B) + 점진적 실패(B)
**선택지**: Redis, Memcached

---

## Part 2: 메인 서비스 기술 선택 ⭐⭐⭐

### 2.1 검색 엔진 선택

**패밀리 요구**:
- Full-text search
- 관련성 스코어링
- 동적 필드 매핑
- 빠른 인덱싱

---

#### 옵션 1: Elasticsearch

**핵심 스펙**:
- **쿼리 속도**: 50-100ms (단순), 100ms-10초+ (복잡 집계)
- **인덱싱**: 초당 1만~10만 문서
- **처리량**: 초당 1만~10만 쿼리
- **확장**: 수평 확장 (샤딩)

**비용**:
- **Self-hosted**: 월 $25~$500 (소규모), $2,000~$7,000 (대규모)
- **Elastic Cloud**: 월 $95~$175 (Standard~Enterprise)
- **AWS OpenSearch**: 월 $500~$5,000

**장점**:
- 🔍 강력한 Full-text search, 다국어 지원
- 📊 복잡한 집계 (aggregations) 가능
- 🌐 풍부한 생태계, Kibana 시각화
- 🔧 유연한 쿼리 DSL, 필터링

**단점**:
- 💰 높은 비용 (대규모 시)
- 🔧 복잡한 설정, 튜닝 필요
- 💾 메모리 많이 사용
- 📈 클러스터 관리 부담

**적합한 경우**:
- 대기업, 복잡한 검색 요구
- 대용량 데이터 (TB급)
- 로그 분석, 모니터링
- 다국어, 지리 검색

**검증 사례**: Zillow (11.5-25.6% 레이턴시 감소), Uber, GitHub

---

#### 옵션 2: Typesense

**핵심 스펙**:
- **쿼리 속도**: <50ms (p99)
- **인덱싱**: 초당 1만~5만 문서
- **처리량**: 초당 5만~20만 쿼리
- **메모리**: Elasticsearch 대비 50% 절감

**비용**:
- **Self-hosted**: 월 $50~$300
- **Typesense Cloud**: 월 $29~$299 (사용량 기반)

**장점**:
- ⚡ 극도로 빠름, 메모리 효율
- 💰 저렴한 비용
- 🔧 간단한 설정, RESTful API
- 🔥 Typo tolerance (오타 허용)

**단점**:
- 📊 제한적 집계 (Elasticsearch 대비)
- 📦 작은 생태계, 커뮤니티
- 🔧 고급 기능 부족 (ML, 파이프라인)
- 📈 대규모 확장 제한

**적합한 경우**:
- 스타트업, MVP
- e-commerce 검색
- 예산 <$500/월
- 단순한 검색 요구

**검증 사례**: 여러 스타트업, e-commerce 사이트

---

#### 옵션 3: Meilisearch

**핵심 스펙**:
- **쿼리 속도**: <20ms (p99)
- **인덱싱**: 초당 5,000~20,000 문서
- **처리량**: 초당 1만~5만 쿼리
- **특징**: Search-as-you-type 최적화

**비용**:
- **Self-hosted**: 월 $30~$200
- **Meilisearch Cloud**: 월 $15~$500

**장점**:
- ⚡ 초고속, Instant search
- 🎯 Search-as-you-type 우수
- 🔧 간단한 API, 개발자 친화
- 💰 매우 저렴

**단점**:
- 📊 집계 없음
- 📈 대규모 데이터 제한 (GB급)
- 🔧 고급 쿼리 부족
- 🌐 작은 생태계

**적합한 경우**:
- 문서 검색, 웹사이트 검색
- 소규모 (GB급 데이터)
- Instant search UX 필수
- 최소 비용

**검증 사례**: 여러 문서 사이트, 소규모 앱

---

#### 검색 엔진 비교표

| 항목 | Elasticsearch | Typesense | Meilisearch |
|------|--------------|-----------|-------------|
| **쿼리 속도** | 50-100ms | <50ms | <20ms |
| **인덱싱** | 10K~100K/s | 10K~50K/s | 5K~20K/s |
| **비용** | $500~$7K/월 | $50~$300/월 | $30~$200/월 |
| **집계** | 강력 | 제한적 | 없음 |
| **확장성** | 무제한 | 중간 | 제한적 |
| **복잡도** | ⚙️⚙️⚙️ 높음 | ⚙️⚙️ 중간 | ⚙️ 낮음 |

**의사결정 가이드**:
```
데이터 > TB급? → Elasticsearch
  └─ NO
     ↓
복잡한 집계 필요? → Elasticsearch
  └─ NO
     ↓
Instant search 필수? → Meilisearch
  └─ NO
     ↓
예산 <$500/월? → Typesense
  └─ NO → Elasticsearch
```

---

### 2.2 Vector DB 선택 (AI/RAG 앱만 해당)

**패밀리 요구**:
- 의미적 검색 (semantic search)
- 고차원 벡터 저장 (768~1536 차원)
- K-NN 검색 (<100ms)
- 메타데이터 필터링

---

#### 옵션 1: Pinecone

**핵심 스펙**:
- **쿼리 속도**: p50 <10ms, p99 <50ms
- **처리량**: 초당 10만+ 쿼리
- **확장**: 억 단위 벡터 지원
- **인덱싱**: 초당 1만+ 벡터

**비용**:
- **Serverless**: 월 $50 최소 (pay-as-you-go)
- **Standard**: 월 $40~$200 (소중형)
- **Enterprise**: 월 $500~$2,000+

**장점**:
- ⚡ 극도로 빠름, 일관된 성능
- 🤖 완전 관리형, 자동 스케일링
- 🔧 간단한 API, SDK 풍부
- 🔒 SOC 2, HIPAA 인증

**단점**:
- 💰 높은 비용 (대규모 시)
- 🔒 벤더 종속
- 📊 제한적 쿼리 (K-NN 중심)
- 🔧 커스터마이징 제한

**적합한 경우**:
- 프로덕션 RAG 앱
- 빠른 배포, 운영 최소화
- 억 단위 벡터
- 예산 $200~$2,000/월

**검증 사례**: 다수 RAG 앱, LLM 기반 서비스

---

#### 옵션 2: Weaviate

**핵심 스펙**:
- **쿼리 속도**: p99 <50ms
- **처리량**: 초당 5만~10만 쿼리
- **확장**: 억 단위 벡터 지원
- **특징**: Hybrid search (Vector + BM25)

**비용**:
- **Self-hosted**: 무료 (오픈소스)
- **Serverless**: 월 $25~$153 (사용량 기반)
- **Classic**: $0.05/백만 차원

**장점**:
- 🔓 오픈소스, Self-host 가능
- 🔧 Hybrid search, GraphQL
- 🌐 Multi-modal (텍스트, 이미지)
- 💰 저렴한 비용

**단점**:
- ⏱️ Pinecone 대비 약간 느림
- 🔧 Self-host 시 운영 부담
- 📦 생태계 작음 (Pinecone 대비)
- 🔧 복잡한 설정 (고급 기능)

**적합한 경우**:
- Hybrid search 필요
- Self-host 선호
- Multi-modal 데이터
- 예산 <$200/월

**검증 사례**: 여러 RAG 앱, 지식 그래프

---

#### 옵션 3: pgvector (PostgreSQL 확장)

**핵심 스펙**:
- **쿼리 속도**: 10-100ms (데이터 규모 의존)
- **처리량**: 초당 1만~5만 쿼리
- **확장**: 백만 단위 벡터 권장
- **특징**: PostgreSQL 네이티브

**비용**:
- **Self-hosted**: 월 $50~$500 (PostgreSQL 비용)
- **Supabase**: 월 $25~$599
- **AWS RDS**: 월 $70~$2,000

**장점**:
- 🔧 PostgreSQL 통합, SQL 사용
- 💰 저렴한 비용
- 🔒 트랜잭션 보장 (ACID)
- 📦 기존 인프라 활용

**단점**:
- ⏱️ 전용 Vector DB 대비 느림
- 📈 대규모 확장 제한 (백만 단위)
- 🔧 튜닝 필요 (인덱스, 쿼리)
- 💾 메모리 사용 높음

**적합한 경우**:
- PostgreSQL 이미 사용 중
- 소중형 (백만 단위 벡터)
- SQL + Vector 통합
- 예산 <$500/월

**검증 사례**: 여러 스타트업, 프로토타입

---

#### Vector DB 비교표

| 항목 | Pinecone | Weaviate | pgvector |
|------|----------|----------|----------|
| **쿼리 속도** | <10ms (p50) | <50ms (p99) | 10-100ms |
| **처리량** | 100K+/s | 50K~100K/s | 10K~50K/s |
| **확장** | 억 단위 | 억 단위 | 백만 단위 |
| **비용** | $50~$2K/월 | $25~$153/월 | $50~$500/월 |
| **운영** | ⚙️ 낮음 | ⚙️⚙️ 중간 | ⚙️⚙️ 중간 |

**의사결정 가이드**:
```
벡터 > 1억? → Pinecone or Weaviate
  └─ NO
     ↓
PostgreSQL 사용 중? → pgvector
  └─ NO
     ↓
Hybrid search 필요? → Weaviate
  └─ NO
     ↓
완전 관리형 필요? → Pinecone
  └─ NO → Weaviate (self-host)
```

---

### 2.3 캐시 레이어 선택

**패밀리 요구**:
- 핫 쿼리 결과 캐싱
- 밀리초 미만 응답
- TTL 관리
- 높은 처리량

---

#### 옵션 1: Redis

**핵심 스펙**:
- **레이턴시**: 0.15ms (GET)
- **처리량**: 초당 120만 트랜잭션
- **자료구조**: String, Hash, Sorted Set
- **특징**: TTL, Pub/Sub

**비용**:
- **Self-hosted**: 월 $50~$500
- **AWS ElastiCache**: 월 $50~$1,000
- **Redis Cloud**: 월 $30~$2,000

**장점**:
- ⚡ 초고속, 다양한 자료구조
- 🔧 TTL 자동 만료
- 🔔 Pub/Sub (캐시 무효화)
- 📦 풍부한 클라이언트

**단점**:
- 💰 메모리 기반, 비용 높음
- 🔧 단일 스레드
- 📈 클러스터 설정 복잡

**적합한 경우**:
- 대부분의 검색 시스템
- 복잡한 캐시 로직
- Pub/Sub 필요
- 쿼리 결과 캐싱

**검증 사례**: Zillow, GitHub, Uber

---

#### 옵션 2: Memcached

**핵심 스펙**:
- **레이턴시**: <0.1ms
- **처리량**: 초당 100만+ operations
- **자료구조**: Key-Value만
- **특징**: 멀티 스레드

**비용**:
- **Self-hosted**: 월 $30~$300
- **AWS ElastiCache**: 월 $30~$500

**장점**:
- ⚡ 극도로 빠름
- 💰 저렴한 비용
- 🔧 멀티 스레드, CPU 효율
- 📉 낮은 메모리 오버헤드

**단점**:
- 📊 단순한 자료구조
- 🚫 TTL 정밀도 낮음
- 💾 지속성 없음

**적합한 경우**:
- 단순 캐싱만
- 최소 비용
- 초고속 필수
- 복잡한 자료구조 불필요

---

#### 캐시 비교표

| 항목 | Redis | Memcached |
|------|-------|-----------|
| **레이턴시** | 0.15ms | <0.1ms |
| **자료구조** | 다양 | Key-Value |
| **TTL** | 정밀 | 제한적 |
| **비용** | 중간 | 낮음 |

**의사결정 가이드**:
```
복잡한 자료구조? → Redis
  └─ NO
     ↓
정밀한 TTL? → Redis
  └─ NO → Memcached
```

---

## Part 2.5: DNA 시스템 기술 선택 ⭐⭐⭐

### 2.5.1 API Gateway (DNA #9) - 검색 쿼리 최적화 ⭐⭐⭐

**패밀리 요구**:
- 복잡한 검색 쿼리 파싱 (필터, 정렬, 페이지네이션)
- 타입 안전한 쿼리 파라미터
- 쿼리 복잡도 제한 (DoS 방지)
- 캐싱 전략 통합
- Rate limiting, 인증 미들웨어

B-B-B 패밀리에서 API Gateway는 검색 UX의 핵심입니다. 사용자의 복잡한 검색 요구사항(필터링, 정렬, 패싯, 하이라이팅)을 어떻게 API로 노출할지가 개발 복잡도와 프론트엔드 개발 속도를 좌우합니다.

---

#### 옵션 1: GraphQL

**핵심 스펙**:
- **쿼리 유연성**: 클라이언트가 필요한 필드만 선택
- **타입 안전성**: 스키마 기반 타입 체크 (컴파일 타임)
- **페이지네이션**: Cursor-based (Relay), Offset-based 모두 지원
- **복잡도 제한**: Query complexity analysis, depth limiting

**비용**:
- **Self-hosted**: 추가 비용 없음 (오픈소스)
- **Apollo Server/Hasura**: 무료~월 $99~$499 (Managed 시)
- **개발 시간**: 초기 스키마 설계 1~2주

**장점**:
- 🎯 **극도로 유연한 쿼리**: 클라이언트가 필요한 것만 요청 (over-fetching 방지)
- 🛡️ **강력한 타입 안전성**: 스키마 기반, 컴파일 타임 에러 감지
- 📊 **복잡한 필터링 지원**: nested filters, AND/OR/NOT 조합
- 🔧 **자동 문서 생성**: GraphQL Playground/GraphiQL
- 🚀 **프론트엔드 개발 속도**: 백엔드 수정 없이 새로운 쿼리 작성 가능

**단점**:
- 🔧 **초기 학습 곡선**: GraphQL 스키마 설계, Resolver 작성
- 💰 **오버헤드**: 단순 검색에도 Resolver 레이어 필요
- 🐌 **N+1 문제**: DataLoader 없으면 성능 저하
- 🔒 **복잡도 관리**: 악의적 쿼리 (깊은 중첩) 방지 필요

**적합한 경우**:
- 복잡한 검색 UI (다중 필터, 동적 필드)
- 프론트엔드 개발 속도 > 백엔드 단순성
- 타입 안전성 중시 (TypeScript 팀)
- 다중 클라이언트 (웹, 모바일) 지원

**검증 사례**: GitHub Search (GraphQL API), Shopify (Product search), Airbnb

---

#### 옵션 2: REST API with Query Builder

**핵심 스펙**:
- **쿼리 방식**: URL 쿼리 파라미터 + POST body
- **필터링**: `?filter[category]=books&filter[price][gte]=10`
- **정렬**: `?sort=-relevance,price`
- **페이지네이션**: Offset-based (`?page=2&limit=20`)

**비용**:
- **Self-hosted**: 무료 (Express.js + Query Builder 라이브러리)
- **개발 시간**: 1주 (쿼리 파서, 검증 로직)

**장점**:
- 🔧 **단순한 구현**: Express.js + 쿼리 빌더 라이브러리로 빠른 구현
- 📚 **익숙한 패턴**: 대부분 개발자가 REST 경험 보유
- 🚀 **빠른 프로토타입**: API 엔드포인트별로 점진적 추가 가능
- 💰 **낮은 학습 곡선**: 추가 개념 학습 불필요

**단점**:
- 📝 **수동 문서화**: OpenAPI/Swagger 수동 작성 필요
- 🔄 **Over-fetching**: 클라이언트가 불필요한 필드도 받음
- 🔧 **쿼리 파라미터 복잡**: 복잡한 필터는 URL이 길어짐
- 🚫 **타입 안전성 약함**: 런타임 검증만 가능

**적합한 경우**:
- 단순~중간 복잡도 검색
- REST API 경험 팀
- 빠른 MVP 출시
- 쿼리 복잡도 제한적 (1~2 depth 필터)

**검증 사례**: Stripe API (검색 엔드포인트), Twilio, SendGrid

---

#### 옵션 3: Elasticsearch DSL 직접 노출

**핵심 스펙**:
- **쿼리 방식**: 프론트엔드가 Elasticsearch Query DSL 직접 전송
- **필터링**: JSON 쿼리 본문 (Elasticsearch DSL 그대로)
- **복잡도**: 무제한 (클라이언트 책임)
- **타입 안전성**: 없음 (JSON)

**비용**:
- **Self-hosted**: 무료 (Thin proxy만 필요)
- **개발 시간**: 2~3일 (인증, rate limiting 미들웨어만)

**장점**:
- ⚡ **최소 레이턴시**: 백엔드 변환 레이어 없음
- 🔧 **개발 최소화**: 거의 proxy만 구현
- 🎯 **완전한 Elasticsearch 기능**: Aggregation, Script, Geo 등 모두 사용 가능
- 💰 **최저 비용**: 백엔드 로직 거의 없음

**단점**:
- 🚨 **보안 위험**: 악의적 쿼리 (DoS, 민감 인덱스 접근) 방지 어려움
- 🔒 **권한 관리 복잡**: 문서 레벨 권한을 쿼리에 강제 삽입 필요
- 📝 **프론트엔드 복잡도**: Elasticsearch DSL 학습 필수
- 🐛 **디버깅 어려움**: 프론트엔드 쿼리 오류 추적 어려움

**적합한 경우**:
- 내부 도구, 관리자 대시보드 (신뢰된 사용자만)
- 매우 복잡한 검색 요구 (Elasticsearch 전체 기능 필요)
- 개발 리소스 극히 제한
- 프론트엔드 팀이 Elasticsearch 전문가

**검증 사례**: Kibana (내부 도구), 일부 관리자 대시보드

---

#### API Gateway 비교표

| 항목 | GraphQL | REST + Query Builder | Elasticsearch DSL 노출 |
|------|---------|---------------------|---------------------|
| **쿼리 유연성** | ⭐⭐⭐ 최고 | ⭐⭐ 중간 | ⭐⭐⭐ 최고 |
| **타입 안전성** | ⭐⭐⭐ 강함 | ⭐ 약함 | ❌ 없음 |
| **개발 시간** | 1~2주 | 1주 | 2~3일 |
| **학습 곡선** | ⭐⭐⭐ 높음 | ⭐ 낮음 | ⭐⭐ 중간 |
| **보안** | ⭐⭐⭐ 높음 | ⭐⭐ 중간 | ⚠️ 위험 |
| **비용** | 중간 | 낮음 | 최저 |
| **복잡도** | ⚙️⚙️⚙️ 높음 | ⚙️⚙️ 중간 | ⚙️ 낮음 |

**의사결정 플로우차트**:
```
내부 도구 (신뢰된 사용자만)? 
├─ YES → Elasticsearch DSL 직접 노출
│         (최저 비용, 최대 유연성)
└─ NO
   ↓
복잡한 검색 UI (다중 필터, 동적 필드)?
├─ YES → 프론트엔드 팀이 GraphQL 경험?
│        ├─ YES → GraphQL
│        │         (타입 안전성 + 유연성)
│        └─ NO → REST + Query Builder
│                  (빠른 개발, 익숙한 패턴)
└─ NO → REST + Query Builder
         (단순한 검색에 충분)
```

---

## Part 3: 도메인 선택 요소 (프로젝트별)

이 요소들은 **패밀리와 무관**하게 프로젝트 요구사항에 따라 선택합니다.

### 3.1 프론트엔드 프레임워크
- **선택 기준**: 팀 역량, 생태계, 프로젝트 규모
- **옵션**: React (대형, 풍부한 생태계), Vue (중소형, 학습 곡선 낮음), Svelte (경량, 빠른 성능)
- **패밀리 무관**: C-B-B는 프론트엔드 선택에 영향 없음

### 3.2 백엔드 언어/프레임워크
- **선택 기준**: 팀 역량, 검색 엔진 클라이언트 지원
- **옵션**: Node.js (Elasticsearch 클라이언트 우수), Python (ML/AI 통합), Go (성능 중시)
- **고려사항**: 검색 엔진 SDK 품질 확인 필요

### 3.3 인증/권한
- **선택 기준**: 보안 요구사항, 규제 준수
- **옵션**: Auth0 (엔터프라이즈), Clerk (개발자 친화), Firebase Auth (간편)
- **검색 연동**: 사용자별 검색 결과 필터링 고려

### 3.4 Embedding 모델 (AI/RAG 시)
- **선택 기준**: 정확도, 비용, 레이턴시
- **옵션**: OpenAI Ada-002 (높은 품질, $0.0001/1K tokens), Cohere (다국어), Sentence Transformers (무료, self-host)
- **Vector DB 연동**: 차원 수 호환성 확인 (768, 1536 등)

---

## Part 4: Stage 2 통합

### 4.1 Layer 3 제약 반영 예시

**시나리오**: e-commerce 검색 플랫폼

**Layer 3 제약 발견**:
- 규제: GDPR, 유럽 데이터 저장
- 팀: Python 경험, Go 없음
- 인프라: AWS 중심
- 비용: 초기 예산 $1,000/월

**기술 선택 영향**:
```
검색 엔진:
- Elasticsearch (선호) → Typesense
- 이유: 비용 절감 ($7K → $300/월)

Vector DB:
- Pinecone (선호) → Weaviate (self-host)
- 이유: GDPR 준수, 유럽 서버 필요

캐시:
- Redis 유지
- 이유: TTL, 쿼리 결과 캐싱 필수
```

---

### 4.2 충돌 해결 예시

**NFR 목표 vs Layer 3 제약**:

**충돌 1**: 속도 A + 예산 제한
- NFR: <50ms 검색
- 제약: 예산 $1,000/월
- **해결**: Typesense ($300) + 적극적 캐싱
  - **트레이드오프**: 복잡한 집계 불가 (Elasticsearch 대비), 대규모 확장 제한

**충돌 2**: 관련성 A + 개발 기간
- NFR: AI 의미적 검색
- 제약: 3개월 출시
- **해결**: Pinecone (관리형) 대신 pgvector (간단)
  - **트레이드오프**: 성능 낮음 (<10ms → 10-100ms), 백만 단위 벡터로 제한

---

### 4.3 ADR 작성 준비

**선택한 기술 스택 정리**:
```
Bootstrap 필수:
✅ 검색: Typesense (AWS EC2)
✅ Vector DB: pgvector (AWS RDS PostgreSQL)
✅ 캐시: Redis (AWS ElastiCache)

도메인 선택:
✅ 백엔드: Python + FastAPI
✅ 프론트엔드: React
✅ 인증: Auth0
✅ Embedding: OpenAI Ada-002
```

**ADR 작성 대상**:

Bootstrap ADR:
1. Typesense 선택 (Elasticsearch, Meilisearch 대비)
2. pgvector 선택 (Pinecone, Weaviate 대비)
3. Redis 선택 (Memcached 대비)

도메인 ADR:
4. FastAPI 선택 (Django 대비)
5. React 선택 (Vue 대비)
6. OpenAI Ada-002 선택 (Cohere 대비)

---

## 📚 참고 자료

### 벤치마크
- [Elasticsearch Performance Tuning](https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html)
- [Typesense vs Elasticsearch Benchmark](https://typesense.org/docs/guide/performance.html)
- [Pinecone Performance Benchmarks](https://www.pinecone.io/learn/series/performance/)

### 비용 계산기
- [Elasticsearch Pricing](https://www.elastic.co/pricing/)
- [Typesense Cloud Pricing](https://cloud.typesense.org/pricing)
- [Pinecone Pricing Calculator](https://www.pinecone.io/pricing/)
- [Weaviate Pricing](https://weaviate.io/pricing)

### 공식 문서
- [Elasticsearch Documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [Typesense Documentation](https://typesense.org/docs/)
- [Meilisearch Documentation](https://www.meilisearch.com/docs)
- [Pinecone Documentation](https://docs.pinecone.io/)
- [Weaviate Documentation](https://weaviate.io/developers/weaviate)
- [pgvector Documentation](https://github.com/pgvector/pgvector)

### 검증 사례
- Zillow: [Elasticsearch 레이턴시 개선](https://www.elastic.co/customers/zillow)
- RAG Apps: [Vector DB 벤치마크](https://www.pinecone.io/learn/vector-database-benchmark/)
- e-commerce: [Typesense 사례](https://typesense.org/showcase/)

---

**마지막 업데이트**: 2025-11-12  
**다음 검토**: 2026-02-12 (기술 스택 업데이트 반영)


================================================================================

📄 FILE: 05_real_time_streaming_tech_options.md
--------------------------------------------------------------------------------

# 실시간 스트리밍 패밀리 (B-C-A) - 기술 매트릭스

**작성일**: 2024-11-12  
**패밀리**: 실시간 스트리밍 (B-C-A)  
**검증 사례**: Netflix RDG (100만 msg/s), Uber GPS, Twitter 타임라인

---

## Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐

### 1.1 B-C-A 특성이 강제하는 것

#### B (점진적 실패) → 이벤트 스트리밍 필수

**특성**:
- 일부 메시지 손실 허용
- 버퍼링 및 재시도 메커니즘
- 최종 일관성 (Eventual Consistency)
- At-least-once 전달 보장

**강제되는 기술적 요구**:
```
✅ 메시지 큐/스트림 플랫폼 필수
✅ 이벤트 재생(replay) 기능
✅ Dead Letter Queue (DLQ)
✅ 체크포인트/오프셋 관리
```

**검증 사례**:
- Netflix: Kafka at-least-once, 메시지 재생으로 장애 복구
- Uber: GPS 데이터 일시 손실 허용, 보간(interpolation)으로 복구

---

#### C (비구조화 데이터) → 유연한 스키마 필수

**특성**:
- 이벤트 스트림, 시계열 데이터
- JSON, Protobuf 같은 유연한 포맷
- 스키마 진화 (Schema Evolution)
- 가변 필드 구조

**강제되는 기술적 요구**:
```
✅ NoSQL 또는 시계열 DB
✅ Schema Registry (선택)
✅ JSON/Protobuf 직렬화
✅ 동적 필드 처리
```

**검증 사례**:
- Twitter: 트윗 이벤트의 가변 메타데이터 (리트윗, 인용, 미디어)
- IoT: 센서별 다른 데이터 구조 (온도, 습도, 진동 등)

---

#### A (밀리초~수초 응답) → 저지연 아키텍처 필수

**특성**:
- p99 < 5초 목표
- 실시간 느낌 제공
- 고처리량 요구
- 수평 확장 가능

**강제되는 기술적 요구**:
```
✅ 파티셔닝 (병렬 처리)
✅ 인메모리 캐시
✅ 비동기 처리
✅ 수평 확장 아키텍처
```

**검증 사례**:
- Uber GPS: 2-5초 위치 업데이트, 초당 100만 쿼리
- Netflix: 5초 미만 추천 업데이트

---

### 1.2 이 패밀리에 필요한 DNA 시스템 및 메인 서비스

#### DNA 11개 시스템 중 필요한 것

B-C-A 패밀리는 다음 DNA 시스템이 필요합니다:

| DNA 시스템 | 중요도 | 이유 |
|-----------|-------|------|
| 1. Testing | ✅ 필수 | 이벤트 처리 로직 검증 |
| 2. Code Quality | ✅ 필수 | 비동기 코드 품질 유지 |
| 3. Architecture | ✅ 필수 | 스트림 처리 모듈 분리 |
| 4. Type System | ✅ 필수 | 이벤트 타입 안전성 |
| 5. Error Handling | ✅ 필수 | DLQ, 재시도 전략 |
| 6. Configuration | ✅ 필수 | 파티션 수, 버퍼 크기 등 |
| 7. Identity & Access | ✅ 필수 | Producer/Consumer 인증 |
| 8. **Observability** | **⭐⭐⭐ 매우 중요** | **메시지 lag, 처리량, 백프레셔 모니터링 필수** |
| 9. API Gateway | ✅ 필수 | 스트림 데이터 API 노출 |
| 10. **Resilience** | **⭐⭐⭐ 매우 중요** | **체크포인트, 재생, 장애 복구** |
| 11. **Performance** | **⭐⭐⭐ 매우 중요** | **처리량, 레이턴시 최적화** |

**특별히 중요한 DNA 시스템 (⭐⭐⭐)**:
- **Observability**: 메시지 lag, 처리량, 워터마크 추적 없이는 장애 감지 불가
- **Resilience**: 체크포인트 없으면 장애 시 데이터 손실
- **Performance**: 초당 100만 메시지 처리 위해 지속적 프로파일링 필수

→ **Part 2.5에서 이 3가지 DNA 시스템의 기술 옵션을 다룹니다.**

#### 메인 서비스 필수 요소 (패밀리 강제)

B-C-A 패밀리는 다음 3가지 메인 서비스 기술을 **반드시** 포함해야 합니다:

#### 1. 스트리밍 플랫폼 (필수!)
**역할**: 이벤트 수집, 파티셔닝, 전달
**이유**: 점진적 실패(B) + 연속 스트림(C)
**선택지**: Kafka, Kinesis, RabbitMQ

#### 2. 시계열 DB (필수!)
**역할**: 이벤트 저장, 시간 순 조회
**이유**: 비구조화 데이터(C) + 빠른 쓰기(A)
**선택지**: Cassandra, DynamoDB, TimescaleDB

#### 3. 캐시 레이어 (필수!)
**역할**: 핫 데이터 빠른 조회
**이유**: 밀리초 응답(A)
**선택지**: Redis, Memcached

---

## Part 2: 메인 서비스 기술 선택 ⭐⭐⭐

### 2.1 스트리밍 플랫폼 선택

**패밀리 요구**:
- 연속 이벤트 처리
- 파티션 기반 병렬 처리
- At-least-once 전달
- 이벤트 재생 가능

---

#### 옵션 1: Apache Kafka + Flink

**핵심 스펙**:
- **처리량**: 초당 200K~2M 메시지
- **레이턴시**: p99.9 <10ms
- **Peak throughput**: 605 MB/sec (managed cloud)
- **보장**: At-least-once 기본, exactly-once 선택 가능

**아키텍처**:
```
Producer → Kafka (Partitioned Topics)
           ↓
        Flink (Stream Processing)
           ↓
    Cassandra/ScyllaDB + Redis
```

**비용**:
- **Self-hosted**: 월 $2,000~$10,000+ (3노드 클러스터)
- **AWS MSK**: $0.21~$0.84/hour per vCPU, 예상 $3,000~$10,000/월
- **Confluent Cloud**: eCKU 기반, 예상 $5,000~$20,000/월

**배포 & 운영**:
- 배포 시간: 1~4주 (self-hosted), 1~3일 (MSK)
- 운영 복잡도: ⚙️⚙️⚙️ 높음
- 필요 역량: Kafka 전문가, Java/Scala, ZooKeeper

**장점**:
- ⚡ 최고 성능: 처리량 & 레이턴시
- 🔧 완벽한 제어: 세밀한 튜닝
- 🌐 풍부한 생태계: 검증된 커넥터
- 📈 무제한 확장

**단점**:
- 💰 높은 총비용
- 🧑‍💻 전문 인력 필수
- ⏱️ 긴 배포 시간
- 🔧 복잡한 운영

**적합한 경우**:
- 대기업, 미션 크리티컬
- 초당 100만+ 메시지
- 전담 DevOps 팀
- 멀티 클라우드/온프레미스

**검증 사례**: Netflix RDG (100만 msg/s), LinkedIn, Uber

---

#### 옵션 2: AWS Kinesis + Lambda

**핵심 스펙**:
- **처리량**: 1 MB/sec per shard (input), 2 MB/sec (output)
- **레이턴시**: p99 <1초
- **Capacity**: 1,000 PUT records/sec per shard
- **확장**: Shard 추가로 수평 확장

**아키텍처**:
```
Producer → Kinesis Data Streams (Shards)
           ↓
        Lambda (Serverless Processing)
           ↓
    DynamoDB + DAX Cache
```

**비용**:
- **Provisioned**: $0.015/shard/hour (~$11/shard/월)
- **On-Demand**: $0.0134/GB + $0.015/shard-hour
- **예상** (10 shards): 월 $500~$2,000

**배포 & 운영**:
- 배포 시간: 수 시간~1일
- 운영 복잡도: ⚙️ 낮음
- 필요 역량: AWS 기본, Lambda 경험

**장점**:
- 🚀 빠른 배포: 몇 시간 내 production
- 🤖 완전 관리형: 자동 스케일링
- 💵 예측 가능한 비용
- 🔗 AWS 통합: Lambda, S3, DynamoDB

**단점**:
- 🔒 AWS 종속
- ⚡ 성능 제한: Kafka 대비 낮음
- 🔧 튜닝 제한
- 📊 대규모는 비용 급증

**적합한 경우**:
- AWS 중심 조직
- 초당 1만~50만 메시지
- 제한된 DevOps 리소스
- 빠른 MVP/출시

**검증 사례**: Amazon 내부, Sonos, 중소기업

---

#### 옵션 3: RabbitMQ + 자체 처리

**핵심 스펙**:
- **처리량**: 초당 ~3만 메시지
- **레이턴시**: 30K msg/s까지 낮음, 초과 시 급증
- **메모리**: 메시지 큐잉, 지속 스토리지 아님

**아키텍처**:
```
Producer → RabbitMQ (Queues/Exchanges)
           ↓
    Custom Workers (Node.js/Python)
           ↓
    PostgreSQL + Redis
```

**비용**:
- **Self-hosted**: 월 $100~$500 (t3.medium~m5.large)
- **Amazon MQ**: ~$703/월 (3-node mq.m5.large)

**배포 & 운영**:
- 배포 시간: 1~3일
- 운영 복잡도: ⚙️⚙️ 중간
- 필요 역량: AMQP 이해, 기본 DevOps

**장점**:
- 💰 저렴한 비용
- 📚 성숙한 기술
- 🛠️ 간단한 운영
- 🔌 다양한 프로토콜 지원

**단점**:
- 📉 낮은 처리량
- ⏱️ 부하 시 레이턴시 증가
- 💾 단기 보관
- 🚫 확장 어려움

**적합한 경우**:
- 스타트업, MVP
- 초당 1만 미만 메시지
- 예산 $1,000/month 이하
- 전통적 메시징 패턴

---

#### 스트리밍 플랫폼 비교표

| 항목 | Kafka + Flink | Kinesis + Lambda | RabbitMQ |
|------|--------------|------------------|----------|
| **처리량** | 200K~2M/s | 50K~500K/s | ~30K/s |
| **레이턴시** | p99.9 <10ms | p99 <1s | 낮음 (저부하) |
| **비용 (중규모)** | $5K~$20K/월 | $500~$2K/월 | $200~$1.5K/월 |
| **배포** | 1~4주 | 수시간~1일 | 1~3일 |
| **운영** | ⚙️⚙️⚙️ 높음 | ⚙️ 낮음 | ⚙️⚙️ 중간 |
| **확장성** | 무제한 | Shard 제한 | 제한적 |
| **클라우드** | 멀티/온프렘 | AWS 전용 | 자유 |

**의사결정 가이드**:
```
처리량 > 100만/s? → Kafka
  └─ NO
     ↓
AWS 전용 OK? → Kinesis
  └─ NO → Kafka (self-hosted)
     ↓
처리량 > 5만/s? → Kinesis
  └─ NO
     ↓
예산 < $1K/월? → RabbitMQ
  └─ NO → Kinesis
```

---

### 2.2 시계열 DB 선택

**패밀리 요구**:
- 빠른 쓰기 성능 (초당 수만~수십만 건)
- 시간 순 조회 최적화
- 파티션/샤딩 지원
- 유연한 스키마 (JSON, Key-Value)

---

#### 옵션 1: Apache Cassandra / ScyllaDB

**핵심 스펙**:
- **쓰기 처리량**: 초당 100만+ 쓰기
- **레이턴시**: p99 <10ms (쓰기)
- **확장**: 선형 수평 확장
- **일관성**: Tunable (Quorum 권장)

**아키텍처**:
- Masterless, Peer-to-Peer
- 파티션 키 기반 분산
- Compaction 전략 (Time-Window)

**비용**:
- **Self-hosted**: 월 $1,000~$5,000 (3노드)
- **ScyllaDB Cloud**: 월 $500~$3,000
- **AWS Keyspaces**: 사용량 기반

**장점**:
- ⚡ 초고속 쓰기
- 📈 선형 확장
- 🌐 멀티 데이터센터 복제
- 💪 고가용성 (P2P)

**단점**:
- 🔧 복잡한 데이터 모델링
- 📊 제한적 쿼리 (No JOIN)
- 🧑‍💻 전문 지식 필요
- 💰 높은 리소스 사용

**적합한 경우**:
- 초고속 쓰기 (100만+ writes/sec)
- 시계열 데이터 (센서, 로그)
- 멀티 리전 배포
- Netflix, Uber 규모

**검증 사례**: Netflix (5M+ writes/sec), Uber, Discord

---

#### 옵션 2: AWS DynamoDB

**핵심 스펙**:
- **쓰기 처리량**: RCU/WCU 기반 확장
- **레이턴시**: p99 <10ms (single-digit ms)
- **확장**: 자동 스케일링
- **일관성**: Eventually consistent 기본

**아키텍처**:
- Managed NoSQL
- 파티션 키 + 정렬 키
- DynamoDB Streams (CDC)

**비용**:
- **On-Demand**: $1.25/million writes
- **Provisioned**: $0.00065/WCU/hour
- **예상**: 월 $500~$5,000

**장점**:
- 🤖 완전 관리형
- 🚀 빠른 배포
- 🔗 AWS 통합 (Lambda, Kinesis)
- 💵 사용량 기반 과금

**단점**:
- 🔒 AWS 종속
- 💰 대규모 시 비싸짐
- 📊 제한적 쿼리
- 🔧 핫 파티션 주의

**적합한 경우**:
- AWS 중심
- 중간 규모 (초당 1만~10만)
- 빠른 프로토타이핑
- 운영 부담 최소화

---

#### 옵션 3: TimescaleDB (PostgreSQL 확장)

**핵심 스펙**:
- **쓰기 처리량**: 초당 10만 건
- **레이턴시**: <10ms (쓰기)
- **확장**: Hypertable 파티셔닝
- **쿼리**: Full SQL 지원

**아키텍처**:
- PostgreSQL 기반
- 자동 시간 기반 파티셔닝
- 압축 (10:1 비율)

**비용**:
- **Self-hosted**: 월 $200~$2,000
- **Timescale Cloud**: 사용량 기반

**장점**:
- 🔍 Full SQL 지원
- 📊 복잡한 쿼리 가능
- 🛠️ 익숙한 PostgreSQL
- 💰 상대적 저렴

**단점**:
- ⚡ 쓰기 성능 한계 (vs Cassandra)
- 📈 확장 제한
- 🔧 Cassandra보다 운영 쉬움

**적합한 경우**:
- SQL 필수
- 중소 규모 (초당 ~10만)
- 복잡한 분석 쿼리
- PostgreSQL 팀 역량

---

#### 시계열 DB 비교표

| 항목 | Cassandra/ScyllaDB | DynamoDB | TimescaleDB |
|------|-------------------|----------|-------------|
| **쓰기 처리량** | 1M+/s | 100K~500K/s | ~100K/s |
| **쿼리 기능** | 제한적 | 제한적 | Full SQL |
| **확장성** | 선형 | 자동 | 제한적 |
| **비용** | $1K~$5K/월 | $500~$5K/월 | $200~$2K/월 |
| **운영** | ⚙️⚙️⚙️ 높음 | ⚙️ 낮음 | ⚙️⚙️ 중간 |

**의사결정 가이드**:
```
쓰기 > 100만/s? → Cassandra
  └─ NO
     ↓
AWS 전용 + 관리형? → DynamoDB
  └─ NO
     ↓
복잡한 SQL 필요? → TimescaleDB
  └─ NO → DynamoDB
```

---

### 2.3 캐시 레이어 선택

**패밀리 요구**:
- 밀리초 미만 응답
- 핫 데이터 빠른 조회
- 높은 처리량

---

#### 옵션 1: Redis

**핵심 스펙**:
- **레이턴시**: 0.15ms (GET)
- **처리량**: 초당 120만 트랜잭션
- **자료구조**: String, Hash, List, Set, Sorted Set, Stream

**비용**:
- **Self-hosted**: 월 $100~$500
- **AWS ElastiCache**: 월 $50~$1,000

**장점**:
- ⚡ 초고속
- 🔧 다양한 자료구조
- 📡 Pub/Sub 지원
- 💾 지속성 옵션 (AOF, RDB)

**단점**:
- 💰 메모리 기반 (비쌈)
- 🔧 단일 스레드

**적합한 경우**:
- 대부분의 스트리밍 시스템
- 복잡한 캐시 로직
- Pub/Sub 필요

---

#### 옵션 2: Memcached

**핵심 스펙**:
- **레이턴시**: 마이크로초
- **처리량**: 초당 100만+ operations
- **자료구조**: Key-Value만

**비용**:
- **Self-hosted**: 월 $50~$300
- **AWS ElastiCache**: 월 $30~$500

**장점**:
- ⚡ 극도로 빠름
- 💰 더 저렴
- 🔧 단순함

**단점**:
- 📊 단순한 자료구조
- 💾 지속성 없음

**적합한 경우**:
- 단순 캐싱만
- 최소 비용
- 초고속 필수

---

#### 캐시 비교표

| 항목 | Redis | Memcached |
|------|-------|-----------|
| **레이턴시** | 0.15ms | <0.1ms |
| **자료구조** | 다양 | Key-Value |
| **지속성** | 옵션 있음 | 없음 |
| **비용** | 중간 | 낮음 |

**의사결정 가이드**:
```
복잡한 자료구조 필요? → Redis
  └─ NO
     ↓
Pub/Sub 필요? → Redis
  └─ NO → Memcached
```

---

## Part 2.5: 중요 DNA 시스템 기술 선택 🆕

이 섹션에서는 B-C-A 패밀리에서 **⭐⭐⭐ 매우 중요한 DNA 시스템 3가지**의 기술 옵션을 다룹니다.

### 2.5.1 Observability (DNA #8) - 스트리밍 모니터링 ⭐⭐⭐

**패밀리 요구**:
- 메시지 lag 실시간 추적
- 처리량 (throughput) 모니터링
- 백프레셔 (backpressure) 감지
- 워터마크 (watermark) 추적

---

#### 옵션 1: Prometheus + Grafana + Jaeger

**핵심 스펙**:
- **메트릭 수집**: Prometheus (pull 방식)
- **시각화**: Grafana 대시보드
- **분산 추적**: Jaeger (OpenTelemetry)
- **비용**: 오픈소스 (인프라 비용만)

**장점**:
- 오픈소스, 커뮤니티 활성화
- Kafka Exporter로 lag, offset 자동 추적
- 무제한 메트릭, 무제한 대시보드
- Kubernetes 네이티브 통합

**단점**:
- 직접 운영 필요 (설치, 스케일링, 백업)
- 고가용성 구성 복잡 (Thanos, Cortex 추가)
- 알림 규칙 수동 작성
- 팀 러닝 커브

**적합한 경우**:
- 인프라 운영 역량 있는 팀
- 비용 민감한 프로젝트
- 커스터마이징 요구사항 많음
- 멀티 클라우드 환경

**검증 사례**: Uber, Twitter, Netflix (일부)

---

#### 옵션 2: DataDog

**핵심 스펙**:
- **메트릭 + 로그 + APM**: 통합 플랫폼
- **자동 Kafka 통합**: Agent 설치만으로 lag 추적
- **비용**: $15~$31/호스트/월 (Pro~Enterprise)

**장점**:
- 완전 관리형, 설치 5분
- Kafka, Flink 자동 통합
- AI 기반 이상 탐지
- 300+ 통합 (Slack, PagerDuty 등)
- 머신러닝 기반 알림

**단점**:
- 고비용 (호스트당 $15~$31/월)
- 메트릭 제한 (커스텀 메트릭 추가 비용)
- 벤더 락인
- 데이터 보존 기간 짧음 (기본 15일)

**적합한 경우**:
- 빠른 프로덕션 배포 필요
- 운영 인력 부족
- 통합 모니터링 선호
- 예산 여유

**검증 사례**: Airbnb, Spotify

---

#### 옵션 3: AWS CloudWatch + X-Ray

**핵심 스펙**:
- **메트릭**: CloudWatch (Kinesis 네이티브)
- **분산 추적**: X-Ray
- **비용**: $0.30/메트릭/월 + 데이터 전송

**장점**:
- AWS 서비스 네이티브 통합 (Kinesis, MSK)
- 서버리스, 관리 불필요
- IAM 통합 보안
- CloudWatch Insights (쿼리 언어)

**단점**:
- AWS 락인
- 대시보드 기능 제한적
- 커스텀 메트릭 비쌈 ($0.30/월 × 메트릭 수)
- 고급 기능 부족 (알림, 상관관계)

**적합한 경우**:
- AWS 올인 환경
- Kinesis/MSK 사용
- 서버리스 우선
- 최소 운영 부담

**검증 사례**: AWS 고객 다수

**의사결정 플로우차트**:
```
운영 역량 있나요?
├─ YES → 비용 민감?
│   ├─ YES → Prometheus + Grafana (옵션 1)
│   └─ NO → DataDog (옵션 2)
└─ NO → AWS 올인?
    ├─ YES → CloudWatch (옵션 3)
    └─ NO → DataDog (옵션 2)
```

---

### 2.5.2 Resilience (DNA #10) - 장애 복구 ⭐⭐⭐

**패밀리 요구**:
- 체크포인트 자동 저장
- 이벤트 재생 (replay)
- Dead Letter Queue
- Circuit Breaker

---

#### 옵션 1: Apache Flink State

**핵심 스펙**:
- **체크포인트**: 자동, RocksDB 백엔드
- **Exactly-once**: 2PC 지원
- **복구 시간**: 초~분 (상태 크기 의존)

**장점**:
- Kafka 네이티브 통합
- Exactly-once 보장
- 대규모 상태 처리 (TB급)
- Savepoint로 업그레이드 무중단

**단점**:
- Flink 전용 (Kafka Streams 불가)
- 운영 복잡도 높음
- 체크포인트 오버헤드 (5~10%)
- 러닝 커브 높음

**적합한 경우**:
- Exactly-once 필수
- 대규모 상태 처리
- 복잡한 스트림 처리
- Flink 채택 확정

**검증 사례**: Uber, Alibaba

---

#### 옵션 2: Resilience4j

**핵심 스펙**:
- **Circuit Breaker**: 5가지 상태
- **Retry**: Exponential backoff
- **Rate Limiter**: Token bucket
- **비용**: 오픈소스

**장점**:
- 경량 (Zero dependency)
- Java 8+ 함수형 스타일
- Spring Boot 통합
- Micrometer 메트릭 자동

**단점**:
- Java/Kotlin 전용
- 체크포인트 미지원 (별도 구현)
- Kafka 재생 수동 구현
- 분산 상태 관리 없음

**적합한 경우**:
- Java/Spring 환경
- 마이크로서비스 패턴
- 경량 솔루션 선호
- 애플리케이션 레벨 복원력

**검증 사례**: Spring Cloud 사용자 다수

---

#### 옵션 3: AWS Kinesis + Lambda DLQ

**핵심 스펙**:
- **체크포인트**: 자동 (Kinesis 관리)
- **DLQ**: SQS/Lambda 통합
- **재시도**: Lambda 최대 2회

**장점**:
- 완전 관리형
- 자동 체크포인트
- SQS DLQ 통합
- 서버리스

**단점**:
- Kinesis 제약 (샤드당 1MB/s)
- Exactly-once 미지원
- 복잡한 재생 로직 불가
- AWS 락인

**적합한 경우**:
- AWS 서버리스 환경
- 간단한 스트림 처리
- 운영 최소화
- At-least-once 충분

**검증 사례**: AWS 서버리스 사용자

**의사결정 플로우차트**:
```
Exactly-once 필요?
├─ YES → Flink 사용?
│   ├─ YES → Flink State (옵션 1)
│   └─ NO → 다른 스트리밍 고려
└─ NO → AWS 환경?
    ├─ YES → Kinesis + Lambda (옵션 3)
    └─ NO → Resilience4j (옵션 2)
```

---

### 2.5.3 Performance (DNA #11) - 벤치마크 및 프로파일링 ⭐⭐⭐

**패밀리 요구**:
- 처리량 측정 (메시지/초)
- 레이턴시 분포 (p50, p99, p999)
- 메모리 프로파일링
- 패턴별 성능 (sequential, random, burst)

---

#### 옵션 1: Criterion (Rust) / Criterion.rs

**핵심 스펙**:
- **통계**: 정규분포, 아웃라이어 검출
- **회귀 탐지**: 자동 (5% 임계값)
- **시각화**: HTML 리포트 자동 생성
- **비용**: 오픈소스

**장점**:
- 통계적으로 정확 (Welch's t-test)
- 회귀 자동 탐지
- 웜업 자동 처리
- 그래프 자동 생성 (Gnuplot)

**단점**:
- Rust 전용
- 마이크로벤치마크 위주
- 분산 벤치마크 미지원
- 대규모 통합 테스트 부적합

**적합한 경우**:
- Rust 프로젝트
- 마이크로 최적화
- CI/CD 성능 회귀 방지
- 통계적 정확성 필요

**검증 사례**: Rust 생태계 표준

---

#### 옵션 2: JMH (Java Microbenchmark Harness)

**핵심 스펙**:
- **JVM 워밍업**: JIT 최적화 고려
- **멀티스레드**: 동시성 벤치마크
- **프로파일러 통합**: perf, async-profiler
- **비용**: 오픈소스

**장점**:
- JVM 특화 (JIT, GC 고려)
- 멀티스레드 벤치마크
- Black hole (최적화 방지)
- Spring 통합 가능

**단점**:
- Java/Kotlin 전용
- 설정 복잡 (어노테이션 다수)
- 결과 해석 어려움
- 러닝 커브 높음

**적합한 경우**:
- Java/Kotlin 프로젝트
- Kafka Streams, Flink 최적화
- 멀티스레드 성능 측정
- JVM 전문가 팀

**검증 사례**: Netflix, Uber (JVM 프로젝트)

---

#### 옵션 3: pytest-benchmark (Python)

**핵심 스펙**:
- **통계**: min, max, mean, stddev
- **히스토그램**: 자동 생성
- **비교**: --benchmark-compare
- **비용**: 오픈소스

**장점**:
- pytest 네이티브 통합
- 간단한 사용법 (@pytest.mark.benchmark)
- CI 통합 쉬움
- JSON 결과 저장

**단점**:
- Python 전용 (GIL 제약)
- 통계 기능 제한적
- 회귀 탐지 수동
- 대규모 벤치마크 느림

**적합한 경우**:
- Python 프로젝트
- pytest 기반 테스트
- 간단한 성능 추적
- 빠른 프로토타입

**검증 사례**: Python 오픈소스 프로젝트

**의사결정 플로우차트**:
```
언어 스택?
├─ Rust → Criterion (옵션 1)
├─ Java/Kotlin → JMH (옵션 2)
└─ Python → pytest-benchmark (옵션 3)
```

---

## Part 3: 도메인 선택 요소 도메인 선택 요소 (프로젝트별)

이 요소들은 **패밀리와 무관**하게 프로젝트 요구사항에 따라 선택합니다.

### 3.1 프론트엔드 프레임워크
- React, Vue, Angular, Svelte
- (패밀리 영향 없음, 프로젝트 선호도)

### 3.2 백엔드 언어/프레임워크
- Node.js (Express, NestJS)
- Python (FastAPI, Django)
- Java (Spring Boot)
- Go
- (패밀리 영향 적음, 팀 역량 우선)

### 3.3 인증/권한
- Auth0, Cognito, Keycloak
- (패밀리 무관, 보안 요구사항)

### 3.4 모니터링/로깅
- Prometheus + Grafana
- ELK Stack
- Datadog, New Relic
- (패밀리 무관, 운영 선호도)

---

## Part 4: Stage 2 통합

### 4.1 Layer 3 제약 반영 예시

**시나리오**: 주식 거래 플랫폼

**Layer 3 제약 발견**:
- 증권사 API: 초당 20건 제한
- OS: Windows 전용 (일부 증권사)
- 비용: API 호출당 과금

**기술 선택 영향**:
```
스트리밍 플랫폼:
- Kafka (선호) → RabbitMQ (Windows 호환성)
- 이유: 일부 증권사 Windows DLL 제약

시계열 DB:
- Cassandra (선호) → PostgreSQL + TimescaleDB
- 이유: API 호출 제한으로 대용량 불필요

캐시:
- Redis 유지
- 이유: API 호출 최소화 필수
```

---

### 4.2 충돌 해결 예시

**NFR 목표 vs Layer 3 제약**:

**충돌 1**: 정확성 A + API 20건/초
- NFR: 100% 정확, 즉시 감지
- 제약: API 호출 제한
- **해결**: 우선순위 종목 + 폴링 주기 조정

**충돌 2**: 즉시성 A + API 지연
- NFR: 밀리초 응답
- 제약: API 응답 100ms
- **해결**: 적극적 캐싱 + WebSocket 활용

---

### 4.3 ADR 작성 준비

**선택한 기술 스택 정리**:
```
Bootstrap 필수:
✅ 스트리밍: RabbitMQ (Layer 3 제약)
✅ DB: PostgreSQL + TimescaleDB
✅ 캐시: Redis

도메인 선택:
✅ 백엔드: Node.js + TypeScript
✅ 프론트엔드: React
✅ 인증: JWT (자체 구현)
```

**ADR 작성 대상**:
1. 스트리밍 플랫폼 선택 (Kafka vs RabbitMQ)
2. DB 선택 (Cassandra vs TimescaleDB)
3. 캐시 전략
4. 증권사 API 통합 방식

---

## 📚 참고 자료

### 벤치마크
- [Confluent: Kafka vs Pulsar vs RabbitMQ (2020)](https://www.confluent.io/blog/kafka-fastest-messaging-system/)
- [OpenMessaging Benchmark Framework](https://openmessaging.cloud/docs/benchmarks/)
- Netflix Tech Blog: RDG 아키텍처

### 비용 계산기
- [AWS Kinesis Pricing](https://aws.amazon.com/kinesis/data-streams/pricing/)
- [AWS MSK Pricing](https://aws.amazon.com/msk/pricing/)
- [Confluent Cloud Pricing](https://www.confluent.io/confluent-cloud/pricing/)

### 공식 문서
- [Apache Kafka](https://kafka.apache.org/documentation/)
- [AWS Kinesis Developer Guide](https://docs.aws.amazon.com/kinesis/)
- [RabbitMQ Documentation](https://www.rabbitmq.com/documentation.html)
- [Cassandra Documentation](https://cassandra.apache.org/doc/)
- [DynamoDB Developer Guide](https://docs.aws.amazon.com/dynamodb/)
- [TimescaleDB Documentation](https://docs.timescale.com/)
- [Redis Documentation](https://redis.io/documentation)

### 검증 사례
- Netflix: [Building Netflix's Distributed Tracing Infrastructure](https://netflixtechblog.com/)
- Uber: [Real-Time Data Infrastructure at Uber](https://eng.uber.com/)
- Twitter: [The Infrastructure Behind Twitter](https://blog.twitter.com/engineering/)

---

**마지막 업데이트**: 2024-11-12  
**다음 검토**: 2025-02-12 (기술 스택 업데이트 반영)


================================================================================

📄 FILE: 06_analytics_batch_tech_options.md
--------------------------------------------------------------------------------

# 분석/배치 패밀리 (B-A-C) - 기술 매트릭스

**작성일**: 2025-11-12  
**패밀리**: 분석/배치 (B-A-C)  
**검증 사례**: Snowflake (8초 쿼리), Redshift, BigQuery, dbt

---

## Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐

### 1.1 B-A-C 특성이 강제하는 것

#### B (점진적 실패) → 배치 재시도 필수

**특성**:
- 작업 실패 시 재시도
- 체크포인트 기반 복구
- 부분 성공 허용
- Idempotent 처리

**강제되는 기술적 요구**:
```
✅ 배치 스케줄러 (Airflow, dbt)
✅ 작업 재시도 메커니즘
✅ 데이터 리니지 추적
✅ 점진적 로드 (Incremental)
```

**검증 사례**:
- Snowflake: 작업 실패 시 자동 재시도, 체크포인트 복구
- dbt: Incremental 모델, 실패한 노드만 재실행

---

#### A (구조화 데이터) → 고정 스키마 필수

**특성**:
- 테이블 기반 구조
- 고정된 컬럼 정의
- SQL 쿼리 최적화
- ACID 트랜잭션 (배치 완료 시)

**강제되는 기술적 요구**:
```
✅ 관계형 스키마
✅ SQL 기반 변환
✅ 스키마 마이그레이션 도구
✅ 데이터 타입 검증
```

**검증 사례**:
- Snowflake: Zero-Copy Cloning, Time Travel (90일)
- Redshift: Columnar storage, Sort/Dist keys
- BigQuery: Nested/Repeated fields (STRUCT/ARRAY)

---

#### C (배치 처리) → ETL/ELT 파이프라인 필수

**특성**:
- 시간/일 단위 스케줄
- 대용량 데이터 처리
- 집계 및 변환
- 비실시간 (분~시간)

**강제되는 기술적 요구**:
```
✅ 배치 스케줄러
✅ 대용량 데이터 로더
✅ Materialized Views
✅ Query Result Caching
```

**검증 사례**:
- Snowflake: 8-12초 TPC-DS 쿼리 (벤치마크)
- Redshift: 8.24초 평균 쿼리, 82% 유휴 시간
- BigQuery: 11.18초 평균, 서버리스

---

### 1.2 이 패밀리에 필요한 DNA 시스템 및 메인 서비스

#### DNA 11개 시스템 중 필요한 것

B-A-C 패밀리는 다음 DNA 시스템이 필요합니다:

| DNA 시스템 | 중요도 | 이유 |
|-----------|-------|------|
| 1. Testing | ✅ 필수 | 배치 변환 로직 검증 |
| 2. Code Quality | ✅ 필수 | SQL/Python 품질 유지 |
| 3. Architecture | ✅ 필수 | ETL 파이프라인 모듈 분리 |
| 4. Type System | ✅ 필수 | 스키마 타입 안전성 |
| 5. Error Handling | ✅ 필수 | 배치 실패 재시도 전략 |
| 6. Configuration | ✅ 필수 | 배치 스케줄, DW 설정 |
| 7. Identity & Access | ✅ 필수 | DW 접근 권한, RLS |
| 8. Observability | ✅ 필수 | 배치 작업 상태 모니터링 |
| 9. API Gateway | ⚠️ 조건부 | BI 임베딩 시 필요 |
| 10. Resilience | ✅ 필수 | 체크포인트, 재시도 |
| 11. Performance | ✅ 필수 | 쿼리 최적화, 파티셔닝 |

**특별히 중요한 DNA 시스템 (⭐⭐⭐)**: 없음

B-A-C 패밀리는 모든 DNA 시스템이 **기본 수준**으로 필요합니다. 특별히 매우 중요한 시스템은 없습니다. 이유는:

- **배치 처리(C)**: 실시간이 아니라 디버깅 시간 충분
- **점진적 실패(B)**: 작업 재시도로 복구 가능
- **구조화 데이터(A)**: 스키마가 고정되어 예측 가능

→ **Part 2.5는 생략**합니다. 모든 DNA 시스템은 각 기술의 기본 가이드를 따르면 됩니다.

#### 메인 서비스 필수 요소 (패밀리 강제)

B-A-C 패밀리는 다음 3가지 메인 서비스 기술을 **반드시** 포함해야 합니다:

#### 1. 데이터 웨어하우스 (필수!)
**역할**: 대용량 분석 쿼리, 집계, 저장
**이유**: 구조화 데이터(A) + 배치 처리(C)
**선택지**: Snowflake, Redshift, BigQuery

#### 2. ETL/ELT 도구 (필수!)
**역할**: 데이터 추출, 변환, 로드
**이유**: 배치 파이프라인(C) + 스케줄링
**선택지**: dbt, Airflow, Fivetran

#### 3. BI/시각화 (필수!)
**역할**: 대시보드, 리포트 생성
**이유**: 분석 결과 시각화
**선택지**: Tableau, Looker, Power BI

---

## Part 2: 메인 서비스 기술 선택 ⭐⭐⭐

### 2.1 데이터 웨어하우스 선택

**패밀리 요구**:
- 대용량 SQL 쿼리 (수백 GB~PB)
- Columnar Storage (읽기 최적화)
- MPP (Massively Parallel Processing)
- 시간별/일별 배치 로드

---

#### 옵션 1: Snowflake

**핵심 스펙**:
- **쿼리 성능**: 8-12초 (TPC-DS 벤치마크)
- **처리량**: 수십 TB/일, PB급 스토리지
- **동시성**: 무제한 가상 웨어하우스
- **아키텍처**: Storage-Compute 분리, 3-Layer

**비용**:
- **Compute**: $2~$4/credit (웨어하우스 크기별)
- **Storage**: $23~$40/TB/월 (압축 후)
- **예상** (중규모): 월 $2,000~$10,000
- **대규모**: 월 $20,000~$100,000+

**장점**:
- ⚡ 최고 성능: 8초 TPC-DS
- 🔧 Zero-Copy Cloning: 개발/테스트 환경
- 📈 무제한 확장: 가상 웨어하우스 독립
- ⏱️ Time Travel: 90일 (Enterprise)
- 🌐 멀티 클라우드: AWS, Azure, GCP

**단점**:
- 💰 높은 비용: 크레딧 기반 과금
- 📊 러닝 커브: 최적화 복잡
- 🔒 클라우드 종속 (하지만 멀티)

**적합한 경우**:
- 대기업, 복잡한 분석
- 수십 TB~PB 데이터
- 멀티 팀 동시 작업
- 개발/스테이징 환경 필수

**검증 사례**: Instacart, Capital One, DoorDash

---

#### 옵션 2: AWS Redshift

**핵심 스펙**:
- **쿼리 성능**: 8.24초 평균 (벤치마크)
- **처리량**: 수 TB/일, PB급 확장
- **동시성**: WLM (Workload Management)
- **아키텍처**: MPP, Columnar, Sort/Dist Keys

**비용**:
- **RA3 (Storage-Compute 분리)**: $1.086~$13.04/node/hour
- **DC2 (Compute 최적화)**: $0.25~$4.80/node/hour
- **예상** (RA3.4xl, 2노드): 월 $1,600~$5,000
- **대규모** (10+ 노드): 월 $15,000~$50,000+

**장점**:
- 🔗 AWS 통합: S3, Lambda, Kinesis
- 💵 상대적 저렴: DC2 $0.25/시간부터
- 📊 성숙한 생태계: 다양한 커넥터
- ⚙️ WLM: 쿼리 우선순위 제어

**단점**:
- 🔒 AWS 종속
- 🔧 운영 복잡: 수동 튜닝 필요
- ⏱️ 동시성 제약: WLM 큐 관리
- 📉 유휴 비용: 82% 유휴 시간 (평균)

**적합한 경우**:
- AWS 중심 조직
- 수 TB~수십 TB 데이터
- 예측 가능한 워크로드
- SQL 최적화 역량 있음

**검증 사례**: Netflix, Lyft, McDonald's

---

#### 옵션 3: Google BigQuery

**핵심 스펙**:
- **쿼리 성능**: 11.18초 평균 (벤치마크)
- **처리량**: 수십 TB/일, PB급 스토리지
- **동시성**: 서버리스, 자동 확장
- **아키텍처**: Dremel, Columnar, Capacitor

**비용**:
- **On-Demand**: $6.25/TB (스캔된 데이터)
- **Flat-Rate**: $2,000~$10,000+/월 (slot 예약)
- **Storage**: $0.02/GB/월 (Active), $0.01 (Long-term)
- **예상** (On-Demand, 1TB/일): 월 $187

**장점**:
- 🚀 서버리스: 인프라 관리 불필요
- 💵 On-Demand: 사용한 만큼만
- 🔗 GCP 통합: Cloud Storage, Dataflow
- 📈 무제한 확장: 자동 슬롯 할당

**단점**:
- 🔒 GCP 종속
- 💰 대규모 시 비쌈: 쿼리 스캔량 기반
- 🔧 튜닝 제한: 서버리스라 제어 적음
- ⏱️ 스캔량 최적화 필요

**적합한 경우**:
- GCP 중심 조직
- 중소 규모, 비정기 쿼리
- 빠른 프로토타이핑
- 운영 부담 최소화

**검증 사례**: Spotify, Twitter, The New York Times

---

#### 데이터 웨어하우스 비교표

| 항목 | Snowflake | Redshift | BigQuery |
|------|-----------|----------|----------|
| **쿼리 성능** | 8-12초 | 8.24초 | 11.18초 |
| **처리량** | PB급 | PB급 | PB급 |
| **비용 (중규모)** | $2K~$10K/월 | $1.6K~$5K/월 | $187~$2K/월 |
| **운영** | ⚙️⚙️ 중간 | ⚙️⚙️⚙️ 높음 | ⚙️ 낮음 |
| **확장성** | 무제한 | 노드 추가 | 무제한 (서버리스) |
| **클라우드** | 멀티 | AWS | GCP |

**의사결정 가이드**:
```
데이터 > 100TB? → Snowflake
  └─ NO
     ↓
AWS 전용 OK? → Redshift
  └─ NO
     ↓
GCP 전용 OK? → BigQuery
  └─ NO → Snowflake (멀티 클라우드)
     ↓
운영 리소스 < 1명? → BigQuery
  └─ NO → Redshift or Snowflake
```

---

### 2.2 ETL/ELT 도구 선택

**패밀리 요구**:
- 배치 스케줄링 (cron, 이벤트 기반)
- 데이터 변환 (SQL, Python)
- 의존성 관리 (DAG)
- 재시도 및 모니터링

---

#### 옵션 1: dbt (Data Build Tool)

**핵심 스펙**:
- **변환 방식**: ELT (DW 내 SQL 변환)
- **배포**: Cloud ($50~$400+/월) or Core (오픈소스)
- **언어**: SQL + Jinja2
- **의존성**: DAG 자동 생성

**비용**:
- **dbt Core**: 무료 (오픈소스)
- **dbt Cloud Developer**: $50/seat/월
- **dbt Cloud Team**: $100+/seat/월
- **예상** (5명): 월 $250~$500

**장점**:
- 📊 SQL 중심: 데이터 분석가 친화적
- 🔧 Incremental 모델: 효율적 배치
- 📚 데이터 문서화: 자동 docs 생성
- 🧪 테스트: SQL 기반 데이터 품질 검증

**단점**:
- 🔧 오케스트레이션 제한: Airflow 필요 (대규모)
- 🐍 Python 제약: SQL 외 복잡 로직 어려움
- 📈 대규모 확장: 수천 모델 시 느림

**적합한 경우**:
- SQL 중심 팀
- 중소 규모 (수백 모델)
- Snowflake/Redshift/BigQuery 사용
- 데이터 분석가 주도 변환

**검증 사례**: GitLab, Zapier, JetBlue

---

#### 옵션 2: Apache Airflow

**핵심 스펙**:
- **변환 방식**: ETL/ELT 모두 지원
- **배포**: Self-hosted or Managed (MWAA)
- **언어**: Python (DAG 정의)
- **의존성**: 복잡한 DAG 지원

**비용**:
- **Self-hosted**: 월 $500~$2,000 (인프라)
- **AWS MWAA**: $0.49/hour (Environment) + $0.24/vCPU/hour
- **예상** (MWAA, 2 vCPU): 월 $700~$1,500
- **Google Cloud Composer**: 유사

**장점**:
- 🐍 Python 기반: 복잡한 로직 구현
- 🔧 유연성: 모든 데이터 소스 통합
- 📈 대규모 확장: 수천 작업 지원
- 📊 모니터링: UI + 알림

**단점**:
- 🧑‍💻 높은 러닝 커브: Python 필수
- 💰 운영 복잡: 워커 관리, 스케일링
- 🔧 설정 복잡: Executor, Queue 설정

**적합한 경우**:
- Python 팀
- 복잡한 파이프라인 (100+ 작업)
- 다양한 데이터 소스 통합
- 실시간 + 배치 혼합

**검증 사례**: Airbnb, Lyft, Reddit

---

#### 옵션 3: Fivetran

**핵심 스펙**:
- **변환 방식**: ELT (자동 커넥터)
- **배포**: Fully Managed (SaaS)
- **언어**: No-code (UI 설정)
- **커넥터**: 500+ 소스

**비용**:
- **Starter**: $120/월 (500K MAR)
- **Standard**: $180/월 (500K MAR)
- **Enterprise**: 맞춤형 가격
- **MAR**: Monthly Active Rows (변경된 행)
- **예상**: 월 $1,000~$10,000+

**장점**:
- 🚀 빠른 배포: 커넥터 클릭만
- 🤖 자동 스키마 변경 감지
- 🔗 500+ 커넥터: Salesforce, MySQL 등
- 💼 관리형: 유지보수 불필요

**단점**:
- 💰 높은 비용: MAR 기반 폭증 가능
- 🔧 커스터마이징 제한
- 🔒 벤더 종속

**적합한 경우**:
- No-code 선호
- 표준 SaaS 통합 (Salesforce 등)
- 빠른 MVP
- 운영 리소스 < 1명

**검증 사례**: DocuSign, Autodesk, Square

---

#### ETL/ELT 비교표

| 항목 | dbt | Airflow | Fivetran |
|------|-----|---------|----------|
| **언어** | SQL | Python | No-code |
| **비용** | $250~$500/월 | $700~$1.5K/월 | $1K~$10K/월 |
| **배포** | 수 시간 | 1~2주 | 수 시간 |
| **운영** | ⚙️ 낮음 | ⚙️⚙️⚙️ 높음 | ⚙️ 낮음 |
| **유연성** | SQL만 | 무제한 | 제한적 |

**의사결정 가이드**:
```
Python 팀? → Airflow
  └─ NO
     ↓
복잡한 로직 필요? → Airflow
  └─ NO
     ↓
표준 SaaS 통합? → Fivetran
  └─ NO → dbt
```

---

### 2.3 BI/시각화 선택

**패밀리 요구**:
- 대시보드 생성
- 드릴다운 분석
- 스케줄 리포트
- 공유 및 권한 관리

---

#### 옵션 1: Tableau

**핵심 스펙**:
- **배포**: Desktop, Server, Cloud
- **라이선스**: Creator, Explorer, Viewer
- **커넥터**: 100+ 데이터 소스

**비용**:
- **Creator**: $70/user/월
- **Explorer**: $42/user/월
- **Viewer**: $15/user/월
- **예상** (5 Creator, 20 Viewer): 월 $650

**장점**:
- 🎨 강력한 시각화
- 📊 드래그앤드롭: No-code
- 🔗 다양한 커넥터
- 📈 대규모 조직 지원

**단점**:
- 💰 높은 비용
- 🔧 서버 운영 필요 (온프렘)
- 📚 러닝 커브

**적합한 경우**:
- 대기업
- 복잡한 시각화
- 많은 Viewer

**검증 사례**: LinkedIn, Walmart, Verizon

---

#### 옵션 2: Google Looker

**핵심 스펙**:
- **배포**: Cloud only
- **모델링**: LookML (YAML 기반)
- **임베딩**: API 지원

**비용**:
- **Standard**: $5,000+/월 (10 users)
- **Enterprise**: 맞춤형
- **예상**: 월 $5,000~$20,000

**장점**:
- 🔗 GCP 통합
- 📊 LookML: 코드 기반 모델링
- 🔧 임베딩: 제품 통합

**단점**:
- 💰 매우 비쌈
- 🔒 GCP 종속
- 📚 LookML 러닝 커브

**적합한 경우**:
- GCP 중심
- 개발자 중심 팀
- 임베딩 필수

**검증 사례**: BuzzFeed, Warby Parker, Venmo

---

#### 옵션 3: Power BI

**핵심 스펙**:
- **배포**: Desktop, Service, Premium
- **라이선스**: Pro, Premium Per User

**비용**:
- **Pro**: $10/user/월
- **Premium Per User**: $20/user/월
- **예상** (20 users): 월 $200~$400

**장점**:
- 💵 저렴함
- 🔗 Microsoft 생태계
- 📊 Excel 친화적

**단점**:
- 🔒 Windows 권장
- 📉 복잡한 시각화 제약

**적합한 경우**:
- Microsoft 생태계
- 예산 제약
- Excel 중심 팀

**검증 사례**: Adobe, HP, Coca-Cola

---

#### BI 비교표

| 항목 | Tableau | Looker | Power BI |
|------|---------|--------|----------|
| **비용** | $650/월 | $5K+/월 | $200/월 |
| **시각화** | ⭐⭐⭐ | ⭐⭐ | ⭐⭐ |
| **러닝 커브** | 중간 | 높음 | 낮음 |

**의사결정 가이드**:
```
예산 > $5K/월? → Tableau or Looker
  └─ NO
     ↓
GCP 중심? → Looker
  └─ NO
     ↓
Microsoft 생태계? → Power BI
  └─ NO → Tableau
```

---

## Part 3: 도메인 선택 요소 (프로젝트별)

이 요소들은 **패밀리와 무관**하게 프로젝트 요구사항에 따라 선택합니다.

### 3.1 프론트엔드 프레임워크
- React, Vue, Angular (BI 임베딩 시)

### 3.2 백엔드 API
- REST API for 대시보드 데이터
- GraphQL for 복잡한 쿼리

### 3.3 인증/권한
- SSO, SAML (BI 통합)
- Row-Level Security (RLS)

### 3.4 모니터링
- Datadog, New Relic (파이프라인 모니터링)

---

## Part 4: Stage 2 통합

### 4.1 Layer 3 제약 반영 예시

**시나리오**: 금융 리포팅 시스템

**Layer 3 제약 발견**:
- 규제: SOX, GDPR 준수
- 비용: 쿼리 비용 제한 ($5K/월)
- 팀: SQL 중심 (Python 약함)

**기술 선택 영향**:
```
DW:
- BigQuery (선호) → Snowflake
- 이유: SOX 준수 인증, Time Travel

ETL:
- Airflow (선호) → dbt
- 이유: SQL 중심 팀

BI:
- Looker (선호) → Tableau
- 이유: 비용 ($650 vs $5K)
```

---

### 4.2 충돌 해결 예시

**NFR 목표 vs Layer 3 제약**:

**충돌 1**: 정확성 A + 비용 제약
- NFR: 100% 정확, 실시간 대시보드
- 제약: 쿼리 비용 $5K/월
- **해결**: Materialized Views + 1시간 새로고침

**충돌 2**: 속도 A + 팀 역량
- NFR: 초 단위 쿼리
- 제약: SQL만 가능 (Python 약함)
- **해결**: DW 내 최적화 (Clustering, Partitioning)

---

### 4.3 ADR 작성 준비

**선택한 기술 스택 정리**:
```
Bootstrap 필수:
✅ DW: Snowflake (SOX, Time Travel)
✅ ETL: dbt (SQL 중심)
✅ BI: Tableau (비용 효율)

도메인 선택:
✅ 인증: Okta SSO
✅ 모니터링: Datadog
```

**ADR 작성 대상**:
1. DW 선택 (Snowflake vs Redshift)
2. ETL 선택 (dbt vs Airflow)
3. BI 선택 (Tableau vs Looker)
4. 새로고침 주기 (1시간 vs 실시간)

---

**마지막 업데이트**: 2025-11-12  
**다음 검토**: 2026-02-12 (기술 스택 업데이트 반영)


================================================================================

📄 FILE: 07_safety_critical_iot_tech_options.md
--------------------------------------------------------------------------------

# 안전-임계 IoT 패밀리 (A-B-A) - 기술 매트릭스

**작성일**: 2025-11-12  
**패밀리**: 안전-임계 IoT (A-B-A)  
**검증 사례**: SCADA (5-250ms), IoT 긴급 경보 (450ms), 산업 안전 시스템

---

## Part 1: 패밀리가 요구하는 시스템 구조 ⭐⭐⭐

### 1.1 A-B-A 특성이 강제하는 것

#### A (치명적 실패) → 안전 시스템 필수

**특성**:
- 실패 시 인명 손실, 재산 피해
- 산업 재해, 화재, 폭발 위험
- 긴급 대응 필수 (경보, 셧다운)
- 규제 준수 (SIL 2+, UL, IEC)

**강제되는 기술적 요구**:
```
✅ Fail-Safe 설계 (기본값 안전)
✅ 중복성 (Redundancy)
✅ 워치독 (Watchdog) 타이머
✅ 감사 로그 (Audit Trail)
✅ 긴급 셧다운 (Emergency Shutdown)
```

**검증 사례**:
- 산업 제어 시스템 (SCADA): 센서 고장 시 자동 정지
- 긴급 경보 (EAS): 10분 내 전국 경보, FEMA/FCC

---

#### B (반구조화 데이터) → 센서 융합 필수

**특성**:
- JSON, XML 센서 데이터
- 가변 스키마 (센서별 다른 필드)
- 시계열 데이터 (온도, 압력, 진동)
- 다중 센서 융합 (Sensor Fusion)

**강제되는 기술적 요구**:
```
✅ 유연한 스키마 (Flexible Schema)
✅ 시계열 DB (Time-Series DB)
✅ 센서 융합 알고리즘
✅ JSON/XML 파싱
✅ 동적 필드 처리
```

**검증 사례**:
- IoT 센서: 온도 + 습도 + 진동 + 가스 농도
- SCADA: PLCraw 데이터 + 알람 메시지 + 상태 정보

---

#### A (밀리초 응답) → 실시간 처리 필수

**특성**:
- SCADA: 5-250ms 응답
- 긴급 경보: 450ms 미만
- 산업 제어: 수 밀리초 루프
- Edge Computing 필수

**강제되는 기술적 요구**:
```
✅ Edge Computing (로컬 처리)
✅ 경량 프로토콜 (MQTT, CoAP)
✅ 비동기 처리
✅ 우선순위 큐
✅ 저지연 네트워크 (5G, LoRaWAN)
```

**검증 사례**:
- Uber GPS: 2-5초 위치 업데이트
- 제조 안전: 밀리초급 센서-액추에이터 루프

---

### 1.2 이 패밀리에 필요한 DNA 시스템 및 메인 서비스

#### DNA 11개 시스템 중 필요한 것

A-B-A 패밀리는 다음 DNA 시스템이 필요합니다:

| DNA 시스템 | 중요도 | 이유 |
|-----------|-------|------|
| 1. Testing | ✅ 필수 | 안전 로직 검증, SIL 준수 |
| 2. Code Quality | ✅ 필수 | 결함 없는 코드 필수 |
| 3. Architecture | ✅ 필수 | Fail-safe 모듈 분리 |
| 4. **Type System** | **⭐⭐⭐ 매우 중요** | **컴파일 타임 안전성, SIL 인증** |
| 5. **Error Handling** | **⭐⭐⭐ 매우 중요** | **Fail-safe 전략, Watchdog** |
| 6. Configuration | ✅ 필수 | 센서 임계값, 타임아웃 설정 |
| 7. Identity & Access | ✅ 필수 | 센서 인증, 명령 권한 |
| 8. Observability | ✅ 필수 | 센서 상태, 알람 모니터링 |
| 9. API Gateway | ⚠️ 조건부 | SCADA 연동 시 필요 |
| 10. **Resilience** | **⭐⭐⭐ 매우 중요** | **N+1 중복, Failover, 생명 안전** |
| 11. Performance | ✅ 필수 | 밀리초 응답 보장 |

**특별히 중요한 DNA 시스템 (⭐⭐⭐)**:
- **Type System**: 런타임 에러 0을 목표, 컴파일 타임 검증 필수 (SIL 2+ 인증)
- **Error Handling**: 모든 에러는 안전 모드 전환, Watchdog 필수, 복구 불가 시 셧다운
- **Resilience**: 센서/액추에이터 N+1 중복, 5-250ms 페일오버, 크로스 체크

→ **Part 2.5에서 이 3가지 DNA 시스템의 기술 옵션을 다룹니다.**

#### 메인 서비스 필수 요소 (패밀리 강제)

A-B-A 패밀리는 다음 3가지 메인 서비스 기술을 **반드시** 포함해야 합니다:

#### 1. IoT 메시징 (MQTT/AMQP) (필수!)
**역할**: 센서 데이터 수집, 명령 전송
**이유**: 반구조화(B) + 밀리초(A)
**선택지**: EMQX, AWS IoT Core, RabbitMQ

#### 2. 시계열 DB (필수!)
**역할**: 센서 데이터 저장, 이력 조회
**이유**: 반구조화(B) + 시계열
**선택지**: InfluxDB, TimescaleDB, DynamoDB

#### 3. Edge Computing (필수!)
**역할**: 로컬 실시간 처리, 긴급 대응
**이유**: 치명적(A) + 밀리초(A)
**선택지**: AWS IoT Greengrass, Azure IoT Edge, K3s

---

## Part 2: 메인 서비스 기술 선택 ⭐⭐⭐

### 2.1 IoT 메시징 선택

**패밀리 요구**:
- 경량 프로토콜 (배터리 제약)
- QoS 보장 (메시지 손실 방지)
- 대규모 연결 (수만~수백만 센서)
- 낮은 레이턴시 (밀리초~초)

---

#### 옵션 1: EMQX (Enterprise)

**핵심 스펙**:
- **연결 처리량**: 500만+ 동시 연결
- **메시지 처리량**: 초당 100만+ 메시지
- **레이턴시**: 밀리초 미만 (단일 홉)
- **프로토콜**: MQTT 3.1/3.1.1/5.0, MQTT-SN, CoAP, LwM2M

**비용**:
- **오픈소스**: 무료 (EMQX Broker)
- **Enterprise**: $5,000~$20,000/년 (노드당)
- **클라우드**: $0.15~$0.30/million messages

**장점**:
- ⚡ 초대규모 확장 (500만+ 연결)
- 🔧 완벽한 MQTT 지원
- 📡 다중 프로토콜 (MQTT, CoAP, LwM2M)
- 💪 고가용성 (클러스터링)
- 🔐 TLS/SSL, 인증/권한

**단점**:
- 💰 Enterprise 고가
- 🧑‍💻 복잡한 운영 (클러스터)
- 📚 학습 곡선
- 🔧 튜닝 필요

**적합한 경우**:
- 산업 IoT (수만~수백만 센서)
- SCADA, 스마트 팩토리
- 높은 신뢰성 필수
- 예산 $20K~$100K /year

**검증 사례**: 중국 제조업, 스마트 시티 프로젝트

---

#### 옵션 2: AWS IoT Core

**핵심 스펙**:
- **연결 처리량**: 무제한 (자동 확장)
- **메시지 처리량**: 사용량 기반
- **레이턴시**: 수십~수백 밀리초
- **프로토콜**: MQTT, MQTT over WebSocket, HTTPS

**비용**:
- **연결 비용**: $0.08/million connection-minutes
- **메시지 비용**: $1/million messages (first 1B/월)
- **예상**: 월 $1,000~$10,000 (중규모)

**장점**:
- 🤖 완전 관리형 (운영 부담 없음)
- 🚀 무제한 확장
- 🔗 AWS 통합 (Lambda, S3, DynamoDB)
- 🔐 강력한 보안 (X.509 인증)
- 📊 내장 규칙 엔진

**단점**:
- 🔒 AWS 종속
- 💰 대규모 시 비용 급증
- 📊 제한적 프로토콜 (MQTT 중심)
- 🌐 글로벌 배포 복잡

**적합한 경우**:
- AWS 중심 조직
- 소규모~중규모 (수만~수십만 센서)
- 빠른 프로토타이핑
- 운영 부담 최소화

**검증 사례**: 스마트 홈, 소규모 공장 자동화

---

#### 옵션 3: RabbitMQ (MQTT 플러그인)

**핵심 스펙**:
- **연결 처리량**: 수만~수십만 연결
- **메시지 처리량**: 초당 3만 메시지
- **레이턴시**: 밀리초~초
- **프로토콜**: MQTT, AMQP, STOMP, HTTP

**비용**:
- **오픈소스**: 무료
- **Self-hosted**: 월 $200~$2,000 (VM 비용)
- **CloudAMQP**: $19~$1,199/월

**장점**:
- 💰 저렴한 비용
- 📚 성숙한 기술
- 🔧 간단한 운영
- 🔌 다양한 프로토콜
- 💪 메시지 라우팅 유연성

**단점**:
- 📉 제한적 확장 (수만 연결)
- ⚡ EMQX 대비 낮은 성능
- 🔧 MQTT 기능 제한 (플러그인)
- 📊 대규모 IoT 부적합

**적합한 경우**:
- 소규모 IoT (수천~수만 센서)
- 레거시 통합 (AMQP)
- 예산 $5K~$30K /year
- 간단한 아키텍처

**검증 사례**: 스타트업 IoT, 빌딩 자동화

---

#### IoT 메시징 비교표

| 항목 | EMQX | AWS IoT Core | RabbitMQ |
|------|------|--------------|----------|
| **연결 수** | 500만+ | 무제한 | 수만 |
| **메시지/초** | 100만+ | 사용량 기반 | ~3만 |
| **레이턴시** | <10ms | 수십~수백ms | 밀리초~초 |
| **비용** | $5K~$20K/년 | $1K~$10K/월 | $200~$2K/월 |
| **운영** | ⚙️⚙️⚙️ 높음 | ⚙️ 낮음 | ⚙️⚙️ 중간 |

**의사결정 가이드**:
```
센서 > 10만? → EMQX
  └─ NO
     ↓
AWS 중심? → AWS IoT Core
  └─ NO
     ↓
센서 < 5만? → RabbitMQ
  └─ NO → AWS IoT Core
```

---

### 2.2 시계열 DB 선택

**패밀리 요구**:
- 빠른 쓰기 (초당 수십만~수백만 포인트)
- 시간 기반 쿼리 최적화
- 압축 (저장 공간 절약)
- 다운샘플링 (Downsampling)

---

#### 옵션 1: InfluxDB (Enterprise)

**핵심 스펙**:
- **쓰기 처리량**: 초당 100만+ 포인트
- **압축**: 10:1 이상
- **레이턴시**: 밀리초 미만 (쓰기)
- **보존 정책**: 자동 다운샘플링

**비용**:
- **오픈소스**: 무료 (InfluxDB OSS)
- **Cloud**: $50~$500/월
- **Enterprise**: $10,000~$50,000/년

**장점**:
- ⚡ 초고속 쓰기
- 🔧 IoT 최적화 (Telegraf 통합)
- 📊 강력한 쿼리 (Flux, InfluxQL)
- 💾 효율적 압축
- 🕐 자동 다운샘플링

**단점**:
- 💰 Enterprise 고가
- 📊 제한적 분산 (클러스터링 Enterprise만)
- 🔧 메모리 사용량 높음
- 📈 대규모 확장 어려움

**적합한 경우**:
- IoT 센서 데이터 (초당 수십만 포인트)
- SCADA, 제조 라인
- 실시간 대시보드
- 예산 $10K~$100K /year

**검증 사례**: Cisco IoT, Salesforce 모니터링

---

#### 옵션 2: TimescaleDB (PostgreSQL 확장)

**핵심 스펙**:
- **쓰기 처리량**: 초당 10만 포인트
- **압축**: Native 압축 (7:1)
- **레이턴시**: <10ms (쓰기)
- **쿼리**: Full SQL 지원

**비용**:
- **오픈소스**: 무료
- **Timescale Cloud**: $50~$500/월
- **Enterprise**: $5,000~$20,000/년

**장점**:
- 🔍 Full SQL 지원
- 📊 복잡한 조인 가능
- 🛠️ PostgreSQL 생태계
- 💰 상대적 저렴
- 🔧 익숙한 운영

**단점**:
- ⚡ InfluxDB 대비 느림
- 📈 확장 제한 (vs 분산 DB)
- 💾 압축률 낮음
- 🔧 튜닝 필요

**적합한 경우**:
- SQL 필수 (복잡한 분석)
- PostgreSQL 팀 역량
- 중소규모 (초당 수만 포인트)
- 예산 $5K~$50K /year

**검증 사례**: 에너지 모니터링, 스마트 빌딩

---

#### 옵션 3: DynamoDB (AWS)

**핵심 스펙**:
- **쓰기 처리량**: 사용량 기반 (무제한)
- **레이턴시**: 단일 자릿수 밀리초
- **확장**: 자동 스케일링
- **TTL**: 자동 데이터 만료

**비용**:
- **On-Demand**: $1.25/million writes
- **Provisioned**: $0.00065/WCU/hour
- **예상**: 월 $500~$5,000

**장점**:
- 🤖 완전 관리형
- 🚀 무제한 확장
- 🔗 AWS 통합
- 💵 사용량 기반 과금
- 🕐 자동 TTL

**단점**:
- 🔒 AWS 종속
- 💰 대규모 시 비용 급증
- 📊 제한적 쿼리 (NoSQL)
- 🔧 시계열 최적화 부족

**적합한 경우**:
- AWS 중심
- 소규모~중규모
- 빠른 프로토타이핑
- 운영 부담 최소화

**검증 사례**: AWS IoT 사용자, 스타트업

---

#### 시계열 DB 비교표

| 항목 | InfluxDB | TimescaleDB | DynamoDB |
|------|----------|-------------|----------|
| **쓰기/초** | 100만+ | 10만 | 사용량 기반 |
| **SQL** | Flux/InfluxQL | ✅ Full SQL | ❌ NoSQL |
| **압축** | 10:1 | 7:1 | N/A |
| **비용** | $10K~$50K/년 | $5K~$20K/년 | $500~$5K/월 |
| **운영** | ⚙️⚙️ 중간 | ⚙️⚙️ 중간 | ⚙️ 낮음 |

**의사결정 가이드**:
```
쓰기 > 10만/초? → InfluxDB
  └─ NO
     ↓
SQL 필수? → TimescaleDB
  └─ NO
     ↓
AWS 중심? → DynamoDB
  └─ NO → InfluxDB
```

---

### 2.3 Edge Computing 선택

**패밀리 요구**:
- 로컬 실시간 처리 (밀리초)
- 오프라인 동작 (네트워크 단절 시)
- 경량 (저전력, 제한된 리소스)
- 클라우드 동기화

---

#### 옵션 1: AWS IoT Greengrass

**핵심 스펙**:
- **레이턴시**: 밀리초급 (로컬)
- **언어**: Python, Node.js, Java, C++
- **배포**: Over-the-Air (OTA)
- **오프라인**: 완전 지원

**비용**:
- **소프트웨어**: 무료
- **디바이스**: $10~$500 (하드웨어)
- **클라우드 연동**: AWS IoT Core 비용

**장점**:
- ⚡ 로컬 실시간 처리
- 🔗 AWS 완벽 통합
- 🤖 Lambda 로컬 실행
- 🔐 강력한 보안 (X.509)
- 📡 오프라인 동작

**단점**:
- 🔒 AWS 종속
- 💰 디바이스 비용 (ARM/x86)
- 🔧 복잡한 설정
- 📊 ML 추론 제한적

**적합한 경우**:
- AWS 중심 IoT
- 중간~고성능 Edge (Raspberry Pi 이상)
- 오프라인 필수
- 예산 $100~$500 per device

**검증 사례**: 석유/가스 리모트 모니터링, 스마트 빌딩

---

#### 옵션 2: Azure IoT Edge

**핵심 스펙**:
- **레이턴시**: 밀리초급 (로컬)
- **언어**: C#, Python, Node.js, Java, C
- **컨테이너**: Docker 기반
- **AI**: Azure ML 로컬 배포

**비용**:
- **소프트웨어**: 무료
- **디바이스**: $10~$500 (하드웨어)
- **클라우드 연동**: Azure IoT Hub 비용

**장점**:
- ⚡ 로컬 AI 추론 (ML 모델)
- 🐳 Docker 컨테이너 (표준)
- 🔗 Azure 통합
- 🔐 보안 모듈 (TPM)
- 📡 오프라인 동작

**단점**:
- 🔒 Azure 종속
- 💰 디바이스 비용
- 🧑‍💻 .NET 편향
- 📊 대규모 관리 복잡

**적합한 경우**:
- Azure 중심 조직
- AI/ML 추론 필요
- Docker 친숙
- 예산 $100~$500 per device

**검증 사례**: 제조업 품질 검사 (AI), 소매 매장 분석

---

#### 옵션 3: K3s (경량 Kubernetes)

**핵심 스펙**:
- **메모리**: 512MB RAM 이상
- **언어**: 모든 컨테이너화 앱
- **배포**: GitOps (Flux, ArgoCD)
- **클라우드**: 멀티 클라우드 지원

**비용**:
- **오픈소스**: 무료
- **디바이스**: $10~$200 (하드웨어)
- **관리**: Rancher (무료/Enterprise)

**장점**:
- 💰 완전 무료 (오픈소스)
- 🌐 멀티 클라우드 (AWS, Azure, GCP)
- 🔧 표준 Kubernetes API
- 🐳 모든 컨테이너 지원
- 📚 풍부한 생태계

**단점**:
- 🧑‍💻 Kubernetes 학습 곡선
- 🔧 직접 운영 필요
- 📊 클라우드 통합 별도 구현
- ⚠️ IoT 최적화 부족

**적합한 경우**:
- 멀티 클라우드 전략
- Kubernetes 팀 역량
- 예산 최소화
- 완전한 제어 필요

**검증 사례**: 엣지 AI 플랫폼, 스마트 시티 게이트웨이

---

#### Edge Computing 비교표

| 항목 | AWS Greengrass | Azure IoT Edge | K3s |
|------|----------------|----------------|-----|
| **레이턴시** | 밀리초 | 밀리초 | 밀리초 |
| **AI 추론** | 제한적 | ✅ Azure ML | ✅ 모든 프레임워크 |
| **오프라인** | ✅ | ✅ | ✅ |
| **비용** | AWS 연동 | Azure 연동 | 무료 |
| **운영** | ⚙️⚙️ 중간 | ⚙️⚙️ 중간 | ⚙️⚙️⚙️ 높음 |

**의사결정 가이드**:
```
AWS 중심? → AWS IoT Greengrass
  └─ NO
     ↓
AI 추론 필요? → Azure IoT Edge
  └─ NO
     ↓
멀티 클라우드? → K3s
  └─ NO → AWS IoT Greengrass
```

---

## Part 2.5: 핵심 DNA 시스템 기술 선택 ⭐⭐⭐

이 패밀리에서 특별히 중요한 DNA 시스템(⭐⭐⭐)에 대한 기술 선택입니다.

### 2.5.1 Type System (DNA #4) - 안전 인증 타입 시스템 ⭐⭐⭐

**패밀리 요구**:
- 런타임 에러 0 목표 (컴파일 타임 검증)
- SIL 2+ 인증 지원
- 메모리 안전성 보장
- 정적 분석 통합
- Null pointer, buffer overflow 완전 방지

---

#### 옵션 1: Rust + RTIC

**핵심 스펙**:
- **메모리 안전성**: 컴파일 타임 보장 (borrow checker)
- **실시간 지원**: RTIC 프레임워크 (Zero-cost abstractions)
- **타겟**: Cortex-M, RISC-V 임베디드
- **인증**: ISO 26262 (자동차), IEC 61508 진행 중

**비용**: 오픈소스 (무료), 도구체인 무료

**장점**:
- 🔧 메모리 안전성 컴파일 타임 보장
- 🔧 Zero-cost abstractions (C 수준 성능)
- 🔧 우선순위 기반 리소스 공유 (RTIC)
- 🔧 활발한 임베디드 생태계 (Embassy, probe-rs)

**단점**:
- ⚠️ SIL 인증 아직 진행 중 (완료 아님)
- ⚠️ 학습 곡선 (borrow checker)
- ⚠️ 레거시 C 코드와 통합 복잡
- ⚠️ 일부 MCU 지원 제한

**적합한 경우**:
- 신규 프로젝트 (레거시 없음)
- SIL 2 미만 또는 인증 불필요
- 팀이 Rust 경험 있음
- 메모리 안전성 최우선

**검증 사례**: Volvo (자동차), Oxide Computer, Arm Pelion

---

#### 옵션 2: Ada/SPARK

**핵심 스펙**:
- **정적 검증**: SPARK 프로버 (수학적 증명)
- **인증**: DO-178C (항공), EN 50128 (철도), IEC 61508 인증 완료
- **타겟**: 모든 주요 MCU, x86, ARM
- **역사**: 40년+ 안전-임계 시스템 검증

**비용**: GNAT Community (무료), GNAT Pro ($10K~$50K/년)

**장점**:
- 🔧 SIL 4까지 인증 완료
- 🔧 DO-178C Level A 인증 (항공)
- 🔧 수학적 증명 가능 (SPARK)
- 🔧 40년 검증된 안전 기록

**단점**:
- ⚠️ 개발자 풀 제한적
- ⚠️ GNAT Pro 고비용 ($10K+/년)
- ⚠️ 현대 라이브러리 생태계 부족
- ⚠️ 학습 자료 제한적

**적합한 경우**:
- SIL 3/4 필수 (항공, 철도, 원자력)
- DO-178C 인증 필수
- 장기 유지보수 (20년+)
- 예산 충분

**검증 사례**: Boeing 787, Airbus A380, 프랑스 TGV

---

#### 옵션 3: C + MISRA + 정적 분석

**핵심 스펙**:
- **표준**: MISRA C:2012 (자동차/산업 표준)
- **인증**: IEC 61508, ISO 26262 광범위 인증
- **도구**: Polyspace, PC-lint, Coverity, PVS-Studio
- **타겟**: 모든 MCU 지원

**비용**: 도구 $5K~$50K/년 (PC-lint $400, Polyspace $20K+)

**장점**:
- 🔧 가장 넓은 MCU 지원
- 🔧 개발자 풀 풍부
- 🔧 레거시 코드 활용 가능
- 🔧 기존 인증 사례 풍부

**단점**:
- ⚠️ 언어 자체 안전성 없음 (도구 의존)
- ⚠️ 정적 분석으로 모든 버그 못 잡음
- ⚠️ MISRA 준수 수동 검토 필요
- ⚠️ 메모리 오류 런타임에 발생 가능

**적합한 경우**:
- 레거시 C 코드 유지보수
- 기존 팀 C 전문성
- 검증된 도구체인 필수
- MCU 지원 범위 우선

**검증 사례**: 자동차 ECU 대부분, 산업 PLC, 의료기기

---

**Type System 의사결정 플로우차트**:
```
SIL 3/4 또는 DO-178C 필수? → Ada/SPARK
  └─ NO
     ↓
신규 프로젝트 + 메모리 안전성 우선? → Rust + RTIC
  └─ NO
     ↓
레거시 C + 넓은 MCU 지원? → C + MISRA
```

---

### 2.5.2 Error Handling (DNA #5) - Fail-Safe 전략 ⭐⭐⭐

**패밀리 요구**:
- 모든 에러 → 안전 모드 전환
- Watchdog 타이머 필수
- 센서 융합 에러 처리
- 복구 불가 시 안전한 셧다운
- 에러 전파 차단

---

#### 옵션 1: Rust Result + Custom Error Types

**핵심 스펙**:
- **에러 모델**: Result<T, E> (강제 처리)
- **전파**: `?` 연산자 (명시적)
- **패닉 처리**: `#[panic_handler]` 커스텀
- **Watchdog**: HAL 통합 (cortex-m, stm32)

**비용**: 오픈소스 (무료)

**장점**:
- 🔧 컴파일 타임 에러 처리 강제
- 🔧 에러 무시 불가능
- 🔧 Zero-cost (런타임 오버헤드 없음)
- 🔧 패닉 → 안전 모드 자동 전환 가능

**단점**:
- ⚠️ 학습 곡선 (Result, Option)
- ⚠️ 기존 C 라이브러리 래핑 필요
- ⚠️ 에러 타입 설계 복잡
- ⚠️ 일부 HAL 미성숙

**적합한 경우**:
- Rust 기반 신규 프로젝트
- 컴파일 타임 안전성 우선
- 팀이 함수형 프로그래밍 경험
- 에러 처리 누락 방지 필수

---

#### 옵션 2: C + Defensive Programming + Watchdog

**핵심 스펙**:
- **패턴**: MISRA C 에러 처리 규칙
- **Watchdog**: 하드웨어 WDT + 소프트웨어 타이머
- **방어**: 어설션, 범위 체크, 센서 크로스 체크
- **복구**: 상태 머신 기반 복구 로직

**비용**: 도구 $1K~$20K/년 (정적 분석 포함)

**장점**:
- 🔧 검증된 패턴 풍부
- 🔧 하드웨어 Watchdog 직접 제어
- 🔧 레거시 코드와 호환
- 🔧 MISRA 준수 도구 지원

**단점**:
- ⚠️ 에러 처리 누락 가능 (컴파일러 미강제)
- ⚠️ 수동 방어 코딩 필요
- ⚠️ 정적 분석 의존
- ⚠️ 런타임 에러 가능

**적합한 경우**:
- 레거시 C 코드베이스
- 검증된 Watchdog 패턴 필요
- MISRA 준수 필수
- 팀 C 전문성

---

#### 옵션 3: Ada Exception + SPARK 계약

**핵심 스펙**:
- **에러 모델**: Ada Exception (구조화된 예외)
- **계약**: SPARK Pre/Post conditions (정적 증명)
- **검증**: 런타임 체크 + 정적 증명 조합
- **복구**: Exception handler 체계

**비용**: GNAT Community (무료), GNAT Pro ($10K+/년)

**장점**:
- 🔧 수학적 에러 부재 증명 (SPARK)
- 🔧 구조화된 예외 처리
- 🔧 Pre/Post condition 강제
- 🔧 런타임 + 정적 검증 조합

**단점**:
- ⚠️ SPARK 증명 복잡
- ⚠️ 예외 오버헤드 (SPARK 미사용 시)
- ⚠️ 개발자 풀 제한적
- ⚠️ 도구 비용

**적합한 경우**:
- SIL 3/4 프로젝트
- 수학적 증명 필수
- Ada 팀 구성 가능
- 장기 유지보수

---

**Error Handling 의사결정 플로우차트**:
```
수학적 에러 부재 증명 필수? → Ada Exception + SPARK
  └─ NO
     ↓
컴파일 타임 에러 처리 강제? → Rust Result
  └─ NO
     ↓
레거시 C + Watchdog? → C Defensive Programming
```

---

### 2.5.3 Resilience (DNA #10) - 생명 안전 중복성 ⭐⭐⭐

**패밀리 요구**:
- N+1 센서/액추에이터 중복
- 5-250ms 페일오버
- 센서 크로스 체크 (Voting)
- 자동 복구 (Self-healing)
- Health Check + 격리

---

#### 옵션 1: 하드웨어 중복 + Voting

**핵심 스펙**:
- **패턴**: Triple Modular Redundancy (TMR)
- **Voting**: 2-out-of-3, 다수결
- **페일오버**: 하드웨어 스위칭 (<1ms)
- **격리**: 물리적 분리 (별도 전원, 별도 회로)

**비용**: 하드웨어 3배 + 설계 $50K~$500K

**장점**:
- 🔧 하드웨어 레벨 안전성
- 🔧 1ms 미만 페일오버
- 🔧 Byzantine Fault Tolerance
- 🔧 SIL 4 달성 가능

**단점**:
- ⚠️ 하드웨어 비용 3배+
- ⚠️ 설계 복잡도 높음
- ⚠️ 전력 소비 증가
- ⚠️ 물리적 공간 필요

**적합한 경우**:
- SIL 3/4 필수
- 예산 충분
- 물리적 공간 여유
- 하드웨어 팀 존재

**검증 사례**: 항공기 비행 제어, 원자력 발전소

---

#### 옵션 2: 소프트웨어 Failover + Circuit Breaker

**핵심 스펙**:
- **패턴**: Primary-Standby, Active-Active
- **Circuit Breaker**: failsafe-rs, 지수 백오프
- **Health Check**: 주기적 Heartbeat
- **페일오버**: 5-50ms (소프트웨어)

**비용**: 추가 하드웨어 $500~$5K + 개발

**장점**:
- 🔧 비용 효율적
- 🔧 유연한 복구 전략
- 🔧 소프트웨어 업데이트 가능
- 🔧 Circuit Breaker로 장애 전파 차단

**단점**:
- ⚠️ 하드웨어 TMR보다 느림 (5-50ms)
- ⚠️ 소프트웨어 버그 가능
- ⚠️ SIL 4 달성 어려움
- ⚠️ 복잡한 상태 관리

**적합한 경우**:
- SIL 2 이하
- 예산 제한
- 소프트웨어 팀 강점
- 유연한 복구 필요

**검증 사례**: 산업 자동화, 스마트 팩토리

---

#### 옵션 3: 클라우드 기반 Redundancy

**핵심 스펙**:
- **패턴**: Edge + Cloud 이중화
- **동기화**: 상태 복제 (MQTT, Kafka)
- **페일오버**: 100-500ms (네트워크 의존)
- **관리**: AWS IoT Greengrass, Azure IoT Edge

**비용**: 클라우드 $100~$1K/월 + Edge 하드웨어

**장점**:
- 🔧 원격 모니터링/관리
- 🔧 자동 스케일링
- 🔧 글로벌 분산
- 🔧 OTA 업데이트

**단점**:
- ⚠️ 네트워크 의존 (오프라인 시 제한)
- ⚠️ 페일오버 느림 (100-500ms)
- ⚠️ 데이터 주권 이슈
- ⚠️ SIL 인증 어려움

**적합한 경우**:
- 비-임계 모니터링
- 원격 관리 필수
- 네트워크 안정적
- SIL 인증 불필요

**검증 사례**: 스마트 빌딩, 원격 자산 모니터링

---

**Resilience 의사결정 플로우차트**:
```
SIL 3/4 + 1ms 미만 페일오버? → 하드웨어 TMR
  └─ NO
     ↓
Edge 로컬 처리 + 유연한 복구? → 소프트웨어 Failover
  └─ NO
     ↓
원격 관리 + 비-임계? → 클라우드 Redundancy
```

---

## Part 3: 도메인 선택 요소 (프로젝트별)

이 요소들은 **패밀리와 무관**하게 프로젝트 요구사항에 따라 선택합니다.

### 3.1 센서 하드웨어

**선택지**:
- **Raspberry Pi 4**: 범용, Linux, Python/C++
- **Arduino**: 저전력, 실시간, C/C++
- **ESP32**: WiFi/BLE, 초저전력, MicroPython
- **산업용 PLC**: Siemens, Allen-Bradley (규제 인증)

**선택 기준**:
- 처리 능력: 복잡한 센서 융합 → Raspberry Pi
- 저전력: 배터리 → Arduino, ESP32
- 산업 표준: 규제 준수 → PLC

**A-B-A 영향**: **큼** - 실시간 처리(A) + 센서 융합(B) 요구  
(Edge Computing 성능 결정)

---

### 3.2 통신 프로토콜

**선택지**:
- **WiFi**: 고대역폭, 짧은 거리, 실내
- **4G/5G**: 이동성, 넓은 범위, 고비용
- **LoRaWAN**: 초저전력, 장거리 (수 km), 저속 (50kbps)
- **Zigbee**: 저전력, 메쉬 네트워크, 짧은 거리

**선택 기준**:
- 레이턴시: 밀리초(A) → WiFi, 4G/5G
- 저전력: 배터리 수명 → LoRaWAN, Zigbee
- 이동성: 차량, 드론 → 4G/5G
- 범위: 공장/건물 → WiFi, Zigbee

**A-B-A 영향**: **매우 큼** - 밀리초(A) 달성 가능 여부  
(WiFi: 5-50ms, 4G: 50-100ms, LoRaWAN: 1-5초)

---

### 3.3 대시보드/시각화

**선택지**:
- **Grafana**: 오픈소스, 시계열, Prometheus 통합
- **Kibana**: Elasticsearch, 로그 중심
- **Power BI**: 엔터프라이즈, Microsoft 생태계
- **Custom Web**: React, D3.js (맞춤형)

**선택 기준**:
- 실시간 모니터링: Grafana (초 단위 갱신)
- 로그 분석: Kibana (ELK Stack)
- 비즈니스 리포트: Power BI (주간/월간)
- 특수 요구사항: Custom Web

**A-B-A 영향**: 최소 (패밀리 무관, 사용자 선호도)

---

### 3.4 클라우드 vs 온프레미스

**선택지**:
- **클라우드**: AWS IoT, Azure IoT (확장성, 관리 편의)
- **하이브리드**: Edge + 클라우드 (로컬 처리 + 중앙 집계)
- **온프레미스**: 완전 자체 호스팅 (데이터 주권, 규제)

**선택 기준**:
- 밀리초 응답(A): 하이브리드 또는 온프레미스 (네트워크 지연 회피)
- 규제: 데이터 주권, SIL 인증 → 온프레미스
- 확장성: 수십만 센서 → 클라우드

**A-B-A 영향**: **큼** - 치명적 실패(A) + 밀리초(A) 요구  
(클라우드 왕복 100-500ms → 로컬 처리 필수)

---

## Part 4: Stage 2 통합

### 4.1 Layer 3 제약 반영 예시

**시나리오**: 제조 공장 안전 시스템

**Layer 3 제약 발견**:
- 규제: SIL 2 인증 필수 (IEC 61508)
- 네트워크: 공장 WiFi 불안정 (패킷 손실 5%)
- 예산: $100K/년 (전체)
- 기존 시스템: Siemens PLC (Profinet)

**기술 선택 영향**:
```
IoT 메시징:
- EMQX (선호) → RabbitMQ
- 이유: 예산 제약, Profinet 연동

시계열 DB:
- InfluxDB (선호) → TimescaleDB
- 이유: SQL 필수 (규제 보고), 예산

Edge Computing:
- AWS Greengrass (불가능) → K3s
- 이유: 공장 내 온프레미스, 오프라인
```

---

### 4.2 충돌 해결 예시

**NFR 목표 vs Layer 3 제약**:

**충돌 1**: 밀리초 응답 A + WiFi 불안정
- **NFR**: 450ms 미만 경보 응답
- **제약**: 공장 WiFi 불안정 (패킷 손실 5%)
- **해결**: Edge Computing 필수 (로컬 처리) + 유선 백업
- **트레이드오프**:
  - ✅ 로컬 처리로 50ms 응답 달성 (WiFi 독립)
  - ✅ 네트워크 장애 시에도 작동
  - ⚠️ Edge 디바이스 비용 증가 ($200~$500/센서)
  - ⚠️ 유선 백업 설치 비용 ($50~$100/센서)
  - ⚠️ 유지보수 복잡도 증가 (센서별 업데이트)

---

**충돌 2**: 치명적 실패 A + 예산 제약
- **NFR**: SIL 2 인증 필수 (안전 규제)
- **제약**: 예산 $100K/년 (EMQX Enterprise, InfluxDB Enterprise 불가)
- **해결**: 오픈소스 스택 (RabbitMQ + TimescaleDB + K3s) + 외부 인증 비용
- **트레이드오프**:
  - ⚠️ 확장성 제한 (수만 센서까지, 수백만 불가)
  - ⚠️ 고가용성 구성 복잡 (직접 클러스터링)
  - ✅ 소프트웨어 비용 $50K/년 → $10K/년 (80% 절감)
  - ✅ SIL 2 인증 $30K (외부 인증 기관)
  - ✅ 총 예산 $40K/년 (목표 $100K 내)

---

**충돌 3**: 센서 융합 B + 레거시 PLC
- **NFR**: JSON 센서 데이터 (온도, 습도, 진동 융합)
- **제약**: Siemens PLC (Profinet 바이너리 프로토콜)
- **해결**: Edge Gateway 변환 (Profinet → MQTT/JSON)
- **트레이드오프**:
  - ⚠️ 레이턴시 추가 10-50ms (변환 오버헤드)
  - ⚠️ Gateway 단일 장애 지점 (SPOF)
  - ⚠️ Gateway 비용 $2,000~$5,000
  - ✅ 레거시 PLC 활용 (교체 불필요)
  - ✅ 표준 MQTT 인프라 구축
  - ✅ 향후 센서 추가 용이

**추가 해결**: Gateway 이중화 (Active-Standby)  
**추가 비용**: $3,000~$6,000 (Gateway 2대)

---

### 4.3 ADR 작성 준비

**선택한 기술 스택 정리**:
```
Bootstrap 필수:
✅ IoT 메시징: RabbitMQ (MQTT 플러그인)
✅ 시계열 DB: TimescaleDB
✅ Edge Computing: K3s (온프레미스)

도메인 선택:
✅ 센서: Raspberry Pi 4 + DHT22 + MCP3008
✅ 통신: WiFi (주) + 유선 Ethernet (백업)
✅ 대시보드: Grafana + Prometheus
```

**ADR 작성 대상**:
1. IoT 메시징 선택 (EMQX vs RabbitMQ)
2. 시계열 DB 선택 (InfluxDB vs TimescaleDB)
3. Edge Computing 전략 (Greengrass vs K3s)
4. 네트워크 이중화 방안 (WiFi + 유선)
5. SIL 2 인증 경로

---

## 📚 참고 자료

### IoT 메시징 벤치마크
- [EMQX Performance](https://www.emqx.com/en/products/emqx/performance)
- [AWS IoT Core Limits](https://docs.aws.amazon.com/general/latest/gr/iot-core.html)

### 시계열 DB 벤치마크
- [InfluxDB Performance](https://www.influxdata.com/influxdb-performance/)
- [TimescaleDB Benchmark](https://docs.timescale.com/timescaledb/latest/overview/how-it-works/)

### Edge Computing
- [AWS IoT Greengrass](https://aws.amazon.com/greengrass/)
- [Azure IoT Edge](https://azure.microsoft.com/en-us/products/iot-edge/)
- [K3s](https://k3s.io/)

### 산업 표준
- [IEC 61508: SIL](https://en.wikipedia.org/wiki/IEC_61508)
- [ISA-95: 제조 표준](https://www.isa.org/standards-and-publications/isa-standards/isa-standards-committees/isa95)

### 검증 사례
- [IoT 긴급 경보 시스템](https://www.fcc.gov/emergency-alert-system-eas)
- [SCADA 시스템](https://en.wikipedia.org/wiki/SCADA)

---

**마지막 업데이트**: 2025-11-12  
**다음 검토**: 2026-02-12 (기술 스택 업데이트 반영)


================================================================================



# DNA Standards - 파일 명명 규칙, Stage 구조, 프로젝트 표준 템플릿
# 생성일: 2025-12-10
# 포함된 파일 수: 4

================================================================================

📄 FILE: 00_FILE_NAMING_CONVENTION.md
--------------------------------------------------------------------------------

# DNA 방법론 파일 및 코드 명명 규칙

> **목적**: 모든 파일(문서, 코드, 테스트, 설정)의 위치와 이름을 즉시 파악
> **버전**: v2.0 (2025-12-09)
> **적용 범위**: DNA 방법론의 모든 파일

---

## 📖 문서 구조

```
이 문서의 Part 구성:

Part 1: 방법론 산출물 (문서)     Line 23-248
Part 2: 소스 코드 구조           Line 249-443
Part 3: 테스트 파일              Line 444-578
Part 4: 스크립트/임시 파일       Line 579-709
Part 5: 설정 파일                Line 710-909
```

---

# Part 1: 방법론 산출물 (문서)

---

## 🎯 핵심 원칙

**"파일명만 봐도 어느 Stage의 무슨 역할인지 즉시 알 수 있어야 한다"**

### 왜 필요한가?

❌ **명명 규칙 없으면**:
```
core_functions.md
family.md
constraints_final_v2.md
ADR-fastapi.md
```
→ 어느 Stage인지? 순서는? 타입은? → **혼란!**

✅ **명명 규칙 있으면**:
```
01F-01_core_functions.md          # Stage 1, Function 문서
01C-01_family_classification.md   # Stage 1, Classification 문서
02D-01_tech_stack_decision.md     # Stage 2, Decision 문서
03A-103_fastapi_selection.md      # Stage 3, ADR (Domain)
```
→ **Stage, Type, 순서 즉시 파악!**

---

## 📋 문서 파일명 구조

### **패턴**: `{Stage}{Type}-{Seq}_{descriptive_name}.md`

```
01F-01_core_functions.md
│││ ││ └────────────────── 설명적 이름 (영문, snake_case)
│││ ││
│││ │└─────────────────── 순서 번호 (01~99)
│││ │
│││ └──────────────────── 구분자 (하이픈)
││└─────────────────────── 문서 타입 (알파벳 1글자)
│└──────────────────────── Stage 번호 (01~09)
└───────────────────────── 2자리 숫자 (앞에 0 붙임)
```

### **구성 요소**

| 요소 | 포맷 | 설명 | 예시 |
|------|------|------|------|
| **Stage** | 2자리 숫자 | 01~09 (9개 Stage) | `01`, `02`, `03` |
| **Type** | 알파벳 1글자 | 문서 유형 코드 | `F`, `C`, `D`, `A`, `G` |
| **Seq** | 2자리 숫자 | 01~99 (같은 Stage+Type 내 순서) | `01`, `02`, `03` |
| **Name** | snake_case | 설명적 이름 (영문) | `core_functions` |

---

## 🔤 Type 코드 정의

### **프로젝트 산출물**

| Code | 의미 | 용도 | 예시 |
|------|------|------|------|
| **F** | Function | 기능 정의 | `01F-01_core_functions.md` |
| **C** | Classification | 분류/분석 결과 | `01C-01_family_classification.md` |
| **D** | Decision | 결정 사항 | `02D-01_tech_stack_decision.md` |
| **S** | Schema | 스키마/설계 | `02S-02_data_schema.md` |
| **A** | ADR | Architecture Decision Record | `03A-001_logging.md` |
| **B** | Blueprint | 청사진 | `07B-01_project_blueprint.md` |
| **T** | Task | 작업 분해 | `08T-01_task_breakdown.md` |
| **L** | List/Checklist | 체크리스트 | `09L-01_task_001_checklist.md` |

### **방법론 문서**

| Code | 의미 | 용도 | 예시 |
|------|------|------|------|
| **G** | Guide | 간결한 가이드 | `01G-00_core_definition_guide.md` |
| **M** | Manual | 상세 해설서 | `01M-01_layer1_manual.md` |
| **E** | Example/Case | 사례집 | `02E-01_stock_trading_case.md` |

### **특수 문서**

| Code | 의미 | 용도 | 예시 |
|------|------|------|------|
| **00** | Meta | 방법론 자체 문서 | `00_FILE_NAMING_CONVENTION.md` |

---

## 📁 Stage별 산출물 요약

### Stage 1: 패밀리 구분과 핵심기능 파악
```
01F-01_core_functions.md          # 핵심 기능 정의
01C-01_family_classification.md   # 패밀리 분류 (A-C-A)
01C-02_nfr_profile.md             # NFR 프로파일 (A-B-B-A)
01D-01_tech_candidates.md         # 기술 후보군
```

### Stage 2: 구조설계
```
02C-01_layer3_constraints.md      # Layer 3 제약 조사
02C-02_conflicts_analysis.md      # 충돌 패턴 분석
02D-01_tech_stack_decision.md     # 기술 스택 확정
02S-01_architecture_diagram.png   # 아키텍처 다이어그램
02S-02_data_schema.md             # 데이터 스키마
02S-03_api_design.md              # API 설계
02L-01_adr_list.md                # ADR 작성 대상 목록
```

### Stage 3: ADR 문서화
```
docs/adr/dna-system/
  03A-001_logging.md              # DNA 시스템 ADR (001~099)
  03A-002_error_handling.md
  ...

docs/adr/domain/
  03A-101_api_selection.md        # Domain ADR (100~999)
  03A-102_strategy_pattern.md
  ...
```

### Stage 4-5: DNA 시스템
```
04B-01_dna_system_blueprint.md    # DNA 시스템 청사진
04L-01_dna_system_checklist.md    # DNA 시스템 체크리스트
05D-01_module_usage_docs.md       # 모듈 사용법 문서
```

### Stage 6: Project Standards
```
06D-01_project_standards.md       # 프로젝트 표준 (THE 산출물)
```

### Stage 7: Project Blueprint
```
07B-01_project_blueprint.md       # 프로젝트 청사진
07S-01_domain_architecture.md     # 도메인 아키텍처
```

### Stage 8: Task Breakdown
```
08T-01_task_breakdown.md          # 작업 분해
```

### Stage 9: Checklist
```
09L-01_task_001_checklist.md      # 작업별 체크리스트
09L-02_task_002_checklist.md
...
```

---

## 📦 문서 저장 위치

### **방법론 문서** (dna-methodology 리포지토리)
```
docs/guides/
├── 00_CORE_METHODOLOGY.md
├── 01_DNA_METHODOLOGY_DETAILED.md
├── 01G-00_core_definition_guide.md
├── 02G-00_environment_constraints_guide.md
├── ...
├── standards/
│   ├── 00_FILE_NAMING_CONVENTION.md   # 이 문서!
│   └── 01_STAGE_STRUCTURE.md
│   ├── 02_PROJECT_STANDARDS_TEMPLATE.md
│   └── 03_DNA_SYSTEMS_GUIDE.md
└── manuals/
    └── (언어별 매뉴얼)
```

### **프로젝트 산출물** (실제 프로젝트)
```
docs/
├── architecture/              # Stage 1-2 산출물
│   ├── 01F-01_core_functions.md
│   └── 02D-01_tech_stack_decision.md
│
├── adr/                       # Stage 3 산출물
│   ├── dna-system/
│   │   └── 03A-001_logging.md
│   └── domain/
│       └── 03A-101_api_selection.md
│
├── dna-system/                # Stage 4-5 산출물
│   └── 04B-01_dna_system_blueprint.md
│
├── standards/                 # Stage 6 산출물
│   └── 06D-01_project_standards.md
│
├── blueprint/                 # Stage 7 산출물
│   └── 07B-01_project_blueprint.md
│
├── tasks/                     # Stage 8 산출물
│   └── 08T-01_task_breakdown.md
│
└── checklists/                # Stage 9 산출물
    ├── 09L-01_task_001_checklist.md
    └── ...
```

---

## 🎯 Type 치트시트

```
프로젝트 산출물:
F = Function       C = Classification   D = Decision
S = Schema         A = ADR              B = Blueprint
T = Task           L = List/Checklist

방법론 문서:
G = Guide          M = Manual           E = Example/Case
```

### 읽는 법
```
03A-101_fastapi_selection.md
│││ │││
││└─┴┴─ A-101 = ADR, 101번 (Domain ADR)
│└──── 03 = Stage 3
└───── "Stage 3의 101번 ADR (Domain)"
```

---

# Part 2: 소스 코드 구조

---

## 🏗️ 디렉토리 구조

### 표준 프로젝트 구조
```
project-root/
├── src/                           # 소스 코드 루트
│   ├── core/                      # DNA 시스템 (Stage 5)
│   │   ├── logging/
│   │   ├── config/
│   │   ├── errors/
│   │   ├── types/
│   │   ├── database/
│   │   ├── cache/
│   │   ├── auth/
│   │   ├── validation/
│   │   ├── events/
│   │   ├── http/
│   │   └── testing/
│   │
│   ├── domain/                    # 도메인 로직 (Stage 9)
│   │   └── {domain_name}/
│   │       ├── entities/
│   │       ├── value_objects/
│   │       ├── services/
│   │       ├── repositories/
│   │       └── events/
│   │
│   ├── application/               # 유스케이스
│   │   └── {domain_name}/
│   │       ├── commands/
│   │       ├── queries/
│   │       └── handlers/
│   │
│   ├── infrastructure/            # 외부 연동
│   │   ├── persistence/
│   │   ├── external_apis/
│   │   └── messaging/
│   │
│   └── api/                       # API 레이어
│       ├── routes/
│       ├── schemas/
│       └── middleware/
│
├── tests/                         # Part 3 참조
├── scripts/                       # Part 4 참조
├── docs/                          # Part 1 참조
└── (설정 파일들)                   # Part 5 참조
```

---

## 📝 소스 파일 명명 규칙

### 기본 원칙
```
1. snake_case 사용 (모든 언어 공통 권장)
2. 역할이 명확한 접미사 사용
3. 복수형/단수형 일관성 유지
```

### 레이어별 파일명 패턴

#### core/ (DNA 시스템)
```
src/core/{system_name}/
├── index.*                       # 모듈 진입점 (언어별 상이)
├── {system_name}.*               # 주요 구현
├── config.*                      # 설정
├── types.*                       # 타입 정의
├── errors.*                      # 예외/에러 정의
└── constants.*                   # 상수

언어별 진입점:
├── Python:     __init__.py
├── TypeScript: index.ts
├── Rust:       mod.rs
├── Go:         (폴더명이 패키지)
└── Java:       (패키지 구조)

예시 (언어 무관):
src/core/logging/
├── index.*                       # 모듈 진입점
├── logger.*                      # get_logger(), bind_context()
├── config.*                      # LogConfig
├── formatters.*                  # JSON, Console formatter
└── handlers.*                    # File, Stream handler
```

#### domain/ (도메인)
```
src/domain/{domain_name}/
├── entities/
│   └── {entity_name}.*           # 단수형: user.*, order.*
├── value_objects/
│   └── {value_name}.*            # money.*, address.*
├── services/
│   └── {domain}_service.*        # order_service.*
├── repositories/
│   └── {entity}_repository.*     # user_repository.* (인터페이스)
└── events/
    └── {entity}_events.*         # order_events.*

예시:
src/domain/trading/
├── entities/
│   ├── order.*
│   └── position.*
├── value_objects/
│   ├── money.*
│   └── quantity.*
├── services/
│   └── trading_service.*
├── repositories/
│   └── order_repository.*
└── events/
    └── order_events.*
```

#### application/ (유스케이스)
```
src/application/{domain_name}/
├── commands/
│   └── {action}_{entity}_command.*    # create_order_command.*
├── queries/
│   └── get_{entity}_query.*           # get_order_query.*
└── handlers/
    └── {command/query}_handler.*      # create_order_handler.*

예시:
src/application/trading/
├── commands/
│   ├── create_order_command.*
│   └── cancel_order_command.*
├── queries/
│   └── get_order_history_query.*
└── handlers/
    ├── create_order_handler.*
    └── get_order_history_handler.*
```

#### infrastructure/ (인프라)
```
src/infrastructure/
├── persistence/
│   └── {db_type}_{entity}_repository.*   # postgres_user_repository.*
├── external_apis/
│   └── {service_name}_client.*           # kis_api_client.*
└── messaging/
    └── {broker}_{purpose}.*              # kafka_event_publisher.*
```

#### api/ (API)
```
src/api/
├── routes/
│   └── {domain}_routes.*          # trading_routes.*
├── schemas/
│   └── {domain}_schemas.*         # trading_schemas.*
└── middleware/
    └── {purpose}_middleware.*     # auth_middleware.*
```

---

## 🏷️ 클래스/함수 명명 규칙

### 클래스명 (PascalCase)
```
Entity:        User, Order, Product
Value Object:  Money, Address, Email
Service:       OrderService, TradingService
Repository:    UserRepository, OrderRepository
Handler:       CreateOrderHandler, GetUserHandler
Command:       CreateOrderCommand, UpdateUserCommand
Query:         GetOrderQuery, ListUsersQuery
Event:         OrderCreated, UserRegistered
Exception:     OrderNotFoundError, InvalidAmountError
```

### 함수명 (snake_case)
```
생성:    create_order(), register_user()
조회:    get_order(), find_by_id(), list_orders()
수정:    update_order(), change_status()
삭제:    delete_order(), remove_item()
검증:    validate_amount(), is_valid()
변환:    to_dict(), from_dto()
```

### 상수 (UPPER_SNAKE_CASE)
```
MAX_RETRY_COUNT = 3
DEFAULT_TIMEOUT_MS = 5000
ORDER_STATUS_PENDING = "pending"
```

---

# Part 3: 테스트 파일

---

## 🧪 테스트 디렉토리 구조

```
tests/
├── unit/                          # 단위 테스트
│   ├── core/                      # DNA 시스템 테스트
│   │   ├── test_logging.*
│   │   ├── test_config.*
│   │   └── ...
│   │
│   ├── domain/                    # 도메인 테스트
│   │   └── {domain_name}/
│   │       ├── test_{entity}.*
│   │       └── test_{service}.*
│   │
│   └── application/               # 유스케이스 테스트
│       └── {domain_name}/
│           └── test_{handler}.*
│
├── integration/                   # 통합 테스트
│   ├── test_database.*
│   ├── test_external_api.*
│   └── test_{domain}_flow.*
│
├── e2e/                           # E2E 테스트
│   └── test_{scenario}.*
│
├── fixtures/                      # 공용 픽스처/헬퍼
│   ├── factories.*                # 테스트 데이터 팩토리
│   ├── mocks.*                    # 공용 Mock
│   └── data/                      # 테스트 데이터 파일
│       └── sample_orders.json
│
└── [테스트 설정 파일]              # 언어별 상이
    # Python: conftest.py
    # TypeScript: jest.config.ts, vitest.config.ts
    # Go: *_test.go (동일 폴더)
    # Java: src/test/resources/
```

---

## 📝 테스트 파일 명명 규칙

### 파일명 패턴
```
test_{대상모듈명}.*

예시:
test_user.*                        # User 엔티티 테스트
test_order_service.*               # OrderService 테스트
test_create_order_handler.*        # CreateOrderHandler 테스트
test_postgres_user_repository.*    # PostgresUserRepository 테스트
```

### 테스트 함수명 패턴
```
test_{기능}_{조건}_{예상결과}

예시 (언어별 스타일 다름):
# snake_case (Python, Rust)
test_create_order_with_valid_data_returns_order_id()
test_create_order_with_zero_amount_raises_error()

# camelCase (JavaScript, TypeScript, Java)
testCreateOrderWithValidDataReturnsOrderId()
shouldThrowErrorWhenAmountIsZero()

# BDD 스타일 (Jest, Vitest)
it('should create order with valid data')
describe('when amount is zero', () => { ... })
```

### 테스트 클래스명 패턴 (선택적)
```
class Test{대상클래스명}:
class Test{기능그룹}:

예시:
TestUser, TestOrderCreation, TestAuthenticationFlow
```

---

## 🎯 테스트 파일 위치 규칙

### 소스 ↔ 테스트 대응
```
소스 파일:
src/domain/trading/entities/order.*

테스트 파일:
tests/unit/domain/trading/test_order.*
```

### 미러링 원칙
```
src/                               tests/unit/
├── core/                          ├── core/
│   └── logging/                   │   └── test_logging.*
│       └── logger.*               │
│                                  │
├── domain/                        ├── domain/
│   └── trading/                   │   └── trading/
│       └── entities/              │       ├── test_order.*
│           └── order.*            │       └── test_position.*
│                                  │
└── application/                   └── application/
    └── trading/                       └── trading/
        └── handlers/                      └── test_create_order_handler.*
            └── create_order_handler.py
```

---

## 📦 픽스처 명명 규칙

### 팩토리 함수
```
def create_{entity}(**overrides) -> Entity:
def build_{entity}_dict(**overrides) -> dict:

예시:
def create_user(name="Test User", email="test@example.com") -> User:
def build_order_dict(amount=10000, status="pending") -> dict:
```

### Mock 객체
```
mock_{대상}_repository
mock_{서비스명}_client
stub_{외부시스템}

예시:
mock_user_repository
mock_kis_api_client
stub_payment_gateway
```

---

# Part 4: 스크립트/임시 파일

---

## 🔧 스크립트 디렉토리 구조

```
scripts/
├── setup/                         # 환경 설정 스크립트
│   ├── install_dependencies.sh
│   ├── setup_database.sh
│   └── init_project.sh
│
├── migration/                     # 마이그레이션 스크립트
│   ├── migrate_v1_to_v2.py
│   └── seed_data.py
│
├── deployment/                    # 배포 관련 스크립트
│   ├── deploy_staging.sh
│   └── deploy_production.sh
│
├── utils/                         # 유틸리티 스크립트
│   ├── generate_test_data.py
│   ├── cleanup_logs.sh
│   └── health_check.py
│
└── ci/                            # CI/CD 스크립트
    ├── run_tests.sh
    └── build_image.sh
```

---

## 📝 스크립트 명명 규칙

### 파일명 패턴
```
{동작}_{대상}.{확장자}

예시:
setup_database.sh                  # 데이터베이스 설정
run_tests.sh                       # 테스트 실행
generate_test_data.py              # 테스트 데이터 생성
migrate_v1_to_v2.py                # v1에서 v2로 마이그레이션
cleanup_old_logs.sh                # 오래된 로그 정리
```

### 스크립트 종류별 접두사
```
setup_     환경/초기 설정
run_       실행 스크립트
build_     빌드 관련
deploy_    배포 관련
migrate_   마이그레이션
generate_  생성 스크립트
cleanup_   정리 스크립트
check_     검증/확인
```

---

## 📁 임시 파일 관리

### 임시 작업 디렉토리
```
.work/                             # 임시 작업 (gitignore 필수!)
├── notes/                         # 작업 메모
│   └── 2024-01-15_api_research.md
├── scratch/                       # 실험 코드
│   └── test_concept.py
├── debug/                         # 디버깅용
│   └── error_trace_20240115.log
└── exports/                       # 임시 내보내기
    └── report_draft.csv
```

### 임시 파일 명명 규칙
```
날짜 포함 권장:
{YYYY-MM-DD}_{설명}.{확장자}

예시:
2024-01-15_api_response_analysis.md
2024-01-15_performance_test_results.json
```

### .gitignore 필수 항목
```
# 임시 작업 폴더
.work/
temp/
tmp/

# 개인 메모
*.local.md
*.draft.md

# IDE/편집기
.idea/
.vscode/
*.swp
```

---

## 🗂️ 작업 관련 문서

### 작업 중 생성되는 문서 위치
```
docs/work/                         # 작업 관련 문서 (선택적 버전 관리)
├── research/                      # 리서치 문서
│   └── {date}_{topic}_research.md
├── decisions/                     # 미확정 결정 메모
│   └── {date}_{topic}_draft.md
└── reviews/                       # 리뷰/피드백
    └── {date}_{target}_review.md
```

### vs 공식 산출물 구분
```
공식 산출물 (Part 1 규칙):
docs/architecture/01F-01_core_functions.md    # 버전 관리 O
docs/adr/03A-001_logging.md                   # 버전 관리 O

작업 중 문서 (이 섹션):
docs/work/research/2024-01-15_db_comparison.md  # 버전 관리 △
.work/notes/quick_memo.md                       # 버전 관리 X
```

---

# Part 5: 설정 파일

---

## ⚙️ 프로젝트 루트 설정 파일

### 표준 레이아웃
```
project-root/
├── pyproject.toml                 # 빌드/린터/타입체커 (Python)
├── package.json                   # 빌드/린터 (TypeScript)
├── Cargo.toml                     # 빌드 설정 (Rust)
├── go.mod                         # 모듈 설정 (Go)
│
├── .pre-commit-config.yaml        # pre-commit hooks
├── .importlinter                  # 아키텍처 의존성 (Python)
│
├── .env.example                   # 환경변수 예시 (버전 관리 O)
├── .env                           # 실제 환경변수 (버전 관리 X)
├── .env.local                     # 로컬 오버라이드 (버전 관리 X)
│
├── .gitignore                     # Git 제외 파일
├── .dockerignore                  # Docker 제외 파일
│
├── Dockerfile                     # Docker 빌드
├── docker-compose.yml             # 로컬 개발 환경
├── docker-compose.test.yml        # 테스트 환경
│
├── Makefile                       # 공용 명령어 (선택)
└── README.md                      # 프로젝트 소개
```

---

## 📝 설정 파일 명명 규칙

### 환경별 설정 파일
```
.env.example                       # 예시 (버전 관리 O, 실제 값 X)
.env                               # 기본 환경
.env.local                         # 로컬 오버라이드
.env.development                   # 개발 환경
.env.staging                       # 스테이징 환경
.env.production                    # 운영 환경 (버전 관리 X!)
.env.test                          # 테스트 환경
```

### Docker 관련
```
Dockerfile                         # 기본 (운영용)
Dockerfile.dev                     # 개발용
Dockerfile.test                    # 테스트용

docker-compose.yml                 # 기본 (개발용)
docker-compose.test.yml            # 테스트용
docker-compose.prod.yml            # 운영용
```

### CI/CD 설정
```
.github/
├── workflows/
│   ├── ci.yml                     # CI 파이프라인
│   ├── cd.yml                     # CD 파이프라인
│   └── codeql.yml                 # 보안 분석
├── CODEOWNERS                     # 코드 소유자
└── pull_request_template.md       # PR 템플릿

.gitlab-ci.yml                     # GitLab CI
```

---

## 🔒 버전 관리 주의 파일

### 버전 관리 O (반드시 포함)
```
✅ .env.example                    # 환경변수 구조 공유
✅ pyproject.toml / package.json   # 의존성 정의
✅ .pre-commit-config.yaml         # 품질 도구 설정
✅ Dockerfile                      # 빌드 정의
✅ docker-compose.yml              # 개발 환경
✅ .gitignore                      # 제외 파일 정의
```

### 버전 관리 X (반드시 제외)
```
❌ .env                            # 실제 환경변수
❌ .env.local                      # 개인 설정
❌ .env.production                 # 운영 비밀키
❌ *.pem, *.key                    # 인증서/키 파일
❌ node_modules/, __pycache__/     # 의존성/캐시
❌ .work/, temp/                   # 임시 파일
❌ *.log                           # 로그 파일
❌ .DS_Store                       # 시스템 파일
```

---

## 🗂️ 설정 파일 배치 원칙

### 1. 루트 vs 하위 폴더
```
프로젝트 전체 설정 → 루트
├── pyproject.toml
├── .pre-commit-config.yaml
└── docker-compose.yml

특정 영역 설정 → 해당 폴더
├── src/core/logging/config.py
├── tests/conftest.py
└── .github/workflows/ci.yml
```

### 2. 환경별 분리 원칙
```
공통 설정:     기본 파일 (docker-compose.yml)
환경별 설정:   접미사로 구분 (.env.{environment})
오버라이드:    .local 접미사 (.env.local)
```

---

# 부록: 체크리스트

---

## ✅ 새 파일 생성 시 확인

### 문서 파일 (Part 1)
```
[ ] Stage 번호가 정확한가? (01~09)
[ ] Type 코드가 올바른가? (F/C/D/S/A/B/T/L/G/M/E)
[ ] Seq 번호가 중복되지 않는가?
[ ] 설명적 이름이 snake_case인가?
[ ] 저장 위치가 올바른가? (docs/{category}/)
```

### 소스 코드 (Part 2)
```
[ ] 올바른 레이어에 위치하는가? (core/domain/application/infrastructure/api)
[ ] 파일명이 역할을 명확히 표현하는가?
[ ] 클래스/함수명이 명명 규칙을 따르는가?
[ ] 도메인 폴더 구조가 일관적인가?
```

### 테스트 파일 (Part 3)
```
[ ] tests/ 하위 올바른 위치에 있는가?
[ ] test_ 접두사가 있는가?
[ ] 소스 파일과 경로가 미러링되는가?
[ ] 테스트 함수명이 기능_조건_결과 패턴인가?
```

### 스크립트/임시 (Part 4)
```
[ ] scripts/ 하위 적절한 폴더에 있는가?
[ ] 동작_대상 패턴을 따르는가?
[ ] 임시 파일은 .work/ 또는 gitignore된 위치인가?
```

### 설정 파일 (Part 5)
```
[ ] 비밀 정보가 포함된 파일은 gitignore되었는가?
[ ] .env.example이 존재하는가?
[ ] 환경별 파일명이 일관적인가?
```

---

## 🔍 빠른 검색 명령어

```bash
# Stage 2 문서 찾기
find docs/ -name "02*"

# 모든 ADR 찾기
find docs/adr/ -name "03A-*"

# 특정 도메인 테스트 찾기
find tests/ -path "*trading*" -name "test_*.py"

# DNA 시스템 코드 찾기
find src/core/ -name "*.py" | head -20
```

---

## 📚 참고 문서

- **01_STAGE_STRUCTURE.md**: 9개 Stage 전체 구조
- **00_CORE_METHODOLOGY.md**: DNA 방법론 개요
- **06G-00_project_standards_guide.md**: 프로젝트 표준 가이드

---

**버전 이력**:
- v2.0 (2025-12-09): 소스코드/테스트/스크립트/설정 규칙 추가 (AI 어시스턴트)
- v1.0 (2025-11-12): 초기 작성 - 문서 명명 규칙 (Jason + AI)


================================================================================

📄 FILE: 01_STAGE_STRUCTURE.md
--------------------------------------------------------------------------------

# DNA 방법론 Stage 구조 기준서

> **목적**: 아이디어부터 구현까지 9개 Stage의 목적, 범위, 산출물을 명확히 정의
>
> **버전**: v1.1 (2025-11-13)
> **기반**: Phase 2 실전 검증 (주식 거래 플랫폼)

---

## 🎯 전체 흐름 개요

```
아이디어 → 실현 가능한 소프트웨어

Stage 1: 패밀리 구분과 핵심기능 파악 (큰 방향)
   ↓
Stage 2: 구조설계 (결정 요소 파악)
   ↓
Stage 3: ADR 문서화 (결정)
   ↓
Stage 4: DNA 시스템 계획 (청사진+작업분해+체크리스트)
   ↓
Stage 5: DNA 시스템 구축 (표준+구현)
   ↓
Stage 6: Project Standards (규칙)
   ↓
Stage 7: Project Blueprint (상세 청사진)
   ↓
Stage 8: Task Breakdown (작업 분할)
   ↓
Stage 9: Checklist (작업별 체크리스트)
   ↓
구현 (TDD 9-Step)
```

---

## Stage 1: 패밀리 구분과 핵심기능 파악

### 목적
- **큰 방향과 큰 틀만 잡기**
- 시스템의 본질적 특성 파악
- 필수 기술 방향 자동 결정

### 범위
1. **Part 0: 핵심 기능 파악**
   - 이 시스템의 존재 이유는?
   - 구현 방식이 아닌 비즈니스 목적으로 구분
   - 예: "거래" (O) vs "수동 거래 + 자동 거래" (X)

2. **Layer 1: 아키텍처 패밀리 식별**
   - L1-Q1: 실패 파급력 (A/B/C)
   - L1-Q2: 정보 형태 (A/B/C)
   - L1-Q3: 응답 시점 (A/B/C)
   - 결과: 패밀리 패턴 (예: A-C-A)

3. **Layer 2: NFR 우선순위**
   - L2-Q1: 핵심 품질 (A/B/C)
   - L2-Q2: 규모 (A/B/C)
   - L2-Q3: 데이터 노출 (A/B/C)
   - L2-Q4: 데이터 최신성 (A/B/C)
   - 결과: NFR 프로파일 (예: A-B-B-A)

### 산출물
- **패밀리 결정**: A-C-A (실시간 트랜잭션)
- **핵심 기능**: 거래
- **필수 기술 방향**:
  - ✅ 실시간 통신 필수 (WebSocket 계열)
  - ✅ 숫자 데이터 처리 (시계열 DB 고려)
  - ✅ 정확성 보장 (ACID 또는 강력한 일관성)
- **기술 후보군**:
  - WebSocket, FastAPI, Redis, PostgreSQL 계열

### 제외 사항
- ❌ 구체적 기술 스택 선택 (Stage 2에서)
- ❌ 외부 제약 조사 (Stage 2에서)
- ❌ 아키텍처 다이어그램 (Stage 2에서)

### 관련 문서
- `01_CORE_DEFINITION_GUIDE.md`
- `01-1_CORE_DEFINITION_MANUAL_Part1.md`
- `01-2_CORE_DEFINITION_MANUAL_Part2.md`

---

## Stage 2: 구조설계

### 목적
- **결정해야 할 요소 목록 만들기**
- 내부 자원과 외부 제약/기회 파악
- 구체적 설계 (청사진 수준)

### 범위
1. **Part 1: Layer 3 - 환경 제약 조사**
   - L3-Q1: 기술 스택 제약 (외부 조사 필수!)
     - 외부 API/서비스 비교 (예: 증권사 6개)
     - 법적 규제 조사
     - 개인정보보호 조사
   - L3-Q2: 팀 역량
   - L3-Q3: 배포 환경

2. **Part 2: 충돌 패턴 발견**
   - Layer 2 NFR vs Layer 3 제약 충돌
   - 충돌 매트릭스 작성
   - 트레이드오프 옵션 정리

3. **Part 3: 5단계 구현방법**
   - 1단계: 기능 분해
   - 2단계: 속성 질문 (NFR → 구체적 수치)
   - 3단계: 제약조건
   - 4단계: 기술 옵션 비교
   - 5단계: 통합 설계
     - 아키텍처 다이어그램
     - 데이터 스키마 v1.0
     - API 설계 v1.0

### 산출물
- **제약 목록**:
  - 외부: 한국투자증권 API (20건/초, WebSocket 41개)
  - 내부: 팀 역량, 비용 제약
- **충돌 목록**:
  - #1: 정확성 A vs API 20건/초
  - #2: 즉시성 A vs WebSocket 41개
  - #3: 모의 검증 vs 실전 차이
- **기술 스택 (확정)**:
  - 백엔드: FastAPI (Python)
  - 실시간: WebSocket
  - Queue: Redis + Bull/Celery
  - DB: PostgreSQL
  - 캐시: Redis
  - 프론트: Next.js + React
- **아키텍처 다이어그램**
- **데이터 스키마 v1.0**
- **API 설계 v1.0**
- **ADR 작성 대상 목록** (18개)

### 제외 사항
- ❌ ADR 작성 (Stage 3에서)
- ❌ DNA 시스템 설계 (Stage 4에서)
- ❌ 도메인별 상세 설계 (Stage 7에서)

### 관련 문서
- `02_STRUCTURE_DESIGN_GUIDE.md` (새로 작성 예정)
- `02-1_STRUCTURE_DESIGN_MANUAL.md` (새로 작성 예정)

---

## Stage 3: 결정 문서화 (ADR)

### 목적
- **모든 아키텍처 결정을 문서화**
- "왜?"에 대한 근거 명확히
- 시스템 강제(System Enforcement) 기반 마련

### 범위
1. **DNA 시스템 ADR 작성 (001-011)**
   - 11개 DNA 시스템 각각에 대한 결정
   - 예: Type System, Observability, Testing, Code Quality, Architecture Enforcement, Configuration, Error Handling, Performance, API, Data, Security

2. **도메인 ADR 작성 (100-999)**
   - 프로젝트 특화 요소
   - 예: 한국투자증권 선택, 하이브리드 전략, Redis Queue

3. **ADR 작성 원칙**
   - 하나의 ADR = 하나의 결정
   - 너무나 당연한 요소도 모두 작성
   - 제약도 ADR이다 (선택지 1개여도 기록)

### 산출물
- **DNA 시스템 ADR (001-011)** - 11개 필수
  - 001: Type System 선택 (mypy, TypeScript strict 등)
  - 002: Observability 전략 (structlog, winston 등)
  - 003: Testing 프레임워크 (pytest, jest 등)
  - 004: Code Quality 도구 (ruff, eslint 등)
  - 005: Architecture Enforcement (import-linter 등)
  - 006: Configuration 관리 (uv, pnpm 등)
  - 007: Error Handling 패턴 (Result/Either 등)
  - 008: Performance 측정 (pytest-benchmark, Criterion 등)
  - 009: API 설계 (FastAPI, NestJS 등)
  - 010: Data 접근 (SQLAlchemy, Prisma 등)
  - 011: Security 전략 (bandit, helmet 등)

- **도메인 ADR (100-999)** (예상 15-20개)
  - 외부 제약 관련 (예: 한국투자증권 선택)
  - 충돌 해결 관련 (예: 하이브리드 전략)
  - 기술 스택 관련 (예: FastAPI 선택)
  - 데이터 설계 관련
  - API 설계 관련
  - ...

### 제외 사항
- ❌ 구현 (Stage 5, 9에서)
- ❌ 테스트 코드 (Stage 9에서)

### 관련 문서
- `03_ADR_GUIDE.md`
- `03-1_ADR_MANUAL.md` (작성 예정)

---

## Stage 4: DNA 시스템 계획

### 목적
- **11개 DNA 시스템 구축 계획 수립**
- DNA 청사진, 작업 분해, 체크리스트 작성

### 배경
**DNA 시스템 = 모든 소프트웨어의 기본 설계도**

생명의 DNA가 모든 생물의 기초이듯, 11개 DNA 시스템은 모든 소프트웨어 프로젝트의 기초입니다.
- 언어, 프레임워크, 도메인 무관
- 11개 모두 필수
- 자동 강제 (지키지 않으면 빌드/실행 실패)
- 일관성 필수 (한 곳만 다르면 전체 혼란)

**11개 DNA 시스템**:
1. Type System (타입 체커)
2. Observability System (로깅/메트릭/추적)
3. Testing System (테스트 프레임워크)
4. Code Quality System (포맷터/린터)
5. Architecture Enforcement (Layer 경계)
6. Configuration System (환경 변수 + 의존성)
7. Error Handling System (Result/Either)
8. Performance System (벤치마크/프로파일링)
9. API System (인터페이스)
10. Data System (저장/조회)
11. Security System (인증/암호화)

### 범위
1. **DNA 청사진 작성**
   - DNA 시스템 ADR (001-011) 기반
   - 디렉토리 구조 (src/core/)
   - 각 DNA 시스템별 파일 구조
   - 공통 모듈 인터페이스

2. **DNA 작업 분해**
   - 11개 DNA → 하위 작업으로 분해
   - 우선순위 결정 (기반 6개 → 도메인 5개)
   - 의존성 파악

3. **DNA 체크리스트 작성**
   - 11개 DNA 통합 체크리스트 (1개 파일)
   - 각 DNA별 섹션
   - 하위 작업 체크박스

### 산출물
- **04D-01_dna_blueprint.md** (DNA 청사진)
  - 전체 디렉토리 구조
  - 각 DNA 시스템별 파일 목록
  - 인터페이스 설계

- **04T-01_dna_tasks.md** (DNA 작업 분해)
  - 11개 DNA 시스템 → N개 하위 작업
  - 우선순위 및 의존성

- **04L-01_dna_checklist.md** (DNA 체크리스트)
  - 통합 체크리스트 1개
  - 11개 섹션 (DNA별)
  - 하위 작업 체크박스

### 관련 문서
- `04G-00_dna_planning_guide.md` (작성 예정)
- `03_DNA_SYSTEMS_GUIDE.md` (참조)

---

## Stage 5: DNA 시스템 구축

### 목적
- **11개 DNA 시스템 실제 구현**
- 구현 표준 정의 및 검증

### 범위
1. **DNA 구현 표준 작성**
   - 파일 구조 규칙 (src/core/)
   - 네이밍 규칙 (클래스, 함수, 상수)
   - Import 규칙
   - 테스트 규칙 (95%+ 커버리지)
   - 문서화 규칙

2. **DNA 시스템 구현**
   - 체크리스트 (04L-01) 기반 구현
   - 구현 표준 (05S-01) 준수
   - TDD 기반 개발
   - 각 DNA 시스템별 검증

3. **통합 검증**
   - 11개 DNA 시스템 통합 테스트
   - Kent Beck 검증 (10/11개 달성 확인)
   - 모든 DNA 동작 확인

### 산출물
- **05S-01_dna_standards.md** (DNA 구현 표준)
  - 파일 구조 규칙
  - 네이밍 컨벤션
  - Import/테스트/문서화 규칙

- **실제 구현 파일**:
  - `pyproject.toml` (Type, Testing, Quality, Config)
  - `.pre-commit-config.yaml` (Quality)
  - `mypy.ini` / `ruff.toml` (Type, Quality)
  - `src/core/logger.py` (Observability)
  - `src/core/error.py` (Error Handling)
  - `src/core/config.py` (Configuration)
  - `tests/core/` (Testing)
  - 벤치마크 설정 (Performance)
  - 보안 스캔 설정 (Security)

- **검증 보고서**:
  - 11개 DNA 시스템 동작 확인
  - 테스트 커버리지 95%+ 달성
  - 품질 검사 0 violations

### 관련 문서
- `05G-00_dna_implementation_guide.md` (작성 예정)
- `03_DNA_SYSTEMS_GUIDE.md` (참조)

---

## Stage 6: Project Standards 작성

### 목적
- **프로젝트 종료 시까지 지켜야 할 규칙 정의**
- 일관성 보장

### 범위
1. **코딩 스타일**
   - Naming conventions
   - File organization
   - Code formatting

2. **로깅 표준**
   - Log levels
   - Log format
   - Log rotation

3. **에러 처리 표준**
   - Error types
   - Error messages
   - Error propagation

4. **설정 관리 표준**
   - Environment variables
   - Config files
   - Secrets management

5. **기타 룰**
   - Git commit convention
   - PR 규칙
   - Review 기준

6. **DNA 시스템 사용 강제**
   - src/core/ 모듈 필수 사용
   - 직접 구현 금지 항목
   - DNA 시스템 표준 준수

### 산출물
- **PROJECT_STANDARDS.md**

### 관련 문서
- `04_PROJECT_STANDARDS_GUIDE.md` (기존)

---

## Stage 7: Project Blueprint 작성

### 목적
- **초상세 프로젝트 전체 청사진**
- 도메인별 구현 가이드

### 범위
1. **아키텍처 구조**
   - 전체 시스템 아키텍처
   - 레이어별 구조
   - 컴포넌트 다이어그램

2. **도메인 구조**
   - 도메인 모델
   - 도메인별 경계
   - 도메인 간 관계

3. **전체 시스템 다이어그램**
   - 시스템 컨텍스트
   - 컨테이너 다이어그램
   - 컴포넌트 다이어그램
   - 시퀀스 다이어그램

4. **도메인별 다이어그램**
   - 각 도메인의 상세 설계
   - 데이터 흐름
   - API 엔드포인트

5. **도메인별 구현 가이드**
   - 구현해야 할 기능 목록
   - 기술 스택 활용 방법
   - 최신 기술/기법 적용 방안

### 산출물
- **PROJECT_BLUEPRINT.md** (초상세)
- **아키텍처 다이어그램** (여러 레벨)
- **도메인별 구현 가이드**

### 관련 문서
- `05_BLUEPRINT_GUIDE.md` (기존)

---

## Stage 8: Task Breakdown 문서 작성

### 목적
- **AI가 집중해서 완전하게 구현할 크기로 작업 분할**

### 범위
1. **작업 분할 기준**
   - 1개 작업 = 1개 파일 또는 1개 기능
   - 4시간 이내 완료 가능 크기
   - 독립적으로 테스트 가능

2. **작업 목록 작성**
   - 도메인별 작업 분할
   - 우선순위 결정
   - 의존성 파악

3. **작업별 설명**
   - 목표
   - 입력/출력
   - 제약 조건
   - 참고 자료

### 산출물
- **TASK_BREAKDOWN.md**
- **작업별 상세 설명**

### 관련 문서
- `06_TASK_BREAKDOWN_GUIDE.md` (기존)

---

## Stage 9: 작업별 Checklist 작성

### 목적
- **TDD 기반 9-Step Checklist**
- 모든 기능 구현, 0 violations, 95%+ coverage 보장

### 범위
**TDD 9-Step Checklist**:
1. **목표 이해**
   - 요구사항 명확히
   - 성공 기준 정의

2. **테스트 작성**
   - 단위 테스트 먼저
   - 실패하는 테스트 확인

3. **구현**
   - 테스트 통과하는 최소 코드
   - 점진적 개선

4. **정적 검증**
   - Ruff, Mypy 실행
   - 0 violations 확인

5. **단위 테스트 실행**
   - Pytest 실행
   - 95%+ 커버리지 확인

6. **리팩토링**
   - 코드 정리
   - 중복 제거

7. **종합 테스트**
   - 통합 테스트
   - E2E 테스트

8. **문서화**
   - Docstring
   - README 업데이트

9. **커밋**
   - Git commit
   - PR 생성

### 산출물
- **작업별 체크리스트 문서**
- **테스트 템플릿**

### 관련 문서
- `07_CHECKLIST_GUIDE.md` (기존)

---

## 📊 Stage 간 관계

```
Stage 1 (패밀리+핵심기능)
   ↓ 필수 기술 방향, 기술 후보군
Stage 2 (구조설계)
   ↓ ADR 작성 대상 목록, 기술 스택 확정
Stage 3 (ADR)
   ↓ DNA 시스템 ADR (001-011), 도메인 ADR (100-999)
Stage 4 (DNA 계획)
   ↓ DNA 청사진, 작업 분해, 체크리스트
Stage 5 (DNA 구축)
   ↓ DNA 구현 표준, 실제 구현 파일 (src/core/)
Stage 6 (Standards)
   ↓ 프로젝트 규칙 (DNA 시스템 사용 강제)
Stage 7 (Blueprint)
   ↓ 초상세 청사진 (DNA 시스템 활용)
Stage 8 (Task Breakdown)
   ↓ 작업 목록
Stage 9 (Checklist)
   ↓ 작업별 체크리스트
구현 (TDD 9-Step)
```

---

## 🎯 각 Stage의 핵심 원칙

### Stage 1: 큰 방향만
- ✅ 패밀리 결정 → 필수 기술 방향 자동 결정
- ✅ 핵심 기능 파악 → 구현 후보군 결정
- ❌ 구체적 기술 선택 금지

### Stage 2: 구체적 설계
- ✅ 외부 제약 조사 (실제 API, 법규 확인)
- ✅ 충돌 발견 → 트레이드오프 정리
- ✅ 기술 스택 확정 → 아키텍처 다이어그램

### Stage 3: 모든 결정 문서화
- ✅ 너무 당연한 것도 ADR 작성
- ✅ 제약도 ADR (선택지 1개여도)
- ✅ DNA 시스템 (001-011) vs 도메인 (100-999) 구분

### Stage 4-5: DNA 시스템 구축
- ✅ 11개 DNA 모두 필수
- ✅ 계획 (청사진→작업분해→체크리스트) → 구축 (표준→구현)
- ✅ Kent Beck 검증 (10/11개 달성)
- ✅ src/core/ 구조 완성

### Stage 6-9: 프로젝트 구현 준비
- ✅ DNA 시스템 활용 강제 (Standards)
- ✅ 상세 설계 (Blueprint)
- ✅ 작업 분할 → 체크리스트 → 구현

---

## 📝 문서 명명 규칙

### 가이드 파일 (completed-guide/)
```
01_STAGE_STRUCTURE.md (이 문서)
01G-00_core_definition_guide.md (Stage 1)
01M-01_layer1_manual.md
01M-02_layer2_manual.md
02G-00_structure_design_guide.md (Stage 2)
02M-01_structure_design_manual.md
02M-02_architecture_decision_manual.md
03G-00_adr_guide.md (Stage 3)
04G-00_dna_planning_guide.md (Stage 4) ⭐ 신규
05G-00_dna_implementation_guide.md (Stage 5) ⭐ 신규
06G-00_project_standards_guide.md (Stage 6)
07G-00_blueprint_guide.md (Stage 7)
08G-00_task_breakdown_guide.md (Stage 8)
09G-00_checklist_guide.md (Stage 9)
```

### 프로젝트 산출물 파일 (프로젝트별)
```
Stage 3: ADR
- 03A-001_type_system.md ~ 03A-011_security_system.md (DNA ADR)
- 03A-101_xxx.md ~ 03A-999_xxx.md (Domain ADR)

Stage 4: DNA 계획
- 04D-01_dna_blueprint.md (청사진)
- 04T-01_dna_tasks.md (작업 분해)
- 04L-01_dna_checklist.md (체크리스트)

Stage 5: DNA 구축
- 05S-01_dna_standards.md (구현 표준)
- src/core/ (실제 구현)

Stage 6: 프로젝트 표준
- 06S-01_project_standards.md

Stage 7: 청사진
- 07B-01_project_blueprint.md

Stage 8: 작업 분해
- 08T-01_task_breakdown.md

Stage 9: 체크리스트
- 09L-01~N_task_*_checklist.md
```

---

## 🔄 현재 작업 상태 (2025-11-13)

- ✅ **Stage 1**: 01_CORE_DEFINITION 완성
  - Part 0, Layer 1-2 완료
  - A-C-A 패밀리 발견 반영

- 🔄 **Stage 2**: 02_STRUCTURE_DESIGN 작성 필요
  - 기존 02_ARCHITECTURE_DECISION + 02_IMPLEMENTATION_APPROACH 통합
  - Layer 3 + 충돌 + 5단계 통합

- ✅ **Stage 3**: 03_ADR 완성
  - DNA 시스템 ADR (001-011) vs 도메인 ADR (100-999) 구분

- 🔄 **Stage 4-5**: DNA 시스템 가이드 작성 중 ⭐
  - 04G-00_dna_planning_guide.md (작성 예정)
  - 05G-00_dna_implementation_guide.md (작성 예정)
  - 03_DNA_SYSTEMS_GUIDE.md (완성)

- ⏸️ **Stage 6-9**: 향후 작업

---

**버전 이력**:
- v1.0 (2025-11-12): 초기 작성 (Phase 2 실전 검증 기반)
- v1.1 (2025-11-13): DNA 시스템 통일 (Bootstrap → DNA)


================================================================================

📄 FILE: 02_PROJECT_STANDARDS_TEMPLATE.md
--------------------------------------------------------------------------------

# Project Standards 템플릿 (언어 중립)

> **버전**: v1.0
> **최종 수정**: 2025-12-09
> **출처**: 06G-00 Stage 6 가이드에서 분리
> **원칙**: 언어/프레임워크에 무관한 범용 템플릿

---

## 📋 개요

이 템플릿은 **Stage 6: Project Standards** 산출물의 기본 구조입니다.
프로젝트의 언어/프레임워크에 맞게 구체화하여 사용하세요.

**언어별 상세 예시**: `manual-cases/` 폴더 참조

---

## 📄 템플릿 시작

```markdown
# Project Standards

> **프로젝트**: [프로젝트명]
> **버전**: v1.0
> **작성일**: YYYY-MM-DD
> **기반 ADR**: 03A-401 ~ 03A-411 (DNA 시스템)
> **언어/프레임워크**: [언어 버전, 주요 프레임워크]

---

## 1. 코드 스타일

### 1.1 포맷팅
- **도구**: [Formatter Tool - 예: Ruff, Prettier, gofmt, rustfmt]
- **줄 길이**: [80/88/100/120자]
- **들여쓰기**: [Spaces/Tabs, 개수]
- **인용부호**: [큰따옴표/작은따옴표]

### 1.2 네이밍
| 대상 | 규칙 | 예시 |
|------|-----|------|
| 클래스/타입 | PascalCase | `OrderService`, `UserDto` |
| 함수/메서드 | [snake_case/camelCase] | `create_order` / `createOrder` |
| 변수 | [snake_case/camelCase] | `user_id` / `userId` |
| 상수 | UPPER_SNAKE_CASE | `MAX_RETRY_COUNT` |
| 비공개 | [_prefix/private 키워드] | `_internal` |

### 1.3 Import/Package 순서
```
# 1. 표준 라이브러리/내장 모듈

# 2. 서드파티/외부 패키지

# 3. 로컬 모듈 (core → domain → api 순)
```

---

## 2. DNA 시스템 사용 규칙

> 각 DNA 시스템별 DO/DON'T 패턴 정의

### 2.1 Logging

**DO ✅**
```
- 구조화된 로거 사용 (core/logging)
- 컨텍스트 정보 포함 (trace_id, user_id)
- 키워드 인자로 데이터 전달
```

**DON'T ❌**
```
- print/console.log 사용 금지
- 표준 로깅 라이브러리 직접 사용 금지
- 문자열 연결/포매팅으로 로그 메시지 생성 금지
```

### 2.2 Configuration

**DO ✅**
```
- 중앙 설정 관리자 사용 (core/config)
- 타입 안전한 설정 접근
- 환경별 설정 분리
```

**DON'T ❌**
```
- 환경변수 직접 접근 금지
- 하드코딩된 설정값 금지
- 설정 검증 없이 사용 금지
```

### 2.3 Types

**DO ✅**
```
- 도메인 타입 사용 (UserId, OrderId, Money 등)
- 모든 공개 API에 타입 명시
- 타입 검사 도구 통과 필수
```

**DON'T ❌**
```
- Any/unknown/dynamic 타입 금지
- 원시 타입만으로 도메인 표현 금지
- 타입 힌트/어노테이션 누락 금지
```

### 2.4 Error Handling

**DO ✅**
```
- 도메인 예외 클래스 사용 (ValidationError, NotFoundError 등)
- 예외에 컨텍스트 정보 포함
- 복구 가능 여부에 따른 예외 분류
```

**DON'T ❌**
```
- 일반 Exception/Error 사용 금지
- 빈 catch/except 블록 금지
- 예외 무시(swallow) 금지
```

### 2.5 Database

**DO ✅**
```
- 중앙 세션/커넥션 관리자 사용
- 파라미터화된 쿼리 사용
- 트랜잭션 경계 명확히 설정
```

**DON'T ❌**
```
- 문자열 연결로 쿼리 생성 금지 (SQL Injection!)
- 수동 커넥션 관리 금지
- 커밋/롤백 누락 금지
```

---

## 3. 품질 기준

### 3.1 Zero Tolerance

| 항목 | 기준 | 검증 방법 |
|------|-----|----------|
| [Lint Tool] | 0 violations | `[lint command]` |
| [Type Check Tool] | 0 errors | `[type check command]` |
| [Test Framework] | 0 failures | `[test command]` |
| Coverage | [95%+] | `[coverage command]` |

### 3.2 커밋 전 필수

```bash
# 모든 검증 통과 필수 (pre-commit hook)
[pre-commit run command]
```

위반 시 커밋 차단됨.

---

## 4. 아키텍처 규칙

### 4.1 레이어 구조

```
src/
├── core/      # DNA 시스템 (공통 인프라)
├── domain/    # 비즈니스 로직
└── api/       # 인터페이스 (HTTP, CLI, etc.)
```

### 4.2 의존성 방향

```
허용: api → domain → core
금지: core → domain, domain → api
```

### 4.3 아키텍처 검증

```bash
# 의존성 방향 검증 도구
[architecture lint command]

# 위반 시
FAILED: Core는 Domain/API에 의존하지 않음
```

---

## 5. Git 규칙

### 5.1 커밋 메시지

```
<type>(<scope>): <subject>

타입:
- feat: 새 기능
- fix: 버그 수정
- refactor: 리팩토링
- test: 테스트 추가/수정
- docs: 문서 수정
- chore: 빌드/설정 변경
```

### 5.2 브랜치 전략

```
main         ← 운영 (보호됨)
develop      ← 개발 통합
feature/*    ← 기능 개발
fix/*        ← 버그 수정
```

### 5.3 PR 규칙

- [ ] 모든 CI 통과
- [ ] 리뷰어 [N]명 이상 승인
- [ ] 커버리지 유지 또는 증가

---

## 6. 참조

- ADR: `docs/adr/03A-401~411_*.md`
- DNA 구현: `src/core/`
- 자동화 설정: `[빌드 설정 파일]`, `[pre-commit 설정]`
```

## 템플릿 끝

---

## 🔧 사용 방법

### 1. 복사 후 구체화
```bash
cp 02_PROJECT_STANDARDS_TEMPLATE.md docs/06D-01_project_standards.md
```

### 2. 플레이스홀더 교체

| 플레이스홀더 | 언어별 예시 |
|------------|-----------|
| `[Lint Tool]` | Ruff (Python), ESLint (TS), golangci-lint (Go) |
| `[Type Check Tool]` | MyPy (Python), tsc (TS), go vet (Go) |
| `[Test Framework]` | pytest (Python), Jest (TS), go test (Go) |
| `[Formatter Tool]` | Ruff (Python), Prettier (TS), gofmt (Go) |
| `[lint command]` | `ruff check .`, `eslint .`, `golangci-lint run` |

### 3. DNA 규칙 상세화
각 DNA 시스템별로 프로젝트에 맞는 구체적인 DO/DON'T 코드 예시 추가

### 4. 팀 합의 반영
- 줄 길이, 들여쓰기 등 스타일 결정
- 커버리지 기준 결정
- 리뷰어 수 결정

---

## 📚 언어별 상세 예시

- **Python**: `manual-cases/06M-01_python_standards_manual.md` (예정)
- **TypeScript**: `manual-cases/06M-02_typescript_standards_manual.md` (예정)
- **Go**: `manual-cases/06M-03_go_standards_manual.md` (예정)

---

## ✅ 체크리스트: 템플릿 사용 전 확인

- [ ] 프로젝트 언어/프레임워크 결정됨
- [ ] DNA 시스템 ADR 작성 완료 (Stage 4)
- [ ] DNA 시스템 구현 완료 (Stage 5)
- [ ] 품질 도구 선택 완료
- [ ] 팀 스타일 합의 완료


================================================================================

📄 FILE: 03_DNA_SYSTEMS_GUIDE.md
--------------------------------------------------------------------------------

# 🧬 DNA 시스템 11개 - 완전 가이드

> **DNA 시스템 = 모든 소프트웨어의 기본 설계도**
>
> 생명의 DNA가 모든 생물의 기초이듯, 11개 DNA 시스템은 모든 소프트웨어 프로젝트의 기초입니다.

------

## DNA 시스템이란?

**정의**: 전체 시스템에 걸쳐 **"통일"**되어야 하는 횡단 관심사(Cross-Cutting Concerns)

- 언어, 프레임워크, 도메인에 관계없이 모든 프로젝트가 처음부터 끝까지 유지해야 하는 11가지 필수 시스템.

**특징**:

- 언어 무관 (개념/원칙 중심)
- 모두 필수 (선택 없음)
- 자동 강제 (지키지 않으면 빌드/실행 실패)
- 일관성 필수 (한 곳만 다르면 전체 혼란)

**왜 필요한가?**:

```
문서로 알려주기 → AI가 안 읽음/잊어버림
체크리스트 작성 → AI가 안 지킴
지시/설명 반복 → 매 세션마다 반복

✅ 해결: "환경"을 만들어서 잘못할 수 없게!
```

------

## 1. Type System (타입 시스템)

**목적**: 런타임 에러 방지, 타입 안전성 보장

**범위**:

- 모든 변수, 함수, 클래스의 타입 명시
- 타입 체커 통과 필수 (컴파일/빌드 단계)
- any/dynamic/var 금지 또는 엄격 제한
- 타입 불일치 = 실행 불가

**예시**:

- 간단: 함수 인자/리턴 타입 명시
- 중간: 제네릭, Union 타입, 도메인 모델
- 복잡: 타입 안전한 빌더 패턴, 의존성 주입

**언어별 구현**:

- Python: `mypy --strict`, Pydantic v2
- Rust: 기본 타입 시스템 (엄격함)
- TypeScript: `strict: true`, `noImplicitAny`
- Go: 기본 타입 시스템

**왜 필수인가?**: 타입 없으면 "이 변수가 문자열인지 숫자인지" 런타임에 폭탄. 리팩토링 시 어디가 깨졌는지 알 수 없음.

------

## 2. Observability System (관찰 가능성)

**목적**: 시스템 상태 관찰, 디버깅, 성능 모니터링

**범위**:

- **Logging** (구조화된 로깅)
  - JSON/구조화 형식
  - trace_id로 요청 추적
  - print/console.log 금지
  - 중앙 집중 설정
- **Metrics** (메트릭)
  - 성능 지표 수집 (응답 시간, 처리량)
  - 카운터, 게이지, 히스토그램
- **Tracing** (분산 추적)
  - 마이크로서비스 간 호출 추적
  - 요청 전체 흐름 시각화

**예시**:

- 간단:
  - 함수 진입/종료 로그
  - 에러 발생 로그
- 중간:
  - 구조화된 로깅 (structlog, winston)
  - trace_id 자동 전파
  - 기본 메트릭 수집
- 복잡:
  - OpenTelemetry 통합
  - 분산 추적 (Jaeger, Zipkin)
  - 실시간 대시보드 (Grafana)

**언어별 구현**:

- Python: structlog, OpenTelemetry
- Rust: tracing, tracing-subscriber
- TypeScript: winston, pino, OpenTelemetry
- Go: zap, zerolog, OpenTelemetry

**왜 필수인가?**: print() 남발하면 "무슨 에러인지" "어디서 느린지" 파악 불가능. 구조화된 로깅 없으면 디버깅 지옥.

------

## 3. Testing System (테스팅 시스템)

**목적**: 품질 보증, 회귀 방지, 안전한 리팩토링

**범위**:

- 테스트 우선 (TDD - Test-Driven Development)
- 95%+ 코드 커버리지 강제
- 단위 테스트 (Unit Tests)
- 통합 테스트 (Integration Tests)
- 속성 기반 테스트 (Property-Based Tests)
- 테스트 없이 커밋 불가

**예시**:

- 간단:
  - 함수 단위 테스트
  - 예상 입력/출력 검증
- 중간:
  - Given-When-Then 패턴
  - Mock/Stub 최소화
  - 통합 테스트
- 복잡:
  - Property-based testing (가설 검증)
  - Fuzz testing (무작위 입력)
  - Mutation testing (테스트의 테스트)

**언어별 구현**:

- Python: pytest, hypothesis, pytest-cov
- Rust: cargo test, proptest
- TypeScript: jest, vitest, fast-check
- Go: testing, rapid

**왜 필수인가?**: 테스트 없으면 "고쳤는지 망쳤는지" 알 수 없음. 리팩토링할 때마다 전체 수동 테스트 = 불가능.

------

## 4. Code Quality System (코드 품질)

**목적**: 일관된 스타일, 유지보수성, 자동화된 품질 보증

**범위**:

- **자동 포맷팅** (포맷터 강제 실행)
  - 들여쓰기, 줄바꿈, 공백 통일
- **린팅** (스타일 가이드 강제)
  - 경고 0개 달성
  - 나쁜 패턴 감지
- **TODO/FIXME/pass 금지**
  - 미완성 코드 커밋 차단
- **Pre-commit Hooks**
  - 커밋 전 자동 검사
  - 포맷/린트/타입 체크
- **CI 파이프라인**
  - 빌드 자동 검증
  - 테스트 자동 실행

**예시**:

- 간단:
  - 포맷터 실행 (black, prettier)
  - 기본 린트 (pylint, eslint)
- 중간:
  - pre-commit hooks
  - 복잡도 체크 (cyclomatic complexity)
  - import 정렬
- 복잡:
  - 중복 코드 감지 (jscpd)
  - 보안 린트 (bandit, semgrep)
  - CI/CD 파이프라인 통합

**언어별 구현**:

- Python: ruff, black, mypy, pre-commit
- Rust: cargo fmt, clippy
- TypeScript: prettier, eslint
- Go: gofmt, golangci-lint

**왜 필수인가?**: 스타일 제각각이면 코드 리뷰 시간 낭비. 나쁜 패턴 방치하면 기술 부채 폭발. TODO 남발하면 언제까지나 미완성.

------

## 5. Architecture Enforcement (아키텍처 강제)

**목적**: 아키텍처 경계 유지, 의존성 방향 제어

**범위**:

- **Layer 경계 검증**
  - Domain → Infrastructure 금지
  - Presentation → Domain만 허용
- **순환 의존성 금지**
  - 모듈 A → B → A 차단
- **Import 규칙 강제**
  - 허용된 import만 가능
  - 외부 라이브러리 제한
- **Architecture Tests**
  - 경계 위반 = 테스트 실패

**예시**:

- 간단:
  - 모듈 간 의존성 방향 정의
  - 순환 의존 체크
- 중간:
  - Layer 경계 강제 (Clean Architecture)
  - import-linter 규칙
- 복잡:
  - Architecture decision tests
  - 의존성 그래프 시각화
  - 자동 리팩토링 제안

**언어별 구현**:

- Python: import-linter, pytest (architecture tests)
- Rust: 모듈 시스템 + Architecture tests
- TypeScript: dependency-cruiser, madge
- Go: go-cleanarch, depguard

**왜 필수인가?**: 경계 없으면 스파게티 코드. Domain에서 DB 직접 접근하면 테스트 불가능. 순환 의존하면 리팩토링 지옥.

------

## 6. Configuration System (설정 관리)

**목적**: 환경별 설정 분리, 타입 안전, 민감 정보 보호

**범위**:

- **환경 변수 관리**
  - .env 파일 (dev, staging, prod)
  - 환경별 자동 로딩
- **타입 안전한 설정**
  - 설정 값 타입 검증
  - IDE 자동완성
- **하드코딩 금지**
  - 코드에 URL, 비밀번호 직접 작성 금지
- **의존성 관리** ⭐
  - 패키지 버전 통일
  - lock 파일로 고정
  - 라이센스 체크
  - 보안 취약점 스캔

**예시**:

- 간단:
  - .env 파일 + 환경 변수
  - requirements.txt, package.json
- 중간:
  - 타입 안전한 설정 클래스
  - pyproject.toml (uv), Cargo.toml
  - 의존성 lock 파일
- 복잡:
  - 환경별 설정 상속
  - Feature flags (런타임 토글)
  - 설정 검증 + 기본값
  - 의존성 자동 업데이트

**의존성 관리 도구**:

- Python: **uv** (pyproject.toml 하나로 통일) ⭐
- Rust: Cargo (Cargo.toml + Cargo.lock)
- TypeScript: pnpm (package.json + pnpm-lock.yaml)
- Go: go mod (go.mod + go.sum)

**왜 필수인가?**: 하드코딩하면 환경 바꿀 때마다 코드 수정. 타입 없으면 "PORT가 문자열인지 숫자인지" 런타임에 폭탄. 의존성 버전 안 맞으면 "내 컴퓨터에서는 되는데요?" 지옥.

------

## 7. Error Handling System (에러 처리)

**목적**: 에러 파악 및 복구, 디버깅 가능성

**범위**:

- **구조화된 에러**
  - 에러 타입 정의
  - 에러 컨텍스트 포함 (어디서, 왜, 무엇을)
- **panic/throw 제한**
  - 예외 처리 강제
  - 복구 불가능한 경우만 panic
- **Result/Either 패턴**
  - 명시적 에러 반환
  - 에러 전파 규칙
- **에러 로깅 통합**
  - 모든 에러를 Observability에 기록

**예시**:

- 간단:
  - try-catch + 의미 있는 에러 메시지
  - 에러 타입 구분 (ValueError, TypeError)
- 중간:
  - 커스텀 예외 클래스
  - 에러 체인 (원인 추적)
  - Result<T, E> 패턴
- 복잡:
  - 에러 복구 전략 (재시도, 폴백)
  - Circuit Breaker 패턴
  - 에러 집계 및 알림

**언어별 구현**:

- Python: 커스텀 예외 + Result 패턴 (라이브러리)
- Rust: Result<T, E> 강제, panic! 금지
- TypeScript: neverthrow, Either 패턴
- Go: error 타입 (기본), pkg/errors

**왜 필수인가?**: "Error: Something went wrong" → 무슨 에러인지 모름. 에러 컨텍스트 없으면 디버깅 불가능. panic하면 전체 프로그램 죽음.

------

## 8. Performance System (성능 측정)

**목적**: 객관적 성능 평가, 최적화 검증

**범위**:

- **벤치마크** (전체 성능 측정)
  - 함수/모듈별 실행 시간
  - 처리량 (throughput) 측정
  - 리팩토링 전후 비교
- **프로파일링** (병목 분석) ⭐
  - 함수별 실행 시간 분포
  - 메모리 할당 추적
  - CPU 사용량 분석
  - 핫스팟(느린 부분) 찾기
- **성능 회귀 감지**
  - 벤치마크 자동 실행
  - 이전 버전 대비 느려지면 실패

**예시**:

- 간단:
  - 함수 실행 시간 측정 (time.time())
  - 수동 비교
- 중간:
  - pytest-benchmark, Criterion
  - 통계적 벤치마크 (평균, p95, p99)
  - 프로파일링 스냅샷
- 복잡:
  - Instruments (macOS), perf (Linux)
  - 지속적 프로파일링 (production)
  - 성능 대시보드
  - 자동 회귀 감지

**프로파일링 도구**:

- Python: py-spy, cProfile, memory_profiler
- Rust: Instruments (macOS), perf, flamegraph
- TypeScript: clinic.js, 0x, Chrome DevTools
- Go: pprof (기본 내장)

**왜 필수인가?**: 리팩토링 후 "느려진 건지 빨라진 건지" 객관적 증거 없으면 논쟁. 병목 지점 모르면 "감으로" 최적화 = 시간 낭비.

------

## 9. API System (인터페이스/통신)

**목적**: 모듈/서비스 간 통신 규약 통일

**범위**: ⚠️ "API"를 좁게 생각하지 마세요!

- ✅ **외부 REST API** (서버)
- ✅ **내부 마이크로서비스 통신** (gRPC, 메시지 큐)
- ✅ **모듈 간 함수 호출 규약** (인터페이스)
- ✅ **라이브러리 public API** (pub fn, export)
- ✅ **CLI 명령어 인터페이스** (argparse, clap)

**모든 인터페이스/통신을 포함합니다!**

**예시**:

- 간단:
  - 함수 시그니처 정의
  - CLI 명령어 인터페이스
  - 모듈 간 호출 규약
- 중간:
  - 라이브러리 public API
  - 타입 안전한 인터페이스
  - API 문서 자동 생성
- 복잡:
  - REST API (FastAPI, Express)
  - GraphQL, gRPC
  - WebSocket 실시간 통신
  - OpenAPI 스펙 준수

**언어별 구현**:

- Python: FastAPI, pydantic (타입 검증), typer (CLI)
- Rust: axum, tonic (gRPC), clap (CLI)
- TypeScript: NestJS, tRPC, express
- Go: gin, gRPC, cobra (CLI)

**왜 필수인가?**: 인터페이스 통일 안 되면 "어떻게 호출하는지" 매번 확인. API 문서 없으면 "이 함수 뭐 하는 거지?" 코드 뒤져야 함. CLI 도구도 명령어 인터페이스 = API!

------

## 10. Data System (저장/조회)

**목적**: 데이터 영속성 및 접근 통일

**범위**: ⚠️ "대용량 데이터"만 생각하지 마세요!

- ✅ **일반 DB** (PostgreSQL, MySQL, SQLite)
- ✅ **파일 읽기/쓰기** (로컬, S3)
- ✅ **캐시** (Redis, 메모리)
- ✅ **대용량 처리** (ETL, Streaming, Batch)
- ✅ **메모리 관리** (Arena, 객체 풀링)

**모든 저장/조회를 포함합니다!**

**예시**:

- 간단:
  - 설정 파일 읽기/쓰기
  - 로컬 파일 저장
  - 히스토리 저장
- 중간:
  - PostgreSQL CRUD
  - Redis 캐싱
  - ORM (SQLAlchemy, TypeORM)
  - 연결 풀 관리
- 복잡:
  - ETL 파이프라인 (Airflow, dbt)
  - 실시간 스트리밍 (Kafka, Flink)
  - 데이터 웨어하우스 (Snowflake, BigQuery)
  - Arena 메모리 관리 (Kent Beck)

**언어별 구현**:

- Python: SQLAlchemy, Pydantic, polars (대용량)
- Rust: diesel, sqlx, Arena allocator
- TypeScript: Prisma, TypeORM, Drizzle
- Go: gorm, sqlx

**왜 필수인가?**: 저장 안 하는 프로그램? 거의 없음. (설정, 히스토리, 결과 등) DB 접근 통일 안 되면 "여기선 raw SQL, 저기선 ORM" 혼란. 메모리 관리도 Data System! (Kent Beck의 Arena)

------

## 11. Security System (보안)

**목적**: 보안 취약점 방지, 민감 정보 보호

**범위**:

- **민감 정보 관리**
  - API 키, 비밀번호 암호화 저장
  - 환경 변수 사용 (.env)
  - 코드에 하드코딩 금지
- **입력 검증** (Injection 방지)
  - SQL Injection 차단
  - XSS (Cross-Site Scripting) 방지
  - Command Injection 방지
  - Path Traversal 방지
- **인증/권한** (Authentication/Authorization)
  - 누가 접근하는가? (인증)
  - 무엇을 할 수 있는가? (권한)
  - JWT, OAuth2, RBAC
- **암호화**
  - 전송 중 (HTTPS, TLS)
  - 저장 중 (DB 암호화)
  - 비밀번호 해싱 (bcrypt, argon2)
- **보안 스캔**
  - SAST (정적 분석)
  - DAST (동적 분석)
  - 의존성 취약점 체크
- **보안 헤더**
  - CORS, CSP, HSTS 설정
- **Rate Limiting** (DDoS 방지)

**예시**:

- 간단:
  - .env에 비밀 저장 (코드 X)
  - 입력 검증 (SQL Injection 방지)
  - HTTPS 사용
- 중간:
  - JWT 인증
  - RBAC 권한 시스템
  - bcrypt 비밀번호 해싱
  - 보안 헤더 설정
  - 의존성 스캔 (npm audit)
- 복잡:
  - OAuth2/OIDC
  - 암호화 키 관리 (KMS)
  - 보안 스캔 자동화 (Snyk, OWASP ZAP)
  - 침입 탐지 시스템 (IDS)
  - 카오스 엔지니어링 (보안 테스트)

**언어별 구현**:

- Python: bandit (SAST), safety (의존성), cryptography
- Rust: cargo-audit, clippy (unsafe 체크), RustCrypto
- TypeScript: helmet (보안 헤더), npm audit, bcrypt
- Go: gosec, go-critic, crypto 패키지

**왜 필수인가?**: 보안 사고 1건 = 프로젝트 전체 신뢰 상실. 개인정보 유출 = 법적 책임 + 벌금. SQL Injection 하나로 DB 전체 탈취 가능. 모든 소프트웨어는 공격 대상.

------

## 📊 DNA 시스템 체크리스트

프로젝트 시작 시 **11개 모두** 체크:

```markdown
## DNA 시스템 11개 구축 (Stage 4-5)

### [ ] 1. Type System
- [ ] 타입 체커 설정
- [ ] strict mode 활성화
- [ ] any/dynamic 금지 규칙

### [ ] 2. Observability System
- [ ] 구조화된 로깅 설정
- [ ] trace_id 전파
- [ ] 메트릭 수집 (선택)

### [ ] 3. Testing System
- [ ] 테스트 프레임워크 설정
- [ ] 95% 커버리지 목표
- [ ] pre-commit hook (테스트 실행)

### [ ] 4. Code Quality System
- [ ] 포맷터 설정 + 자동 실행
- [ ] 린터 설정 + 경고 0개
- [ ] pre-commit hooks
- [ ] CI 파이프라인

### [ ] 5. Architecture Enforcement
- [ ] Layer 경계 정의
- [ ] import 규칙 설정
- [ ] Architecture tests

### [ ] 6. Configuration System
- [ ] .env 파일 설정
- [ ] 타입 안전한 설정 클래스
- [ ] 의존성 관리 도구 선택
- [ ] lock 파일 생성

### [ ] 7. Error Handling System
- [ ] 에러 타입 정의
- [ ] Result/Either 패턴
- [ ] 에러 로깅 통합

### [ ] 8. Performance System
- [ ] 벤치마크 설정
- [ ] 프로파일링 도구 설치
- [ ] 성능 회귀 체크

### [ ] 9. API System
- [ ] 인터페이스 정의
- [ ] API 문서 자동 생성 (선택)
- [ ] 타입 안전한 계약

### [ ] 10. Data System
- [ ] DB/파일 접근 계층 정의
- [ ] 연결 풀 설정
- [ ] 캐시 전략 (필요 시)

### [ ] 11. Security System
- [ ] 민감 정보 관리 (.env)
- [ ] 입력 검증 규칙
- [ ] 보안 스캔 설정
- [ ] 인증/권한 (API 있을 시)
```

------

## 🎯 Kent Beck 프로젝트 검증

Kent Beck의 BPlusTree 프로젝트에서 11개 DNA 모두 확인:

| DNA               | Kent Beck 구현                        | 검증 |
| ----------------- | ------------------------------------- | ---- |
| 1. Type           | Rust 타입 시스템 + strict             | ✅    |
| 2. Observability  | (명시적 로깅 없음)                    | ⚠️    |
| 3. Testing        | 95%+ 커버리지 + fuzz + property       | ✅    |
| 4. Code Quality   | cargo fmt + clippy + "Dead code dead" | ✅    |
| 5. Architecture   | Architecture tests                    | ✅    |
| 6. Configuration  | Cargo.toml + lock                     | ✅    |
| 7. Error Handling | Result<T,E> 강제, panic! 금지         | ✅    |
| 8. Performance    | Criterion + Instruments profiling     | ✅    |
| 9. API            | pub fn 인터페이스                     | ✅    |
| 10. Data          | Arena 메모리 관리                     | ✅    |
| 11. Security      | Memory safety, unsafe 감사            | ✅    |

**10/11개 명확히 구현!** (Observability는 라이브러리라서 최소화)



================================================================================
