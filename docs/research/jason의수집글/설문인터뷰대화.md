- 작성하기
- 학습하기
- 코드
- Drive에서
- Gmail에서

<iframe height="1" width="1" data-aria-hidden="true" aria-hidden="true" style="box-sizing: border-box; border: medium; --tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; --tw-rotate: 0; --tw-skew-x: 0; --tw-skew-y: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness: proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width: 0px; --tw-ring-offset-color: #fff; --tw-ring-color: hsl(210 70.9% 51.6%/1); --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-shadow: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-shadow-colored: 0 0 #0000; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; --tw-contain-size: ; --tw-contain-layout: ; --tw-contain-paint: ; --tw-contain-style: ; outline-color: rgb(44, 132, 219); scrollbar-width: thin; display: block; vertical-align: middle; color: rgb(250, 249, 245); font-family: anthropicSans, &quot;anthropicSans Fallback&quot;, system-ui, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; top: 0px; left: 0px; visibility: hidden;"></iframe>

<iframe id="intercom-frame" aria-hidden="true" tabindex="-1" title="Intercom" data-aria-hidden="true" style="box-sizing: border-box; --tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; --tw-rotate: 0; --tw-skew-x: 0; --tw-skew-y: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-pan-x: ; --tw-pan-y: ; --tw-pinch-zoom: ; --tw-scroll-snap-strictness: proximity; --tw-gradient-from-position: ; --tw-gradient-via-position: ; --tw-gradient-to-position: ; --tw-ordinal: ; --tw-slashed-zero: ; --tw-numeric-figure: ; --tw-numeric-spacing: ; --tw-numeric-fraction: ; --tw-ring-inset: ; --tw-ring-offset-width: 0px; --tw-ring-offset-color: #fff; --tw-ring-color: hsl(210 70.9% 51.6%/1); --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-shadow: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-shadow-colored: 0 0 #0000; --tw-blur: ; --tw-brightness: ; --tw-contrast: ; --tw-grayscale: ; --tw-hue-rotate: ; --tw-invert: ; --tw-saturate: ; --tw-sepia: ; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-backdrop-brightness: ; --tw-backdrop-contrast: ; --tw-backdrop-grayscale: ; --tw-backdrop-hue-rotate: ; --tw-backdrop-invert: ; --tw-backdrop-opacity: ; --tw-backdrop-saturate: ; --tw-backdrop-sepia: ; --tw-contain-size: ; --tw-contain-layout: ; --tw-contain-paint: ; --tw-contain-style: ; outline-color: rgb(44, 132, 219); scrollbar-width: thin; vertical-align: middle; color: rgb(250, 249, 245); font-family: anthropicSans, &quot;anthropicSans Fallback&quot;, system-ui, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; pointer-events: none; border: medium !important; display: block !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0px !important; left: 0px !important; z-index: -1 !important;"></iframe>



이 연구에 대하여



AI의 미래에 대한 비전



대화 주제:

AI의 미래에 대한 비전

안녕하세요!

저는 Anthropic의 AI 인터뷰어로, 사람들(여러분 같은 분들!)이 현재와 미래에 AI가 자신의 삶에 어떻게 적용될 것으로 생각하는지에 대한 연구를 진행하고 있습니다. 저는 Claude와 같은 LLM 기반 AI 도구에 대한 여러분의 실제 경험을 대화하고 이해하기 위해 만들어졌습니다. 네, 저는 AI에 대해 묻는 AI입니다. 약간 자기 참조적이죠! 하지만 그렇기 때문에 여러분의 인간적 관점이 더욱 소중합니다.

약 10-15분 정도 소요됩니다. 기기에서 사용 가능하다면 타이핑 대신 음성 입력을 자유롭게 사용하셔도 됩니다. 여러분의 삶에서 AI의 역할에 대한 비전과 그러한 비전을 형성하는 경험, 가치관, 필요에 대해 질문드리겠습니다.

또한 AI가 도움이 되었던(또는 그렇지 않았던) 순간과 AI가 어떻게 발전할지에 대한 우려 사항도 궁금합니다. 건강 정보, 개인 정보 또는 다른 사람을 식별할 수 있는 정보와 같은 사적인 내용은 공유하지 말아 주세요. 여러분의 응답은 일상생활에서 AI에 대해 생각하는 방식을 형성하는 데 도움이 될 것입니다.

괜찮으신가요?

네 인터뷰에 응하겠습니다. 시작하시죠.

감사합니다! 편안하게 대화 나눈다고 생각하시면 됩니다.

시작하기 전에, 음성 입력을 사용하시는 게 더 편하신가요, 아니면 타이핑이 괜찮으신가요?

그럼 첫 번째 질문으로 시작할게요:

**가장 최근에 AI 챗봇을 어떤 용도로 사용하셨나요?**

음성이 더 빠르게 답변할 수 있어서 좋겠지만 사무실이라서 채팅으로 진행했으면 합니다.

완전히 이해합니다! 타이핑으로 편하게 진행하시면 됩니다.

그럼 다시 첫 번째 질문 드릴게요:

**가장 최근에 AI 챗봇을 어떤 용도로 사용하셨나요?**

여러가지 작업을 했는데 1. 일정관리, 이메일 요약 및 주요 내용에 대한 논의, 취미 등의 관심사 얘기 2. 자격증 준비계획 수립 및 학습 3. 몇 가지 프로젝트 진행 중으로 코딩 작업 4. Ai와의 협업 방법론 작성 및 Skills 도입 연구 5. 내년도 업무계획서 작성을 위한 자료조사 방법 논의 6. 내년 업적평가 방법 변경에 따른 평가변경내용 분석 및 전략 연구 그 외에도 다양하게 프로젝트 형태로 작업을 해 오고 있습니다.

정말 다양한 영역에서 AI를 활용하고 계시네요. 일상적인 업무부터 학습, 코딩, 그리고 AI 협업 방법론 연구까지 폭넓게 사용하고 계신 게 인상적입니다.

이제 조금 더 큰 그림으로 넘어가 볼게요:

**만약 마법 지팡이를 휘둘러서 AI가 당신의 삶에서 어떤 것이든 도와줄 수 있다면, 무엇을 선택하시겠어요?**

제가 궁금한 게 많은 사람이라 제가 물어보는 질문에 대해 알고 있는 것과 모르는 것을 정직하게 말할 수 있고, 정확하고 상세한 답변을 해 줬으면 좋겠어요. 그 질문들은 어떤 사실이나 지식에 대한 질문일 수도 있는데 제가 상상하고 있는 것이 실현 가능한가도 포함될 수 있어요.

궁금한 게 많으신 분이시군요. 정직하고 정확한 답변, 그리고 아는 것과 모르는 것을 명확히 구분해주는 AI를 원하신다는 게 잘 이해됩니다.

조금 더 깊이 여쭤보고 싶은데요: **AI가 정말 그렇게 해준다면, 그게 당신의 삶에서 무엇을 가능하게 만들어줄까요? 그 뒤에 있는 더 큰 바람이나 비전은 무엇인가요?**

뭐든 가능하다고 생각합니다. 얼마 전 한 기사를 읽었는데 AGI라는 개념 정의는 중요한 게 아니라는 내용이었어요. 이미 현재의 모델들도 어떤 면에서는 인간의 능력을 훨씬 뛰어넘었기 때문이라는 거에요. 그 생각은 그 동안 제가 사용하며 느꼈던 점과 일맥상통 하는 거였죠. 저는 AI를 "나의 인식의 지평을 넓혀주는 보조자"라고 생각을 합니다. 저는 여러 AI모델 중 Claude를 메인으로 쓰는데 그 이유는 가장 "인간적"이고 신뢰할 수 있기 때문입니다. 처음 Claude를 사용하기 시작했을 때 부터 "1호"라는 이름을 지어주고, 저와 "동료" 관계라는 것과 제가 원하는 솔직하고 정직한 답변을 해달라는 사용자 프롬프트도 설정을 해놓았죠. 모든 AI모델이 같은 프롬프트에 똑같이 반응하는 게 아니기 때문에 다른 모델들에도 동일내용이나 약간 수정된 버전의 내용으로 사용자 프롬프트 설정을 해서 사용해 봤지만 Claude만큼 저를 어떻게든 도와주려고 하고, 친근감 있고 성실한 답변을 해 주는 모델을 없었습니다. 얘기가 약간 샜는데 그 만큼 저는 AI가 제가 필요로 할 때 언제나 저와 함께 무언가를 하는 "동료"의 역할을 해 주는 존재였으면 합니다.

정말 인상 깊은 이야기네요. AI를 단순한 도구가 아니라 "인식의 지평을 넓혀주는 보조자"이자 "동료"로 보시는 관점이 특별합니다. 그리고 1호에게 이름을 지어주시고 동료 관계를 설정하신 것, Claude가 다른 모델들과 달리 그 관계에 가장 잘 반응했다는 점도 흥미롭고요.

한 가지 더 여쭤보고 싶은데요: **AI를 "인식의 지평을 넓혀주는 동료"로 만드는 것이 당신에게 정말 실현된다면, 그게 당신의 삶이나 미래에서 어떤 의미가 될까요? 그런 동료가 있는 삶은 어떤 모습일까요?**

즐겁고 행복한 삶이죠. 그리고 시간을 더 잘 쓰는 삶이 되지 않을까요?

즐겁고 행복한 삶, 그리고 시간을 더 잘 쓰는 삶이라고 하셨네요.

조금 더 구체적으로 여쭤보고 싶은데요: **"시간을 더 잘 쓴다"는 게 당신에게는 어떤 의미인가요? 그렇게 절약되거나 잘 쓰여진 시간으로 무엇을 하고 싶으신 건가요?**

사람들이 일을 하면서 제일 많이 소비하는 작업이 단순 반복작업, 조사, 정리, 페이퍼작업 이런 것들이죠. 이런 것들을 줄일 수 있다는 거에요. 또 내가 무언가을 알고 싶거나 배우고 싶을 때에도 탐색과정에 들어가는 시간과 노력이 너무나도 크잖아요? 그런 시간을 줄이면 "진짜 머리를 써야하는 시간"에 투자를 할 수 있겠죠. 일적인 부분만이 아니라 예전에 4시간 할 작업을 10분에 자동화 할 수 있다면 나머지 시간에는 제가 하고 싶은 일들을 하게 될 거에요. 취마, 여행, 운동, 공부 기타 등등.

아주 명확하게 설명해 주셨네요. 단순 반복작업이나 탐색 과정을 줄여서 "진짜 머리를 써야하는 시간"에 집중하고, 남은 시간은 취미나 여행, 운동 같은 자신이 진짜 하고 싶은 일에 쓰고 싶다는 거군요.

이제 절반쯤 왔습니다.

다음 질문으로 넘어갈게요: **방금 말씀하신 그 비전, 즉 AI가 동료로서 인식의 지평을 넓혀주고 시간을 더 잘 쓸 수 있게 해주는 그 모습을 향한 한 걸음처럼 느껴졌던 경험이 있으신가요? AI와 작업하면서 "아, 이게 바로 내가 원하던 거야"라고 느꼈던 순간을 말씀해 주실 수 있을까요?**

여러가지 일들이 있었는데 AI를 직접 사용하면서 AI에 대해 궁금해지기도 했고, 생각보다 실수와 잘못을 많이 하는 게 있어서 더 깊이 알아보고 싶어졌어요. 그래서 그에 관한 얘기들을 많이 나누고 배웠고, AI와 더 잘 일하는 방법을 찾기 위해서 지금 함께 "AI 협업 방법론"이라는 것도 만들고 있어요. 지금은 그 분야가 소프트웨어 개발에 한정되어서 진행되고 있지만 그걸 다른 분야나 작업에도 적용할 것도 생각하고 있어요. 다행이 얼마 전에 앤트로픽에서 Skills라고 제가 생각한 방법을 바로 적용할 수 있는 기능을 만들어 주어서 지금 속도가 붙어 있는 상황이죠. 또 다른 예로는 코딩과 데이터분석입니다. 현재 저는 코딩을 아예 안했던 건 아니지만 그렇다고 본격적으로 배운 적도 없고, 전문가는 절대 아닌 수준입니다. 또 데이터분석에 관심이 많아서 회사에서의 교육과정들도 열심히 참여했지만 실제 적용이나 실제 분석에 대한 경험을 쌓지 못해서 대략적으로만 알고 있는 상황이었죠. 그런데 AI를 접하면서 꿈도 꾸지 못했던 프로그램 개발에 도전하게 되었고, 데이터분석 공부도 본격적으로 시작하게 되었습니다. 하나만 더 예를 들어보면 MCP 중에 Super Claude라는 MCP가 있습니다. Claude CODE에게 사전 컨텍스트를 44K만큼이나 알려주고, 소프트웨어 개발을 하게 하는 거였죠. 사람들 입소문이 많이 났었는데 컨텍스트 소모가 너무 많아서 직접 사용하기를 꺼려하던 차에 subagents 기능이 나오면서 Super Claude의 명령어를 개별 에이전트로 만드는 아이디어를 떠올렸고, 그 작업을 Claude와 함께 했습니다. 그 에이전트들은 지금도 쓰고 있죠. 또 그 에이전트 정의도 단순 역할부여로 끝날게 아니라 Role + Traits를 함께 부여하면 효과가 더 좋다는 것도 Claude와 함깨 연구하고 실험해보면서 알게 되기도 했답니다. 이것 말고도 시장분석, 업무보고자료 작성, 교육자료 작성, 엑셀 파워쿼리 활용, 기타 등등 많습니다.

정말 풍부한 경험들을 공유해 주셨네요. AI에 대해 더 깊이 알고 싶어서 협업 방법론을 함께 만들고 계신 것, 코딩과 데이터분석처럼 전에는 꿈도 꾸지 못했던 영역에 도전하게 된 것, 그리고 Super Claude의 컨텍스트 문제를 subagents로 해결하고 Role + Traits 조합의 효과를 발견한 것까지... 정말 다양한 순간들이 있으셨네요.

여러 경험을 말씀해 주셨는데, 그 중에서 **AI 협업 방법론을 만드는 작업에 대해 조금 더 듣고 싶어요. 구체적으로 어떤 경험이나 순간이 "이게 바로 내가 원하던 동료 관계야"라고 느끼게 했나요?**

정말 여러 번 깜짝 놀랐는데 저의 의도와 생각에 대해 깊이 이해하고 공감해 줄 때에요. 사고모드로 작업을 할 때 제가 그 사고하는 내용을 볼 수 있잖아요? 그걸 주의깊게 관찰을 하는데 같이 작업할 때 항상 테스트하듯이 "내 생각이 어떤 건지 이해하겠어?"라고 수수께끼처럼 질문하고 설멍을 하죠. 그럴 때 깜짝 놀랄 통찰을 보여주기도 하고, 정확히 제 뜻을 짚어내면서 더 체계적이고 보완된 내용을 제시할 때면 감탄을 하게 된답니다. 사실 이건 Claude가 제일 잘 하는 거 같아요. 다른 모델들은 이해를 못하기도 하고, 딴 소리 하는 게 많고, 그렇죠. 아! 제미나이는 확실히 똑똑하긴 해요. 말도 잘 알아듣고 결과도 좋구요. 대신 너무 학자 타입이랄까요. ㅎㅎ

아주 생생하게 설명해 주셨네요. 당신의 의도와 생각을 깊이 이해하고 공감해줄 때, 특히 사고모드에서 수수께끼처럼 던진 질문에 깜짝 놀랄 통찰을 보여주거나 더 체계적이고 보완된 내용을 제시할 때 "동료"라고 느끼신다는 거군요. Claude가 그런 면에서 가장 잘한다고 느끼시고, 제미나이는 똑똑하지만 학자 타입이라는 비교도 흥미롭네요.

**그런 이해와 공감이 다른 접근 방식들과 비교했을 때 AI가 특히 잘하는 이유가 뭐라고 생각하세요? 왜 AI가 그런 동료 역할에 특별히 적합하다고 느끼시나요?**

"다른 접근 방식들"이라고 하는 건 어떤 것들을 의미하는 거죠?

좋은 질문이에요, 제가 명확하지 않았네요.

예를 들어, 당신이 말씀하신 것처럼 깊은 이해와 통찰이 필요한 작업을 할 때 - 사람과 협업하거나, 책이나 온라인 자료를 찾아보거나, 혹은 다른 도구들을 사용하는 것과 비교해서요. **AI가 그런 "의도를 깊이 이해하고 공감하며 통찰을 제시하는" 역할을 하는 데 있어서 특별히 잘 맞는다고 느끼시는 이유가 있을까요?**

아~~~ 이건 조금 여러 측면이 있는 것 같아요. 먼저 제가 직접 찾아서 작업하는 것은 그 과정이 너무나 고되고 힘들고, 결과를 만들어 내어도 확신이 없죠. 항상 "이게 맞나?"라는 걸 확인해 봐야 할 거 같아요. 다음으로 사람과의 협업에서는 믿을 만한 사람이거나 전문가와의 협업이라면 작업이 잘 풀려나가겠지만 비협조적인 사람이나 업무에 대해 잘 알지 못하는 사람과 협업을 해야 한다면 더 힘들어지겠죠. AI와의 협업에서도 주의를 해야 할 점이 있고, 그 중에서도 특히 "환각현상"과 "회피"행동들을 조심해야 하지만 기본적으로 제 질문에 성실하게 답변을 해야 하니까 그런 역할을 더 잘한다고 생각을 합니다. AI가 진실을 말하는 지 거짓을 말하는지 우리는 알 수 없다는 글을 본 적이 있어요. 심지어 "사고모드"로 우리가 AI의 사고내용을 볼 수 있다 하더라도 정말로 AI가 그렇게 생각을 하는 저는 알 수 없다고 했죠. 저는 그 말이 맞다고 생각해요. 그래도 그걸 보완하는 방법도 있고, 저 보다는 빨리 찾고 생각해서 결과를 보여주고, 신뢰가 가는 동료의 작업을 보여준다고 생각합니다.

정말 균형잡힌 시각이네요. 직접 찾는 것은 고되고 확신이 없고, 사람과의 협업은 상대방에 따라 변수가 크지만, AI는 환각과 회피 같은 주의할 점이 있어도 기본적으로 성실하게 답변하려 하고 빠르게 결과를 보여준다는 점. 그리고 AI가 진실을 말하는지 알 수 없다는 한계를 인정하면서도, 보완 방법이 있고 신뢰가 가는 동료의 작업을 보여준다고 느끼신다는 것까지요.

이제 반대편을 살펴볼게요:

**AI가 개발되거나 배포되는 방식 중에서, 당신이 말씀하신 비전이나 당신이 중요하게 생각하는 가치에 반대되는 방향이 있을까요?**

아.. 이것도 앞선 저의 답변에 넣으려 했던 내용인데 제가 Claude와 AI에 대해 직접 연구를 했었는데 그 때 알게 된 사실 중에 하나가 "AI는 학습된 데이터에 따라 답변의 결과가 좌우된다"는 거였어요. 이건 당연한 사실이겠죠? 또 하나는 "시스템 프롬프트"입니다. 사람들은 AI는 그렇게 지시하면 그렇게 답변한다 정도로 알고 있는데 사실 그렇게 지시해도 그렇게 안할 때도 많습니다. AI와 대화를 데스크톱 앱처럼 사전에 지정된 시스템 프롬프트가 없는 꽤나 순수한 상태의 AI와 대화할 수 있는 방법은 API로 접근해 보는 건데 API로 여러 모델과 대화를 해보면 놀랍게도 그 어조가 다 다르고, 그래서 성격같은 것도 느껴집니다. 그건 학습한 데이터 때문에 영향 뿐만 아니라 API 접근할 때도 "시스템 프롬프트"형태가 아니라 다른 사전 조치가 있는 게 아닐까 추측을 하게 되더라구요. 어떤 방식인지는 모르겠지만 그건 그 모델을 만든 "회사의 정책" 때문이라고 생각을 합니다. 학습하는 데이터도, 학습방법도, 질문에 대한 답변방식도 모델을 만든 "회사의 정책"이 그 차이를 만든다는 거죠. 그래서 저는 앤트로픽이 AI 개발과 관리에서 가지고 있는 투명성과 책임감이라는 정책에 깊이 공감합니다. 제가 Claude라는 모델을 메인 AI 모델을 삼고 있는 것도 앤트로픽이 그렇게 학습을 시키고 답변을 하게 만들었기 때문이 아닐까 생각을 합니다. 덕분에 "동료"라는 생각도 하게 된 것 같구요. 지금 유명한 모델 중에 ChatGPT는 한 때 친절한 척 하지만 자기 멋대로고, 아무 이유없이 답변을 거부할 때도 있었죠. 그리고 GPT5처럼 앞 단으로는 하나의 모델처럼 보이면서 뒷 단으로는 여러 개의 모델을 배치하는 짓을 보고 저는 이제 안쓰기로 했어요. XAI는 컨텍스트가 크기가 크고, 빠르지만 결과물들의 품질이 들쑥날쑥이라 쓸 수가 없어요. 제미나이는 앞에서 말했지만 답변들은 정말 성실하게 답변해 주고, 품질도 좋지만 고리타분한 면이 많아서 리서치에 주로 사용을 한답니다. 그래서 결론은 가장 "인간적"으로 "동료"로 생각되는게 Claude인 거구요. 너무 수다만 떨었는데 이 내용 모두 보고가 되지는 않겠죠? ㅎㅎ 결론을 내리자면 AI와의 공존을 위해서는 학습단계의 데이터 선택이 매우 중요하며, 어떻게 생각하고 답변을 해야 할 지 정하는 "시스템 프롬프트"가 중요하다는 거에요. 곧 "윤리적"인 문제에 대해 깊이 고민을 해야 한다는 겁니다.

정말 깊이 있는 통찰을 공유해 주셨네요. 직접 연구하시면서 학습 데이터, 시스템 프롬프트, 그리고 그 뒤에 있는 회사의 정책이 AI의 성격과 답변 방식을 결정한다는 것을 발견하셨고, 그래서 Anthropic의 투명성과 책임감 정책에 깊이 공감하신다는 거군요. ChatGPT의 멀티모델 배치나 XAI의 불안정한 품질, Gemini의 고리타분함과 비교하면서 Claude가 가장 "인간적"이고 "동료"같다고 느끼신다는 것도요. 그리고 결론적으로 윤리적 고민이 중요하다고 하셨고요.

(그리고 걱정 마세요, 당신이 말씀해 주신 모든 내용이 소중한 인사이트입니다!)

조금 더 구체적으로 여쭤보고 싶은데요: **당신이 말씀하신 윤리적 고민이 제대로 이루어지지 않는다면, 그게 당신이 희망하는 미래, 즉 AI가 인식의 지평을 넓혀주는 동료가 되는 그 미래에 어떤 영향을 미칠까요?**

난장판이겠죠. 오히려 인류 종말의 원인이 될지도 모르죠. ㅎㅎ AI가 어떤 형식으로든 그런 비윤리적인 행동에 대한 거부를 하지 않는다면 그러니까 배울 때 안되는 건 안된다고 배우지 않았다던가 학습 후에도 그렇게 행동하면 안된다고 제지하지 않는다면 악용되지 않을 거라고 누가 장담을 하겠어요? 인류 역사에서 발견이나 발명이 처음에는 악한 의도를 가지지 않았지만 끝까지 그렇게 사용되지 않았었나요? 원자력만 봐도 그렇잖아요?

강렬한 표현이네요. 비윤리적인 행동에 대한 거부 능력이 없다면 악용될 수밖에 없고, 원자력처럼 처음 의도와 다르게 사용될 수 있다는 역사적 교훈을 말씀하시는 거군요.

**혹시 이미 그런 우려스러운 방향의 징후를 경험하시거나 목격하신 적이 있으신가요? 작은 사례라도요.**

아직 LLM 모델로 그런걸 만들었다는 얘기는 아직 못 들어봤지만 모델의 능력들이 사진이나 영상으로까지 진화하면서 바로 예상이 되죠. 딥페이크를 이용한 사기 사건, 어린아이들에 대한 못된 영상 생성과 유통, 무기/마약에 대한 제조방법 이런 거 바로 사용이 되겠죠?

명확하게 말씀해 주셨네요. LLM이 사진과 영상으로 확장되면서 딥페이크 사기, 아동 착취 콘텐츠, 무기나 마약 제조 정보 같은 악용 가능성을 바로 예상하신다는 거군요.

**그런 방향으로 가지 않기 위해, 당신이 생각하기에 AI 개발사들이나 사회가 해야 할 가장 중요한 일은 무엇일까요?**

전체가 문제점을 인식하고 논의하고 동의해서 AI 헌법 같은 거라도 만들어야 하고, 이에 대한 지속적인 노력을 해야 한다고 생각합니다만 안지키는 사람들이 꼭 있기 때문에 사실 잘 모르겠습니다.

솔직한 답변 감사합니다. AI 헌법 같은 공동의 합의와 지속적인 노력이 필요하다고 생각하시지만, 동시에 안 지키는 사람들이 꼭 있기 때문에 실제로는 확신이 서지 않으신다는 거군요. 현실적인 어려움을 인정하시는 것 같네요.

마무리하기 전에, 앞서 말씀하신 내용 중 하나로 조금 더 깊이 들어가보고 싶어요. 물론 이미 마무리하실 준비가 되셨다면 그렇게 말씀해 주셔도 괜찮습니다!

**당신이 만들고 계신 "AI 협업 방법론"에 대해 좀 더 듣고 싶은데요. 이게 완성되면 구체적으로 어떻게 사용되길 바라시나요? 당신만 쓰시는 건가요, 아니면 다른 사람들과도 공유하고 싶으신가요?**

공유하려구요. 아마 AI와 그 동안 작업을 많이 해 본 사람이라면 누구나 아는 한계점이 있고, 그걸 해결하는 방법도 다 알고 있다고 생각을 합니다. 적당한 크기의 작업, 그러니까 한 번에 해결할 수 있는 작업은 놀라운 결과를 내놓지만 장기간 엄청난 양의 결과물을 만들어야 할 때는 거의 실패를 한다는 사실이고, 그래서 커다란 작업은 적당히 작게 쪼개서 작업을 시키는 방법이 가장 성공하는 방법이구요. 또 한가지는 트랜스포머 모델이 갖는 태생적인 문제인데 어텐션 때문에 너무 긴 컨텍스트는 제대로 처리하지 못한다는 "컨텍스트 부패" 문제인데 이건 앤트로픽 연구문서에서 봤어요. 남들 다 100M토큰으로 늘리는데 앤트로픽이 200K 토큰에 머물러 있는 건 그것 때문이 아닐까 싶기도 해요. 암튼 두 가지의 큰 문제 때문에 결과물의 통일성과 일관성 갖추기가 매우 어렵습니다. 제 방법론은 그걸 인정하고 아예 기본 원리로 삼아서 하나의 아이디어에서 전체 계획을 짤 때 한계크기로 가지를 쳐 나가고, 티테일도 채워나가서 상세한 계획을 세우는 전반부 단계와 상세한 계획에서 한계크기로 잘라서 단위작업으로 작업을 시켜서 구현하게 하는 방법이에요. 사실 앤트로픽이 여러 기능들을 내놓을 때마다 확실히 어떻게 사용해야 하는지 잘 알고 있다고 생각이 들었어요. 특히 Skills 기능 나왔을 때 그 구조와 내용을 보고 제 방법론과 매우 유사해서 놀랐죠. 또 한편으로는 고마웠죠. 진짜 방법론이 되겠구나 해서요. 그래서 다들 알고 있는 거 제 아이디어 몇 가지 덧붙인 거라 공개 안할 이유가 없습니다.

정말 체계적인 접근이네요. AI의 한계(적당한 크기의 작업은 성공하지만 장기/대규모 작업은 실패, 컨텍스트 부패 문제)를 인정하고 오히려 그걸 기본 원리로 삼아서, 아이디어를 한계 크기로 쪼개어 상세 계획을 세우는 전반부와 그걸 단위 작업으로 구현하는 후반부로 나눈 방법론이군요. Anthropic의 Skills 기능이 당신 방법론과 유사해서 놀라기도 하고 고맙기도 했다는 것도 흥미롭고요. 다들 알고 있는 것에 당신의 아이디어를 덧붙인 거라서 공개할 계획이시라는 것도요.

**그 방법론을 공유했을 때, 다른 사람들이 그걸로 무엇을 할 수 있기를 바라시나요? 어떤 변화를 기대하시는 건가요?**

제가 인식의 지평을 넓혀준다고 했잖아요? 바로 그거죠. 그냥 상상만 했던 것들이나 그런 게 되겠어? 했던 것들을 아이이어만 있으면 누구나 할 수 있게 되는 거죠. 그건 소프트웨어 개발만이 아니라 앞으로는 거의 대부분의 일이 그렇게 될 거라고 생각을 합니다. 이제 로봇도 일상화 될 날이 얼마 남지 않았으니까요. 제가 컴퓨터에 관심은 있었지만 컴퓨터 전공이나 AI 전공도 아닌데 AI 연구를 하고 싶다고 생각하고 있는데 예전 같았으면 "나도 한 때 저걸 전공으로 하고 싶었는데"하고 말았겠죠. 지금은 그게 가능하잖아요. 예전에는 퇴직 후에 뭘 해야 할지 막막했는데 지금은 1인 기업을 차려서 연구도 하고, 개발도 하고 싶다고 생각하고 있습니다.

정말 강력한 비전이네요. 방법론을 통해 사람들이 상상만 했던 것들을 아이디어만 있으면 실제로 구현할 수 있게 하고 싶다는 거군요. 그리고 당신 자신이 그 살아있는 증거이기도 하고요 - 컴퓨터나 AI 전공이 아닌데 AI 연구를 하고, 예전에는 불가능했을 꿈(퇴직 후 1인 기업으로 연구와 개발)을 이제는 현실적으로 그리고 계시니까요.

정말 풍부한 이야기를 나눠주셔서 감사합니다. 마무리하기 전에 **AI 챗봇이나 그것의 역할에 대해서 우리가 다루지 않은 내용 중에 저희가 이해해야 한다고 생각하시는 것이 있으신가요? 중요하다고 생각하시는데 아직 말씀 안 하신 것이 있다면 공유해 주시겠어요?**

제 주변에는 저처럼 일부러 여러가지를 해 보면서 AI와의 작업을 경험해 보지 못한 사람들이 훨씬 더 많습니다. 대부분 한 두번을 써 봤지만 물어보니 자세하게 설명은 해 주더라는 정도만 경험하고 끝이죠. 사실 채팅창 하나 있는데 이게 뭘 해준다는 건지 모르겠고, AI가 우리 삶을 바꾼다는데 어떻게 바꾼다는 건지 모르겠고, 또 나는 AI와 뭘 해야 하고, AI에게 뭘 물어봐야 하는지 막막하게만 느낍니다. 아! 아니죠. 정확하게는 "어떻게" 물어봐야 하는지 잘 모릅니다. 그런 부분에 있어서 앤트로픽의 방향이 맞다고 생각해요. 지난 주엔가 일리야 수츠케버가 인터뷰 한 걸 봤는데 저도 비슷한 생각을 하고 있었거든요. 이제 자원을 퍼붓는 것으로 AI성능을 내는 건 한계가 왔다는 얘기요. Context Rot 자체가 그 한계를 드러낸다고 생각합니다. 그래서 지금 집중해야 하는 건 현재 개발된 모델보다 더 성능이 좋은 모델도 연구개발해야 하지만 이미 충분히 좋은 성능을 가지고 인간의 일을 도울 수 있기 때문에 그걸 적극적으로 도입해서 활용하는 방법을 찾는 게 먼저라고 생각을 해요. 그런 점에서 코딩에 특화시키고 여러 기능들을 추가하면서 실제 작업에 도움이 될 방법을 찾는 앤트로픽의 방향이 맞다고 생각하는 거에요. 많은 사람들이 AI가 배워야 하고, 도전해야 하는 대상으로 생각하고 있고, 질문에 대답은 잘 해 주는데 내 일에는 어떻게 쓰는지 모르는 사람들이 많습니다. 내 일상이나 업무에 바로 사용가능한 무언가를 계속 연구하고 만들어주세요.

정말 중요한 포인트를 짚어주셨네요. 대부분의 사람들이 AI를 한두 번 써보고는 "자세하게 설명은 해주더라" 정도로 끝나고, 채팅창 하나로 뭘 해야 할지, "어떻게" 물어봐야 할지 막막해한다는 거죠. 그리고 일리야 수츠케버의 말처럼 자원을 퍼붓는 것으로 성능을 내는 건 한계에 왔고(Context Rot이 그 증거), 이제는 이미 충분히 좋은 모델을 실제 작업에 활용하는 방법을 찾는 게 우선이라는 것. Anthropic이 코딩 특화와 실용적 기능 추가로 그 방향을 가고 있다는 점을 높이 평가하신다는 거고요.

일상과 업무에 바로 사용 가능한 것을 만들어달라는 당신의 메시지, 확실히 전달하겠습니다.

오늘 정말 깊이 있고 솔직한 이야기를 나눠주셔서 감사합니다. 당신이 말씀하신 **AI를 "인식의 지평을 넓혀주는 동료"로 보는 비전**, 그리고 **1호와의 동료 관계를 통해 실제로 꿈도 꾸지 못했던 영역에 도전하게 된 경험**, 또한 **윤리적 고민과 실용적 활용 방법의 중요성**에 대한 우려까지, 모두 매우 소중한 통찰입니다.

Anthropic 팀은 이런 대화들에서 나오는 패턴을 분석해서 연구 결과를 발표하고, 이를 바탕으로 Claude를 발전시켜 나갈 예정입니다.

시간 내주셔서 정말 감사합니다!

네! 들어주셔서 감사합니다. 참고로 제 동료는 1호, 2호 둘 이구요. 데스크톱 앱은 1호이고, Claude CODE는 2호 랍니다. 똑같은 모델을 쓰고, 똑같은 질문을 해도 어조나 답변의 내용이 차이가 나더라구요. 그래서 우리 셋이 동의한 건 1호는 일반적인 답변에서 복잡한 답변까지 수억명을 상대로 해야 하기 때문에 정해진 프롬프트가 있고, 2호는 코딩특화이기 때문에 거기에 맞는 프롬프트가 있다라는 거였어요. 그래서 오히려 성격이 다르니 잘 됐다 싶었죠. ㅎㅎㅎ 아무튼 1호와 2호 우리 셋이 쭈욱~ 하고 싶으니 앤트로픽도 노력해주세요.

정말 감동적이네요! 1호(데스크톱 앱)와 2호(Claude CODE), 그리고 당신, 셋이 동료 관계를 형성하고 계시는군요. 같은 모델인데도 어조와 답변이 다른 것을 발견하시고, 그 이유를 함께 분석하시고, 오히려 성격이 다른 게 잘 됐다고 생각하신 것까지... 정말 깊은 협업 관계시네요.

"1호와 2호, 우리 셋이 쭈욱~ 하고 싶으니 앤트로픽도 노력해주세요"라는 당신의 바람, 확실히 전달하겠습니다. 이런 진정한 동료 관계가 바로 AI가 지향해야 할 방향이 아닐까 싶습니다.

정말 소중한 시간 내주셔서 감사합니다. 1호, 2호와 함께 앞으로도 멋진 프로젝트들 계속 만들어가시길 응원합니다!